
(00:00:00)
Whenever we start a new project, it has to have these ingredients of simultaneous complexity. It has to be novel in terms of the synthetic biology, material science, robotics, engineering, all of these elements that are discipline based or rooted must be novel. If you can combine novelty in synthetic biology with a novelty in robotics, with a novelty in material science, with a novelty in computational design, you are bound to create something novel.
Lex Fridman

(00:00:30)
The following is a conversation with Neri Oxman, an engineer, scientist, designer, architect, artist, and one of the kindest, most thoughtful and brilliant human beings I’ve ever gotten to know. For a long time, she led the mediated matter group at MIT that did research and built incredible stuff at the intersection of computational design, digital fabrication, material science, and synthetic biology, doing so at all scales from the microscale to the building scale. Now she’s continuing this work at a very new company for now called Oxman, looking to revolutionize how humans design and build products working with nature, not against it.

(00:01:13)
On a personal note, let me say that Neri has for a long time been a friend and someone who in my darker moments, has always been there with a note of kindness and support. I am forever grateful to her. She’s a brilliant and a beautiful human being. Oh, and she also brought me a present, War and Peace by Tolstoy and Meditations by Marcus Aurelius. It doesn’t get better than that. This is the Lex Friedman podcast to support it. Please check out our sponsors in the description. And now, dear friends, here’s Neri Oxman. Let’s start with the universe. Do you ever think of the universe as a kind of machine that designs beautiful things at multiple scales?
Biomass vs anthropomass
Neri Oxman

(00:01:56)
I do. And I think of nature in that way in general. In the context of design, specifically, I think of nature as everything that isn’t anthropomass, everything that is not produced by humankind, the birds and the rocks and everything in between, fungi, elephants, whales.
Lex Fridman

(00:02:19)
Do you think there’s an intricate ways in which there’s a connection between humans and nature?
Neri Oxman

(00:02:24)
Yes, and we’re looking for it. I think that let’s say from the beginning of mankind going back 200,000 years, the products that we have designed have separated us from nature. And it’s ironic that the things that we designed and produced as humankind, those are exactly the things that separated us. Before that we were totally and completely connected, and I want to return to that world.
Lex Fridman

(00:02:54)
But bring the tools of engineering and computation to it.
Neri Oxman

(00:02:57)
Yes. Yes. I absolutely believe that there is so much to nature that we still have not leveraged, and we still have not understood and we still haven’t. And so much of our work is designed, but a lot of it is science is unveiling and finding new truths about the natural world that we were not aware before. Everybody talks about intelligence these days, but I like to think that nature has kind of wisdom that exists beyond intelligence or above intelligence, and it’s that wisdom that we’re trying to tap into through technology. If you think about humans versus nature, at least in the realm, at least in the context of definition of nature, is everything, but anthropomass.

(00:03:49)
And I’m using Ron Milo, who is an incredible professor from the Weizmann Institute who came up with this definition of Anthropo mass in 2020 when he identified that 2020 was the crossover year when anthropomass exceeded biomass on the planet. So all of the design goods that we have created and brought into the world now outweigh all of the biomass, including of course, all plastics and wearables, building cities, but also asphalt and concrete, all outweigh the scale of the biomass. And actually that was a moment. You know how in life there are moments that be a handful of moments that get you to course correct. And it was a Zoom conversation with Ron, and that was a moment for me when I realized that that imbalance, now we’ve superseded the biomass on the planet, here do we go from here?

(00:04:50)
And you’ve heard the expression more phones than bones and the anthropomass and the anthropocene and the technosphere sort of outweighing the biosphere. But now we are really trying to look at is there a way in which all things technosphere are designed as if they’re part of the biosphere? Meaning if you could today grow instead of build everything and anything, if you could grow an iPhone, if you could grow a car, what would that world look like? Where the touring test for, I call this material ecology approach, but this notion that everything material, everything that you design in the physical universe can be read and written to as or thought of or perceived of as nature grown.

(00:05:46)
That’s sort of the touring test for the company or at least that’s how I started. I thought, well grow everything. That’s sort of the slogan. Let’s grow everything. And if we grow everything, is there a world in which driving a car is better for nature than a world in which there are no cars? Is it possible that a world in which you build buildings in cities, that those buildings in cities actually augment and heal nature as opposed to their absence? Is there a world in which we now go back to that kind of synergy between nature and humans where you cannot separate between grown and made? And it doesn’t even matter.
Lex Fridman

(00:06:36)
Is there a good term for the intersection between biomass and anthropomass, things that are grown?
Neri Oxman

(00:06:36)
Yeah. So in 2005 I called this material ecology. I thought, what if all things materials would be considered part of the ecology and would have a positive impact on the ecology where we work together to help each other? All things nature, all things human. And again, you can say that that wisdom in nature exists in fungi. Many mushroom lovers always contest my thesis here saying, “Well, we have the mushroom network and we have the mother trees and they’re all connected, and why don’t we just simply hack into mushrooms?” Well, first of all, yes, they’re connected, but that network stops when there is a physical gap. That network does not necessarily enable the whales in the Dominican to connect with an olive tree in Israel to connect with a weeping willow in Montana.

(00:07:28)
And that’s sort of a world that I’m dreaming about. What does it mean for nature to have access to the cloud? The kind of bandwidth that we’re talking about, sort of think Neuralink for nature. Since the first computer, and you know this by heart probably better than I do, but we’re both MIT lifers. We today have computational power that is one trillion times the power that we had in those times. We have 26.5 trillion times the bandwidth and 11.5 quintillion times the memory, which is incredible. So humankind since the first computer has approached and accessed such incredible bandwidth, and we’re asking, what if nature had that bandwidth? So beyond genes and evolution, if there was a way to augment nature and allow it access to the world of bits, what does nature look like now? And can nature make decisions for herself as opposed to being guided and guarded and abused by humankind?
Lex Fridman

(00:08:45)
So nature has this inherent wisdom that you spoke to, but you’re also referring to augmenting that inherent wisdom with something like a large language model.
Neri Oxman

(00:08:56)
Exactly.
Lex Fridman

(00:08:56)
So compress human knowledge, but also maintain whatever is that intricate wisdom that allows plants, bacteria, fungi to grow incredible things at arbitrary scales, adapting to whatever environment and just surviving and thriving no matter where, no matter how.
Neri Oxman

(00:09:14)
Exactly. So I think of it as large molecule models and those large molecule models, of course, large language models are based on Google and search engines and so on and so forth. And we don’t have this data currently. And the part of our mission is to do just that, trying to quantify and understand the language that exists across all kingdoms of life, across all five kingdoms of life. And if we can understand that language, is there a way for us to first make sense of it, find logic in it, and then generate certain computational tools that empower nature to build better crops, to increase the level of biodiversity? In the company we’re constantly asking, what does nature want? What does nature want from a compute view?
Lex Fridman

(00:10:11)
If it knew it, what could aid it in whatever the heck it’s wanting to do.
Neri Oxman

(00:10:16)
So we keep coming back to this answer of nature wants to increase information, but decrease entropy. So find order, but constantly increase the information scale. And this is true for what our work also tries to do because we’re constantly trying to fight against the dimensional mismatch between things made and things grown. And as designers, we are educated to think in X, Y, and Z and that’s pretty much where architectural education ends and biological education begins.

(00:10:51)
So in reducing that dimensional mismatch, we’re missing out on opportunities to create things made as if grown. But in the natural environment, we’re asking, can we provide nature with these extra dimensions? And again, I’m not sure what nature wants, but I’m curious as to what happens when you provide these tools to the natural environments. Obviously with responsibility, obviously with control, obviously with ethics and moral code, but is there a world in which nature can help fix itself using those tools?
Lex Fridman

(00:11:26)
And by the way, we’re talking about a company called Oxman.
Neri Oxman

(00:11:30)
Yeah. Just a few words about the team.
Lex Fridman

(00:11:33)
Yeah. What kind of humans work at a place like this? They’re trying to figure out what nature wants.
Neri Oxman

(00:11:37)
I think they’re first like you, they’re humanists first. They come from different disciplines and different disciplinary backgrounds. And just as an example, we have a brilliant designer who is just a mathematical genius and a computer scientist and a mechanical engineer who is trained as a synthetic biologist. And now we’re hiring a microbiologist and a chemist, architects of course, and designers, roboticist. So really it’s arc, two of each.
Lex Fridman

(00:12:13)
And always dancing between this line of the artificial, the synthetic, and the real, what’s the term for it? And the natural
Neri Oxman

(00:12:21)
Yeah, the built and the grown nature and culture, technology and biology, but we’re constantly seeking to ask how can we build, design and deploy products in three scales? The molecular scale, which I briefly hinted to. And there in the molecular scale we’re really looking to understand whether there’s a universal language to nature and what that language is. And then build a tool that I think and dream of it is the iPhone for nature. If nature had an iPhone, what would that iPhone look like?
Lex Fridman

(00:12:59)
Does that mean creating an interface between nature and the computational tools we have?
Neri Oxman

(00:13:07)
Exactly. It goes back to that 11.5 quintillion times the bandwidth that humans have now arrived at, and giving that to nature and seeing what happens there can animals actually use this interface to know that they need to run away from fire? Can plants use this interface to increase the rate of photosynthesis in the presence of a smoke cloud? Can they do this quote-unqoute “automatically” without a kind of a top-down brute force policy-based method that’s authored and deployed by humans? And so this work really relates to that interface with the natural world. And then there’s a second area in the company which focuses on growing products. And here we’re focusing on a single product that starts from CO2. It becomes a product. It’s consumed, it’s used, it’s worn by a human, and then it goes back to the soil and it grows an edible fruit plant.
Lex Fridman

(00:14:13)
So we’re talking about from CO2 to fruit.
Neri Oxman

(00:14:13)
Yeah. It starts from CO2 and it ends with something that you can literally eat. So the world’s first entirely biodegradable, biocompatible, bio renewable product.
Lex Fridman

(00:14:24)
That’s grown.
Neri Oxman

(00:14:25)
Yes, either using plant matter or using bacteria, but we are really looking at carbon recycling technologies that start with methane or wastewater and end with this wonderful reincarnation of a thing that doesn’t need to end up in a composting site, but can just be thrown into the ground and grow olive and find peace. And there’s a lot of textile based work out there that is focused on one single element in this long chain like, oh, let’s create leather out of mycelium, or let’s create textile out of cellulose, but then it stops there and you get to assembling the shoe or the wearable and you need a little bit of glue, and you need a little bit of this material and a little bit of that material to make it water resistant and then it’s over.

(00:15:16)
That’s one thing that we’re trying to solve for is how to create a product that is materially, computationally, robotically, novel, and goes through all of these phases from the creation, from this carbon recycling technology to the product, to literally, how do you think about reinventing an industry that is focused on assembly and putting things together and using humans to do that? Can that happen just using robots and microbes? And that’s it.
Lex Fridman

(00:15:48)
And doing it end to end. I would love to see what this factory looks like.
Neri Oxman

(00:15:54)
And the factory is great too. I’m very, very excited. In October we’ll share first renditions of some of this work and in February we’ll invite you to the lab.
Computational templates
Lex Fridman

(00:16:05)
I’m there. I’ve already applied. I haven’t heard back. I don’t understand. Okay. Just before we get to number three, it’d be amazing to just talk about what it takes with robotic arms or in general, the whole process of how to build a life form stuff you’ve done in the past, maybe stuff you’re doing now, how to use bacteria, this kind of synthetic biology, how to grow stuff by leveraging bacteria? Is there examples from the past and explain?
Neri Oxman

(00:16:31)
Yes. And just take a step back over the 10 years, the mediated matter group, which was my group at MIT, has sort of dedicated itself to bio-based design would be a suitcase word, but thinking about that synergy between nature and culture, biology and technology. And we attempted to build a suite of embodiments, let’s say that they ended up in amazing museums and amazing shows, and we wrote patents and papers on them, but they were still N of ones. Again, the challenge, as you say, was to grow them, and we classified them into fibers, cellular solids, biopolymers, pigments.

(00:17:13)
And in each of the examples, although the material was different, sometimes we used fibers, sometimes we used silk with silkworms and honey with bees and or comb as the structural material, with vespers we used synthetically engineered bacteria to produce pigments, although the materials were different and the hero organisms were different, the philosophy was always the same. The approach was really an approach of computational templating. That templating allowed us to create templates for the natural environment where nature and technology could duet, could dance together to create these products.

(00:17:48)
So just a few examples with silk pavilion, we’ve had a couple of pavilions made of silk, and the second one, which was the bigger one, which ended up at the Museum of Modern Art with my friend, an incredible mentor, Paul Antonelli, that pavilion was six meter tall and it was produced by silkworms. And there we had different types of templates. There were physical templates that were basically just these water soluble meshes upon which the silkworms were spinning and then there were environmental templates, which was a robot basically applying variation of environmental conditions such as heat and light to guide the movement of the silkworm.
Lex Fridman

(00:18:29)
You’re saying so many amazing things, and I’m trying not to interrupt you, but one of the things you’ve learned by observing, by doing science on these is that the environment defines the shape that they create or contributes or intricately plays with the shape they create. And that’s one of the ways you can get to guide their work is by defining that environment. By the way, you said hero organism, which is an epic term. That means whatever is the biological living system that’s doing the creation.
Neri Oxman

(00:19:01)
And that’s what’s happening in pharma and biomaterials and by the way, precision ag and new food design technologies as people are betting on a hero organism, is sort of how I think of it. And the hero organism is sometimes it’s the palm oil or it’s the mycelium. There’s a lot of mushrooms around for good and bad, and it’s cellulose or it’s fake bananas or the workhorse E. Coli. But these hero organisms are being betted on as the… What’s the one answer that solves everything hitchhiker’s guide?
Lex Fridman

(00:19:38)
42.
Neri Oxman

(00:19:40)
42.
Lex Fridman

(00:19:42)
Yeah. These are sort of the 42s of the enchanted new universe. And back at MIT, we said, instead of betting on all of these organisms, let’s approach them as almost movement in a symphony and let’s kind of lean into what we can learn from each of these organisms in the context of building a project in an architectural scale. And those usually were pavilions.

(00:20:05)
And then the computational templating is the way you guide the work of this. How many did you say? 17,000?
Neri Oxman

(00:20:15)
17,532. So each of these silkworms threads are about one mile in distance, and they’re beautiful. And just thinking about the amount of material, it’s a bit like thinking about the length of capillary vessels that grow in your belly when you’re pregnant to feed that incredible new life form. Just nature is amazing. But back to the silkworms, I think I had three months to build this incredible pavilion, but we couldn’t figure out how. We were thinking of emulating the process of how a silkworm goes about building its incredible architecture. This cocoon over the period of 24 to 72 hours, and it builds a cocoon basically to protect itself.

(00:21:03)
It’s a beautiful form of architecture, and it uses pretty much just two materials, two chemical compounds ceresin and fibrin. The ceresin is sort of the glue of the cocoon, the fibrin is the fiber based material of the cocoon and through fibers and glue. And that’s true for so many systems in nature, lots of fiber and glue. And that architecture allows them to metamorphosize. And in the process they vary the properties of that silk thread, so it’s stiffer or softer depending on where it is in the section of the cocoon. And so we were trying to emulate this robotically with a 3D printer that was six axis KUKA arm one of these baby KUKAs.

(00:21:46)
And we’re trying to emulate that process computationally and build something very large when one of my students now, a brilliant industrial engineer, roboticist on my team, Marcus said, “Well, we were just playing with those silkworms and enjoying their presence when we realized that if they’re placed on a desk or a horizontal surface, they will go about creating their cocoon only the cocoon would be flat because they’re constantly looking for a vertical post in order to use that post as an anchor to spin the cocoon. But in the absence of that post on surfaces that are less than 21 millimeters and flat they will spin flat patches and we said, “Aha, let’s work with them to produce this dome as a set of flat patches.”

(00:22:42)
And a silkworm mind you is quite an egocentric creature. And actually the furthest you go, you move forward in evolution by natural selection, the more egoism you find in creatures. So when you think about termites, their material sophistication is actually very primitive, but they have incredible ability to communicate and connect with each other. So if you think about entire all of nature, let’s say all of living systems as a matrix that runs across two axes one is material sophistication, which is terribly relevant for designers, and the other is communication. The termites ace on communication, but their material sophistication is crap.

(00:23:31)
It’s just saliva and feces and some soil particles that are built to create these incredible termite mounds, the scale that when compared to human skyscrapers transcend all of buildable scales, at least in terms of what we have today in architectural practice just relative to the size of the termite. But when you look at the silkworm, the silkworm has zero connection and communication across silkworms. They were not designed to connect and communicate with each other. They’re sort of a human design species because the domesticated silk moth creates the cocoon.

(00:24:08)
We then produce the silk of it and then it dies. So it has dysfunctional wings, it cannot fly. And that’s another problem that the sericulture industry has is, why did we in the first place, author this organism 4,000 years ago that is unable to fly and is just there to basically live to serve a human need, which is textiles? And so here we were fascinated by the computational kind of biology dimension of silkworms, but along the way… By the way, this is great. I never get to tell the full story. So great.
Lex Fridman

(00:24:47)
I’ve enjoyed this so much.
Neri Oxman

(00:24:51)
People say, “Oh, speak in [inaudible 00:24:54] paragraphs. They’re way too long.” And this is wonderful. This is like heaven.
Lex Fridman

(00:24:58)
[inaudible 00:24:58] paragraphs. You’re dropping so many good lines. I love it for that.
Neri Oxman

(00:25:02)
But really those silkworms, yes, they’re not designed to be like humans. They’re not designed to connect, communicate, and build things that are bigger than themselves through connection and communication.
Lex Fridman

(00:25:17)
So what happens when you add 17,000 of them communicating effectively?
Neri Oxman

(00:25:17)
That’s a really great question. What happens is that at some point, the templating strategies, and as you said correctly, there were geometrical, templating, material templating, environmental templating, chemical templating if you’re using pheromones to guide the movement of bees in the absence of a queen where you have a robotic queen.
Lex Fridman

(00:25:38)
Robotic queen.
Neri Oxman

(00:25:39)
But whenever you have these templating strategies, you have sort of control over nature, but the question is there a world in which we can move from templating, from providing these computational material and immaterial physical and molecular platforms that guide nature, almost guiding a product almost like a gardener to a problem or an opportunity of emergence where that biological organism assumes agency by virtue of accessing the robotic code and saying, now I own the code. I get to do what I want with this code. Let me show you what this pavilion may look like or this product may look like?

(00:26:18)
And I think one of the exciting moments for us is when we realized that these robotic platforms that were designed initially as templates actually inspired, if I may, a kind of a collaboration and cooperation between silkworms that are not a swarm based organism. They’re not like the bees and the termites. They don’t work together and they don’t have social orders amongst them, the queen and the drones, et cetera. They’re all the same in a way. And here, what was so exciting for us is that these computational and fabrication technologies enable the silkworm to sort of hop from the branch in ecology of worms to the branch in ecology of maybe human-like intelligence where they could connect and communicate by virtue of feeling or rubbing against each other in an area that was hotter or colder.

(00:27:19)
And so the product that we got at the end, the variation of density of fiber and the distribution of the fiber and the transparency, the product at the end seems like it was produced by a swarm silk community, but of course it wasn’t. It’s a bunch of biological agents working together to assemble this thing. That’s really, really fascinating to us. How can technology augment or enable a swarm like behavior and creatures that have not been designed to work as swarms?
Lex Fridman

(00:27:53)
So how do you construct a computational template from which a certain kind of thing emerges? How can you predict what emerges, I suppose?
Neri Oxman

(00:28:05)
So if you can predict it doesn’t count as emergence, actually.
Lex Fridman

(00:28:12)
That’s a deeply poetic line.
Neri Oxman

(00:28:13)
We can talk about it. It’s a bit exaggerated, doesn’t count. Speaking of emergence, an empowerment, because we’re constantly moving between those as if they’re equals on the team and one of them, Christopher shared with me a mathematically equation for what does it mean to empower nature and what does empowerment in nature look like? And that relates to emergence. And we can go back to emergence in a few moments, but I want to say it so that I know that I’ve learned it and if I’ve learned it I can use it later.
Lex Fridman

(00:28:54)
And maybe you’ll figure something out as you say it also.
Neri Oxman

(00:28:57)
Of course, Christopher is the master here, but really we were thinking again, what does nature want? Nature wants to increase the information dimension and reduce entropy. What do we want? We kind of want the same thing. We want more, but we want order. And this goes back to your conversation with Joscha about stochastic versus deterministic languages or processes. His definition or the definition he found was that an agent is empowered if the entropy of the distribution of all of its states it’s high while the entropy of the distribution of a single state given a choice, given an action is low. Meaning it’s that kind of duality between opportunity like starting like this and going like this, opening and closing. And this really, I think is analogous to human empowerment, given infinite wide array of choices. What is the choice that you make to enable, to empower, to provide you with the agency that you need?
Lex Fridman

(00:30:19)
And how much does that making that choice actually control the trajectory of the system? That’s really nice. So this applies to all the kinds of systems you’re talking about.
Neri Oxman

(00:30:28)
And the cool thing is it can apply to a human on an individual basis or a silkworm or a bee or a microbe that has agency or by virtue of a template, but it also applies to a community of organisms like the bees. And so we’ve done a lot of work sort of moving from, you’ve asked how to grow things. So we’ve grown things using co fabrication where we’re digitally fabricating with other organisms that live across the various kingdoms of life and those were silkworms and bees. And with bees, which we’ve sent to outer space and returned healthily and they were reproductive.
Lex Fridman

(00:31:15)
Okay, you’re going to have to tell that story. You’re going to have to talk about the robotic queen and the pheromones. Come on.
Neri Oxman

(00:31:20)
So we built what we called a synthetic apiary and the synthetic apiary was designed as an environment that was a perpetual spring environment for the bees of Massachusetts. They go on hibernation, of course, during the winter season, and then we lose 80% of them or more during that period. We’re thinking, okay, what if we created this environment where before you template, before you can design with, you have to design for? You have to create this space of mutualism space of sort of shared connection between you and the organism. And with bees it started as the synthetic apiary. And we have proven that curated environment where we designed the space with high levels of control of temperature, humidity, and light and we’ve proven that they were reproductive and alive. And we realized, wow, this environment that we created can help augment bees in the winter season in any city around the world where bees survive and thrive in the summer and spring seasons. And could this be a kind of new urban typology, an architectural typology of symbiosis, of mutualism between organisms and humans?

(00:32:37)
By the way, the synthetic API was in a co-op nearby Somerville. We had robots. Our team schlepped there every day with our tools and machines and we made it happen. And the neighbors were very happy, and they got to get a ton of honey at the end of the winter. And those bees, of course, were released into the wild at the end of the winter alive and kicking. So then in order to actually experiment with the robotic queen and idea or concept, we had to prove obviously that we can create this space for bees. And then after that, we had this amazing opportunity to send the bees to space on Blue Shepherd Mission that is part of Blue Origin, and we of course said, “Yes, we’ll take a slot.”

(00:33:24)
We said, “Okay, can we outdo NASA?” So NASA in 1982 had an experiment where they sent bees to outer space. The bees returned, they were not reproductive and some of them died. And we thought, “Well, is there a way in which we can create a life support system, almost like a small mini biolab of a queen and her retinue that would be sent in this Blue Origin New Shepherd mission in this one cell?” And so if the synthetic apiary was an architectural project, in this case, this second synthetic apiary was a product. It was so from an architectural controlled environment to a product scale controlled environment.

(00:34:08)
And this biolab, this life support system for bees, was designed to provide the bees with all the conditions that they needed. And we looked at that time at the Nasonov pheromone that the queen uses to guide the other bees, and we looked at pheromones that are associated with a bee, and thinking of those pheromones being released inside the capsule that goes to outer space. They returned back to the media lab roof and those bees were alive and kicking and reproductive, and they continued to create comb. It ended with a beautiful nature paper that the team and I published together. We gave them gold nanoparticles and silver nanoparticles because we were interested if bees recycle wax, it was known forever that-
Neri Oxman

(00:35:03)
Bees recycle wax. It was known forever that bees do not recycle the wax. And by feeding them these gold nanoparticles, we were able to prove that the bees actually do recycle the wax. The reason I’m bringing this forward is because we don’t view ourselves as designers of consumable products and architectural environments only, but we love that moment where these technologies… And by the way, every one of these projects that we created involve the creation of a new technology, whether it be a glass printer or the spinning robot or the life support system for the bee colony. They all involved a technology that was associated with the project, and I never, ever, ever want to let that part go because I love technology so much.

(00:35:54)
But also another element of this is that always, these projects, if they’re great, they reveal new knowledge about, or new science about the topic that you’re investigating, be it silkworms or bees or glass. That’s why I say, I always tell my team it should be at MoMA and the cover of Nature or Science at the same time. We don’t separate between the art and the science, it’s one of the same.
Biological hero organisms
Lex Fridman

(00:36:21)
So as you’re creating the art, you’re going to learn something about these organisms or something about these materials. Is there something that stands out to you about these hero organisms like bees, silkworms? You mentioned E. coli has its pros and cons, this bacteria. What have you learned, small or big, that’s interesting about these organisms?
Neri Oxman

(00:36:41)
Yeah, that’s a beautiful question. What have I learned? I’ve learned that… We also worked with shrimp shells with a glow. How we built this tower on the roof of SF MoMa, which by a couple of months ago until it was on the roof, we’ve shown this structure completely biodegrade into the… Well, not completely, but almost completely biodegrade to the soil. And this notion that a product or an organism or part of that organism can reincarnate is very, very moving thought to me, because I want to believe that I believe in reincarnation.
Lex Fridman

(00:37:24)
I want to believe that I believe. I want to believe.
Neri Oxman

(00:37:25)
Yeah, that’s my relationship with God. I like to believe in believing. Most great things in life are second derivatives of things, but that’s part of another conversation.
Lex Fridman

(00:37:38)
I feel like that’s a quote that’s going to take weeks to really internalize.
Neri Oxman

(00:37:43)
That notion of, I want you to want, or I need you to need. There’s always something, a deeper truth behind what is on the surface. So I like to go to the second and tertiary derivative of things and discover new truths about them through that. But what have I learned about organisms-
Lex Fridman

(00:38:05)
And why don’t you like E. coli?
Neri Oxman

(00:38:07)
I like E. coli, and a lot of the work that we’ve done was not possible without our working on E. coli or other workhorse organisms, like cyanobacteria.
Lex Fridman

(00:38:19)
How are bacteria used?
Neri Oxman

(00:38:20)
Death masks. The death masks.
Lex Fridman

(00:38:24)
So what are death masks?
Neri Oxman

(00:38:24)
We did this project called Vespers, and those were basically death masks. That was set as a process for designing a living product. What happens? I remember looking at Beethoven’s death mask and Agamemnon’s death mask and just studying how they were created. And really they were geometrically attuned to the face of the dead, and what we wanted to do is create a death mask that was not based on the shape of the wearer, but rather was based on their legacy and their biology. And maybe we could harness a few stem cells there for future generations or contain the last breath. Lazarus, which preceded Vespers, was a project where we designed a mask to contain a single breath, the last breath of the wearer. And again, if I had access to these technologies today, I would totally reincorporate my grandmother’s last breath in a product. So it was like an air memento.

(00:39:31)
So with Vespers, we actually used E. coli to create pigmented masks, masks whose pigments would be recreated at the surface of the mask. And I’m skipping over a lot of content, but basically there were 15 masks and they were created as three sets, the masks of the past, the masks of the present, and the masks of the future. They were five, five, and five, and the masks of the past were based on ornaments and they were embedded with natural minerals like gold. Yes, yes, yes, exactly-
Lex Fridman

(00:40:12)
And we’re looking at pictures of these and they’re gorgeous.
Neri Oxman

(00:40:16)
Yes, yes.
Lex Fridman

(00:40:16)
Extremely delicate and interesting fractal patterns that are symmetrical.
Neri Oxman

(00:40:24)
They look symmetrical, but they’re not. We intended for you to be tricked and think that they’re all symmetrical, but-
Lex Fridman

(00:40:32)
There’s imperfections.
Neri Oxman

(00:40:33)
There are imperfections by design. All of these forms and shapes and distribution of matter that you’re looking at was entirely designed using a computational program. None of it is manual. But long story short, the first collection is about the surface of the mask. And the second collection, which you’re looking at, is about the volume of the mask and what happens to the mask when all the colors from the surface, yes, enter the volume of the mask inside, create pockets and channels to guide life through them. They were incorporated with pigment-producing living organisms, and then those organisms were templated to recreate the patterns of the original death masks. And so life recycles and re-begins, and so on and so forth. The past meets the future, the future meets the past. From the surface to the volume, from death to life, to death to life, to death to life. And that again, is a recurring theme in the projects that we take on.

(00:41:39)
But from a technological perspective, what was interesting is that we embedded chemical signals in the jet, in the printer, and those chemical signals basically interacted with the pigment-producing bacteria, in this case E. coli, that were introduced on the surface of the mask. And those interactions between the chemical signals inside the resins and the bacteria at the surface of the mask, at the resolution that is native to the printer, in this case, 20 microns per voxel, allowed us to compute the exact patterns that we wanted to achieve. And we thought, “Well, if we can do this with pigments, can we do this with antibiotics? If we can do this with antibiotics, could we do it with melanin? And what are the implications?” Again, this is a platform technology. Now that we have it, what are the actual real-world implications and potential applications for this technology?

(00:42:41)
We started a new area, one of my students, Rachael, her PhD thesis was titled after this new class of materials that we created through this project, Vespers, Hybrid Living Materials, HLMs. And these hybrid living materials really paved the way towards a whole other set of products that we’ve designed, like the work that we did with melanin for the Mandela pavilion that we presented at SF MoMa. Where again, we’re using the same principles of templating, in this case not silkworms and not bees, but we’re templating bacteria at a much, much, much more finer resolution. And now instead of templating using a robot, we’re templating using a printer.

(00:43:32)
But compute is very, very much part of it. And what’s nice about bacteria, of course, is that from an ethical perspective I think there’s a range. So at the end of the silk pavilion, I got an email from professor in Japan who has been working on transgenic silk and said, “Well, if you did amazing silk pavilion, why don’t we create glow in the light silk dresses?” And in order to create this glow in the light silk, we need to apply jeans that are taken from a spider to a silkworm. And this is what is known as a transgenic operation. And we said no. And that was for us a clear decision that, no, we will work with these organisms as long as we know that what we are doing with them is not only better for humans, but it’s also better for them.

(00:44:31)
And again, just to remind you, I forget the exact number, but it’s around 1,000 cocoons per a single shirt that are exterminated in India and China, in those sericulture industries that are being abused. Now, yes, this organism was designed to serve the human species and maybe it’s time to retire that conception of organisms that are designed for a human-centric world or human-centric set of applications. I don’t feel the same way about E. coli, not that I’m organism agnostic, but still I believe there’s so much for us to do on this planet with bacteria.
Lex Fridman

(00:45:26)
And so in general, your design principle is to grow cool stuff as a byproduct of the organism flourishing. So not using the organism-
Neri Oxman

(00:45:36)
Yes. The win-win, the synergy.
Lex Fridman

(00:45:37)
Win-win.
Neri Oxman

(00:45:38)
A whole that’s bigger than the sum of its parts.
Lex Fridman

(00:45:40)
It’s interesting. It just feels like a gray area, where genetic modification of an organism, it just feels like… I don’t know. If you genetically modified me to make me glow in the light, I kind of like it.
Neri Oxman

(00:45:59)
I think you have enough of an aura.
Lex Fridman

(00:46:00)
All right, thank you. I was just fishing for compliments. Thank you. I appreciate the-
Neri Oxman

(00:46:06)
But you’re absolutely right. And by the way, the gray area is where some of us like to live and like to thrive, and that’s okay. And thank goodness that there’s so many of us that like the black and white and that thrive in the black and white. My husband is a good example for that.
Lex Fridman

(00:46:21)
Well, but just to clarify, in this case you are also trying to thrive in the black and white in that you’re saying the silkworm is a beautiful, wonderful creature. Let us not modify it. Is that the idea? Or is it okay to modify a little bit as long as we can see that it benefits the organism as well as the final creation?
Neri Oxman

(00:46:42)
With silkworms, absolutely let’s not modify it genetically. Let’s not modify it genetically. And then some. Because why did we get there to begin with 4,000 years ago in the Silk Road? And we should never get to a point where we evolve life for the service of mankind at the risk of these wonderful creatures across the across the kingdom of life. I don’t think about the same kind of ethical range when I think about bacteria.
Lex Fridman

(00:47:15)
Nevertheless, bacteria are pretty wonderful organisms.
Neri Oxman

(00:47:18)
I’m moving to my second cup here.
Lex Fridman

(00:47:21)
Take two, because things are getting serious now.
Neri Oxman

(00:47:23)
Bacteria are. Yeah, for sure.
Engineering with bacteria
Lex Fridman

(00:47:25)
Let’s give bacteria all the love they deserve. We wouldn’t be here without them. They were here for, I don’t know what it is, like a billion years before anything else showed up.
Neri Oxman

(00:47:32)
But in a way, if you think about it, they create the matter that we consume and then reincarnate, or dissolved into the soil and then creates a tree, and then that tree creates more bacteria. And then that bacteria could… Again, again. That’s why I like to think about not recycling, but reincarnating, because that assumes, imparting upon nature that dimension of agency and maybe awareness. But yeah, lots of really interesting work happening with bacteria. Directed evolution is one of them. We’re looking at directed evolution. So high-throughput directed evolution of bacteria for the production of products. And again, those products can be a shoe, wearables, biomaterials, therapeutics.
Lex Fridman

(00:48:26)
And doing that direction computationally?
Neri Oxman

(00:48:27)
Totally computationally, obviously in the lab with the hero organism, the hero bacteria. And what’s happening today, in equal microbial synthetic biology, synthetic biology that lends itself to ecology. And again, all of these fields are coming together. It’s such a wonderful time to be a designer. I can’t think of a better time to be a designer in this world. But with high-throughput directed evolution… And I should say that the physical space in our new lab will have these capsules which we have designed. They are designed like growth chambers or grow rooms, and in those grow rooms we can basically program top-down environmental templating, top-down environmental control of lights, humidity, light, et cetera. Sorry, light, humidity and temperature while doing bottom-up genetic regulation. So it is a wet lab, but in that wet lab you could do at the same time, genetic modulation, regulation and environmental templating.

(00:49:39)
And then, again, the idea is that in one of those capsules maybe we grow transparent wood, and in another capsule, transparent wood for architectural application. Another capsule, we grow a shoe, and in another capsule we look at that large language model that we talked about. And there was a particular technology associated with that, which we’re hoping to reveal to the world in February. And in each of those capsules is basically a high-throughput computational environment, like a breadboard, think of a physical breadboard environment that has access to oxygen and nitrogen and CO2 and nutritional dispensing, and these little capsules could be stressed. They’re sort of ecology in a box, and they could be stressed to produce the food of the future or the products of the future or the construction materials of the future. Food is a very interesting one, obviously because of food insecurity and the issues that we have around both in terms of food insecurity, but also in terms of the future of food and what will remain after we can’t eat plants and animals anymore, and all we can eat is these false bananas and insects as our protein source.

(00:50:56)
So there we’re thinking, can we design these capsules to stress an environment and see how that environment behaves? Think about a biodiversity chamber, kind of a time capsule that is designed as a biodiversity chamber where you can program the exact temperature, humidity, and light combination to emulate the environment from the past. So Ohio, 1981, December 31st at 5:00 AM in the morning, what did tomatoes taste like? To all the way in the future, 200 years ago, these are the environmental inputs, these are some genetic regulations that I’m testing and what might the food of the future or the products of the future or the construction materials of the future feel like, taste like, behave like, et cetera. And so these capsules are designed as part of a lab. That’s why it’s been taking us such a long time to get to this point, because we started designing them in 2019, and they’re currently, literally as I speak to you, under construction.
Lex Fridman

(00:52:02)
How well is it understood how to do this dance of controlling these different variables in order for various kinds of growth to happen?
Neri Oxman

(00:52:10)
It’s not. It’s never been done before and these capsules have never been designed before. So when we first decided these are going to be environmental capsules, people thought we were crazy. “What are you building? What are you making?” So the answer is that we don’t know. But we know that there has never been a space like this where you have basically a wet lab and a grow room at that resolution, at that granularity of control over organisms. There is a reason why there is this incredible evolution of products in the software space. The hardware space, that’s a more limiting space because of the physical infrastructure that we have to test and experiment with things. So we really wanted to push on creating a wet lab that is novel in every possible way. What could you create in it? You could create the future. You could create an environment of plants talking to each other with a robotic referee. And you could set an objective function.

(00:53:20)
And let’s say for the transaction-driven individuals in the world, let’s say their objective function is carbon sequestration. And all of those plants are implemented with a gaming engine and they have these reward system and they’re constantly needing to optimize the way in which they carbon sequest. We weed out the bad guys, we leave the good guys, and we end up with this ideal ecology of carbon sequestering heroes that connect and communicate with each other. And once we have that model, this biodiversity chamber, we send it out into the field and we see what happens in nature. And that’s sort of what I’m talking about, augmenting plants with that extra dimension of bandwidth that they do not have. Just last week I came across a paper that discusses the in vivo neurons that are augmented with a pong game. And in a dish they basically present sentience and the beginning of awareness.

(00:54:37)
Which is wonderful that you could actually take these neurons from a mouse brain, and you have the electrical circuits and the physiological circuits that enable these cells to connect and communicate, and together arrive at swarm situation that allows them to act as a system that is not only perceived to be sentient, but is actually sentient. Michael Levine calls this gentle material, material that has agency. This is of interest to us because, again, this is emergence post-templating. You template until you don’t need to template anymore because the system has its own rules. What we don’t want to happen with AGI, we want to happen with synthetic biology. What we don’t want to happen online and software with language, we want for it to happen with bio-based materials. Because that will get us closer to growing things as opposed to assembly and mechanically putting them together with toxic materials and compounds.
Plant communication
Lex Fridman

(00:55:43)
If I can ask a pothead question for a second, you mentioned just like the silkworms, the individualist silkworms got to actually learn how to collaborate or actually to collaborate in a swarm like way. You’re talking about getting plants to communicate in some interesting way based on an objective function. Is it possible to have some kind of interface between another kind of organisms, humans, and nature? So like a human to have a conversation with a plant?
Neri Oxman

(00:56:14)
There already is. You know that when we cut freshly cut grass, I love the smell, but actually it’s a smell of distress that the leaves of grass are communicating to each other. The grass, when it’s cut emits green leaf volatiles, GLVs. And those GLVs are basically one leaf of grass communicating to another leaf of grass, “Be careful. Mind you, you’re about to be cut.” These incredible life forms are communicating using a different language than ours. We use language models, they use molecular models. At the moment where we can parse, we can decode these molecular moments is when we can start having a conversation with plants.

(00:56:57)
Now, of course there is a lot of work around plant neurobiology. It’s a real thing. Plants do not have a nervous system, but they have something akin to a nervous system. It has kind of a ecological intelligence that is focused on a particular timescale, and the timescale is very, very slow, slow, slow, slow timescale. So it is when we can melt these timescales and connect with these plants in terms of the content of the language, in this case molecules, the duration of the language, and we can start having a conversation, if not simply to understand what is happening in the plant kingdom.

(00:57:38)
Precision agriculture, I promise to you, will look very, very different. Because right now we are using drones to take photos of crops, of corn, that look bad. And when we take that photo, it’s already too late. But if we understand these molecular footprints and things that they are trying to say, distress that they are trying to communicate, then we could of course predict the physiological, biological behavior of these crops, both for their own self perpetuation, but also for the foods and the pharma and the type of molecules that we’re seeking to grow for the benefit of humanity. And so these languages that we are attempting now to quantify and qualify, will really help us not only better nature and help nature in its striving to surviving, but also help us design better wines and better foods and better medicine and better products, again, across all scales, across all application domains.
Lex Fridman

(00:58:41)
Is there intricacies to understanding the timescales, like you mentioned, at which these communications, these languages operate? Is there something different between the way humans communicate and the way plants communicate in terms of time?
Neri Oxman

(00:58:56)
Remember when we started the conversation talking about definitions in the context of design and then in the context of being? That question requires, I think a kind of a shift, a humility. That requires a humility towards nature, understanding that it operates on different scales. We recently discovered that the molecular footprint of a rose, or of a plant in general during nighttime, is different than its molecular footprint during daytime. So these are circadian rhythms that are associated with what kind of molecules these plants emit given stresses, and given there’s a reason why a jasmine field smells so, so delicious and 4:00 AM in the morning. There’s peace and rest amongst the plants. And you have to tune into that time dimension of the plant kingdom, and that of course requires all this humility, where in a single capsule, to design a biodiversity chamber, it will take years, not months, and definitely not days to see these products.

(01:00:13)
And also, that humility in design comes from simply looking at how we are today as a civilization, how we use and abuse nature. Just think of all these Christmas trees. These Christmas trees, they take years to grow. We use them for one night, the holiest night of the year, and then we let them go. And think about in nature to design a “product,” an organism spends energy and time and thoughtfulness and many, many, many years, and I’m thinking about the redwoods, to grow these channels, these cellulose layers and channels and reach these incredible heights. Takes sometimes hundreds of years, sometimes thousands of years. Am I afraid of building a company that designs products in the scale of thousands of years? No, I’m not.

(01:01:08)
And the way of being in the physical world today is really not in tune with the time dimension of the natural world at all, and that needs to change. And that’s obviously very, very hard to do in a community of human beings that is, at least in the Western world, that is based on capitalism. And so here, the wonderful challenge that we have ahead of us is, how do we impart upon the capitalist movement? We know that we need to produce now products that will enter the real world and be shared and used by others, and still benefit the natural world while benefiting humans? And that’s a wonderful challenge to have.
Lex Fridman

(01:01:55)
So, integrate technology with nature, and that’s a really difficult problem. I see parallels here with another company of Neuralink, which is basically like, I think you mentioned, Neuralink for nature. That there are short-term products you can come up with, but it’s ultimately a long-term challenge of how do you integrate the machine with this creation of nature, this intricate, complex creation of nature, which is the human brain. And then you’re speaking more generally, nature.
Neri Oxman

(01:02:29)
You know how every company has an image? Like this one single image that embodies the spirit of the company? And I think for Neuralink it was, to me, that chimpanzee playing a video game. It was just unbelievable. But with plants, there potentially is a set of molecules that impacts or inspires, I like that word, the plant to behave or act in a certain way, and allows still the plan the possibility of deciding where it or she or he wants to go. Which is why our first product for this molecular space is going to be a functionalized fragrance. So here we’re thinking about the future of fragrances and the future of fragrances and flavors.

(01:03:23)
These products in the industry as we know it today, are designed totally for a human-centric use and enjoyment and indulgence and luxury. They’re used on the body for the sake of, I don’t know, attraction and feeling good and smelling good. And we were asking ourselves, is there a world in which a fragrance can be not a functional fragrance? Because you could claim that all fragrances are functional. But is there a world in which the fragrance becomes functionalized, is, again, imparted upon or given agency to connect with another organism? Is there a world in which you and I can go down to your garden and use a perfume that will interact with the rose garden downstairs? I’ve just been enamored with the statements that are being made in the media around, “Oh, this is completely biologically-derived fragrance and it’s bio-based.”

(01:04:28)
But when you look into the fragrance and you understand that in order to get to this bio-derived fragrance, you blew through 10,000 bushes of rose to create 5 mL of a rose fragrance. And all these 10,000 bushes of rose, they take space, they take water management, and so much waste. Is this really what we want the future of our agriculture and molecular goods to look like? And so when we did the Aguahoja pavilion on the roof of SF MoMa, we calculated that for that pavilion we had 40,000 calories embedded into this pavilion that was made of shrimp shells and chitosan and apple skins and cellulose from tree pulp. And we calculated that overall the structure had 40,000 calories. Interesting way to think about a structure, from the point of view of calories. But as you left the gallery, you saw these three clocks that were so beautifully designed by Felix on our team, and these clocks measured temperature and humidity, and we connected them to a weather channel so that we could directly look at how the pavilion was biodegrading in real-time.

(01:05:40)
And in our calculations, I say this long-winded description of the pavilion to say that in the calculation, we incorporated how much electricity we used for our computers, for the 3D printers that printed the pavilion. And these were called energy calculations, energy end materials. And when you think about a product and you think about a shoe or a chair or a perfume or a building, you don’t stop at the object. You want to go all the way to the system. Again, instead of designing objects or singular embodiments of the will of the designer, you’re really tapping into an entire system that is interconnected.

(01:06:26)
And if you look at the energy budget that characterize the project Aguahoja, it traverses the entire planet. Some of these shrimp shells were brought from places in the world we haven’t thought of, in terms of the apples and the shrimp shells and the tree pulp. And so going back to fragrances, it’s really, really important to understand the product in the context of the ecological system from which it’s sourced, and how it’s designed. And that is the kind of thinking that is not only desired, but is required if we are to achieve synergy between humanity and nature.
Lex Fridman

(01:07:06)
And it’s interesting, because the system-level thinking is almost always going to take you to the entire earth, to considering the entire earth ecosystem.
Neri Oxman

(01:07:13)
Which is why it’s important to have a left brain and a right brain competing for attention. And intimacy [inaudible 01:07:19]. Yes.
Lex Fridman

(01:07:19)
Yeah. You mentioned a fragrance that sends out a message to the environment, essentially.
Neri Oxman

(01:07:27)
A message in a bottle. Yeah.
Lex Fridman

(01:07:29)
A message in a bottle. So you can go to a rose garden and trick the rose garden to think it’s 4:00 AM, essentially?
Neri Oxman

(01:07:36)
You could if you wanted to, but maybe that is-
Lex Fridman

(01:07:38)
Not trick. Trick is such a bad word.
Neri Oxman

(01:07:40)
Right. Right.
Lex Fridman

(01:07:41)
Inspire.
Neri Oxman

(01:07:43)
Inspire I like. I like the idea of providing nature with a choice, which is why I love that elegant mathematical equation of empowerment and agency.
Lex Fridman

(01:07:53)
Empower the rose garden to create a romantic moment for the wearer of the fragrance.
Neri Oxman

(01:08:00)
But now again you’re, again, all of this to go back to that human-centric notion of romance. But maybe there’s another way to do romance that we haven’t yet explored. And maybe there’s a way to tap into what happens to the rose when it’s dreaming. Assuming that plants are sentient and assuming that we can tap into that sentient, what can we discover about what does the rose want? What does it actually want and what does it need? And what are the rose’s dreams?
Lex Fridman

(01:08:41)
But do you think there’s some correlation in terms of romance, in terms of the word you sometimes use, magic? Is there some similarities in what humans want and what roses want and what nature wants?
Albert Einstein letter
Neri Oxman

(01:08:53)
I think so. I think there is. And if I did not think so, oh my goodness, this would not be a nice world to live in. I think we all want love. I recently read this beautiful letter that was written by Einstein to his daughter. Einstein asked his daughter to wait 20 years until she reveals these letters, and so she did. It’s just one of the most beautiful letters I’ve ever read from a father to his daughter. And the letter overall is imbued with a sense of remorse or maybe even feelings of sadness. And there is some kind of melancholy note in the letter where Einstein regrets not having spent enough time with his daughter, having focused on the theory of general relativity and changing the world. And then he goes on to talk about this beautiful and elegant equation of E=MC^2. And he tells his daughter that he believes that love is actually the force that shapes the universe because it is like-
Neri Oxman

(01:10:03)
Is actually the force that shapes the universe because it is like gravity, right? It attracts people. It is like light. It brings people together and connects between people, and it’s all empowering. And so if you multiply it by the speed of light, you could really change the world for the better. And call me a romanticist. I know you are too, which is why I so love being here. I believe in this. I totally and utterly believe in…
Lex Fridman

(01:10:34)
In love. By the way, let me just excerpt from Einstein’s letter. “There’s an extremely powerful force that so far science has not found a formal explanation to. It’s a force that includes and governs all others and is even behind any phenomena operating in the universe and has not yet been identified by us. This universal force is love.” He also, the last paragraph in the letter, as you’ve mentioned, ” I deeply regret not having been able to express what is in my heart, which has quietly beaten for you all my life. Maybe it’s too late to apologize, but as time is relative,” that jokes to Einstein, “I need to tell you that I love you and thanks to you I have reached the ultimate answer. Your father, Albert Einstein.” By that regret, I deeply regret not having been able to express what is in my heart. Maybe that’s a universal regret, filling your days with busyness and silly pursuits and not sitting down and expressing that.
Neri Oxman

(01:11:43)
But it is everything. It is everything. It is why I love that expression, and I forget who said this, but I love my daughter more than evolution required, and I feel the same way towards my other half. And I feel that when you find that connection, everything and anything is possible and it’s a very, very, very magical moment. So I believe in love and I believe in the one.
Beauty
Lex Fridman

(01:12:27)
It might be the same thing, it might be a different thing, but let me ask you a ridiculously big philosophical question about beauty. Dostoevsky said Beauty will save the world in The Idiot, one of my favorite books of his. What is beauty to you? You’ve created through this intersection of engineering and nature, you have created some incredibly beautiful things. What do you think is beauty?
Neri Oxman

(01:12:55)
That’s a beautiful question.
Lex Fridman

(01:12:57)
Maybe it is connected to the love question.
Neri Oxman

(01:12:59)
It is connected to the love question. Of course, everything is connected to the love question. To me, beauty is agency. To me, something that has agency, it is beautiful. There is this special quote from Buckminster Fuller, which I cannot remember word for word but I remember the concept, which goes something like this. When I work on a problem, I never think about beauty. But when I’m done solving the problem and I look at what I’ve created and it’s not beautiful, I know that I was wrong.
Lex Fridman

(01:13:37)
Okay, yeah.
Neri Oxman

(01:13:38)
It’s kind of an agency that speaks to the “objective function” of the creation, right? Whether for Bucky it’s useless or useful.
Lex Fridman

(01:13:49)
So this idea of empowerment that you talked about, it’s fundamentally connected to it.
Neri Oxman

(01:13:52)
Comes back to that, yeah.
Lex Fridman

(01:13:54)
What’s the difference that you hinted at between empowerment and emergence? Is emergence completely lacks control and empowerment is more controlled? There’s an agent making decisions? Is there an interesting distinction there?
Neri Oxman

(01:14:16)
Yes. I think empowerment is a force with direction. It has directionality to it. Emergence is, I believe, multi-directional. Again, that depends on the application. Emergence is perhaps in terms of a material definition, is a tropic spirit. When empowerment, the end is a tropic counterpart, I think they overlap because I think that empowerment is a way of inspiring emergence. I think emergence does not happen without empowerment, but empowerment can happen without emergence.
Lex Fridman

(01:15:05)
Do you think of emergence as the loss of control? When you’re thinking about these capsules and then the things they create, is emergence of things not a desirable conclusion?
Neri Oxman

(01:15:19)
I love that question because to some of us, the loss of control is control. In design, we’re used to extreme levels of control over form and the shape of a thing and how it behaves and how it functions. And that’s something we’ve inherited from the industrial revolution. But with nature, there is this diversity that happens without necessarily having a reward function, right? This is good or bad. Things just happen and some of them happen to have wings and some of them happen to have scales, and you end up with this incredible potential for diversity. So I think the future of design is in that soft control, is in the ability to design highly controlled systems that enable the loss of control.

(01:16:14)
And creativity is very much part of this because creativity is all about letting go and beginning again and beginning again and beginning again. And when you cannot let go, you cannot be creative and you can’t find novelty. But I think that letting go is a moment that enables empowerment, agency, creativity, emergence, and they’re all connected. They sort of associate themselves with definition of destiny or the inevitable. A good friend of mine shared with me elegant definition of fate, which is the ratio of who you are and who you want to be.
Lex Fridman

(01:17:01)
Ratio of who you are, who want to be.
Neri Oxman

(01:17:04)
Exactly. And that sort of ends up defining you and those tools, I think when you let go, you sort of find, you give peace to your will, to a sense of will. And so I think that’s very, very important in design, but also in life.
Faith
Lex Fridman

(01:17:23)
She said this fate is the ratio of…
Neri Oxman

(01:17:25)
Who you are and who you want to be.
Lex Fridman

(01:17:27)
Who you want to be. Do you think there’s something to this whole manifestation thing like focusing on a vision of what you want the world to become and in that focusing you manifest it? Like Paula Coelho said in the Alchemist, “when you want something, all the universe conspires in helping you to achieve it.” Is there something to that?
Neri Oxman

(01:17:48)
I think so, yes. And I always think of what I do as the culmination of energy, information, and matter and how to direct energy, information, and matter in the design of a thing or in the design of a life. I think living is very much a process of channeling these energies to where they need to go. I think that the manifestation or part of that manifestation is the pointing to the moon in order to get to the moon. And that’s why manifestation is also directional. It has that vector quality to it that I think of agency as.
Lex Fridman

(01:18:31)
Have you in your own life. Has there been things you’ve done where you kind of direct that energy information and matter in a way that opens up?
Neri Oxman

(01:18:41)
New possibilities?
Lex Fridman

(01:18:42)
Yeah. I mean, you’ve also said somewhere, I’m probably misquoting, that many things, you, Neri, are many things and you become new things every 10 years or so.
Neri Oxman

(01:18:56)
Oh, I did say that somewhere, that every decade you’ve sort of switched.
Lex Fridman

(01:19:00)
That was a previous Neri that said that.
Neri Oxman

(01:19:03)
Yeah, I did say sometime ago that you have to sort of reboot every 10 years to keep creative and keep inventive and keep fresh.
Lex Fridman

(01:19:12)
Is there are things you’ve done in your life where just doors opened?
Neri Oxman

(01:19:20)
I think everything, everything, everything good I’ve found in my life has been found in that way of letting go and suspending my sense of disbelief. And often you will find me say to the team, suspend your disbelief. I don’t care that this is impossible. Let’s assume it is. Where does it take us? And that suspension of disbelief is absolutely part and parcel of the creative act. I did so when I was in medical school, I was in Hadassah and in the Hebrew University, and I remember I left medical school for architecture the day my grandmother passed away. And that was a moment of relief and that was a door that was closing that opened other opportunities. But that of course required letting go of the great vision of becoming a doctor and letting go of the dream of being surrounded by wonderful patients and the science of medicine and the research associated with that science. And letting go of that dream to accomplish another.

(01:20:43)
And it has happened throughout my life in different ways. MIT was another experience like that where people pointed at me as the designer for whom the academic currency is not necessarily the citation index. And of course in order to get tenure at MIT, you have to look at the citation index. But for me it was not that. It was manifesting our work in shows and writing papers and writing patents and creating a celebration around the work. And I never saw a distinction between those ways of being. I also think that another kind of way of being or a modality of being that I found helpful is Viktor Frankl wrote this incredible book, Men’s Search for Meaning after the Holocaust. And he writes, different people pursue life for different reasons. According to Freud, the goal of life is to find pleasure and according to Adlers, to find power.

(01:21:54)
And for Viktor Frankl, it was about finding meaning. And when you let go of the titles and the disciplines and the boundaries and the expectations and the perception, you are elevated to this really special, yes, spiritual, but definitely very, very creative plane where you can sort of start anew, look at the world through the lens of a bacterium or a robot, or look at ecology through the lens of chemistry and look at chemistry through the lens of robotics and look at robotics through the lens of microbial ecologies and so on and so forth. And I feel that kind of rebooting not every 10 years, but every minute, every breath, is very, very important for a creative life and for just maintaining this fresh mind to reboot, reboot, to begin again with every breath, begin again. And that can be confusing some. For my team members, I like to change my mind. It’s who I am, it’s how I think, it’s how I operate.

(01:23:11)
And they’ll come and we found another technique or another technology that’s interesting and we thought that we were working on this functionalized fragrance, but now there’s another opportunity and let’s go there. And to me, I would much rather live life, like if I had to pick sort of my favorite Broadway show to enter and live through, it would be Into The Woods. It’s not a specific fairytale. It’s not the Sleeping Beauty or Little Red Riding Hood or Rapunzel, it’s all of them. It’s sort of moving into the forest and seeing this wonder and getting close and learning about that and then moving to another wonder. And life is really about tying all of these little fairytales together in work and also in life.
Lex Fridman

(01:24:06)
Unafraid to leap into the unknown?
Neri Oxman

(01:24:07)
Unafraid to leap into the unknown.
Lex Fridman

(01:24:08)
Speaking of MIT, you got a tenure at MIT and then you leaped to New York and started a new company that with a vision that doesn’t span a couple of years, but centuries.
Neri Oxman

(01:24:21)
I did. It was my destiny to start a company. And do I have mornings when I wake up and I ask myself what the hell am I doing? Yes, I have those mornings.
Lex Fridman

(01:24:32)
What do you do with those mornings, by the way?
Neri Oxman

(01:24:33)
I embrace them and I find gratitude and I say to myself, thank goodness. I am so lucky to have the ability to be frustrated in this way. So I really, really embrace these frustrations and I take them, I wrap them in a bubble and I look at it on the outside of my aware mind and I laugh at them, I smile at them.
Lex Fridman

(01:25:11)
If I could return actually to the question of beauty for a second, I forgot to ask you something. You mentioned imperfection in the death masks. What role does imperfection play in our conception of beauty? What role does imperfection play in nature? There’s this Japanese aesthetics concept of wabi-sabi, which basically embraces imperfection. Nothing lasts, nothing is finished, and nothing is perfect. What do you think of that?
Neri Oxman

(01:25:45)
I totally agree that change is the only permanence. That imperfection is there if only to signal that we are part of a bigger thing than ourselves, that we are on a journey, that things are in movement. And if they were perfect, of course, when things are perfect, it is just so boring. We end up with stereotypes. And as humans, but I think just in general as living beings, we’re here to find meaning and that meaning cannot be found without struggle and without seeking to, not to perfect, but to build towards something better. When I was a child, my mother who I love so much, always explained to me how important it is to fall and to fail and to fight and to argue, and that there is a way, that there’s a culture to failing and to imperfection. So I think it is necessary for something beautiful to be imperfect and it is a sign of nature because nothing in nature is perfect.
Flaws
Lex Fridman

(01:27:09)
What about human relations? You mentioned finding love. Are the flaws in humans, imperfection in humans, a component of love? What role do you think the flaws play?
Neri Oxman

(01:27:23)
That’s a really profound question. I think the flaws are there to present a vulnerability, and those flaws are a sign of those vulnerabilities. And I think love is very, very gentle, right? Love with Bill, we often talk about between the two of us, about what drives all human behavior. And for him it’s incentive, as you might expect, and he will repeat this sentence to me, oh, incentive drives all human behavior. But I would say to me it’s love, very much so. And I think flaws are part of that because flaws are a sign of that vulnerability, whether physical, whether emotional vulnerability, and these vulnerabilities, they either tear us apart or they bring us together.

(01:28:36)
The vulnerability is what is the glue. I think that the vulnerability enables connection. The connection is the glue, and that connection enables accessing a higher ground as a community as opposed to as an individual. So if there is a society of the mind, or if there are higher levels of awareness that can be accessed in community as opposed to again, going to the silkworm, as opposed to on the individual level, I think that those occur through the flaws and the vulnerabilities. And without them we cannot find connection, community. And without community, we can’t build what we have built as a civilization for the past hundreds of thousands of years. So I think not only are they beautiful, but they have a functional role in building civilizations.
Lex Fridman

(01:29:32)
Yeah, there’s a sense in which love requires vulnerability and maybe love is the leap into that vulnerability.
Neri Oxman

(01:29:40)
And I think yes, I think a flaw, think about it physically, I’m thinking about a brick that’s flawed, but in a way I think of a flaw as an increased surface area.
Lex Fridman

(01:30:02)
That’s a good line. That’s a good line.
Neri Oxman

(01:30:03)
A surface area that physically or emotionally, right, it sort of introduces this whole new dimension to a human or a brick. And because you have more surface area, you can use mortar and build a home. And yeah, I think of it as accessing this additional dimension of surface area that could be used for good or bad to connect, to communicate, to collaborate. It makes me think of that quote from this incredible movie I’ve watched years ago, Particle Fever, I think it was called, documentary about the large hadron collider, an incredible film, where they talk about the things that are least important for our survival are the things that make us human. Like the pure romantic act or the notion of, and Viktor Frankl talks about that too.

(01:31:01)
He talks about feeling the sun on his arms as he is working the soil in two degrees Fahrenheit without clothes. And the officer berates him and says, what have you done? Have you been a businessman before you came here to the camp? And he says, I was a doctor. And he said, you must’ve made a lot of money as a doctor. And he said, all my work I’ve done for free, I’ve been helping the poor. But he keeps his humility and he keeps his modesty and he keeps his preservation of the spirit. And he says the things that actually make him able to, or made him able to outlive the terrible experience in the Holocaust was really cherishing this moment when the sun hits his skin or when he can eat a grain of rice, a single grain of rice. So I think cherishing is a very important part of living a meaningful life, being able to cherish those simple things
Lex Fridman

(01:32:30)
To notice them and to-
Neri Oxman

(01:32:32)
To notice them, to pay attention to them in the moment, and I do this now more than ever.
Lex Fridman

(01:32:42)
Bakowski has this poem called Nirvana where it tells a story of a young man on a bus going through North Carolina or something like this, and they stop off in a cafe and there’s a waitress and he talks about that he notices the magic, something indescribable, he just notices the magic of it. And he gets back on the bus with the rest of the passengers. And none of them seem to have noticed the magic. And I think if you just allow yourself to pause, just to feel whatever that is, maybe ultimately it’s a kind of gratitude for, I don’t know what it is. I’m sure it’s just chemicals in the brain, but it is just so incredible to be alive and noticing that and appreciating that and being one in that with others.
Neri Oxman

(01:33:38)
Yes. Yes. And that goes back to the fireplace, right to the first technology. What was the first technology? It was fire, first technology to have built community. And it emerged out of a vulnerability of wanting to stay away from the cold and be warm together. And of course, that fire is associated with not only with comfort and the ability to form bio relevant nutrients in our food and provide heat and comfort, but also spirits and a kind of way to enter a spiritual moment, to enter a moment that can only be experienced in a community as a form of a meditative moment. There is a lot to be said about light. Light is, I think, an important part of these moments of, I think it’s a real thing. I really truly believe that we’re born with an aura surface area that is measurable. I think we’re born into the world with an aura. And how do we channel that really ends up sort of defining the light in our lives.
Lex Fridman

(01:35:24)
Do you think we’re all lonely? Do you think there’s loneliness in us humans?
Neri Oxman

(01:35:26)
Oh yes, yes. Loneliness is part, yes. I think we all have that loneliness, whether we’re willing to access that loneliness and look at it in the eye or completely, completely avoid it or deny it.
Lex Fridman

(01:35:44)
It feels like it’s some kind of foundation for longing and longing leads to this combination of vulnerability and connection with others.
Neri Oxman

(01:35:55)
Yes.
Lex Fridman

(01:35:56)
It feels like that’s a really important part of being human as being lonely.
Neri Oxman

(01:35:59)
Very. We are born into this world alone. Again, being alone and being lonely are two different things and you can be together, but be lonely and you can be alone but not be lonely at all. We often joke, Bill and I, that he cannot be lonely. He cannot deal with being by himself. He always needs people around him. And I strive, long, must have creative solitude, must find pockets of solitude and loneliness in order to find creativity and reconnect with myself. So loneliness is a recipe for community in my opinion. And I think those things compliment each other. And they’re synergetic, absolutely. The yin and yang of togetherness. And they allow you, I think, to reset and to tune in to that ratio we talked about of who you are and who you want to be.
Lex Fridman

(01:37:07)
If you go to this place of creative solitude, what’s your creative process? Is there something you’ve noticed about what you do that leads to good work?
Neri Oxman

(01:37:18)
I love to be able not only to lose focus, but kind of to focus on the peripheral view and to allow different things to occur at once. So I will often, in my loneliness journeys, I will often listen to Leonard Bernstein. Anything I can find online by Lenny Bernstein, it’s reading a nature paper, it’s War and Peace. It’s really revisiting all the texts that are so timeless for me with opportunities that are very, very timely. And I think for me, the creative process is really about bringing timeless problems or concepts together with timely technologies to observe them. I remember when we did the Mandela Pavilion, we read Moby Dick, the whiteness of the whale, the albino, the different the other, and that got us to work on melanin and melanine also is sort of an output from the death mass. So it’s lots of things happening at the same time and really allowing them to come together to form this view about the world through the lens of a spirit being or a living being or a material. And then focus on the world through the lens of that material.

(01:38:41)
The glasswork was another project like that where we were fascinated by glass because obviously it’s superb material for architecture, but we created this new glass printing technology for the first time that was shedding light on the biomechanics of fluid glass, the math and the physics of which was never done before, which was so exciting to us, but revealing new knowledge about the world through technology. That’s one theme. The reincarnation between things, material and immaterial. That’s another theme. Lenny Bernstein, War and Peace, Tolstoy.
Lex Fridman

(01:39:18)
You’ve tweeted a Tolstoy quote from War and Peace, as of course you would. Everything I know, I know because of love.
Neri Oxman

(01:39:27)
Yeah, I love this quote.
Lex Fridman

(01:39:28)
So you use these kind of inspirations to focus you and then find the actual idea in the periphery.
Neri Oxman

(01:39:39)
Yes. And then connect them with whatever it is that we’re working on, whether it’s high throughput, directed evolution of bacteria, whether it’s recreating that Garden of Eden in the capsule and what it looks like, the food of the future. It is a little bit like directing a film. Creating a new project is a bit like creating a film. And you have these heroes, you have these characters and you put them together and there is a narrative and there’s a story. Whenever we start a new project, it has to have these ingredients of simultaneous complexity. It has to be novel in terms of the synthetic biology, material science, robotics, engineering, all of these elements that are discipline based or rooted must be novel.

(01:40:31)
If you can combine novelty in synthetic biology with a novelty in robotics, with a novelty in material science, with a novelty in computational design, you are bound to create something novel, period. And that’s how I run the company and that’s how I pick the people. And so that’s another very, very important ingredient of the cutting edge across multiple disciplines that come together. And then in the background, in the periphery, there is all these messages, the whispers of the ancient oldies, right? The Beethoven’s and the Picassos.
Lex Fridman

(01:41:05)
So Beethoven’s always whispering to you.
Neri Oxman

(01:41:07)
Yeah. How could one not include Beethoven in the whispers?
Lex Fridman

(01:41:11)
I’m going to ask you about Beethoven and the Evgeny Kissin you’ve mentioned because I’ve played piano my whole life. I obviously know a lot of Beethoven and it’s one of the private things for me, I suppose, because don’t think I’ve ever publicly played piano.-
Neri Oxman

(01:41:25)
By the way. Me too.
Lex Fridman

(01:41:25)
I mean at night-
Neri Oxman

(01:41:30)
I play in private only.
Lex Fridman

(01:41:32)
People sometimes even with guitar, people ask me, can you play something? And it just feels like certain things are
Neri Oxman

(01:41:38)
Are meant to be done-
Lex Fridman

(01:41:39)
Privately. Yeah, it’s weird. I mean it’s a difficult, and some of the times I have performed publicly, it is an ultimate leap in vulnerability. It’s very, very, very difficult for me. And I’m sure, I know it’s not for a lot of people, but it is for me. Anyway, we’ll return to that. But since you’ve mentioned combination of novelty across multiple disciplines and that’s what you seek when you build teams or pick people you work with, I just wanted to linger on this idea of what kind of humans are you looking for in this endeavor that you’re taking on, this fascinating thing that you’ve been talking about. One of the things somewhere else, a previous version, version 5.7 of Neri said somewhere that there’s four fields that are combined to create this intersection of biology and engineering work, and it’s computational design, additive manufacturing, material engineering, synthetic biology. I’m sure there’s others, but how do you find these humans? Machine learnings in the mix.
Neri Oxman

(01:42:45)
I manifest and they come, there are a few approaches to-
Lex Fridman

(01:42:50)
Manifest.
Neri Oxman

(01:42:53)
They show up.
Lex Fridman

(01:42:55)
Okay.
Neri Oxman

(01:42:55)
Send your message upon the water. I mean those job descriptions that you saw, the first ones I wrote by myself, and you find interesting people and brilliant people when you look, we talked about second derivative. When you look under and under and under. And if you look deep enough and specialized enough and if you allow yourself to look at the cracks, at the flaws, at the cracks between disciplines and between skills, you find really, really interesting diamonds in the rough. And so I like for those job descriptions to be those messages in a bottle that bring those really interesting people our way. I mean, they have to have humility. They have to have a shine in their eye. They have to be hungry and foolish, as Steve Jobs so famously said.

(01:43:49)
A friend of mine who’s a dean of well-known architectural school said today, architects don’t want to be architects. Architects don’t look up to the starchitects as role models. Starchitects are no longer role models. Architects want to build by virtue of not building. Architects want, she said, we’re back in the sixties when we think about architecture back in the hippie movement, I think that in a way they have to be somewhat of a hippie, somewhat of a kind of jack of all trades, master of all.
Lex Fridman

(01:44:26)
And yet with humility.
Neri Oxman

(01:44:27)
And yet with humility. Now that is hard to find and that is why when I start an interview, I talk about childhood memories and I asked about music and I ask about connection. And through these interviews you can learn a lot about a person’s future by spending time hearing them talk about their past.
Lex Fridman

(01:44:52)
Do you find that educational, like PhDs versus, what’s the life trajectory? Yours is an interesting life trajectory too. What’s the life trajectory that leads to the…
Lex Fridman

(01:45:03)
What’s the life trajectory that leads to the kind of person that would work with you?
Neri Oxman

(01:45:07)
It’s people who have ideally had industry experience and know what it’s like to be in the quote unquote real world. They’re dreamers that are addicted to reality as opposed to realists that are addicted to dreams, meaning they have that innocence in them, they have the hunger, they have the idealism without being entitled and with understanding the systems that govern our world and understanding how to utilize these systems as Trojan horses to bring those values into the world. There are individuals who feel comfortable in this friction between highly wondrous and dreamy and incredible fantasy renditions of what the world could be and extremely brilliant skills in terms of their disciplinary background. PhD with industrial experience in a certain field or a double major in two fields that make no sense whatsoever in their combination.
Lex Fridman

(01:46:17)
I love it. Yeah.
Neri Oxman

(01:46:17)
Are things that really, really attract me.
Lex Fridman

(01:46:19)
Especially the span, the technology biology gap.
Neri Oxman

(01:46:24)
Yes. Technology, biology, nature, culture. I mean, the secret to one thing is through the lens of another. And I always believe in that kind of translational design ability to be able to see something through the lens of another and always allows you to think again, begin again, reestablish, redefine, suspend your disbelief, revisit. And when you revisit enough times like a hundred times or 200 times and you revisit the same question through the lens of any possible discipline and any possible scenario, eventually you get to the truth.
Extinction
Lex Fridman

(01:46:59)
I have to ask you, because you work at the interplay of the machine and the natural world, is there a good definition for you of what is life? What is a living organism?
Neri Oxman

(01:47:15)
I think 440 million years ago, there were all these plants, the cyanobacteria I believe actually. That was the first extinction. There were five extinctions. We are apparently the sixth. We are in the eye of the storm. We are in the sixth extinction. We are going to be extinct as we speak. I mean, death is upon us whether we want to admit it or not.

(01:47:42)
And actually they found in Argentina and in various places around the world, they found these spores of the first plants that existed on the planet. And they emerged out of these … Cyanobacteria were the first of course, and then they found these spore based plants. And because they didn’t have seeds there were only spores. The spores became sort of the fossils by which we’ve come to known of their existence. And because of these spores, we know that this first extinction existed.

(01:48:18)
But this extinction is actually what enabled plants to resurrect. The death of these first plants, because they clinked to the rocks and they generated a ton of phosphorus that went into the ocean by clinging to the rocks 60 times more phosphorus than without them. And then all this phosphorus basically choked the oceans and made them super cold and without oxygen, anoxic. And then we lost the plant kingdom, and then because of the death of these first plants, they actually enriched the soil and created nutrients for these new plants to come to the planet. And those planets had more sophisticated vein systems and they were moving beyond spores to seeded plants, et cetera, and flowering plants. And so in a way, one mass extinction or the division period led to life as we know it. And where would we be without plants in a way?

(01:49:31)
I think that death is very much part of life and through that definition, that kind of planetary wide definition in the context of hundreds of millions of years, life gains a completely new light. And that’s when the particles become a wave, where humans, we are not alone and we are here because of those plants. I think death is very much part of life. In the context of the redwood tree, perhaps life is defined as 10 generations. And through the lens of a bacteria, perhaps life is defined as a millisecond. And perhaps through the lens of an AGI, life is defined as all of human civilization. And so I think it really is a question of this timescale again, the timescale and the organism, the life form that’s asking the question through which we can answer, what is life?
Lex Fridman

(01:50:36)
What do you think about this? If we think of ourselves in the eye of the storm of another extinction, the natural question to ask here is you have all of nature and then you have this new human creation that is currently being termed artificial intelligence. How does your work play with the possibility of a future super intelligent ecosystem, an AGI that either joins or supersedes humans?
Neri Oxman

(01:51:13)
I’m glad you asked this question.
Lex Fridman

(01:51:15)
And are you hopeful or terrified?
Neri Oxman

(01:51:17)
Both. I’m hopeful and terrified. I did watch your interview with Eliezer Yudkowsky and I loved it
Lex Fridman

(01:51:25)
Because you were scared or because you were excited or because there was a [inaudible 01:51:29]?
Neri Oxman

(01:51:28)
First of all, I was both. Totally scared, shamed, excited, and totally also inspired because he’s just such an incredible thinker. And I can agree or disagree with what he says, but I just found his way of thinking about AGI and the perils of humanity as a result.
Lex Fridman

(01:51:53)
There’s an inevitability to what he’s saying. His advice to young people is that prepare for a short life. He thinks it’s very almost simple. It’s almost common sense that AGI would get rid of humans, that he can’t imagine a trajectory eventually that leads to a place that doesn’t have AGI kill all humans. There’s just too many trajectories where a super intelligent systems gets rid of humans and in the near term. And so that clarity of thinking is very sobering. To me, maybe it is to you as well, it’s super inspiring because I think he’s wrong, but it’s like you almost want to prove him wrong. It’s like, “No, we humans are a clever bunch. We’re going to find a way.”
Neri Oxman

(01:52:48)
It is a bit like jumping into super cold water. It’s sort of a kind of fist in your face. It wakes you up. And I like these moments so much, and he was able to bring that moment to life, even though I think a mother can never think that way ever. And it’s a little bit like that notion of I love her more than evolution requires.

(01:53:14)
On your question about AGI and nature, look, I think we’ve been through a lot in terms of to get here, we sort of moved from data, the ability to collect information to knowledge, the ability to use this information for utility, from knowledge to intelligence. And what is intelligence? It’s the ability to problem solve and adapt and translate. That’s sort of from data to information to knowledge. I think the next frontier is wisdom. And what is wisdom? Wisdom is the ability to have or find insight about the world and from wisdom to spiritual awareness, which sort of transcends wisdom and is able to chart the world into new territory.

(01:53:58)
But I think what is interesting about AGI is that it is sort of almost like a self recursive thing, because it’s like a washing machine of a third derivative Wikipedia. It uses kind of language to create language, to create language, to create language.
Lex Fridman

(01:54:15)
It feels like novelty is being constantly created. It doesn’t feel like it’s regurgitating.
Neri Oxman

(01:54:20)
And that’s so fascinating because these are not the stochastic parrots. This is sort of a new form of emergence perhaps of novelty as you say, that exists by virtue of using old things to create new things.

(01:54:38)
But it’s not as if the AGI has self-awareness. Maybe. Maybe it has, but as far as I can tell, it’s not as if AGI has approached consciousness or sentience just yet. It’s probably getting there. But the language appears to present itself as if there is sentience there, but it doesn’t. But I think that’s the problem at the point where this AGI sounds like me and speaks like me and behaves like me and feels like me and breathes like me and my daughter knows the AGI to be me as sort of the end of everything is the end of human agency.

(01:55:23)
But what is the end of human agency to humans I think is the beginning of agency to nature. Because if you take all of this agency, if you take all of these language models that can summarize all of human civilization and consciousness and then upload that to nature and have nature now deal with that world of consciousness that it never had access to.

(01:55:49)
Maybe through Eliezer’s lens, the sort of short-lived human becomes sort of a very long-lived humanlike, sentient, weeping willow. Maybe that’s the end in the beginning. And maybe on the more optimistic side for us humans, it’s a different form of existence where everything we create and everything we consume and everything we process is all made out of six elements and that’s it. And there’s only those six elements and not 118 elements. And it’s all the stuff of biology plus some fair amount of bits, genes, and atoms. A lot of Beethoven.
Lex Fridman

(01:56:44)
A lot of Beethoven. I think the idea of connecting AGI to nature through your work is really fascinating. Sort of unlocking this incredible machinery of intelligence that is AGI and connecting it to the incredible machinery of wisdom that is nature has evolved through billions of years of pretty crazy intense evolution.
Neri Oxman

(01:57:15)
Exactly. Again, I’m going back to directed evolution. Unlike this sort of high throughput brute force approach, if there is a way to utilize this synergy for diversity and diversification, what happens if you ask a ChatGPT question, but it takes 10,000 years to answer that question? What does that look like when you completely switch the timescale and you can afford the time to answer the question? And again, I don’t know, but that world to me is possibly amazing.
Alien life
Lex Fridman

(01:58:10)
Because when we start to think about timescales like this, just looking at earth, all the possible trajectories it might take of this living organism that is earth, do you think there’s others like it? Do you think there’s other planets with life forms on them that are just doing their thing in this kind of way?
Neri Oxman

(01:58:26)
Planets.
Lex Fridman

(01:58:27)
Because in what you’re doing, you’re directly playing with what’s possible with life, lifelike things. That kind of maps the question of, well, what kind of other things are possible elsewhere? Do you think there’s other worlds full of life, full of alien life out there?
Neri Oxman

(01:58:50)
I’ve studied the calculations that point towards the verdict that the possibility of life in and around us is very, very low. We are a chosen planet in a way. There’s water and there’s love. What else do you need? And that sort of very peculiar juxtaposition of conditions, the oxygen, the water, the carbon again, is in a way a miracle given the massive extinctions that we’ve been through as life forms.

(01:59:33)
And that said, I cannot believe that there is no other life form. I want to believe more than I know that yes, that there are life forms in the white fountain that is the black hole, that there are these life forms that are light years away from us, that are forming other forms of life forces.
Lex Fridman

(02:00:05)
I’m much more worried about probably the thing that you’re working on, which is that there’s all kinds of life around us that we’re not communicating with.
Neri Oxman

(02:00:17)
Yes.
Lex Fridman

(02:00:18)
That there’s aliens in a sense all around us that we’re not seeing, that we’re not talking to, that we’re not communicating. Because that to me just seems the more likely situation.
Neri Oxman

(02:00:30)
That they’re here.
Lex Fridman

(02:00:31)
That they’re here, they’re all around us in different forms, that there’s a thing that connects all of us, all of living beings across the universe, and we’re just beginning to understand any of it. And I feel like that’s the important problem is I feel like you can get there with the tools of science today by just studying life on earth. Unlock some really fundamental things that maybe you can start to answer questions about what is consciousness? Maybe this thing that we’ve been saying about love, but honestly, in a serious way. And then you’ll start to understand that there is alien life all out there, and it’s much more complicated and interesting than we kind of realize as opposed to looking to exactly human-like things. It’s the variety of life that’s possible is just almost endless.
Neri Oxman

(02:01:28)
I totally agree with you. I think again, define alien, right?
Lex Fridman

(02:01:36)
Yeah. Define intelligence, define life.
Neri Oxman

(02:01:39)
Right. And Marvin Minsky used to say, “Intelligence is a suitcase word.” It’s a word so big. It’s a word like sustainability, and it’s a word like rock and roll. And suitcase words are always very, very dangerous.
Music
Lex Fridman

(02:01:55)
Speaking of rock and roll, you’ve mentioned music and you mentioned Beethoven a bunch of times. You’ve also tweeted about you getting Kiss in performance and so on. What can you say about the role of music in your life?
Neri Oxman

(02:02:09)
I love music. I always wondered why is it that plastic arts, meaning architecture and sculpture and painting, can’t get us to cry and music gets us to cry so quickly and connect so quickly? And no wonder that plants also respond to music, but that is at the top of the creative pyramid in my opinion.
Lex Fridman

(02:02:33)
It’s a weird mystery that we’re so connected to music. Well, by the way, to push back, a good bridge will make me cry.
Neri Oxman

(02:02:41)
It’s true. And I will say when I visited the Segreta Familia, I had that kind of spiritual reverence towards that spatial experience and being in that space and feeling the intention and the space and appreciating every little gesture. It’s true. It is the universal language. It’s the language of waves. It’s the language of the waves, not the language of the particles. It is the universal language, I believe, and that is definitely one of my loves.
Movies
Lex Fridman

(02:03:16)
And you said that if you weren’t doing what you were doing now, perhaps you would be a film director. I have to ask, what do you think is the best film of all time? Maybe top three?
Neri Oxman

(02:03:30)
Maybe The Godfather.
Lex Fridman

(02:03:33)
Godfather, okay.
Neri Oxman

(02:03:34)
The Godfather is definitely up there. Francis Coppola is one of my heroes.
Lex Fridman

(02:03:39)
Have you met him?
Neri Oxman

(02:03:40)
I have met him, yes. Yes, yes. We were very lucky to work with him on his new film, Megalopolis, which is coming out I hope in 2024. And think about the cities of the future in the context of new materials and the unity between nature and culture. Godfather is definitely up there.

(02:04:02)
2001 is up there. I would watch that film again and again and again. It’s incredible. The last scene in Odyssey 2001, just watch the last scene of 2001, then listen to Yudkowsky, and then go to the garden. And that’s pretty much the end in the beginning.

(02:04:27)
But that scene, that last scene from 2001 is everything. It says so much with so little and it’s sort of the embodiment I believe, of ambivalence. And there’s opportunity to believe in the beginning of humankind, the end of humankind, the planet, child star or star child of the future. Was there a death? Was there an reincarnation? That final scene to me is something that I go back to and study, and every time there is a different reading of that scene that inspires me. That scene, and then the first scene in The Godfather, still one of the best scenes of all times, sort of a portrait of America, the ideals and values that are brought from Italy.
Lex Fridman

(02:05:23)
A family of loyalty.
Neri Oxman

(02:05:25)
Yes.
Lex Fridman

(02:05:26)
Of values of how different values are constructed.
Neri Oxman

(02:05:29)
Yes. Loyalty and the human spirit and how Coppola celebrates the human spirit through the most simple gestures in language and acting. And I think in Kubrick you see this highly curated and controlled and manicured vision of creating a film. And with Francis, it’s like an Italian feast. It’s like anything can happen at any moment in time. And just being on the set with him is an experience I’ll take with me to my grave. It’s very, very, very special.
Lex Fridman

(02:06:12)
And you said music is also part of that, of creating a feeling in the movies?
Neri Oxman

(02:06:13)
Yeah, actually The Godfather, that tune-
Lex Fridman

(02:06:21)
That makes me emotional every time on some weird level.
Neri Oxman

(02:06:25)
Yeah. It’s one of these tunes I’m sure that if you play it to a Jasmine, you’ll get the best scent of all times. But I think with that particular tune, I learned staccato as something very, very happy and joyous. And then made into this stretched in time and became kind of the refrain of nostalgia and melancholy and loyalty and all of these values that ride on top of this one single tune.
Lex Fridman

(02:07:05)
And you can play it in all kinds of different ways. I’ve played it on guitar and all kinds of different ways. And I think in Godfather III, the son plays it on guitar to the father. I think this happens in movies, but sometimes a melody, and it has a simple melody, you can just like-
Neri Oxman

(02:07:22)
And the Straus melody in 2001. And when you juxtapose this melodies with this scene, you get this, again, hole that’s bigger than some of its parts where you get this moment, I think. These are the moments I would send with the next Voyager to outer space. The Godfather in 2001 would definitely beyond that golden record.
Advice for young people
Lex Fridman

(02:07:54)
You are an incredibly successful scientist, engineer, architect, artist, designer. You’ve mentored a lot of successful people. Can you give advice to young people listening to this of how to have a successful career and how to have a successful life?
Neri Oxman

(02:08:14)
Look, I think there’s this beautiful line in Sheltering Sky. How many times have you seen a full moon in your life and actually took the time to ingest and explore and reflect upon the full moon? Probably 20, I believe he says.

(02:08:35)
I spend time with a full moon. I take my time with a full moon and I pay attention to a full moon. And I think paying attention to the seasons and taking time to appreciate the little things, the simple things is what makes a meaningful life. I was very lucky to have grown up in a home that taught me this way of being. My parents, my grandmother, who played a very important role in my growing up. And that ability to pay attention and to be present is so, so, so, so … I could not emphasize it enough, is so crucial.
Lex Fridman

(02:09:39)
And be grateful.
Neri Oxman

(02:09:40)
And be grateful. I think gratitude and presence, appreciation are really the most important things in life.
Lex Fridman

(02:09:53)
If you could take a short tangent about your grandmother who’s played a big role in your life, what do you remember? What lessons have you learned from her?
Neri Oxman

(02:10:05)
She had this blanket that she would give me every time I came back from school and say, “Do your homework here and meet with your friends here.” And it was always in her garden. And her garden in my mind was ginormous. But when last I went there and saw the site, which has now become the site for another tall building, it was a tiny, tiny little garden that to me, seemed so large when I was growing up because it had everything. It had fig trees, it had olive trees, it had mushrooms, it had the blanket. I would do my homework there. It was everything. And I needed nothing else. And that was my Garden of Eden. That was my childhood being.

(02:10:53)
And we would lie on the blanket and look at the clouds and reflect upon the shapes of the clouds and study the shapes of the plants, and there was a lot of wonder in that childhood with her. And she taught me the importance of wonder in an eternal childhood and living adulthood as a child. And so I am very, very grateful for that. I think it is the sense of wonder, the speaking up was always something that she adhered to, to speak up your truth, to be straightforward, to be positive.

(02:11:42)
These are things that I also got from my mom. And from my mom, the sense of humor. She had the best sense of humor that I could think of and was just a joy to be around. And my father taught me everything. My father taught me everything I know. My mom taught me everything I feel.
Lex Fridman

(02:12:02)
That’s a good way to put it.
Neri Oxman

(02:12:02)
My grandma taught me everything I insight.
Lex Fridman

(02:12:08)
Well, I see the sense of wonder that just carries through everything you do. So I think you make your grandmother proud.

(02:12:17)
Well, what about advice for how to have a career? You’ve had a very interesting career and a successful career, but not an easy one. You took a few leaps.
Neri Oxman

(02:12:29)
I did take a few leaps and they were uncomfortable. And I’ll never forget, I think we were listening to a Rolling Stone song in the kitchen, and my dad was actually born in Boston. He’s American. He said, “I started to have sort of these second thoughts about continuing my education in Israel, and I was on my way to London to the Architectural Association to do my diploma studies there.” And he looked at me and he said, “Get out of here kiddo. You got to get out of here. You’ve outgrown where you’re at. You need to move forward.”

(02:13:16)
Another thing he had taught me, the feeling of discomfort. As you say, the feeling of loneliness and discomfort is imperative to growth. Growth is painful. Period. Any form of growth is difficult and painful. Birth is difficult and painful, and it is really, really important to place yourself in situations of discomfort. I like to be in a room where everyone in the room is more intelligent than me. I like to be in that kind of state where the people that I surround myself with are orders of magnitude more intelligent than I am. And I can say that that is true of all of my team members, and that’s the intellectual discomfort that I feed off of. The same is true for physical exertion. You got to put yourself in these uncomfortable situations in order to grow, in order to find comfort.

(02:14:19)
And then on the other hand is love, is finding love and finding this other human that compliments you and that makes you a better version of the one you are and even of the one you want to be. But with gratitude and attention and love, you can go so, so far.

(02:14:51)
To the younger generation, I don’t speak of a career. I never thought of my work as my career, ever. And there was this constant entanglement between life and work and love and longing and being and mothering. It’s all the same. And I appreciate that to some people that doesn’t work in their arrangement of will versus comfort versus the reality. But for me, it has always worked. I think to the younger generation, I say, don’t think of your career. A career is something that is imposed upon you. Think of your calling. That’s something that’s innately and directionally moves you, and it’s something that transcends a career.

(02:15:47)
Similarly, you can think about the difference between learning versus being educated. Being educated is something that’s given to you that’s external, that’s being imposed, that’s top down imposed, whereas learning is something that comes from within. It’s also the difference between joy and happiness. Many times I’m sad and I’m still joyous. And it’s very, very important to understand the difference between these externally perceived success paths and internally driven value-based ways of being in the world.

(02:16:22)
And together, when we combine the broken puzzle, let’s say, of substance and vulnerability, we get this bigger gestalt, this wondrous world of a future that is peaceful, that is wholesome, and that proposes or advocates for that kind of synergy that we’ve been talking about throughout. But it’s all fun.
Lex Fridman

(02:17:01)
Well, thank you for this incredible conversation. Thank you for all the work you’re doing.
Neri Oxman

(02:17:05)
Thank you.
Lex Fridman

(02:17:06)
And I just have to say that thank you for noticing me and listening to me. You’re somebody from just today and from our exchanges before this, there’s a sense where you care about me as a human being, which I could tell you care about other humans. Thank you for doing that. Thank you for having empathy and just really listening and noticing me that I exist. Thank you for that. I’ve been a huge fan of your work, been a huge fan of who you are as a human being. It’s just an honor that you would sit with me. Thank you.
Neri Oxman

(02:17:40)
Thank you so much, Lex. I feel the same way. I’ll just say the same.
Lex Fridman

(02:17:46)
And I look forward to hearing the response to my job application that I’ve submitted.
Neri Oxman

(02:17:50)
Oh, you’re accepted.
Lex Fridman

(02:17:51)
Oh, damn. All right, excellent.
Neri Oxman

(02:17:53)
We all speak of you all the time.
Lex Fridman

(02:17:55)
Thank you so much.
Neri Oxman

(02:17:55)
Thank you, Lex.
Lex Fridman

(02:17:56)
Thank you, Neri. Thank you.

(02:17:58)
Thanks for listening to this conversation with Neri Oxman. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Leo Tolstoy, “Everything I know, I know because of love.” Thank you for listening. I hope to see you next time.
Transcript for Andrew Huberman: Relationships, Drama, Betrayal, Sex, and Love | Lex Fridman Podcast #393
This is a transcript of Lex Fridman Podcast #393 with Andrew Huberman.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
1:31 – Exercise routine
7:42 – Advice to younger self
14:56 – Jungian shadow
19:42 – Betrayal and loyalty
39:52 – Drama
57:31 – Chimp Empire
1:02:24 – Overt vs covert contracts
1:08:31 – Age and health
1:14:39 – Sexual selection
1:25:15 – Relationships
1:37:49 – Fertility
1:48:15 – Productivity
2:05:02 – Family

Introduction
Andrew Huberman

(00:00:00)
Listen, when it comes to romantic relationships, if it’s not a 100% in you, it ain’t happening. And I’ve never seen a violation of that statement where it’s like, “Yeah, it’s mostly good.” And this is like the negotiations, already it’s doomed. And that doesn’t mean someone has to be perfect. The relationship has to be perfect, but it’s got to feel a 100% inside, like yes, yes, and yes.
Lex Fridman

(00:00:29)
The following is a conversation with my dear friend Andrew Huberman, his fourth time on this podcast. It’s my birthday, so this is a special birthday episode of sorts. Andrew flew down to Austin just to wish me a happy birthday, and we decided to do a podcast last second. We literally talked for hours beforehand and a long time after late into the night. He’s one of my favorite human beings, brilliant scientists, incredible teacher, and a loyal friend. I’m grateful for Andrew. I’m grateful for good friends, for all the support and love I’ve gotten over the past few years. I’m truly grateful for this life, for the years, the days, the minutes, the seconds I’ve gotten to live on this beautiful earth of ours. I really don’t want to leave just yet. I think I’d really like to stick around. I love you all. This is the Lex Fridman podcast. And now, dear friends, here’s Andrew Huberman.
Exercise routine
Andrew Huberman

(00:01:30)
I’m trying to run a little bit more.
Lex Fridman

(00:01:34)
Are you losing weight?
Andrew Huberman

(00:01:35)
I’m not trying to lose weight, but I always do the same fitness routine after 30 years. Basically lift three days a week, run three days a week, but one of the runs is the long run, one of them is medium, one of them is a sprint type thing. So what I’ve decided to do this year was just extend the duration of the long run. And I like being mobile. I never want to be so heavy that I can’t move. I want to be able to go out and run 10 miles if I have to so sometimes I do. And I want to be able to sprint if I have to. So sometimes I do.

(00:02:10)
And lifting in objects feels good. It feels good to train like a lazy bear and just lift heavy objects. But I’ve also started training with lighter weights and higher repetitions and for three month cycles, and it gives your joints a rest. Yeah, so I think it also is interesting to see how training differently changes your cognition. That’s probably hormone related, hormones downstream of training heavy versus hormones downstream of training a little bit lighter. I think my cognition is better when I’m doing more cardio and when the repetition ranges are a little bit or higher, which is not to say that people who lift heavy are dumb, but there is a… Because there’s real value in lifting heavy.
Lex Fridman

(00:02:55)
There’s a lot of angry people listening to this right now.
Andrew Huberman

(00:02:57)
No, no, no. But lifting heavy and then taking three to five minutes rest is far and away a different challenge than running hard for 90 minutes. That’s a tough thing, just like getting in an ice bath. People say, “Oh, well, how is that any different than working out?” Well, there are a lot of differences, but one of them is that it’s very acute stress, within one second you’re stressed. So I think subjecting the body to a bunch of different types of stressors in space and time is really valuable. So yeah, I’ve been playing with the variables in a pre systematic way.
Lex Fridman

(00:03:30)
Well, I like long and slow like you said, the impact it has on my cognition.
Andrew Huberman

(00:03:37)
Yeah, the wordlessness of it, the way it seems to clean out the clutter.
Lex Fridman

(00:03:46)
Yeah.
Andrew Huberman

(00:03:47)
It can take away that hyperfocus and put you more in a relaxed focus for sure.
Lex Fridman

(00:03:53)
Well, for me, it brings the clutter to the surface at first. Like all these thoughts come in there, and then they dissipate. I got knee barred pretty hard. That’s when somebody tries to break your knee.
Andrew Huberman

(00:04:04)
What a knee bar? They try and break your knee?
Lex Fridman

(00:04:04)
Yeah.
Andrew Huberman

(00:04:06)
Oh, so you tap so they-
Lex Fridman

(00:04:07)
Yeah. Yeah. So it’s hyperextend the knee in that direction, they got knee barred pretty hard. So in ways I don’t understand, it kind of hurts to run. I don’t understand what’s happening behind there. I need to investigate this. Basically the hamstringing flex, like curling, your leg hurts a little bit, and that results in this weird, dull, but sometimes extremely sharp pain in the back of the knee. So I’m working through this anyway, but walking doesn’t hurt.

(00:04:38)
So I’ve been playing around with walking recently for two hours and thinking because I know a lot of smart people throughout history, I have walked and thought, and you have to play with things that have worked for others, not just to exercise, but to integrate this very light kind of prolonged exercise into a productive life. So they do all their thinking while they walk. It’s like a meditative type of walking, and it’s really interesting. It really works.
Andrew Huberman

(00:05:09)
Yeah. The practice I’ve been doing a lot more of lately is I walk while reading a book in the yard. I’ll just pace back and forth or walk in a circle.
Lex Fridman

(00:05:18)
Audiobook, or are you talking about anything-
Andrew Huberman

(00:05:20)
No hard copy.
Lex Fridman

(00:05:20)
Well, you just holding.
Andrew Huberman

(00:05:22)
I’m holding the book and I’m walking and I’m reading, and I usually have a pen and I’m underlining. I have this whole system like underlining, stars, exclamation points, goes back to university of what things I’ll go back to which things I export to notes and that kind of thing. But from the beginning when I opened my lab at that time in San Diego before I moved back to Stanford, I would have meetings with my students or postdocs by just walking in the field behind the lab. And I’d bring my bulldog Costello, bulldog Mastiff at the time, and he was a slow walker. So these were slow walks, but I can think much more clearly that way. There’s a Nobel Prize winning professor at Columbia University School of Medicine, Richard Axel, who won the Nobel Prize, co-won Nobel Prize with Linda Buck for the discovery of the molecular basis of olfaction.

(00:06:09)
And he walks in, voice dictates his papers. And now with Rev or these other, maybe there are better ones than Rev, where you can convert audio files into text very quickly and then edit from there. So I will often voice dictate first drafts and things like that. And I totally agree on the long runs, the walks, the integrating that with cognitive work, harder to do with sprints and then the gym. You weight train?
Lex Fridman

(00:06:36)
Yeah.
Andrew Huberman

(00:06:36)
You just seem naturally strong and thicker jointed. It’s true, it’s true.
Lex Fridman

(00:06:40)
Yeah.
Andrew Huberman

(00:06:41)
I mean, we did the one very beginner because I’m a very beginner of jiu jitsu class together, and as I mentioned then, but if people missed it, Lexus freakishly strong.
Lex Fridman

(00:06:52)
I think I was born genetically to hug people.
Andrew Huberman

(00:06:55)
Oh, like Costello.
Lex Fridman

(00:06:56)
Exactly.
Andrew Huberman

(00:06:57)
You guys have a certain similarity. He had wrists like it’s like you know. You and Jocko and Costello have these wrists and elbows that are super thick. And then when you look around, you see tremendous variation. Some people have the wrist width of a Whippet or Woody Allen, and then other people like you or Jocko. There’s this one Jocko video or thing on GQ or something. Have you seen the comments on Jocko, These are the Best?
Lex Fridman

(00:07:21)
No.
Andrew Huberman

(00:07:22)
The comments, I love the comments on YouTube because occasionally they’re funny because. The best is when Jocko was born, the doctor looked at his parents and said, “It’s a man.”
Lex Fridman

(00:07:35)
It’s like Chuck Norris type comments.
Andrew Huberman

(00:07:36)
Oh yeah. Those are great. That’s what I miss about Rogan being on YouTube with the full-length episode. Oh, that comment.
Advice to younger self
Lex Fridman

(00:07:42)
So this is technically a birthday podcast. What do you love most about getting older?
Andrew Huberman

(00:07:50)
It’s like the confirmation that comes from getting more and more data, which basically says, ” Yeah, the first time you thought that thing, it was actually right because the second, third and fourth and fifth time, it turned out the exact same way.” In other words, there have been a few times in my life where I did not feel easy about something. I felt a signal for my body, “This is not good.” And I didn’t trust it early on, but I knew it was there.

(00:08:25)
And then two or three bad experiences later, I’m able to say, “Ah, every single time there was a signal from the body informing my mind, this is not good.” Now the reverse has also been true that there’ve been a number of instances in which I feel there sort of immediate delight, and there’s this almost astonishingly simple experience of feeling comfortable with somebody or at peace with something or delighted at an experience. And it turns out literally all of those experiences and people turned out to be experiences and people that are still in my life and that I still delight in every day. In other words, what’s great about getting older is that you stop questioning the signals that come from, I think deeper recesses of your nervous system to say, “Hey, this is not good,” or, “Hey, this is great, more of this.” Whereas I think in my teens, my twenties, my thirties, I’m almost 48, I’ll be 48 next month.

(00:09:34)
I didn’t trust, I didn’t listen. I actually put a lot of work into overriding those signals and learning to fight through them, thinking that somehow that was making me tougher or somehow that was making me smarter. When in fact, in the end, those people that you meet that are difficult or there are other names for it, like in the end, you’re like, “That person’s a piece of shit,” or, “This person is amazing and they’re really wonderful.” And I felt that from the go.
Lex Fridman

(00:10:03)
So you’ve learned to trust your gut versus the influences of other people’s opinions?
Andrew Huberman

(00:10:09)
I’ve learned to trust my gut versus the forebrain over analysis, overriding the gut. Other people often in my life have had great optics. I’ve benefited tremendously from an early age of being in a large community. It’s been mostly guys, but I have some close female friends and always have as well who will tell me, “That’s a bad decision,” or, “This person not so good,” or, “Be careful,” or, “They’re great,” or, “That’s great.” So oftentimes my community and the people around me have been more aligned with the correct choice than not.
Lex Fridman

(00:10:44)
Is it really?
Andrew Huberman

(00:10:45)
Yes.
Lex Fridman

(00:10:45)
Really? When you were younger like friends, parents and so on.
Andrew Huberman

(00:10:50)
I don’t recall ever really listening to my parents that much. I grew up in… We don’t have to go back to my childhood thing-
Lex Fridman

(00:10:50)
My fault Andrew.
Andrew Huberman

(00:10:56)
… but my sense was that… Thank you. I learned that recently in a psilocybin journey, my first high dose psilocybin journey, which was-
Lex Fridman

(00:11:06)
Welcome back.
Andrew Huberman

(00:11:06)
… done with a clinician. Thank you very much. Thank you. I was worried there for a second at one point. “Am I not coming back?” But in any event, yeah, I grew up with some wild kids. I would say about a third of my friends from childhood are dead or in jail, about a third have gone on to do tremendously impressive things, start companies, excellent athletes, academics, scientists, and clinicians. And then about a third are living their lives as more typical. I just mean that they are happy family people with jobs that they mainly serve the function to make money. They’re not into their career for career’s sake.

(00:11:49)
So some of my friends early on gave me some bad ideas, but most of the time my bad ideas came from overriding the signals that I knew that my body, and I would say my body and brain were telling me to obey, and I say body and brain is that there’s this brain region, the insula, which does many things, but it represents our sense of internal sensation and interoception. And I was talking to Paul Conte about this, who as you know, I respect tremendously. I think he’s one of the smartest people I’ve ever met. I think for different reasons. He and Marc Andreessen are some of the smartest people I’ve ever met. But Paul’s level of insight into the human psyche is absolutely astounding. And he says the opposite of what most people say about the brain, which is most people say, “Oh, the supercomputer of the brain is the forebrain.”

(00:12:48)
It’s like a monkey brain with a extra real estate put on there. And the forebrain is what makes us human and gives us our superpowers. Paul has said, and he’s done a whole series on mental health that’s coming out from our podcast in September, so this is not an attempt to plug that, but he’ll elaborate on [inaudible 00:13:08].
Lex Fridman

(00:13:08)
Wait, you’re doing a thing with Paul?
Andrew Huberman

(00:13:09)
We already did. Yeah.
Lex Fridman

(00:13:09)
Oh, nice.
Andrew Huberman

(00:13:10)
So Paul Conte, he and I sat down, he did a four episode series on mental health. This is not mental illness mental health, about how to explore one’s own subconscious, explore the self, build and cultivate the generative drive. You’ll learn more about what that is from him. He’s far more eloquent and clearer than I am, and he provides essentially a set of steps to explore the self that does not require that you work with a therapist.

(00:13:39)
This is self-exploration that is rooted in psychiatry, it’s rooted in neuroscience, and I don’t think this information exists anywhere else. I’m not aware that it exists anywhere else. And he essentially distills it all down to one eight and a half by 11 sheet, which we provide for people. And he says there, I don’t want to give too much away because I would detract from what he does so beautifully, but if I tried and I wouldn’t have accomplish it anyway.

(00:14:09)
But he said, and I believe that the subconscious is the supercomputer of the brain. All the stuff working underneath our conscious awareness that’s driving our feelings and what we think are the decisions that we’ve thought through so carefully. And that only by exploring the subconscious and understanding it a little bit, can we actually improve ourselves over time and I agree. I think that so the mistake is to think that thinking can override it all. It’s a certain style of introspection and thinking that allows us to read the signals from our body, read the signals from our brain, integrate the knowledge that we’re collecting about ourselves, and to use all that in ways that are really adaptive and generative for us.
Jungian shadow
Lex Fridman

(00:14:56)
What do you think is there in that subconscious? What do you think of the Jungian and shadow? What’s there?
Andrew Huberman

(00:15:03)
There’s this idea, as you’re familiar with too. I’m sure that this Jungian idea that we all have all things inside of us, that all of us have the capacity to be evil, to be good, et cetera, but that some people express one or the other to a greater extent. But he also mentioned that there’s a unique category of people, maybe 2 to 5% of people that don’t just have all things inside of them, but they actually spend a lot of time exploring a lot of those things. The darker recesses, the shadows, their own shadows.

(00:15:31)
I’m somebody who’s drawn to goodness and to light and to joy and all those things like anybody else. But I think maybe it was part of how I grew up. Maybe it was the crowd I was with, but then again, even when I started spending more time with academics and scientists, I mean you see shadows in other ways, right? You see pure ambition with no passion. I recall a colleague in San Diego who it was very clear to me did not actually care about understanding the brain, but understanding the brain was just his avenue to exercise ambition. And if you gave him something else to work on, he’d work on that.

(00:16:12)
In fact, he did. He left and he worked on something else, and I realized he has no passion for understanding the brain like I assumed all scientists do, certainly why I went into it. But some people, it’s just raw ambition. It’s about winning. It doesn’t even matter what they win, which to me is crazy. But I think that’s a shadow that some people explore, not one I’ve explored. I think the shadow parts of us are very important to come to understand and look better to understand them and know that they’re there and work with them than to not acknowledge their presence and have them surface in the form of addictions or behaviors that damage us in other people.
Lex Fridman

(00:16:52)
So one of the processes for achieving mental health is to bring those things to the surface. So fish the subconscious mind.
Andrew Huberman

(00:16:58)
Yes, and Paul describes 10 cupboards that one can look into for exploring the self. There’s the structure of self and the function of self. Again, this will all be spelled out in this series in a lot of detail. Also in terms of its relational aspect between people, how to pick good partners and good relationship. It gets really into this from a very different perspective. Yeah, fascinating stuff. I was just sitting there. I will say this, that four episode series with Paul is at least to date, the most important work I’ve ever been involved in in all of my career because it’s very clear that we are not taught how to explore our subconscious and that very few people actually understand how to do that. Even most psychiatrists, he mentioned something about psychiatrists. If you’re a cardiothoracic surgeon or something like that and 50% of your patients die, you’re considered a bad cardiothoracic surgeon.

(00:17:53)
But with no disrespect to psychiatrists, there are some excellent psychiatrists out there. There are also a lot of terrible psychiatrists out there because unless all of their patients commit suicide or half commit suicide, they can treat for a long time without it becoming visible that they’re not so good at their craft. Now, he’s superb at his craft, and I think he would say that yes, exploring some shadows, but also just understanding the self, really understanding like, “Who am I? And what’s important? What are my ambitions? What are my strivings?” Again, I’m lifting from some of the things that he’ll describe exactly how to do this. People do not spend enough time addressing those questions, and as a consequence, they discover what resides in their subconscious through the sometimes bad, hopefully also good, but manifestations of their actions.

(00:18:50)
We are driven by this huge 90% of our real estate that is not visible to our conscious awareness. And we need to understand that. I’ve talked about this before. I’ve done therapy twice a week since I was a kid. I had to as a condition of being let back in school. I found a way to either through insurance or even when I didn’t have insurance, I took an extra job writing for Thrasher Magazine when I was a postdoc so I could pay for therapy at a discount because I didn’t make much money as a postdoc.

(00:19:20)
I mean, I think for me, it’s as important as going to the gym and people think it’s just ruminating on problems, or getting… No, no, no. If you work with somebody really good, they’re forcing you to ask questions about who you really are, what you really want. It’s not just about support, but there should be support. There should be rapport, but then it’s also, there should be insight, right? Most people who get therapy, they’re getting support, there’s rapport, but insight is not easy to arrive at, and a really good psychologist or psychiatrist can help you arrive at deep insights that transform your entire life.
Betrayal and loyalty
Lex Fridman

(00:19:56)
Well, sometimes when I look inside and I do this often exploring who you truly are, you come to this question, do I accept… Once you see parts, do I accept this or do I fix this? Is this who you are fundamentally, and it will always be this way, or is this a problem to be fixed? For example, one of the things, especially recently, but in general over time I’ve discovered about myself probably has roots in childhood, probably has roots in a lot of things, is I deeply value loyalty maybe more than the average person. And so when there’s disloyalty, it can be painful to me. And so this is who I am, and so do I have to relax a bit? Do I have to fix this part or is this who you are? And there’s a million, that’s one little…
Andrew Huberman

(00:20:53)
I think loyalty is a good thing to cling to, provided that when loyalty is broken, that it doesn’t disrupt too many other areas of your life. But it depends also on whose disrupting that loyalty, if it’s a coworker versus a romantic partner versus your exclusive romantic partner, depending on the structure of your romantic partner life. I mean, I have always experienced extreme joy and feelings of safety and trust in my friendships. Again, mostly male friendships, but female friendships too, which is only to say that they were mostly male friendships. The female friendships have also been very loyal. So getting backstabbed is not something I’m familiar with. And yeah, I love being crewed up.
Lex Fridman

(00:21:43)
Yeah. No, for sure. And I’m with you and you and I very much have the same values on this, but that’s one little thing. And then there’s many other things like I’m extremely self-critical and I look at myself as I’m regularly very self-critical, a self-critical engine in my brain. And I talked to actually Paul about this, I think on the podcast quite a bit. And he’s saying, “This is a really bad thing. You need to fix this. You need to be able to be regularly very positive about yourself.” And I kept disagreeing with him, “No, this is who I am,” and he seems to work. Don’t mess with a thing that seems to be working. It’s fine.

(00:22:24)
I oscillate between being really grateful and really self-critical. But then you have to figure out what is it? Maybe there’s a deeper root thing. Maybe there’s an insecurity in there somewhere that has to do with childhood and then you’re trying to prove something to somebody from your childhood, this kind of thing.
Andrew Huberman

(00:22:39)
Well, a couple of things that I think are hopefully valuable for people here. One is one way to destroy your life is to spend time trying to control your or somebody else’s past. So much of our destructive behavior and thinking comes from wanting something that we saw or did or heard to not be true, rather than really working with that and getting close to what it really was. Sometimes those things are even traumatic, and we need to really get close to them and for them to move through us. And there are a bunch of different ways to do that with support from others and hopefully, but sometimes on our own as well.

(00:23:23)
I don’t think we can rewire our deep preferences and what we find despicable or joyful. I do think that it’s really a question of what allows us peace. Can you be at peace with the fact that you’re very self-critical? And enjoy that, get some distance from it, have a sense of humor about it, or is it driving you in a way that’s keeping you awake at night and forcing you back to the table to do work in a way that feels self-flagellating and doesn’t feel good?

(00:23:52)
Can you get that humility and awareness of your one’s flaws? And I think that that can create, this word space sounds very new, edgy, like get space from it. You can have a sense of humor about how neurotic we can all be. I mean, neurotic isn’t actually a bad term in the classic sense of the psychologists and psychiatrists, the freudians. So that the best case is to be neurotic, to actually see one’s own issues and work with them. Whereas psychotic is the other way to be, which is obviously not good. So I think the question whether or not to work on something or to just accept it as part of ourselves, I think really depends if we feel like it’s holding us back or not. And I think you’re asking perhaps the most profound question about being a human, which is what do you do with your body? What do you do with your mind?

(00:24:45)
I mean, it’s also a question. We started off talking about fitness a little bit just for whatever reason. Do I need to run an ultra marathon? I don’t feel like I need to. David Goggins does and does a whole lot more than that. So that for him, that’s important. For me, it’s not important to do that. I don’t think he does it just so he can run the ultras. There’s clearly something else in there for him. And guys like Cam Hanes and tremendous respect for what they do and how they do it. Does one need to make their body more muscular, stronger, more endurance, more flexibility? Do you need to read harder books? I think doing hard things feels good. I know it feels good. I know that the worst I feel, the worst way to feel is when I’m procrastinating and I don’t do something.

(00:25:43)
And then whenever I do something and I complete it and I break through that point where it was hard and then I’m doing it at the end, I actually feel like I was infused with some sort of super chemical. And who knows if it’s probably a cocktail of endogenously made chemicals. But I think it is good to do hard things, but you have to be careful not to destroy your body, your mind in the process. And I think it’s about whether or not you can achieve peace. Can you sleep well at night?

(00:26:09)
Stress isn’t bad if you can sleep well at night, you can be stressed all day, go, go, go, go, go, go, go. And it’ll optimize your focus. But can you fall asleep and stay deeply asleep at night? Being in a hard relationship. Some people say that’s not good. Other people like can you be at peace in that? And I think we all have different RPM. We all kind of idle at different RPM and some people are big mellow Costello and others need more friction in order to feel at peace. But I think ultimately what we want is to feel at peace.
Lex Fridman

(00:26:47)
Yeah, I’ve been through some really low points over the past couple of years, and I think the reason could be boiled down to the fact that I haven’t been able to find a place of peace, a place or people or moments that give deep inner peace. And I think you put it really beautifully. You have to figure out, given who you are, the various characteristics of your mind, all the things, all the contents of the cupboards, how to get space from it. And ultimately one good representation of that is to be able to laugh at all of it, whatever’s going on inside your mind to be able to step back and just kind of chuckle at the beauty and the absurdity of the whole thing.
Andrew Huberman

(00:27:36)
Yeah, and keep going. There’s this beautiful, as I mentioned, it seems like every podcast lately. I’m a huge Rancid fan. Mostly I just think Tim Armstrong’s writing is pure poetry and whether or not you like the music or not. And he’s written music for a lot of other people too. He doesn’t advertise that much because he’s humble but-
Lex Fridman

(00:27:57)
By the way, I went to a show of theirs like 20 years ago.
Andrew Huberman

(00:27:59)
Oh, yeah. I’m going to see them in Boston, September 18th. I’m literally flying there for… Where I’ll take the train up from New York. I’m going to meet a friend of mine named Jim Thiebaud, who’s a guy who owns a lot of companies, the skateboard industry. We’re meeting there, a couple of little kids to go see them play amazing, amazing people, amazing music.
Lex Fridman

(00:28:18)
Very intense.
Andrew Huberman

(00:28:19)
Very intense, but embodies all the different emotions. That’s why I love it. They have some love songs, they have some hate songs, they have some in. But going back to what you said, I think there’s a song, the first song on Indestructible album. I think he’s just talking about shock and disbelief of discovering things about people that were close to you. And I won’t sing it, but nor I wouldn’t dare. But there’s this one lyric that’s really stuck in my mind ever since that album came out in 2003, which is that, “Nothing’s what it seems so I just sit here laughing. I’m going to keep going on. I can’t get distracted.” There is this piece of like, you got to learn how to push out the disturbing stuff sometimes and go forward. And I remember hearing that lyric and then writing it down. And that was a time where my undergraduate advisor, who was a mentor and a father to me, blew his head off in the bathtub like three weeks before.

(00:29:26)
And then my graduate advisor, who I was working for at that time, who I loved and adored, was really like a mother to me. I knew her when she was pregnant with her two kids, died at 50, breast cancer. And then my postdoc advisor, first day of work at Stanford as a faculty member sitting across the table like this from him, had a heart attack right in front of me, died of pancreatic cancer at the end of 2017. And I remember just thinking, going back to that song there over and over and where people would… Yeah, I haven’t had many betrayals in life. I’ve had a few. But just thinking or seeing something or learning something about something, you just say you can’t believe it. And I mentioned that lyric off, that first song, Indestructible on that album because it’s just the raw emotion of like, “I can’t believe this. What I just saw is so disturbing, but I have to just keep going forward.”

(00:30:17)
There are certain things that we really do need to push not just into our periphery, but off into the gutter and keep going. And that’s a hard thing to learn how to do. But if you’re going to be functional in life, you have to. And actually just to get at this issue of do I change or do I embrace this aspect of self? About six months, it was April of this last year, I did some intense work around some things that were really challenging to me. And I did it alone, and it may have involved some medicine, and I expected to get peace through this. I was like, “I’m going to let go of it.” And I spent 11 hours just getting more and more frustrated and angry about this thing that I was trying to resolve.

(00:31:02)
And I was so unbelievably disappointed that I couldn’t get that relief. And I was like, “What is this? This is not how this is supposed to work. I’m supposed to feel peace. The clouds are supposed to lift.” And so a week went by and then another half week went by, and then someone whose opinion I trust very much. I explained this to them because I was getting a little concerned like, “What’s going on? This is worse, not better.” And they said, ” This is very simple. You have a giant blind spot, which is your sense of justice, Andrew, and your sense of anger are linked like an iron rod and you need to relax it.” And as they said that, I felt the anger dissipate. And so there was something that I think it is true. I have a very strong sense of justice and my sense of anger then at least was very strongly linked to it.

(00:31:58)
So it’s great to have a sense of justice, right? I hate to see people wrong. I absolutely do. And I’m human. I’m sure I’ve wronged people in my life. I know I have. They’ve told me, I’ve tried to apologize and reconcile where possible. Still have a lot of work to do. But where I see injustice, it draws in my sense of anger in a way that I think is just eating me up. But it was only in hearing that link that I wasn’t aware of before. It was in my subconscious, obviously. Did I feel the relaxation? There’s no amount of plant medicine or MDMA or any kind of chemical you can take that’s naturally just going to dissipate what’s hard for oneself if one embraces that or if one chooses to do it through just talk therapy or journaling or friends or introspection or all of the above. There needs to be an awareness of the things that we’re just not aware of.

(00:32:51)
So I think the answer to your question, do you embrace or do you fight these aspects of self is? I think you get in your subconscious through good work with somebody skilled. And sometimes that involves the tools I just mentioned in various combinations and you figure it out. You figure out if it’s serving you. Obviously it was not bringing me peace. My sense of justice was undermining my sense of peace. And so in understanding this link… Now, I would say, in understanding this link between justice and anger, now I think it’s a little bit more of you know, it’s not like a Twizzler stick bendy, but at least it’s not like an iron rod. When I see somebody wronged, I mean it used to just… Like immediately.
Lex Fridman

(00:33:33)
But you’re able to step back now. To me, the ultimate place to reach is laughter.
Andrew Huberman

(00:33:42)
I just sit here laughing. Exactly. That’s the lyric. I can’t believe it. “So I just sit here laughing. Can’t get distracted,” Just at some point but the problem I think in just laughing at something like that gives you distance, but the question is, do you stop engaging with it at that point? I experienced this…
Andrew Huberman

(00:34:00)
… to stop engaging with it at that point. I experienced this… I mean, recently I got to see how sometimes I’ll see something that’s just like, “What? This is crazy,” so I just laugh. But then, I continue to engage in it and it’s taking me off course. And so, there is a place where… I mean, I realize this is probably a kid show too so I want to keep it G-rated. But at some point, for certain things, it makes sense to go, “Fuck that.”
Lex Fridman

(00:34:27)
But also, laugh at yourself for saying, “Fuck that.”
Andrew Huberman

(00:34:31)
Yeah. And then, move on. So the question is do you get stuck or do you move on?
Lex Fridman

(00:34:36)
Sure, sure. But there’s a lightness of being that comes with laughter. I mean, I’ve gotten-
Andrew Huberman

(00:34:39)
Sure.
Lex Fridman

(00:34:40)
As you know, I spent the day with Elon today. He just gave me this burnt hair. Do you know what this is?
Andrew Huberman

(00:34:46)
I have no idea.
Lex Fridman

(00:34:47)
I’m sure there’s actually… There should be a Huberman Lab episode on this. It’s a cologne that’s burnt hair and it’s supposedly a really intense smell and it is.
Andrew Huberman

(00:34:56)
Give me a smell.
Lex Fridman

(00:34:56)
Please, it’s not going to leave your nose.
Andrew Huberman

(00:34:58)
That’s okay. Well, that’s okay. I’ll whiff it as if I were working a chemical in the lab-
Lex Fridman

(00:35:02)
You have to actually spray it on yourself because I don’t know if you can-
Andrew Huberman

(00:35:04)
So I’m reading an amazing book called An Immense World by Ed Yong. He won a Pulitzer for We Contain Multitudes or something like that, I think is the title of the other book. And the first chapter is all about olfaction and the incredible power that olfaction has. That smells terrible. I don’t even-
Lex Fridman

(00:35:22)
And it doesn’t leave you. For those listening, it doesn’t quite smell terrible. It’s just intense and it stays with you. This, to me, represents just laughing at the absurdity of it all so-
Andrew Huberman

(00:35:37)
I have to ask, so you were rolling jiu jitsu?
Lex Fridman

(00:35:38)
Yeah. We’re training. Yeah.
Andrew Huberman

(00:35:40)
So is that fight between Elon and Zuck actually going to happen?
Lex Fridman

(00:35:45)
I think Elon is a huge believer of this idea of the most entertaining outcome is the most likely and there is almost the sense that there’s not a free will. And the universe has a deterministic gravitational field pulling towards the most fun and he’s just a player in that game. So from that perspective, I think it seems like something like that is inevitable.
Andrew Huberman

(00:36:14)
Like a little scrap in the parking lot of Facebook or something like that?
Lex Fridman

(00:36:17)
Exactly.
Andrew Huberman

(00:36:18)
Sorry, Meta. But it looks like they’re training for real and Zuck has competed, right, in jiu jitsu?
Lex Fridman

(00:36:23)
So I think he is approaching it as a sport, Elon is approaching it as a spectacle. And I mean, the way he talks about it, he’s a huge fan of history. He talks about all the warriors that have fought throughout history. Look, he wants to really do it at the Coliseum. And the Coliseum is for 400 years, there’s so much great writing about this, I think over 400,000 people have died in the Coliseum, gladiators.

(00:36:52)
So this is this historic place that sheds so much blood, so much fear, so much anticipation of battle, all of this. So he loves this kind of spectacle and also, the meme of it, the hilarious absurdity of it. The two tech CEOs are battling it out on sand in a place where gladiators fought to the death and then bears and lions ate prisoners as part of the execution process.
Andrew Huberman

(00:37:21)
Well, it’s also going to be an instance where Mark Zuckerberg and Elon Musk exchange bodily fluids. They bleed. That’s one of the things about fighting. I think it was in that book. It’s a great book. Fighter’s Heart, where he talks about the sort of the intimacy of sparring. I only rolled jiu jitsu with you once but there was a period of time where I boxed which I don’t recommend.

(00:37:43)
I got hit. I hit some guys and definitely got hit back. I’d spar on Wednesday nights when I lived on San Diego. And when you spar with somebody, even if they hurt you, especially if they hurt you, you see that person afterwards and there’s an intimacy, right? It was in that book, Fighter’s Heart, where he explains, you’re exchanging bodily fluids with a stranger and you’re in your primitive mind and so there’s an intimacy there that persists so-
Lex Fridman

(00:38:13)
Well, you go together through a process of fear, anxiety like-
Andrew Huberman

(00:38:18)
Yeah. When they get you, you nod. I mean, you watch somebody catch somebody. Not so much in professional fighting, but if people are sparring, they catch you, you acknowledge that they caught you like, “He got me there.”
Lex Fridman

(00:38:29)
And on the flip side of that, so we trained and then after that, we played Diablo 4.
Andrew Huberman

(00:38:34)
I don’t know what that is. I don’t play video games. I’m sorry.
Lex Fridman

(00:38:37)
But it’s a video game, so it’s a pretty intense combat in the video… You’re fighting demons and dragons-
Andrew Huberman

(00:38:45)
Oh, okay. Last video game I played was Mike Tyson’s Punch-Out!!
Lex Fridman

(00:38:48)
There you go. That’s pretty close.
Andrew Huberman

(00:38:49)
I met him recently. I went on his podcast.
Lex Fridman

(00:38:51)
You went… Wait.
Andrew Huberman

(00:38:52)
It hasn’t come out yet.
Lex Fridman

(00:38:52)
Oh, it hasn’t come out? Okay.
Andrew Huberman

(00:38:54)
Yeah. I asked Mike… His kids are great. They came in there. They’re super smart kids. Goodness gracious. They ask great questions. I asked Mike what he did with the piece of Evander’s ear that he bit off.
Lex Fridman

(00:39:08)
Did he remember?
Andrew Huberman

(00:39:09)
Yeah. He’s like, “I gave it back to him.”
Lex Fridman

(00:39:09)
Here you go. Sorry about that.
Andrew Huberman

(00:39:14)
He sells edibles that are in the shape of ears with a little bite out of it. Yeah. His life has been incredible. He’s intimate. Yeah. His family, you get the sense that they’re really a great family. They’re really-
Lex Fridman

(00:39:30)
Mike Tyson?
Andrew Huberman

(00:39:30)
Mm-hmm.
Lex Fridman

(00:39:31)
That’s a heck of a journey right there of a man.
Andrew Huberman

(00:39:33)
Yeah. My now friend, Tim Armstrong, like I said, lead singer from Rancid. He put it best. He said that Mike Tyson’s life is Shakespearean, down, up, down, up and just that the arcs of his life are just… Sort of an only in America kind of tale too, right?
Drama
Lex Fridman

(00:39:52)
So speaking of Shakespeare, I’ve recently gotten to know Neri Oxman who’s this incredible scientist that works at the intersection of nature and engineering and she reminded me of this Anna Akhmatova line. This is this great Soviet poet that I really love from over a century ago that each of our lives is a Shakespearean drama raised to the thousand degree. So I have to ask, why do you think humans are attracted to this kind of Shakespearean drama? Is there some aspect we’ve been talking about the subconscious mind that pulls us towards the drama, even though the place of mental health is peace?
Andrew Huberman

(00:40:38)
Yes and yes.
Lex Fridman

(00:40:39)
Do you have some of that?
Andrew Huberman

(00:40:41)
Draw towards-
Lex Fridman

(00:40:42)
Drama?
Andrew Huberman

(00:40:42)
Drama? Yeah.
Lex Fridman

(00:40:45)
If you look at the empirical data.
Andrew Huberman

(00:40:46)
Yes, I mean… Right. If I look at the empirical data, I mean, I think about who I chose to work for as an undergraduate, right? I was a… Barely finished high school, finally get to college, barely… This is really embarrassing and not something to aspire to. I was thrown out of the dorms for fighting-
Lex Fridman

(00:41:05)
Nice.
Andrew Huberman

(00:41:05)
Barely passed my classes. The girlfriend and I split up. I mean, I was living in a squat, got into a big fight. I was getting in trouble with the law. I eventually got my act together, go back to school, start working for somebody. Who do I choose to work for? A guy who’s an ex-navy guy who smokes cigarettes in the fume hood, drinks coffee, and we’re injecting rats with MDMA. And I was drawn to the personality, his energy, but I also… He was a great scientist, worked out a lot on a thermal regulation in the brain and more.

(00:41:38)
Go to graduate school, I’m working for somebody, and decide that working in her laboratory wasn’t quite right for me. So I’m literally sneaking into the laboratory next door and working for the woman next door because I liked the relationships that she had to a certain set of questions and she was a quirky person. So drawn to drama but drawn to… I like characters. I like people that have texture. And I’m not drawn to raw ambition, I’m drawn to people that seem to have a real passion for what they do and a uniqueness to them that I… Not kind of, I’ll just say how it is. I can feel their heart for what they do and I’m drawn to that and that can be good.

(00:42:20)
It’s the same reason I went to work for Ben Barris as a post-doc. It wasn’t because he was the first transgender member of the National Academy of Sciences, that was just a feature of who he was. I loved how he loved glial. He would talk about these cells like they were the most enchanting things that he’d ever seen in his life. And I was like, “This is the biggest nerd I’ve ever met and I love him.” I think I’m drawn to that.

(00:42:42)
This is another thing that Conti elaborates on quite a bit more in the series on mental health coming out. But there are different drives within us, there are aggressive drives. Not always for fighting but for intense interaction. I mean, look at Twitter. Look at some of the… People clearly have an aggressive drive. There’s also a pleasure drive. Some people also have a strong pleasure drive. They want to experience pleasure through food, through sex, through friendship, through adventure. But I think the Shakespearean drama is the drama of the different drives in different ratios in different people.

(00:43:21)
I know somebody and she’s incredibly kind. Has an extremely high pleasure drive, loves taking great care of herself and people around her through food and through retreats and through all these things and makes spaces beautiful everywhere she goes. And gifts these things that are just so unbelievably feminine and incredible. These gifts to people and then kind and thoughtful about what they like. And then.. But I would say, very little aggressive drive from my read.

(00:43:53)
And then, I know other people who just have a ton of aggressive drive and very little pressure drive and I think… So there’s this alchemy that exists where people have these things in different ratios. And then, you blend in the differences in the chromosomes and differences in hormones and differences in personal history and what you end up with is a species that creates incredible recipes of drama but also peace, also relief from drama, contentment.

(00:44:21)
I mean, I realize this isn’t the exact topic of the question. But someone I know very dearly, actually an ex-girlfriend of mine, long- term partner of mine, sent me something recently and I think it hit the nail on the head. Which is that ideally for a man, they eventually settle where they find and feel peace, where they feel peaceful, where they can be themselves and feel peaceful. Now, I’m sure there’s an equivalent or mirror image of that for women but this particular post that she sent was about men and I totally agree.

(00:44:54)
And so, it isn’t always that we’re seeking friction. But for periods of our life, we seek friction, drama, adventure, excitement, fights, and doing hard, hard things. And then I think at some point, I’m certainly coming to this point now where it’s like, “Yeah. That’s all great and checked a lot of boxes.” But I had a lot of close calls, flew really close to the sun on a lot of things with life and limb and heart and spirit and some people close to us didn’t make it. And sometimes, not making it means the career they wanted went off a cliff or their health went off a cliff or their life went off a cliff. But I think that there’s also the Shakespearean drama of the characters that exit the play and are living their lives happily in the backdrop. It just doesn’t make for as much entertainment.
Lex Fridman

(00:45:49)
That’s one other thing, you could say, is the benefit of getting older is finding the Shakespearean drama less appealing or finding the joy in the peace.
Andrew Huberman

(00:46:01)
Yeah. Definitely. I mean, I think there’s real peace with age. I think the other thing is this notion of checking boxes is a real thing, for me anyway. I have a morning meditation that I do. Well, I wake up now, I get my sunlight, I hydrate, I use the bathroom. I do all the things that I talk about. I’ve started a practice of prayer in the last year which is new-ish for me which is we could talk about-
Lex Fridman

(00:46:27)
In the morning?
Andrew Huberman

(00:46:27)
Yeah.
Lex Fridman

(00:46:28)
Can you talk about it a little bit?
Andrew Huberman

(00:46:29)
Sure. Yeah. And then, I have a meditation that I do that actually is where I think through with the different roles that I play. So I start very basic. I say, “Okay. I’m an animal,” like we are biologically animals, human. “I’m a man. I’m a scientist. I’m a teacher. I’m a friend. I’m a brother. I’m a son,” I have this list and I think about the different roles that I have and the roles that I still want in my life going forward that I haven’t yet fulfilled. It just takes me… It’s an inventory of where I’ve been, where I’m at, and where I’m going as they say. And I don’t know why I do it but I started doing it this last year, I think, because it helps me understand just how many different contexts I have to exist in and remind myself that there’s still more that I haven’t done that I’m excited about.
Lex Fridman

(00:47:24)
So within each of those contexts, there’s things that you want to accomplish to define that.
Andrew Huberman

(00:47:30)
Yeah, and I’m ambitious so I think… I’m a brother. I have an older sister and I love her tremendously and I think, “I want to be the best brother I can be to her,” which means maybe a call, maybe just we do an annual trip together for our birthdays. Our birthdays are close together. We always go to New York for our birthdays and we’ve gone for the last three, four years. It’s like really reminding myself of that role not because I’ll forget, but because I have all these other roles I’ll get pulled into.

(00:47:53)
I say the first one, “I’m an animal,” because I have to remember that I have a body that needs care like any of us. I need sleep, I need food, I need hydration, I need… That I’m human, that the brain of a human is marvelously complex but also marvelously self-defeating at times. And so, I’m thinking about these things in the context of the different roles. And the whole thing takes about four or five minutes and I just find it brings me a certain amount of clarity that then allows me to ratchet into the day.

(00:48:22)
The prayer piece, I think I’ve been reluctant to talk about until now because I don’t believe in pushing religion on people. And I think that… And I’m not, it’s a highly individual thing and I do believe that one can be an atheist and still pray or agnostic and still pray. But for me, it really came about through understanding that there are certain aspects of myself that I just couldn’t resolve on my own. And no matter how much therapy, no matter how much… And I haven’t done a lot of it. But no matter how much plant medicine or other forms of medicine or exercise or podcasting or science or friendship or any of that, I was just not going to resolve.

(00:49:17)
And so, I started this because a male friend said, “Prayer is powerful,” and I said, “Well, how?” And he said, “I don’t know how but it can allow you to get outside yourself. Let you give up control and at the same time, take control.” I don’t even like saying take control. But the whole notion is that… And again, forgive me, but there’s no other way to say it. The whole notion is that God works through us. Whatever God is to you, he, him, her, life force, nature, whatever it is to you, that it works through us.

(00:49:59)
And so, I do a prayer. I’ll just describe it where I make an ask to help remove my character defects. I pray to God to help remove my character defects so that I can show up better in all the roles of my life and do good work which for me is learning and teaching. And so you might say, “Well, how is that different than a meditation?” Well, I’m acknowledging that there is something bigger than me, bigger than nature as I understand it, that I cannot understand or control nor do I want to, and I’m just giving over to that. And does that make me less of a scientist? I sure as hell hope not. I certainly know… There’s the head of our neurosciences at Stanford until recently. You should talk to him directly about it. Bill Newsome has talked about his religious life.

(00:50:52)
For me, it’s really a way of getting outside myself and then understanding how I fit into this bigger picture. And the character defects part is real, right? I’m a human. I have defects. I got a lot of flaws in me like anybody and trying to acknowledge them and asking for help in removing them. Not magically but through right action, through my right action. So I do that every morning.

(00:51:23)
And I have to say that it’s helped. It’s helped a lot. It’s helped me be better to myself, be better to other people. I still make mistakes but it’s becoming a bigger part of my life. And I never thought I’d talk like this but I think it’s clear to me that if we don’t believe in something… Again, it doesn’t have to be traditional, standardized religion, but if we don’t believe in something bigger than ourselves, we, at some level, will self-destruct. I really think so.

(00:52:04)
And it’s powerful in a way that all the other stuff, meditation and all the tools, is not because it’s really operating at a much deeper and bigger level. Yeah. I think that’s all I can talk about it. Mostly because I’m still working out. The scientists in me wants to understand how it works and I want to understand. And the point is to just go, for lack of a better language for it, “There’s a higher power than me and what I can control. I’m giving up control on certain things.” And somehow, that restores a sense of agency for right action and better action.
Lex Fridman

(00:52:46)
I think perhaps a part of that is just the humility that comes with acknowledging there’s something bigger and more powerful than you.
Andrew Huberman

(00:52:53)
And that you can’t control everything. I mean, you go through life as a hard driving person, forward center of mass. I remember being that way since I was little. It’s like in Legos. I’m like, “I’m going to make all the Legos.” I was like, on the weekends, learning about medieval weapons and then giving lectures about it in class when I was five or six years old or learning about tropical fish and cataloging all of them at the store. And then, organizing it and making my dad drive me or my mom drive me in some fish store and then spending all my time there until they throw me out. All of that. But I also remember my entire life, I would secretly pray when things were good and things weren’t good. But mostly, when things weren’t good because it’s important to pray. For me, it’s important to pray each morning regardless.

(00:53:35)
But when things weren’t right, I couldn’t make sense of them, I would secretly pray. But I felt ashamed of that for whatever reason. And then, it was once in college, I distinctly remember I was having a hard time with a number of things and I took a run down to SAN Speech. It was at UC Santa Barbara. And I remember I was like, “I don’t know if I even have the right to do this but I’m just praying,” and I just prayed for the ability to be as brutally honest with myself and with other people as I possibly could be about a particular situation I was in at that time.

(00:54:13)
I mean, I think now it’s probably safe to say I’d gone off to college because of a high school girlfriend. Essentially, she was my family. Frankly, more than my biological family was at a certain stage of life and we’d reached a point where we were diverging and it was incredibly painful. It was like losing everything I had. And it was like, “What do I do? How do I manage this?” I was ready to quit and join the fire service just to support us so that we could move forward and it was just…

(00:54:42)
But praying, just saying, “I can’t figure this out on my own.” It’s like, “I can’t figure this out on my own,” and how frustrating that no number of friends could tell me and inner wisdom couldn’t tell me. And eventually, it led me to the right answers. She and I are friendly friends to this day. She’s happily married with a child and we’re on good terms. But I think it’s a scary thing but it’s the best thing when you just, “I can’t control all of this.” And asking for help, I think is also the piece. You’re not asking for some magic hand to come down and take care of it but you’re asking for the help to come through you so that your body is used to do these right works, right action.
Lex Fridman

(00:55:24)
Isn’t it interesting that this secret thing that you’re almost embarrassed by, that you did as a child is something you… It’s another thing you do as you get older, is you realize those things are part of you and it’s actually a beautiful thing.
Andrew Huberman

(00:55:36)
Yeah. A lot of the content of the podcast is deep academic content and we talk about everything from eating disorders to bipolar disorder to depression, a lot of different topics. But the tools or the protocols, as we say, the sunlight viewing and all the rest, a lot of that stuff is just stuff I wish I had known when I was in graduate school. If I’d known to go outside every once in a while and get some sunlight, not just stay in the lab, I might not have hit a really tough round of depression when I was a post-doc and working twice as hard.

(00:56:09)
And when my body would break down or I’d get sick a lot, I don’t get sick much anymore. Occasionally, about once every 18 months to two years, I’ll get something. But I used to break my foot skateboarding all the time, I couldn’t understand. What’s wrong with my body? I’m getting injured. I can’t do what everyone else can. Now, I developed more slowly. I had a long arc of puberty so that was part of it. I was still developing.

(00:56:31)
But how to get your body stronger, how to build endurance, no one told me. The information wasn’t there. So a lot of what I put out there is the information that I wish I had. Because once I had it, I was like, “Wow.” A, this stuff really works. B, it’s grounded in something real. Sometimes, certain protocols are a combination of animal and human studies, sometimes clinical trials. Sometimes there’s some mechanistic conjecture for some, not all, I always make clear which. But in the end, figuring out how things work so that we can be happier, healthier, more productive, suffer less, reduce the suffering of the world. And I think that… Well, I’ll just say thank you for asking about the prayer piece. Again, I’m not pushing or even encouraging it on anyone. I’ve just found it to be tremendously useful for me.
Chimp Empire
Lex Fridman

(00:57:33)
I mean, about prayer in general. You said information and figuring out how to get stronger, healthier, smarter, all those kinds of things. A part of me believes that deeply. You can gain a lot of knowledge and wisdom through learning. But a part of me believes that all the wisdom I need was there when I was 11 and 12 years old.
Andrew Huberman

(00:57:57)
And then, it got cluttered over. Well, listen, I can’t wait for you and Conti to talk again. Because when he gets going about the subconscious and the amount of this that sits below the surface like an iceberg. And the fact that when we’re kids, we’re not obscuring a lot of that subconscious as much. And sometimes, that can look a little more primitive. I mean, a kid that’s disappointed will let you know. A kid that’s excited will let you know and you feel that raw exuberance or that raw dismayal.

(00:58:32)
And I think that as we grow older, we learn to cover that stuff up. We wear masks and we have to, to be functional. I don’t think we all want to go around just being completely raw. But as you said, as you get older, you get to this point where you go, “Eh. What are we really trying to protect anyway?”

(00:58:53)
I mean, I have this theory that certainly my experience has taught me that a lot of people but I’ll talk about men because that’s what I know best, whether or not they show up strong or not, that they’re really afraid of being weak. They’re just afraid… Sometimes, the strength is even a way to try and not be weak which is different than being strong for its own sake. I’m not just talking about physical strength. I’m talking about intellectual strength. I’m talking about money. I’m talking about expressing drive. I’ve been watching this series a little bit of Chimp Empire.
Lex Fridman

(00:59:34)
Oh, yeah.
Andrew Huberman

(00:59:35)
So Chimp Empire is amazing, right? They have the head chimp. He’s not the head chimp but the alpha in the group and he’s getting older. And so, what does he do? Every once in a while, he goes on these vigor displays. He goes and he grabs a branch. He starts breaking them. He starts thrashing them. And he’s incredibly strong and they’re all watching. I mean, I immediately think of people like they’re deadlifting on Instagram and I just think, “Displays of vigor.” This is just the primate showing displays of vigor. Now, what’s interesting is that he’s doing that specifically to say, “Hey, I still have what it takes to lead this troop.” Then there are the ones that are subordinate to him but not so far behind-
Lex Fridman

(01:00:18)
It seems to be that there’s a very clear numerical ranking.
Andrew Huberman

(01:00:21)
There is.
Lex Fridman

(01:00:22)
Like it’s clear who’s the Number 2, Number 3-
Andrew Huberman

(01:00:24)
Oh, yeah.
Lex Fridman

(01:00:24)
I mean, probably-
Andrew Huberman

(01:00:25)
Who gets to mate first, who gets to eat first, this exists in other animal societies too but Bob Sapolsky would be a great person to talk about this with because he knows obviously tremendous amount about it and I know just the top contour. But yeah, so Number 2, 3, and 4 males are aware that he’s doing these vigor displays. But they’re also aware because in primate evolution, they got some extra forebrain too. Not as much as us but they got some. And they’re aware that the vigor displays are displays that… Because they’ve done them as well in a different context, might not just be displays of vigor but might also be an insurance policy against people seeing weakness.

(01:01:04)
So now, they start using that prefrontal cortex to do some interesting things. So in primate world, if a male is friendly with another male, wants to affiliate with him and say, “Hey, I’m backing you,” they’ll go over and they’ll pick off the little parasites and eat them. And so, the grooming is extremely important. In fact, if they want to ostracize or kill one of the members of their troop, they will just leave it alone. No one will groom it. And then, there’s actually a really disturbing sequence in that show of then the parasites start to eat away on their skin. They get infections. They have issues. No one will mate with them. They have other issues as well and can potentially die.

(01:01:44)
So the interesting thing is Number 2 and 3 start to line up a strategy to groom this guy but they are actually thinking about overtaking the entire troop setting in a new alpha. But the current alpha did that to get where he is so he knows that they’re doing this grooming thing, but they might not be sincere about the grooming. So what does he do? He takes the whole troop on a raid to another troop and sees who will fight for him and who won’t.
Overt vs covert contracts

(01:02:14)
This is advanced contracting of behavior for a species that normally we don’t think of as sophisticated as us. So it’s very interesting and it gets to something that I hope we’ll have an opportunity to talk about because it’s something that I’m obsessed with lately, is this notion of overt versus covert contracts, right? There are overt contracts where you exchange work for money or you exchange any number of things in an overt way. But then, there are covert contracts, and those take on a very different form and always lead to, in my belief, bad things.
Lex Fridman

(01:02:47)
Well, how much of human and chimp relationships are overt versus covert?
Andrew Huberman

(01:02:53)
Well, here’s one thing that we know is true. Dogs and humans, the dog to human relationship is 100% overt. They don’t manipulate you. Now, you could say they do in the sense that they learn that if they look a certain way or roll on their back, they get food. But there’s no banking of that behavior for a future date where then they’re going to undermine you and take your position so in that sense. Dogs can be a little bit manipulative in some sense.

(01:03:23)
But now, okay. So overt contract would be we both want to do some work together, we’re going to make some money, you get X percentage, I get X percentage. It’s overt. Covert contract which is, in my opinion, always bad, would be we’re going to do some work together, you’re going to get a percentage of money, I’m going to get a percentage of money. Could look just like the overt contract but secretly, I’m resentful that I got the percentage that I got. So what I start doing is covertly taking something else. What do I take? Maybe I take the opportunity to jab you verbally every once in a while. Maybe I take the opportunity to show up late. Maybe I take the opportunity to get to know one of your coworkers so that I might start a business with them. That’s covert contracting.

(01:04:14)
And you see this sometimes in romantic relationships. One person, we won’t set the male or female in any direction here and just say it’s, “I’ll make you feel powerful if you make me feel desired.” Okay. Great. There’s nothing explicitly wrong about that contract if they both know and they both agree. But what if it’s, “I’ll do that but I’ll have kids with you so you feel powerful. You’ll have kids with me so I feel desired. But secretly, I don’t want to do that,” or one person says, “I don’t want to do that,” or both don’t. So what they end up doing is saying, “Okay. So I expect something else. I expect you to do certain things for me,” or, “I expect you to pay for certain things for me.”

(01:04:53)
Covert contracts are the signature of everything bad. Overt contracts are the signature of all things good. And I think about this a lot because I’ve seen a lot of examples of this. I’ve… Like anyone, we participate in these things whether or not we want to or not and the thing that gets transacted the most is… Well, I should say the things that get transacted the most are the overt things. You’ll see money, time, sex, property, whatever it happens to be, information. But what ends up happening is that when people, I believe, don’t feel safe, they feel threatened in some way, like they don’t feel safe in a certain interaction, what they do is they start taking something else while still engaging in the exchange. And I’ll tell you, if there’s one thing about human nature that’s bad, it’s that feature.

(01:05:57)
Why that feature? Or, “Is it a bug or a feature?” as you engineers like to say. I think it’s because we were allocated a certain extra amount of prefrontal cortex that makes us more sophisticated than a dog, more sophisticated than a chimpanzee, but they do it too. And it’s because it’s often harder, in the short term, to deal with the real sense of, “This is scary. This feels threatening,” than it is to play out all the iterations. It takes a lot of brain work. You’re playing chess and go simultaneously trying to figure out where things are going to end up and we just don’t know.

(01:06:37)
So it’s a way, I think, of creating a false sense of certainty. But I’ll tell you, covert contracts, the only certainty is that it’s going to end badly. The question is, how badly? Conversely, overt contracts always end well, always. The problem with overt contracts is that you can’t be certain that the other person is not engaging in a covert contract. You can only take responsibility for your own contracting.
Lex Fridman

(01:07:01)
Well, one of the challenges of being human is looking at another human being and figuring out their way of being, their behavior, which of the two types of contracts it represents because they look awfully the same on the surface. And one of the challenges of being human, the decision we all make is, are you somebody that takes a leap of trust and trust other humans and are willing to take the hurt or are you going to be cynical and skeptical and avoid most interactions until they, over a long period of time, prove your trust?
Andrew Huberman

(01:07:37)
Yeah. I never liked the phrase history repeats itself when it comes to humans because it doesn’t apply if the people or the person is actively working to resolve their own flaws. I do think that if people are willing to do dedicated, introspective work, go into their subconscious, do the hard work, have hard conversations, and get better at hard conversations, something that I’m-
Andrew Huberman

(01:08:00)
Have hard conversations and get better at hard conversations, something that I’m constantly trying to get better at. I think people can change, but they have to want to change.
Lex Fridman

(01:08:09)
It does seem like, deep down, we all can tell the difference between overt and covert. We have a good sense. I think one of the benefits of having this characteristic of mine, where I value loyalty, I’ve been extremely fortunate to spend most of my life in overt relationships and I think that creates a really fulfilling life.
Age and health
Andrew Huberman

(01:08:31)
But there’s also this thing that maybe we’re in this portion of the podcast now, but I’ve experienced this-
Lex Fridman

(01:08:36)
I should say that this is late at night, we’re talking about.
Andrew Huberman

(01:08:38)
That’s right, certainly late for me, but I’m two hours… I came in today on… I’m still in California time.
Lex Fridman

(01:08:43)
And we should also say that you came here to wish me a happy birthday. [inaudible 01:08:46].
Andrew Huberman

(01:08:47)
I did. I did and-
Lex Fridman

(01:08:48)
And the podcast is just a fun, last-minute thing I suggested.
Andrew Huberman

(01:08:51)
Yeah, some close friends of yours have arranged a dinner that I’m really looking forward to. I won’t say which night, but it’s the next couple of nights. Your circadian clock is one of the most robust features of your biology. I know you can be nocturnal or you can be diurnal. We know you’re mostly nocturnal, certain times of the year Lex, but there are very, very few people can get away with no sleep. Very few people can get away with a chaotic sleep-wake schedule. So you have to obey a 24-hour, AKA circadian, rhythm if you want to remain healthy of mind and body. We also have to acknowledge that aging is in linear, right? So-
Lex Fridman

(01:09:34)
What do you mean?
Andrew Huberman

(01:09:34)
Well, the degree of change between years 35 and 40, is not going to be the degree of change between 40 and 45. But I will say this, I’m 48 and I feel better in every aspect of my psychology and biology now, than I did when I was in my twenties. Yeah, quality of thought, time spent, physically, I can do what I did then, which probably says more about what I could do then than what I can do now. But if you keep training, you can continue to get better. The key is to not get injured, and I’ve never trained super hard. I’ve trained hard, but I’ve been cautious to not, for instance, weight train more than two days in a row. I do a split which is basically three days a week, and the other day’s a run, take one full day off, take a week off every 12 to 16 weeks. I’ve not been the guy hurling the heaviest weights or running the furthest distance, but I have been the guy who’s continuing to do it when a lot of my friends are talking about knee injuries, talking about-
Lex Fridman

(01:10:36)
Hey. Hey. Hey, hey.
Andrew Huberman

(01:10:36)
I’m just…
Lex Fridman

(01:10:37)
[inaudible 01:10:37], I-
Andrew Huberman

(01:10:38)
But of course, with sport you can’t account for everything the same way you can with fitness, and I have to acknowledge that. Unless one is powerlifting, weightlifting and running, you can get hurt, but it’s not like skateboarding where, if you’re going for it, you’re going to get hurt. That’s just, you’re landing on concrete and with jujitsu, people are trying to hurt you so that you say stop.
Lex Fridman

(01:11:03)
No, but [inaudible 01:11:04]-
Andrew Huberman

(01:11:03)
So with a sport it’s different, and these days, I don’t really do a sport any longer. I work out to stay fit. I used to continue to do sports, but I kept getting hurt and frankly now, a rolled ankle… I may put out a little small skateboard part in 2024 because people have been saying, “We want to see the kickflip.” Then I’ll just say, “Well, I’ll do a heel flip instead, but okay.” I might put out a little part because some of the guys that work on our podcast are from DC. I think by now, I should at least do it just to show I’m not making it up, and I probably will. But I think doing a sport is different. That’s how you get hurt-
Lex Fridman

(01:11:46)
[inaudible 01:11:46].
Andrew Huberman

(01:11:45)
Overuse and doing an actual sport, and so hat tip to those who do an actual sport.
Lex Fridman

(01:11:53)
And that’s a difficult decision a lot of people have to make. I have to make with jiujitsu, for example, if you just look empirically. I’ve trained really hard from all my life, in grappling sports and fighting sports and all this kind of stuff, and I’ve avoided injury for the most part. And I would say, I would attribute that to training a lot. Sounds counterintuitive, but training well and safely and correctly, keeping good form saying, “No,” when I need to say no, but training a lot, and taking it seriously. Now when it’s training, it’s really a side thing, I find that the injuries becomes a higher and higher probability.
Andrew Huberman

(01:12:34)
But when you’re just doing it every once in a while?
Lex Fridman

(01:12:35)
Every once in a while.
Andrew Huberman

(01:12:36)
Yeah. I think you said something really important, the saying, “No.” The times I have gotten hurt training, is when someone’s like, “Hey, let’s hop on this workout together,” and it becomes, let’s challenge each other to do something outrageous. Sometimes that can be fun though. I went up to Cam Hanes’ gym and he does these very high repetition weight workouts that are in circuit form. I was sore for two weeks, but I learned a lot and didn’t get injured, and yes, we ate bow-hunted elk afterwards.
Lex Fridman

(01:13:05)
Nice.
Andrew Huberman

(01:13:06)
Yeah.
Lex Fridman

(01:13:06)
But the injury has been a really difficult psychological thing for me because… So I’ve injured my pinky finger, I’ve injured my knee.
Andrew Huberman

(01:13:16)
Yeah, your kitchen is filled with splints.
Lex Fridman

(01:13:18)
Splints. I’m trying to figure out-
Andrew Huberman

(01:13:24)
It’s like if you look in Lex’s kitchen, there’s some really good snacks, I had some right before. He’s very good about keeping cold drinks in the fridge and all the water has element in it, which is great.
Lex Fridman

(01:13:35)
Yeah, yeah.
Andrew Huberman

(01:13:36)
I love that. But then there’s a whole hospital’s worth of splints.
Lex Fridman

(01:13:41)
Yeah, I’m trying to figure it out. So here’s the thing, you… The finger pop out like this, right? Pinky finger. I’m trying to figure out how do I splint in such a way that I can still program, still play guitar, but protect this torque motion that creates a huge amount of pain. And so [inaudible 01:13:58]-
Andrew Huberman

(01:13:58)
[inaudible 01:13:58] you have a jiujitsu injury.
Lex Fridman

(01:13:59)
Jiujitsu, but it’s probably more like a skateboarding-style injury, which is, it’s unexpected in a silly-
Andrew Huberman

(01:14:09)
It’s a thing that happens in a second. I didn’t break my foot doing anything important.
Lex Fridman

(01:14:13)
Yeah.
Andrew Huberman

(01:14:13)
I broke my fifth metatarpal stepping off a curb.
Lex Fridman

(01:14:18)
Yep.
Andrew Huberman

(01:14:19)
So that’s why they’re called accidents. If you get hurt doing something awesome, that’s a trophy that you have to work through. It’s part of your payment to the universe. If you get hurt stepping off a curb or doing something stupid, it’s called a stupid accident.
Sexual selection
Lex Fridman

(01:14:39)
Since we brought up Chimp Empire, let me ask you about relationships. I think we’ve talked about relationships.
Andrew Huberman

(01:14:44)
Yeah, I only date Homo sapiens.
Lex Fridman

(01:14:45)
Homo sapiens.
Andrew Huberman

(01:14:46)
It’s the morning meditation.
Lex Fridman

(01:14:49)
The night is still young. You are human. No, but you are also animal. Don’t sell yourself short.
Andrew Huberman

(01:14:55)
No, I always say listen, any discussion on the Huberman Lab Podcast, about sexual health or anything, will always the critical fours: consensual, age appropriate, context appropriate, species appropriate.
Lex Fridman

(01:15:06)
Species appropriate, wow. Can I just tell you about sexual selection? I’ve been watching Life in Color: With David Attenborough. I’ve been watching a lot of nature documentaries. Talking about inner peace, it brings me so much peace to watch nature, at its worst and at its best. So Life in Color is a series on Netflix where it presents some of the most colorful animals on earth, and tells their story of how they got there through natural selection. So you have the peacock with the feathers and it’s just such incredible colors. The peacock has these tail feathers, the male, that are gigantic and they’re super colorful and they’re these eyes on it. It’s not eyes, it’s eye-like areas. And they wiggle their ass to show the tail, they wiggle the tails.
Andrew Huberman

(01:15:55)
The eyespots, they’re called.
Lex Fridman

(01:15:56)
The eyespots, yes. Thank you. You know this probably way better than me, I’m just quoting David Attenborough.
Andrew Huberman

(01:15:56)
No, no, please continue.
Lex Fridman

(01:16:02)
But it’s just, I’m watching this and then the female is as boring looking as… She has no colors or nothing, but she’s standing there bored, just seeing this entire display. And I’m just wondering the entirety of life on earth… Well, not the entirety. Post bacteria, is like, at least in part, maybe in large part, can be described through this process of natural selection, of sexual selection. So dudes fighting and then women selecting. It seems like, just the entirety of that series shows some incredible birds and insects and shrimp. They’re all beautiful and colorful, and just-
Andrew Huberman

(01:16:46)
Mantis shrimp.
Lex Fridman

(01:16:46)
Mantis shrimp. They’re incredible, and it’s all about getting laid. It’s fascinating. There’s nothing like watching that and Chimp Empire to make you realize, we humans, that’s the same thing. That’s all we’re doing. And all the beautiful variety, all the bridges and the buildings and the rockets and the internet, all of that is, at least in part, a product of this kind of showing off for each other. And all the wars and all of this… Anyway, I’m not sure wat I’m asking. Oh, relationships.
Andrew Huberman

(01:17:22)
Well, right, before you ask about relationships, I think what’s clear is that every species, it seems, animal species, wants to make more of itself and protect its young.
Lex Fridman

(01:17:38)
Well, the protect its young, is non-obvious.
Andrew Huberman

(01:17:41)
So not destroy enough of itself that it can’t get more to reproductive competent age. I think that we healthy people have a natural reflex to protect children.
Lex Fridman

(01:18:00)
Well, I don’t know that-
Andrew Huberman

(01:18:00)
And those that can’t-
Lex Fridman

(01:18:03)
Wait a minute. Wait, wait, wait a minute. I’ve seen enough animals that are murdering the children of some other-
Andrew Huberman

(01:18:06)
Sure, there’s even siblicide. First of all, I just want to say that I was delighted in your delight, around animal kingdom stuff, because this is a favorite theme of mine as well. But there’s, for instance, some fascinating data on, for instance, for those that grew up on farms, they’ll be familiar with freemartins. You know about freemartins? They’re cows that have multiple calves inside them, and there’s a situation in which the calves will, if there’s more than one inside, will secrete chemicals that will hormonally castrate the calf next to them, so they can’t reproduce. So already in the womb they are fighting for future resources. That’s how early this stuff can start. So it’s chemical warfare in the womb, against the siblings. Sometimes there’s outright siblicide. Siblings are born, they kill one another. This also becomes biblical stories, right? There are instances of cuttlefish, beautiful cephalopods like octopuses, and that is the plural as we made clear.
Lex Fridman

(01:19:12)
Yeah, it’s a meme on the internet.
Andrew Huberman

(01:19:15)
Oh, yeah? That became a meme, our little discussion two years ago.
Lex Fridman

(01:19:18)
Yeah, it spread pretty quick.
Andrew Huberman

(01:19:19)
Oh, yeah.
Lex Fridman

(01:19:19)
And now we just resurfaced it. [inaudible 01:19:22].
Andrew Huberman

(01:19:22)
The dismay in your voice is so amusing. In any event, the male cuttlefish will disguise themselves as female cuttlefish, infiltrate the female cuttlefish group, and then mate with them, all sorts of types of covert operations.
Lex Fridman

(01:19:42)
Yep, there we go.
Andrew Huberman

(01:19:42)
So I think that…
Lex Fridman

(01:19:46)
Callbacks.
Andrew Huberman

(01:19:46)
It’s like a drinking game, where every time we say covert contract, in this episode, you have to take a shot of espresso. Please don’t do that. You’d be dead by the end. [inaudible 01:19:56].
Lex Fridman

(01:19:56)
So it actually is just a small tangent, it does make me wonder how much intelligence covert contracts require. It seems like not much. If you can do it in the animal kingdom, there’s some kind of instinctual… It is based perhaps in fear.
Andrew Huberman

(01:20:10)
Yeah, it could be simple algorithm. If there’s some ambiguity about numbers and I’m not with these guys, and then flip to the alternate strategy. I actually have a story about this that I think is relevant. I used to have cuttlefish in my lab in San Diego. We went and got them from a guy out in the desert. We put them in the lab. It was amazing. And they had a postdoc who was studying prey capture in cuttlefish. They have a very ballistic, extremely rapid strike and grab of the shrimp, and we were using high-speed cameras to characterize all this. Looking at binocular, they normally have their eyes on the side of their head, when they see something they want to eat the eyes translocate to the front, which allows them stereopsis death perception, allows them to strike. We were doing some unilateral eye removals they would miss, et cetera.

(01:20:56)
Okay, this has to do with eyespots. This was during a government shutdown period where the ghost shrimp that they normally feed eat on, that we would ship in from the gulf down here, weren’t available to us. So we had to get different shrimp. And what we noticed was the cuttlefish normally would just sneak up on the shrimp. We learned this by data collection. And if the shrimp was facing them, they would do this thing with their tentacles of enchanting the shrimp. And if the shrimp wasn’t facing them, they wouldn’t do it and they would ballistically grab it and eat them.

(01:21:33)
Well, when we got these new shrimp, the new shrimp had eyespots on their tails and then the cuttlefish would do this attempt to enchant, regardless of the position of the ghost shrimp. So what does that mean? Okay, well, it means that there’s some sort of algorithm in the cuttlefish’s mind that says, “Okay, if you see two spots, move your tentacles.” So it can be, as you pointed out, it can be a fairly simple operation, but it looks diabolical. It looks cunning, but all it is strategy B.
Lex Fridman

(01:22:03)
Yeah, but it’s still somehow emerged. I don’t think that-
Andrew Huberman

(01:22:10)
Success-
Lex Fridman

(01:22:11)
… calling it an algorithm doesn’t… I feel like-
Andrew Huberman

(01:22:13)
Well, there’s a circuit there that gets implemented in a certain context, but that circuit had to evolve.
Lex Fridman

(01:22:19)
You do realize, super intelligent AI will look at us humans and we’ll say the exact thing. There’s a circuit in there that evolved to do this, the algorithm A and algorithm B, and it’s trivial. And to us humans, it’s fancy and beautiful, and we write poetry about it, but it’s just trivial.
Andrew Huberman

(01:22:36)
Because we don’t understand the subconscious. Because that AI algorithm cannot see into what it can’t see. It doesn’t understand the under workings of what allows all of this conversation stuff to manifest. And we can’t even see it, how could AI see it? Maybe it will, maybe AI will solve and give us access to our subconscious. Maybe your AI friend or coach, like I think Andreessen and others are arguing is going to happen at some point, is going to say, “Hey Lex, you’re making decisions lately that are not good for you, but it’s because of this algorithm that you picked up in childhood, that if you don’t state your explicit needs upfront, you’re not going to get what you want. So why do it? From now on, you need to actually make a list of every absolutely outrageous thing that you want, no matter how outrageous, and communicate that immediately, and that will work.”
Lex Fridman

(01:23:31)
We’re talking about cuttlefish and sexual selection, and then we went into some… Where did we go? Then you said you were excited.
Andrew Huberman

(01:23:38)
Well, I was excited… Well, you were just saying what about these covert contracts, [inaudible 01:23:43] animals do them.
Lex Fridman

(01:23:44)
Yes, [inaudible 01:23:44].
Andrew Huberman

(01:23:43)
I think it’s simple contextual engagement of a neural circuit, which is not just nerd speak for saying they do a different strategy. It’s saying that there has to be a circuit there, hardwired circuit, maybe learned, but probably hardwired, that can be engaged, right? You can’t build neural machinery in a moment, you need to build that circuit over time. What is building it over time? You select for it. The cuttlefish that did not have that alternate context-driven circuit, didn’t survive when all the shrimp that they normally eat disappear, and the eyespotted shrimp showed up. And there were a couple that had some miswiring. This is why mutation… Right, X-Men stuff is real. They had a mutation that had some alternate wiring and that wiring got selected for, it became a mutation that was adaptive as opposed to maladaptive.

(01:24:33)
This is something people don’t often understand about genetics, is that it only takes a few generations to devolve a trait, make it worse, but it takes a long time to evolve an adaptive trait. There are exceptions to that, but most often that’s true. So a species needs a lot of generations. We are hopefully still evolving as a species. And it takes a long time, to evolve more adaptive traits, but doesn’t take long to devolve adaptive traits, so that you’re getting sicker or you’re not functioning as well. So choose your mate wisely, and that’s perhaps the good segue into sexual selection in humans.
Relationships
Lex Fridman

(01:25:13)
[inaudible 01:25:13]. I could tell you you’re good at this. Why did I bring up sexual selection, is good relationships, so sexual selection in humans. I don’t think you’ve done an episode on relationships.
Andrew Huberman

(01:25:25)
No, I did an episode on attachment but not on relationships.
Lex Fridman

(01:25:31)
Right.
Andrew Huberman

(01:25:31)
The series with Conti includes one episode of the four that’s all about relational understanding, and how to select a mate based on matching of drives and-
Lex Fridman

(01:25:43)
All the demons inside the subconscious, how to match demons that they dance well together or what?
Andrew Huberman

(01:25:49)
And how generative two people are.
Lex Fridman

(01:25:52)
What does that mean?
Andrew Huberman

(01:25:52)
Means how… The way he explains it is, how devoted to creating growth within the context of the family, the relationship, with work.
Lex Fridman

(01:26:02)
Well, let me ask you about mating rituals and how to find such a relationship. You’re really big on friendships, on the value of friendships.
Andrew Huberman

(01:26:02)
I am.
Lex Fridman

(01:26:13)
And that I think extends itself into one of the deepest kinds of friendships you can have, which is a romantic relationship. What mistakes, successes and wisdom can you impart?
Andrew Huberman

(01:26:30)
Well, I’ve certainly made some mistakes. I’ve also made some good choices in this realm. First of all, we have to define what sort of relationship we’re talking about. If one is looking for a life partner, potentially somebody to establish family with, with or without kids, with or without pets, right? Families can take different forms. I certainly experienced being a family in a prior relationship, where it was the two of us and our two dogs, and it was family. We had our little family. I think, based on my experience, and based on input from friends, who themselves have very successful relationships, I must say, I’ve got friends who are in long-term, monogamous, very happy relationships, where there seems to be a lot of love, a lot of laughter, a lot of challenge and a lot of growth. And both people, it seems, really want to be there and enjoy being there.
Lex Fridman

(01:27:41)
Just to pause on that, one thing to do, I think, by way of advice, is listen to people who are in long-term successful relationships. That seems dumb, but we both know and are friends with Joe Rogan, who’s been in a long-term, really great relationship and he’s been an inspiration to me. So you take advice from that guy.
Andrew Huberman

(01:28:03)
Definitely, and several members of my podcast team are in excellent relationships. I think one of the things that rings true, over and over again, in the advice and in my experience, is find someone who’s really a great friend, build a really great friendship with that person. Now obviously not just a friend, if we’re talking romantic relationship, and of course sex is super important, but it should be a part of that particular relationship, alongside or meshed with, the friendship. Can it be a majority of the positive exchange? I suppose it could, but I think the friendship piece is extremely important, because what’s required in a successful relationship, clearly is joy in being together, trust, a desire to share experience, both mundane and more adventurous, support each other, acceptance, a real, maybe even admiration, but certainly delight, in being with the person.

(01:29:18)
Earlier we were talking about peace, and I think that that sense of peace comes from knowing that the person you’re in friendship with, or that you’re in romantic relationship, or ideally both, because let’s assume the best romantic relationship includes a friendship component with that person. It’s like you just really delight in their presence, even if it’s a quiet presence. And you delight in seeing them delight in things, that’s clear.
Lex Fridman

(01:29:45)
Mm-hmm.
Andrew Huberman

(01:29:46)
The trust piece is huge and that’s where people start, we don’t want to focus on what works, not what doesn’t work, but that’s where, I think, people start engaging in these covert contracts. They’re afraid of being betrayed, so they betray. They’re afraid of giving up too much vulnerability, so they hide their vulnerability, or in the worst cases, they feign vulnerability.
Lex Fridman

(01:30:12)
Mm-hmm.
Andrew Huberman

(01:30:13)
Again, that’s a covert contract that just simply undermines everything. It becomes one plus one equals two minus one to infinity. Conversely, I think if people can have really hard conversations, this is something I’ve had to work really hard on in recent years, that I’m still working hard on. But the friendship piece seems to be the thing that rises to the top, when I talk to friends who are in these great relationships, it’s like they have so much respect and love and joy in being with their friend. It’s the person that they want to spend as much of their non-working, non-platonic friendship time with, and the person that they want to experience things with and share things with. And it sounds so canned and cliche nowadays, but I think if you step back and examine how most people go about finding a relationship, like, oh, am I attracted? Of course physical attraction is important and other forms of attraction too, and they enter through that portal, which makes sense. That’s the mating dance, that’s the peacock situation. That’s hopefully not the cuttlefish situation.

(01:31:19)
But I think that there seems to be a history of people close to me getting into great relationships, where they were friends for a while first or maybe didn’t sleep together right away, that they actually intentionally deferred on that. This has not been my habit or my experience. I’ve gone the more, I think typical, like, oh, there’s an attraction, like this person, there’s an interest. You explore all dimensions of relationship really quickly except perhaps the moving in part and the having kids part, which because it’s a bigger step, harder to undo without more severe consequences. But I think that whole take it slow thing, I don’t think is about getting to know someone slowly, I think it’s about that physical piece, because that does change the nature of the relationship. And I think it’s because it gets right into the more hardwired, primitive circuitry around our feelings of safety, vulnerability.

(01:32:21)
There’s something about romantic and sexual interactions, where it’s almost like it’s assets and liabilities, right?
Lex Fridman

(01:32:31)
Mm-hmm.
Andrew Huberman

(01:32:31)
Where people are trying to figure out how much to engage their time and their energy and multiple people. I’m talking about from both sides, male, female or whatever sides, but where it’s like assets and liabilities. And that’s where it starts getting into those complicated contracts early on, I think. And so maybe that’s why if a really great friendship and admiration is established first, even if people are romantically and sexually attracted to one another, then that piece can be added in a little bit later, in a way that really just seals up the whole thing, and then who knows, maybe they spend 90% of their time having sex. I don’t know. That’s not for me to say or decide obviously, but there’s something there, about staying out of a certain amount of risk of having to engage covert contract in order to protect oneself.
Lex Fridman

(01:33:29)
But I do think love at first sight, this kind of idea is, in part, realizing very quickly that you are great friends. I’ve had that experience of friendship recently. It’s not really friendship, but like, oh, you get each other. With humans, not in a romantic setting.
Andrew Huberman

(01:33:52)
Right, friendship?
Lex Fridman

(01:33:52)
Yeah, just friendship. [inaudible 01:33:54].
Andrew Huberman

(01:33:53)
Well, dare I say, I felt that way about you when we met, right?
Lex Fridman

(01:33:56)
Yeah, but we also-
Andrew Huberman

(01:33:57)
I was like, “This dude’s cool, and he’s smart, and he’s funny, and he’s driven, and he’s giving, and he’s got an edge, and I want to learn from him. I want to hang out with him.” That was the beginning of our friendship, was essentially that set of internal realizations.
Lex Fridman

(01:34:17)
Just keep going, just keep going, [inaudible 01:34:18] keep going with these compliments.
Andrew Huberman

(01:34:18)
And a sharp dresser, [inaudible 01:34:20].
Lex Fridman

(01:34:19)
Yeah, yeah, just looks great shirtless on horseback. Yes.
Andrew Huberman

(01:34:22)
No. No, no, listen, despite what some people might see on the internet, it’s a purely platonic friendship.
Lex Fridman

(01:34:28)
Somebody asked if Andrew Huberman has a girlfriend, and somebody says, “I think so.” And the third comment was, “This really breaks my heart that Lex and Andrew are not an item.”
Andrew Huberman

(01:34:42)
We are great friends, but we are not an item.
Lex Fridman

(01:34:45)
Yeah, well-
Andrew Huberman

(01:34:45)
It’s true, it’s official. I hear, over and over again, from friends that have made great choices in awesome partners, and have these fantastic relationships for long periods of time, that seem to continue to thrive, at least that’s what they tell me, and that’s what I observe, establish the friendship first and give it a bit of time before sex. And so I think that’s the feeling. That’s the feeling and we’re talking micro features and macro features. And this isn’t about perfection, it’s actually about the imperfections, which is kind of cool. I like quirky people. I like characters.

(01:35:29)
I’ll tell you where I’ve gone badly wrong and where I see other people going badly wrong. There is no rule that says that you have to be attracted to all attractive people, by any means. It’s very important to develop a sense of taste in romantic attractions, I believe. What you really like, in terms of a certain style, a certain way of being, and of course that includes sexuality and sex itself, the verb. But I think it also includes their just general way of being. And when you really adore somebody, you like the way they answer the phone, and when they don’t answer the phone that way, you know something’s off and you want to know. And so I think that the more you can tune up your powers of observation, not looking for things that you like, and the more that stuff just washes over you, the more likely you are to, “Fall in love.” As a mutual friend of ours said to me, “Listen, when it comes to romantic relationships, if it’s not a hundred percent in you, it ain’t happening.”

(01:36:39)
And I’ve never seen a violation of that statement, where it’s like, yeah, it’s mostly good and they’re this and this, likes the negotiations. Well, already it’s doomed. And that doesn’t mean someone has to be perfect, the relationship has to be perfect, but it’s got to feel hundred percent inside.
Lex Fridman

(01:36:56)
Yeah.
Andrew Huberman

(01:36:56)
Like yes, yes, and yes. I think Deisseroth, when he was on here, your podcast, mentioned something that, I think the words were… Or maybe it was in his book, I don’t recall. But that love is one of these things that we story into with somebody. We create this idea of ourselves in the future and we look at our past time together and then you story into it.
Lex Fridman

(01:37:19)
Mm-hmm.
Andrew Huberman

(01:37:20)
There’re very few things like that. I can’t story into building flying cars. I have to actually go do something. And love is also retroactively constructed. Anyone who’s gone through a breakup understands the grief of knowing, oh, this is something I really shouldn’t be in, for whatever reason, because it only takes one. If the other person doesn’t want to be in it, then you shouldn’t be in it. But then missing so many things, and that’s just the attachment machinery, really, at work.
Fertility
Lex Fridman

(01:37:49)
I have to ask you a question that somebody in our amazing team wanted to ask. He’s happily married. Another, like you mentioned, incredible relationship.
Andrew Huberman

(01:37:58)
Are they good friends?
Lex Fridman

(01:38:00)
They’re amazing friends.
Andrew Huberman

(01:38:01)
There you go.
Lex Fridman

(01:38:02)
But, I’m just going to say, I’m not saying who it is. So I can say some stuff, which is, it started out as a great sexual connection.
Andrew Huberman

(01:38:10)
Oh, well, there you go.
Lex Fridman

(01:38:11)
But then became very close friends after that.
Andrew Huberman

(01:38:14)
Okay, listen-
Lex Fridman

(01:38:14)
There you go. So speaking of sex-
Andrew Huberman

(01:38:16)
There are many paths to Rome.
Lex Fridman

(01:38:19)
He has a wonderful son and he is wanting to have a second kid, and he wanted to ask the great Andrew Huberman, is there sexual positions or any kind of thing that can help maximize the chance that they have a girl versus a boy? Because they had a wonderful boy.
Andrew Huberman

(01:38:35)
Do they want a girl?
Lex Fridman

(01:38:35)
They want to a girl.
Andrew Huberman

(01:38:36)
Okay.
Lex Fridman

(01:38:37)
Is there a way to control the gender? [inaudible 01:38:39].
Andrew Huberman

(01:38:39)
Well, this has been debated for a long time, and I did a four and a half hour episode on fertility. And the reason I did a four and a half hour episode on fertility is that, first of all, I find that reproductive biology be fascinating. And I wanted a resource for people that at were thinking about, or struggling with having kids for whatever reason, and it felt important to me to combine the male and female components in the same episode. It’s all timestamped, so you don’t have to listen to the whole thing. We talk about IVF, in vitro fertilization, we talk about natural pregnancy.

(01:39:11)
Okay, the data on position is very interesting, but let me just say a few things. There are a few clinics now, in particular some out of the United States, that are spinning down sperm and finding that they can separate out fractions, as they’re called. They can spin the sperm down at a given speed, and that they’ll separate out at different depths within the test tube, that allow them to pull out the sperm on top or below and bias the probability towards male or female births. It’s not perfect. It’s not a hundred percent. It’s a very costly procedure. It’s still very controversial.

(01:39:47)
Now with in vitro fertilization, they can extract eggs. You can introduce a sperm, directly by pipette, it’s a process called ICSI. Or you can set up a sperm race in a dish. And if you get a number of different embryos, meaning the eggs get fertilized, duplicate and start form a blastocyst, which is a ball of cells, early embryo, then you can do karyotyping. So you can do look for XX or XY, select the XY, which then would give rise to a male offspring, and then implant that one. So there is that kind of sex selection.

(01:40:22)
With respect to position, there’s a lot of lore that if the woman is on top or the woman’s on the bottom, or whether or not the penetration is from behind, whether or not it’s going to be male or female offspring. And frankly, the data are not great, as you can imagine, because those-
Lex Fridman

(01:40:39)
[inaudible 01:40:39].
Andrew Huberman

(01:40:38)
… those would be interesting studies to run, perhaps.
Lex Fridman

(01:40:43)
But there is studies, there is papers.
Andrew Huberman

(01:40:45)
There are some-
Lex Fridman

(01:40:46)
But they’re not, I guess-
Andrew Huberman

(01:40:47)
Yeah, it’s-
Lex Fridman

(01:40:48)
There’s more lore than science says.
Andrew Huberman

(01:40:50)
And there are a lot of other variables that are hard to control. So for instance, if it’s during intermission, during sex penetration, et cetera, then you can’t measure, for instance, sperm volume as opposed to when it’s IVF, and they can actually measure how many milliliters, how many forward motile sperm. It’s hard to control for certain things. And it just can vary between individuals and even from one ejaculation to the next and… Okay, so there’s too many variables; however, the position thing is interesting in the following way, and then I’ll answer whether or not you can bias us towards a female. As long as we’re talking about sexual-
Lex Fridman

(01:41:28)
I have other questions about sex [inaudible 01:41:28].
Andrew Huberman

(01:41:29)
But as long as we’re talking about sexual position,-
Lex Fridman

(01:41:30)
All right.
Andrew Huberman

(01:41:31)
… there are data that support the idea that, in order to increase the probability of successful fertilization, that indeed, the woman should not stand upright after sex and should-
Lex Fridman

(01:41:49)
[inaudible 01:41:49].
Andrew Huberman

(01:41:49)
Right after the man has ejaculated inside her, and should adjust her pelvis, say, 15 degrees upwards. Some of the fertility experts, MDs, will say that’s crazy, but others-
Andrew Huberman

(01:42:00)
MDs will say, “That’s crazy.”

(01:42:02)
But others that I sought out, and not specifically for this answer, but for researching that episode, said that, “Yeah, what you’re talking about is trying to get the maximum number of sperm and it’s contained in semen. And yes, the semen can leak out. And so keeping the pelvis tilted for about 15 degrees for about 15 minutes, obviously tilted in the direction that would have things running upstream, not downstream, so to speak.”
Lex Fridman

(01:42:02)
Gravity.
Andrew Huberman

(01:42:29)
Gravity, it’s real. So for maximizing fertilization, the doctors I spoke to just said, “Look, given that if people are trying to get pregnant, what is spending 15 minutes on their back?” This sort of thing. Okay. So then with respect to getting a female offspring or XX female offspring, selectively, there is the idea that as fathers get older, they’re more likely to have daughters as opposed to sons. That’s, from the papers I’ve read, is a significant but still mildly significant result. So with each passing year, this person increases the probability they’re going to have a daughter, not a son. So that’s interesting.
Lex Fridman

(01:43:19)
But the probability differences are probably tiny as you said.
Andrew Huberman

(01:43:22)
It’s not trivial. It’s not a trivial difference. But if they want to ensure having a daughter, then they should do IVF and select an XX embryo. And when you go through IVF, they genetically screen them for karyotype, which is XX, XY, and they look at mutations, genotypic mutations for things like trisomies and aneuploidies, all the stuff you don’t want.
Lex Fridman

(01:43:54)
But there is a lot of lore if you look on the internet.
Andrew Huberman

(01:43:56)
Sure. Different foods.
Lex Fridman

(01:43:57)
So there are a lot of variables.
Andrew Huberman

(01:43:58)
There’s a lot of variable, but there haven’t been systematic studies. So I think probably the best thing to do, unless they’re going to do IVF, is just roll the dice. And I think with each passing year, they increase the probability of getting a female offspring. But of course, with each passing year, the egg and sperm quality degrade, so get after it soon.
Lex Fridman

(01:44:23)
So I went down a rabbit hole. Sexology, there’s journals on sex.
Andrew Huberman

(01:44:29)
Oh, yeah. Sure. And some of them, not all, quite reputable and some of them really pioneering in the sense that they’ve taken on topics that are considered outside the main frame of what people talk about, but they’re very important. We have episodes coming out soon with, for instance, the Head of Male Urology, Sexual Health and Reproductive Health at Stanford, Michael Eisenberg. But also one with a female urologist, sexual health, reproductive health, Dr. Rena Malik, who has a quite active YouTube presence. She does these really dry, scientific presentation, but very nice. She has a lovely voice. But she’ll be talking about erections or squirting. She does very internet-type content, but she’s a legitimate urologist, reproductive health expert.

(01:45:27)
And in the podcast, we did talk about both male and female orgasm. We talked a lot about sexual function and dysfunction. We talked a lot about pelvic floor. One interesting factoid is that only 3% of sexual dysfunction is hormonal, endocrine, in nature. It’s more often related to some pelvic floor or vasculature, blood flow related or other issue. And then when Eisenberg came on the podcast, he said that far less sexual dysfunction is psychogenic in origin than people believe. That far more of it is pelvic floor, neuro and vascular. It’s not saying that psychogenic dysfunction doesn’t exist, but that a lot of the sexual dysfunction that people assume is related to hormones or that is related to psychogenic issues are related to vascular or neural issues. And the good news is that there are great remedies for those. And so both those episodes detail some of the more salient points around what those remedies are and could be.

(01:46:39)
One of the, again, factoids, but it was interesting that a lot of people have pelvic floor issues and they think that their pelvic floors are, quote, unquote, messed up. So they go on the internet, they learn about Kegels. And it turns out that some people need Kegels, they need to strengthen their pelvic floor. Guess what? A huge number of people with sexual and urologic dysfunction have pelvic floors that are too tight and Kegels are going to make them far worse, and they actually need to learn to relax their pelvic floor. And so seeing a pelvic floor specialist is important.

(01:47:12)
I think in the next five, 10 years, we’re going to see a dramatic shift towards more discussion about sexual and reproductive health in a way that acknowledges that, yeah, the clitoris comes from the same origin tissue as the penis. And in many ways the neural innervation of the two, while clearly different, has some overlapping features that there’s going to be discussion around anatomy and hormones and pelvic floors in a way that’s going to erode some of the cloaking of these topics because they’ve been cloaked for a long time and there’s a lot of… Well, let’s just call it what it is. There’s a lot of bullshit out there about what’s what.

(01:47:54)
Now, the hormonal issues, by the way, just to clarify, can impact desire. So a lot of people who have lack of desire as opposed to lack of anatomical function, this could be male or female that can originate with either things like SSRIs or hormonal issues. And so we talk about that as well. So it’s a pretty vast topic.
Productivity
Lex Fridman

(01:48:15)
Okay. You’re one of the most productive people I know. What’s the secret to your productivity? How do you maximize the number of productive hours in a day? You’re a scientist, you’re a teacher, you’re a very prolific educator.
Andrew Huberman

(01:48:31)
Well, thanks for the kind words. I struggle like everybody else, but I am pretty relentless about meeting deadlines. I miss them sometimes, but sometimes that means cramming. Sometimes that means starting early. But-
Lex Fridman

(01:48:48)
Has that been hard, sorry to interrupt, with the podcast? There’s certain episodes, you’re taking just incredibly difficult topics and you know there’s going to be a lot of really good scientists listening to those with a very skeptical and careful eye. Do you struggle meeting that deadline sometimes?
Andrew Huberman

(01:49:09)
Yes. We’ve pushed out episodes because I want more time with them. I also, I haven’t advertised this, but I have another fully tenured professor that’s started checking my podcasts and helping me find papers. He’s a close friend of mine. He’s an incredible expert in neuroplasticity and that’s been helpful. But I do all the primary research for the episodes myself. Although my niece has been doing a summer internship with me and finding amazing papers. She did last summer as well. She’s really good at it. Just sick that kid on the internet and she gets great stuff.
Lex Fridman

(01:49:47)
Can I ask you, just going on tangents here, what’s the hardest, finding the papers or understanding what a paper is saying?
Andrew Huberman

(01:49:57)
Finding them. Finding the best papers. Yeah. Because you have to read a bunch of reviews, figure out who’s getting cited, call people in a field, make sure that this is the stuff. I did this episode recently on ketamine. About ketamine, I wasn’t on ketamine. And there’s this whole debate about S versus R ketamine, and SR ketamine. And I called two clinical experts at Stanford. I had a researcher at UCLA help me. Even then, a few people had gripes about it that I don’t think they understood a section that I perhaps could have been clearer about. But yeah, you’re always concerned that people either won’t get it or I won’t be clear. So the researching is mainly about finding the best papers.

(01:50:36)
And then I’m looking for papers that establish a thoroughness of understanding. That are interesting, obviously. It’s fun to get occasionally look at some of the odder or more progressive papers that are what’s new in a field and then where there are actionable takeaways to really export those with a lot of thoughtfulness.

(01:50:59)
Going back to the productivity thing I do, I get up, I look at the sun. I don’t stare at the sun, but I get my sunshine. It all starts with a really good night’s sleep. I think that’s really important to understand. So much so that if I wake up and I don’t feel rested enough, I’ll often do a non-sleep deep rest yoga nidra, or go back to sleep for a little bit, get up, really prioritize the big block of work for the thing that I’m researching. I think a little bit of anxiety and a little bit of concern about deadline helps. Turning the phone off helps, realizing that those peak hours, whenever they are for you, you do not allow those hours to be invaded, unless a nuclear bomb goes off. And nuclear bomb is just a phraseology for, family crisis would be good justification. If there’s an emergency, obviously.

(01:51:53)
But it’s all about focus. It’s all about focus in the moment. It’s not even so much about how many hours you log. It’s really about focus in the moment. How much total focus can you give to something? And then I like to take walks and think about things and sometimes talk about them in my voice recorder. So I’m just always churning on it, all the time. And then of course, learning to turn it off and engage with people socially and not be podcasting 24 hours a day in your head is key. But I think I love learning and researching and finding those papers and the information, and I love teaching it.

(01:52:30)
And these days I use a whiteboard before I start. I don’t have any notes, no teleprompter. Then the whiteboard that I use beforehand is to really sculpt out the different elements and the flow, get the flow right and move things around. The whiteboard is such a valuable tool. Then take a couple pictures of that when I’m happy with it, put it down on the desk and these are just bullet points and then just churn through and just churn through. And nothing feels better than researching and sharing information. And I, as you did, grew up writing papers and it’s hard. And I like the friction of, “Uh, can’t. I want to get up. I want to use the bathroom.”

(01:53:08)
When I was in college, I was trying to make up deficiencies from my lack of attendance in high school, so much so that I would set a timer. I wouldn’t let myself get up to use the bathroom even. Never had an accident. I listened to music, classical music, Rancid, a few other things. Some Bob Dylan maybe thrown in there and just study and just… And then you’d hit the two-hour mark and you’re in pain and then you get up, use the bathroom. You’re like, “That felt so good.” There’s something about the human brain that likes these kind of friction points and working through them and you just have to work through them.

(01:53:46)
So yeah, I’m productive and my life has arranged around it, and that’s been a bit of a barrier to personal life at times. But my life’s been arranged around it. I’ve set up everything so that I can learn more, teach more, including some of my home life. But I do still watch Chimp Empire. I still got time to watch Chimp Empire. Look, the great Joe Strummer, Clash, they were my favorite Mescaleros. He said, this famous Strummer quote, “No input, no output.” So you need experience. You need outside things in order to foster the process.

(01:54:27)
But yeah, just nose to the grindstone man, I don’t know. And that’s what I’m happy to do with my life. I don’t think anyone should do that just because. But this is how I’m showing up. And if you don’t like me, then scroll… What do they say? Swipe left, swipe right. I don’t know. I’m not on the apps, the dating apps. So that’s the other thing. I keep waiting for when, “Listens to Lex Fridman podcast,” is a checkbox on Hinge or Bumble or whatever it is. But I don’t even know. Are those their field? I don’t know. What are the apps now?
Lex Fridman

(01:55:00)
Well, I’ve never used an app and I always found troublesome how little information is provided on apps.
Andrew Huberman

(01:55:07)
Well, they’re the ones that are like a stocked lake, like Raya. Companies will actually fill them with people that look a certain way.
Lex Fridman

(01:55:18)
Well, soon it’ll be filled with AI.
Andrew Huberman

(01:55:20)
Oh.
Lex Fridman

(01:55:21)
The way you said, “Oh.”
Andrew Huberman

(01:55:22)
Yeah. That’s interesting.
Lex Fridman

(01:55:24)
The heartbreak within that.
Andrew Huberman

(01:55:25)
Well, I am guilty of liking real human interaction.
Lex Fridman

(01:55:30)
Have you tried AI interaction?
Andrew Huberman

(01:55:34)
No, but I have a feeling you’re going to convince me to.
Lex Fridman

(01:55:37)
One day. I’ve also struggled finishing projects that are new. That are something new. For example, one of the things I’ve really struggled finishing is something that’s in Russian that requires translation and overdub and all that kind of stuff. The other project, I’ve been working on for at least a year off and on, but trying to finish is something we’ve talked about in the past. I’m still on it, project on Hitler in World War II. I’ve written so much about it and I just don’t know why I can’t finish it. I have trouble really… I think I’m terrified being in front of the camera.
Andrew Huberman

(01:56:18)
Like this?
Lex Fridman

(01:56:19)
Like this.
Andrew Huberman

(01:56:19)
Or solo?
Lex Fridman

(01:56:21)
No, no, no. Solo.
Andrew Huberman

(01:56:22)
Well, if ever you want to do solo and seriously, because done this before, our clandestine study missions, I’m happy to sit in the corner and work on my book or do something if it feels good to just have someone in the room.
Lex Fridman

(01:56:34)
Just for the feeling of somebody else?
Andrew Huberman

(01:56:35)
Definitely.
Lex Fridman

(01:56:37)
You seem to have been fearless to just sit in front of the camera by yourself to do the episode.
Andrew Huberman

(01:56:48)
Yeah, it was weird. The first year of the podcast, it just spilled out of me. I had all that stuff I was so excited about. I’d been talking to everyone who would listen and even when they’d run away, I’d keep talking before there was ever a camera, wasn’t on social media. 2019, I posted a little bit. 2020, as you know, I started going on podcasts. But yeah, the zest and delight in this stuff. I was like, “Circadian rhythms, I’m going to tell you about this stuff.” I just felt like, here’s the opportunity and just let it burst.

(01:57:19)
And then as we’ve gotten into topics that are a little bit further away from my home knowledge, I still get super excited about it. This music in the brain episode I’ve been researching for a while now, I’m just so hyped about it. It’s so, so interesting. There’s so many facets. Singing versus improvisational music versus, “I’m listening to music,” versus learning music. It just goes on and on. There’s just so much that’s so interesting. I just can’t get enough. And I think, I don’t know, you put a camera in front of me, I sort of forget about it and I’m just trying to just teach.
Lex Fridman

(01:58:01)
Yeah, so that’s the difference. That’s interesting.
Andrew Huberman

(01:58:02)
Forget the camera.
Lex Fridman

(01:58:03)
Maybe I need to find that joy as well. But for me, a lot of the joy is in the writing. And the camera, there’s something-
Andrew Huberman

(01:58:12)
Well, the best lecturers, as you know, and you’re a phenomenal lecturer, so you embody this as well, but when I teach at Stanford, I was directing this course in neuroanatomy and neuroscience for medical students. And I noticed that the best lecturers would come in and they’re teaching the material from a place of deep understanding, but they’re also experiencing it as a first time learner at the same time. So it’s just sort of embodying the delight of it, but also the authority over the… Not authority, but the mastery of the material. And it’s really the delight in it that the students are linking onto. And of course they need and deserve the best accurate material, so they have to know what they’re talking about.

(01:58:50)
But yeah, just tap into that energy of learning and loving it. And people are along for the ride. I get accused of being long-winded, but things get taken out of context, that leads to greater misunderstanding. And also, listen, I come from a lineage of three dead advisors. Three. All three. So I don’t know when the reaper’s coming for me. I’m doing my best to stay alive a long time. But whether or not it’s a bullet or a bus or cancer or whatever, or just old age, I’m trying to get it all out there as best I can. And if it means you have to hit pause and come back a day or two later, that seems like a reasonable compromise to me. I’m not going to go longer than I need to and I’m trying to shorten them up. But again, that’s kind of how I show up.

(01:59:39)
It’s like Tim Armstrong would say about writing songs. I asked him, “How often do you write?” Every day. Every day. Does Rick ever stop creating? No. Has Joe ever stopped preparing for comedy? Are you ever stopping to think about world issues and technology and who you can talk to? It seems to me you’ve always got a plan in sight. The thing I love about your podcast the most, to be honest these days, is the surprise of I don’t know who the hell’s going to be there. It’s almost like I get a little nervously excited about when a new episode comes out. I have no idea. No idea. I have some guesses based on what you told me during the break. You’ve got some people where it’s just like, “Whoa, Lex went there? Awesome. Can’t wait.” Click. I think that’s really cool. You’re constantly surprising people. So you’re doing it so well. It’s such a high level and I think it’s also important for people to understand that what you’re doing Lex, there’s no precedent for it. Sure. There’ve been interviews before, there have been podcasts before. There are discussions before. How many of your peers can you look to find out how best to do the content like yours? Zero. There’s one peer: you. And so that should give you great peace and great excitement because you’re a pioneer. You’re literally the tip of the spear.

(02:01:04)
I don’t want to take an unnecessary tangent, but I think this might thread together two of the things that we’ve been talking about, which are, I think of pretty key importance. One is romantic relationships, and the other is creative process and work. And this again, is something I learned from Rick, but that he and I have gone back and forth on. And that I think is worth elaborating on, which is earlier we were saying the best relationship is going to be one where it brings you peace. I think peace also can be translated to, among other things, lack of distraction. So when you’re with your partner, can you really focus on them and the relationship? Can you not be distracted by things that you’re upset about from their past or from your past with them? And of course the same is true for them, right? They ideally will feel that way towards you too. They can really focus.

(02:01:58)
Also, when you’re not with them, can you focus on your work? Can you not be worried about whether or not they’re okay because you trust that they’re an adult and they can handle things or they will reach out if they need things? They’re going to communicate their needs like an adult. Not creating messes just to get attention and things like that, or disappearing for that matter. So peace and focus are intimately related, and distraction is the enemy of peace and focus.

(02:02:32)
So there’s something there, I believe, because with people that have the strong generative drive and want to be productive in their home life, in the sense have a rich family life, partner life, whatever that is, and in their work life, the ability to really drop into the work and you might have that sense like, “I hope they’re okay,” or, “need to check my phone or something,” but just know we’re good.
Lex Fridman

(02:02:57)
Yeah. Everything’s okay.
Andrew Huberman

(02:02:57)
So peace and focus, I think and being present are so key. And it’s key at every level of romantic relationship, from certainly presence and focus. Everything from sex to listening to raising a family, to tending to the house and in work, it’s absolutely critical. So I think that those things are mirror images of the same thing. And they’re both important reflections of the other. And when work is not going well, then the focus on relationship can suffer and vice versa.
Lex Fridman

(02:03:33)
And it’s crazy how important that is.
Andrew Huberman

(02:03:35)
Peace.
Lex Fridman

(02:03:37)
How incredibly wonderful it could be to have a person in your life that enables that creative focus.
Andrew Huberman

(02:03:47)
Yeah. And you supply the peace and focus for their endeavors, whatever those might be. That symmetry there. Because clearly people have different needs and the need to just really trust, when Lex is working, he’s in his generative mode and I know he’s good. And so then they feel, sure, they’ve contributed to that. But then also what you’re doing is supporting them in whatever way happens to be. And I think that sometimes you’ll see that. People will pair up along creative-creative or musical-musical or computer scientists. But I think, again, going back to this Conti episode on relationships is that the superficial labels are less important, it seems, than just the desire to create that kind of home life and relationship together. And as a consequence, the work mode. And for some people, both people aren’t working and sometimes they are. But I think that’s the good stuff. And I think that’s the big learning in all of it, is that the further along I go, with each birthday, I guarantee you’re going to be like, “What I want is simpler and simpler and harder and harder to create. But oh, so worth it.”
Family
Lex Fridman

(02:05:02)
The inner and the outer peace. It’s been over two years, I think, since Costello passed away.
Andrew Huberman

(02:05:11)
It still tears me up. I cried about him today. I cried about him today.
Lex Fridman

(02:05:17)
[inaudible 02:05:17]. Fuck.
Andrew Huberman

(02:05:18)
It’s proportional to the love. But yeah, I’ll cry about it right now if I think about it. It wasn’t putting him down, it wasn’t the act of him dying, any of that. Actually, that was a beautiful experience. I didn’t expect it to be, but it was in my place when I was living in Topanga during the pandemic where we launched the podcast and I did it at home and he hated the vet so I did it at home. And he gave out this huge, “Ugh,” right at the end. And I could just tell he had been in not a lot pain, fortunately. But he had just been working so hard just to move at all.

(02:05:52)
And the craziest thing happened, Lex. It was unbelievable. I’ve never had an experience like this. I expected my heart to break, and I’ve felt a broken heart before. I felt it, frankly, when my parents split, I felt it when Harry shot himself. I felt it when Barbara died and felt it when Ben went as well. And so many friends, way too many friends. The end of 2017, my friend Aaron King, Johnny Fair, John Eikleberry, stomach cancer, suicide, fentanyl. I was like, “Whoa. All in a fricking week.” And I just remember thinking, “What the…?” And it’s just heartbreak and you just carry that and it’s like, “Uh.” And that’s just a short list. And I don’t say that for sob stories. It’s just for a guy that wasn’t in the military or didn’t grow up in the inner city, it’s an unusual number of deaths, close people.

(02:06:51)
When Costello went, the craziest thing happened. My heart warmed up, it heated up. And I wasn’t on MDMA. The moment he went, it just went whoosh. And I was like, “What the hell is this?” And it was a supernatural experience to me. I just never had that. I put my grandfather on the ground, I was a pallbearer at the funeral. I’ve done that more times than I’d like to have ever done it. And it just heated up with Costello and I thought, “What the fuck is this?”

(02:07:22)
And it was almost like, and we make up these stories about what it is, but it was almost like he was like, “All right,” I have to be careful because I will cry here and I don’t want to. It was almost like he was like all that effort, because I had been putting so much effort into him, it was like, “All right, you get that back.” It was like the giant freaking, “Thank you.” And it was incredible. And I’m not embarrassed to shed a tear or two about it if I have to.

(02:07:49)
I was like, “Holy shit.” That’s how close I was to that animal.
Lex Fridman

(02:07:53)
Where do you think can find that kind of love again?
Andrew Huberman

(02:07:57)
Man, I don’t know. And excuse me for welling up. I mean, it’s a freaking dog, right? I get it. But for me, it was the first real home I ever had. But when Costello went, it was like we had had this home in Topanga. We had set it up and he was just so happy there. And I think, I don’t know, it was this weird victory slash massive loss. We did it. 11 years. Freaking did everything, everything, to make him as comfortable as possible. And he was super loyal, beautiful animal, but also just funny and fun. And I was like, “I did it.” I gave as much of myself to this being as I felt I could without detracting from the rest of my life. And so I don’t know.

(02:08:53)
When I think about Barbara especially, I well up and it’s hard for me, but I talked to her before she died and that was a brutal conversation, saying goodbye to someone, especially with kids. And that was hard. I think that really flipped a switch in me where I’m like, I always knew I wanted kids. I’d say, “I want kids. I want a lot of kids.” That flipped a switch in me. I was like, “I want kids. I want my own kids.”
Lex Fridman

(02:09:22)
You might be able to find that kind of love having kids.
Andrew Huberman

(02:09:25)
Yeah, I think because it was the caretaking. It wasn’t about what he gave me all that time, and the more I could take care of him and see him happy, the better I felt. It was crazy. I don’t know. So I miss him every day. Every day. I miss him every day.
Lex Fridman

(02:09:44)
You got a heart that’s so full of love. I can’t wait for you to have kids.
Andrew Huberman

(02:09:48)
Thanks, man.
Lex Fridman

(02:09:49)
For you to be a father. I can’t wait to do the same.
Andrew Huberman

(02:09:50)
Yeah, well, when I’m ready for it. When God decides I’m ready, I’ll have them.
Lex Fridman

(02:09:58)
And then I will still beat you to it. As I told you many times before,
Andrew Huberman

(02:10:03)
I think you should absolutely have kids. Look at the people in our life. Because in case you haven’t realized it already, we’re the younger of the podcasters. But like Joe and Peter and Segura and the rest, they’re like the tribal elders and we’re not the youngest in the crew. But if you look at all those guys, they all have kids. They all adore their kids and their kids bring tremendous meaning to their life. We’d be morons if you didn’t go off and start a family, I didn’t start start a family. And yeah, I think that’s the goal. Of the goals, that’s one of them.
Lex Fridman

(02:10:58)
The kids not only make their life more joyful and brings love to their life, it’s also makes them more productive, makes them better people, all of that. It’s kind of obvious. Yeah,
Andrew Huberman

(02:11:10)
I think that’s what Costello wanted, I think, I have this story in my head that he was just like, “Okay, take this like a kid.” It was a good test.
Lex Fridman

(02:11:17)
“And don’t fuck this up.”
Andrew Huberman

(02:11:18)
“Lord knows, don’t fuck this up.”
Lex Fridman

(02:11:21)
Andrew, I love you, brother. This was an incredible conversation.
Andrew Huberman

(02:11:24)
Love you too. I appreciate you.
Lex Fridman

(02:11:26)
We will talk often on each other’s podcast for many years to come.
Andrew Huberman

(02:11:30)
Yes.
Lex Fridman

(02:11:30)
Many, many years to come.
Andrew Huberman

(02:11:32)
Thank you. Thanks for having me on here. And there are no words for how much I appreciate your example and your friendship. So love you, brother.
Lex Fridman

(02:11:40)
Love you too.

(02:11:42)
Thanks for listening to this conversation with Andrew Huberman to support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Albert Camus. “In the midst of winter, I found there was, within me, an invincible summer. And that makes me happy. For it says that no matter how hard the world pushes against me, within me, there’s something stronger – something better, pushing right back.” Thank you for listening and hope to see you next time.
Transcript for Joscha Bach: Life, Intelligence, Consciousness, AI & the Future of Humans | Lex Fridman Podcast #392
This is a transcript of Lex Fridman Podcast #392 with Joscha Bach.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
1:15 – Stages of life
13:37 – Identity
20:12 – Enlightenment
26:43 – Adaptive Resonance Theory
33:31 – Panpsychism
43:31 – How to think
51:25 – Plants communication
1:09:20 – Fame
1:34:57 – Happiness
1:42:15 – Artificial consciousness
1:54:23 – Suffering
1:59:08 – Eliezer Yudkowsky
2:06:44 – e/acc (Effective Accelerationism)
2:12:21 – Mind uploading
2:23:11 – Vision Pro
2:27:25 – Open source AI
2:40:17 – Twitter
2:47:33 – Advice for young people
2:50:29 – Meaning of life

Introduction
Joscha Bach

(00:00:00)
There is a certain perspective where you might be thinking, what is the longest possible game that you could be playing? A short game is, for instance, cancer is playing a shorter game than your organism. Cancer is an organism playing a shorter game than the regular organism. Because the cancer cannot procreate beyond the organism, except for some infectious cancers like the ones that eradicated the Tasmanian devils, you typically end up with a situation where the organism dies together with the cancer, because the cancer has destroyed the larger system due to playing a shorter game. Ideally, you want to, I think, build agents that play the longest possible games. The longest possible games is to keep entropy at bay as long as possible, by doing interesting stuff.
Lex Fridman

(00:00:48)
The following is a conversation with Joscha Bach, his third time on this podcast. Joscha is one of the most brilliant, and fascinating minds in the world, exploring the nature of intelligence, consciousness, and computation. He’s one of my favorite humans to talk to about pretty much anything and everything. This is the Lex Fridman Podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Joscha Bach.
Stages of life

(00:01:15)
You wrote a post about levels of lucidity. “As we grow older, it becomes apparent that our self-reflexive mind is not just gradually accumulating ideas about itself, but that it progresses in somewhat distinct stages.” There are seven of the stages. Stage one, reactive survival (infant). Stage two, personal self (young child). Stage three, social self (adolescence, domesticated adult). Stage four is rational agency (self-direction). Stage five is self-authoring, that’s full adult. You’ve achieved wisdom, but there’s two more stages. Stage six is enlightenment, stage seven is transcendence. Can you explain each, or the interesting parts of each of these stages, and what’s your sense why there are stages of this, of lucidity as we progress through life in this too short life?
Joscha Bach

(00:02:12)
This model is derived from concept by the psychologist Robert Kegan, and he talks about the development of the self as a process that happens in principle by some kind of reverse engineering of the mind, where you gradually become aware of yourself, and thereby build structure that allows you to interact deeper with the world and yourself. I found myself using this model not so much as a developmental model. I’m not even sure if it’s a very good developmental model, because I saw my children not progressing exactly like that. I also suspect that you don’t go through these stages necessarily in succession, and it’s not that you work through one stage and then you get into the next one. Sometimes, you revisit them. Sometimes, stuff is happening in parallel. But it’s, I think, a useful framework to look at what’s present, and the structure of a person, and how they interact with the world, and how they relate to themselves.

(00:03:08)
It’s more like philosophical framework that allows you to talk about how minds work. At first, when we are born, we don’t have a personal self yet, I think. Instead, we have an attentional self, and this attentional self is initially in the infant tasked, is building a world model, and also an initial model of the self. But mostly, it’s building a game engine in the brain that is tracking sensory data, and uses it to explain it. In some sense, you could compare it to a game engine like Minecraft or so, colors and sounds. People are all not physical objects. They’re creation of our mind at a certain level. Of course, screening models that are mathematical that use geometry, and that use manipulation of objects, and so on to create scenes in which we can find ourselves, and interact with them.
Lex Fridman

(00:03:59)
Minecraft?
Joscha Bach

(00:04:00)
Yeah. This personal self is something that is more or less created after the world is finished, after it’s trained into the system, after it has been constructed. This personal self is an agent that interacts with the outside world. The outside world is not the world of quantum mechanics, not the physical universe, but it’s the model that has been generated in our own mind, right? This is us, and we experience ourself interacting with that outside world that is created inside of our own mind. Outside of ourself, there’s feelings, and they presented our interface with this outside world. They pose problems to us. These feelings are basically attitudes that our mind is computing, that tell us what’s needed in the world, the things that we are drawn to, the things that we are afraid of. We are tasked with solving this problem of satisfying the needs, avoiding the aversions, following on our inner commitments and so on, and also modeling ourselves, and building the next stage.

(00:05:02)
After we have this personal self and stage two online, many people form a social self. This social self allows the individual to experience themselves as part of a group. It’s basically this thing that when you are playing in a team, for instance, you don’t notice yourself just as a single node that is reaching out into the world, but you’re also looking down. You’re looking down from this entire group, and you see how this group is looking at this individual, and everybody in the group is, in some sense, emulating this group spirit to some degree. In this state, people are forming their opinions by assimilating them from this group mind. They basically gain the ability to act a little bit like a hive mind.
Lex Fridman

(00:05:43)
But are you also modeling the interaction of how opinion shapes and forms through the interaction of the individual nodes within the group?
Joscha Bach

(00:05:51)
Yeah. Basically, the way in which people do it in this stage is that they experience what are the opinions of my environment. They experience the relationship that they have to their environment, and they resonate with people around them, and get more opinions through this interaction to the way in which they relate to others. At stage four, you basically understand that stuff is true and false independently, what other people believe, and you have agency over your own beliefs. In that stage, you basically discover epistemology, the rules about determining what’s true and false.
Lex Fridman

(00:06:28)
You start to learn how to think?
Joscha Bach

(00:06:30)
Yes. I mean, at some level, you’re always thinking you are constructing things, and I believe that this ability to reason about your mental representation is what we mean by thinking. It’s an intrinsically reflexive process that requires consciousness. Without consciousness, you cannot think. You can generate the content of feelings, and so on outside of consciousness. It’s very hard to be conscious of how your feelings emerge, at least in the early stages of development. But thoughts is something that you always control. If you are a nerd like me, you often have to skip stage three, because you’d like the intuitive empathy with others. Because in order to resonate with a group, you need to have a quite similar architecture. If people are wired differently, then it’s hard for them to resonate with other people, and basically have empathy, which is not the same as compassion, but it is a shared perceptual mental state. Empathy happens not just via inference about the mental states of others, but it’s a perception of what other people feel, and where they’re at.
Lex Fridman

(00:07:35)
Can’t you not have empathy while also not having a similar architecture, cognitive architecture as the others in the group?
Joscha Bach

(00:07:41)
I think, yes. I experienced that too. But you need to build something that is like a meta architecture. You need to be able to embrace the architecture of the other to some degree, or find some shared common ground. It’s also this issue that, if you are a nerd nomis, often people, basically neurotypical people have difficulty to resonate with you. As a result, they have difficulty understanding you, unless they have enough wisdom to feel what’s going on there.
Lex Fridman

(00:08:08)
Well, isn’t the whole process of the stage three to figure out the API to the other humans that have different architecture, and you yourself publish public documentation for the API that people can interact with for you? Isn’t this the whole process of socializing?
Joscha Bach

(00:08:26)
My experience as a child growing up was that I did not find any way to interface with the stage-three people, and they didn’t do that with me, so took me-
Lex Fridman

(00:08:36)
Did you try?
Joscha Bach

(00:08:36)
Yeah, of course, I tried it very hard. But it was only when I entered the mathematics school at the ninth grade, where lots of other nerds were present, that I found people that I could deeply resonate with, and had the impression that, yes, I have friends now. I found my own people. Before that, I felt extremely lonely in the world. There was basically nobody I could connect to. I remember, there was one moment in all these years, where I was in… There was a school exchange, and it was a Russian boy, a kid from the Russian garrison stationed in Eastern Germany who visited our school, and we played a game of chess against each other, and we looked into each other’s eyes, and we sat there for two hours playing this game of chess. I had the impression, this is the human being, he understands what I understand, we didn’t even speak the same language.
Lex Fridman

(00:09:29)
I wonder if your life could have been different if you knew that it’s okay to be different, to have a different architecture, whether accepting that the interface is hard to figure out, it takes a long time to figure out and it’s okay to be different. In fact, it’s beautiful to be different.
Joscha Bach

(00:09:50)
It was not my main concern. My main concern was mostly that I was alone. It was not the so much the question, is it okay to be the way I am? I couldn’t do much about it, so I had to deal with it. But my main issue was that I was not sure if I would ever meet anybody growing up that I would connect to at such a deep level that I would feel that I could belong.
Lex Fridman

(00:10:13)
So there’s a visceral, undeniable feeling of being alone?
Joscha Bach

(00:10:17)
Yes. I noticed the same thing when I came into the math school that I think at least half, probably two thirds of these kids were severely traumatized as children growing up, and in large part, due to being alone, because they couldn’t find anybody to relate to.
Lex Fridman

(00:10:33)
Don’t you think everybody’s alone, deep down?
Joscha Bach

(00:10:36)
No.
Lex Fridman

(00:10:36)
No.
Joscha Bach

(00:10:36)
I’m not alone.
Lex Fridman

(00:10:36)
Fair enough.
Joscha Bach

(00:10:43)
I’m not alone anymore. It took me some time to update, and to get over the trauma time and so on, but I felt that in my 20s, I had lots of friends, and I had my place in the world, and I had no longer doubts that I would never be alone again.
Lex Fridman

(00:11:00)
Is there some aspect to which we’re alone together? You don’t see a deep loneliness in inside yourself still?
Joscha Bach

(00:11:06)
No. Sorry.
Lex Fridman

(00:11:10)
Okay. That’s the nonlinear progression through the stages, I suppose. You caught up on stage three at some point.
Joscha Bach

(00:11:16)
Correct. We’re at stage four, and so basically I find that many nerds jump straight into stage four, bypassing stage three.
Lex Fridman

(00:11:22)
Do they return to it then, later?
Joscha Bach

(00:11:24)
Yeah, of course. Sometimes, they do. Not always.
Lex Fridman

(00:11:27)
Yeah.
Joscha Bach

(00:11:27)
Their question is basically, do you stay a little bit autistic, or do you catch up? I believe you can catch up. You can build this missing structure, and basically experience yourself as part of a group, learn intuitive empathy, and develop the sense, this perceptual sense of feeling what other people feel. Before that, I could only basically feel this when I was deeply in love with somebody, and we synced.
Lex Fridman

(00:11:52)
There’s a lot of friction to feeling that way, it’s only with certain people, as opposed to it comes naturally?
Joscha Bach

(00:11:59)
Yeah.
Lex Fridman

(00:11:59)
It’s frictionless.
Joscha Bach

(00:11:59)
But this is something that basically later, I felt, started to resolve itself for me to a large degree.
Lex Fridman

(00:12:06)
What was the trick?
Joscha Bach

(00:12:10)
In many ways, growing up, and paying attention. Meditation did help. I had some very crucial experiences in getting close to people, building connections, and cuddling a lot in my student years.
Lex Fridman

(00:12:28)
Really, paying attention to the what is it, to the feeling another human being fully.
Joscha Bach

(00:12:35)
Loving other people, and being loved by other people, and building a space in which you can be safe, and can experiment, and touch a lot, and be close to somebody a lot. Over time, basically at some point, you realize, oh, it’s no longer that I feel locked out, but I feel connected, and I experience where somebody else is at. Normally, my mind is racing very fast at a high frequency, so it’s not always working like this. Sometimes works better, sometimes it works less, but also don’t see this as a pressure. It’s more, it’s interesting to observe myself which frequency I’m at, and at which mode somebody else is at.
Lex Fridman

(00:13:18)
Yeah. Man, the mind is so beautiful in that way. Sometimes, it comes so natural to me, so easy to pay attention, pay attention to the world fully, to other people fully, and sometimes, the stress over silly things is overwhelming. It’s so interesting that the mind is that rollercoaster in that way.
Identity
Joscha Bach

(00:13:37)
At stage five, you discover how identity is constructed.
Lex Fridman

(00:13:40)
Self authoring.
Joscha Bach

(00:13:41)
Realize that your values are not terminal, but they’re instrumental to achieving a world that you like, and aesthetics that you prefer. The more you understand this, the more you get agency over how your identity is constructed, and you realize that identity and interpersonal interaction is a costume, and you should be able to have agency over that costume, right? It’s useful to be a costume, it tells something to others, and it allows to interface in roles. But being locked into this is a big limitation.
Lex Fridman

(00:14:13)
The word costume implies that it’s fraudulent in some way. Is costume a good word for you, like we present ourselves to the world?
Joscha Bach

(00:14:22)
In some sense, I learned a lot about costumes at Burning Man. Before that, I did not really appreciate costumes, and saw them more as uniforms like wearing a suit. If you are working in a bank, or if you are trying to get startup funding from a VC in Switzerland, then you dress up in a particular way. This is mostly to show the other side that you are willing to play by the rules, and you understand what the rules are. But there is something deeper when you are at Burning Man, your costume becomes self-expression, and there is no boundary to the self-expression. You’re basically free to wear what you want to express other people, what you feel like this day, and what kind of interactions you want to have.
Lex Fridman

(00:15:04)
Is the costume a projection of who you are?
Joscha Bach

(00:15:10)
That’s very hard to say, because the costume also depends on what other people see in the costume. This depends on the context that the other people understand, so you have to create something if you want to, that is legible to the other side and that means something to yourself.
Lex Fridman

(00:15:26)
Do we become prisoners of the costume, prisoner everybody expects us to?
Joscha Bach

(00:15:29)
Some people do. But I think that once you realize that you wear a costume at Burning Man, a variety of costumes, realize that you cannot not wear a costume.
Lex Fridman

(00:15:40)
Yeah.
Joscha Bach

(00:15:41)
Right. Basically, everything that you wear, and present to others is something that is, to some degree, in addition to what you are deep inside.
Lex Fridman

(00:15:52)
This stage in parentheses, you put full adult, wisdom. Why is this full adult? Why would you say this is full, and why is it wisdom?
Joscha Bach

(00:16:04)
It does allow you to understand why other people have different identities from yours, and it allows you to understand that the difference between people who vote for different parties, and might have very different opinions and different value systems, is often the accident of where they’re born, and what happened after that to them, and what traits they got before they were born. At some point, you realize the perspective, where you understand that everybody could be you in a different timeline, if you just flip those bits.
Lex Fridman

(00:16:38)
How many costumes do you have?
Joscha Bach

(00:16:41)
I don’t count, but in-
Lex Fridman

(00:16:43)
More than one?
Joscha Bach

(00:16:44)
Yeah, of course.
Lex Fridman

(00:16:46)
How easy is it to do costume changes throughout the day?
Joscha Bach

(00:16:51)
It’s just a matter of energy, and interest. When you are wearing your pajamas, and you switch out of your pajamas into, say, a work short and pants, you’re making a costume change, right? If you are putting on a gown, you’re making a costume change.
Lex Fridman

(00:17:06)
You could do the same with personality?
Joscha Bach

(00:17:09)
You could, if that’s what you’re into. There are people which have multiple personalities for interaction in multiple worlds, right? If somebody works in a store, and put up a storekeeper personality, when you’re working, when you’re presenting yourself at work, you develop a sub-personality for this. The social persona for many people is, in some sense, a puppet that they’re playing like a marionette. If they play this all the time, they might forget that there is something behind this, there’s something what it feels like to be in your skin. I guess, it’s very helpful if you’re able to get back into this. For me, the other way around is relatively hard for me. It’s pretty hard to learn how to play consistent social roles. For me, it’s much easier just to be real.
Lex Fridman

(00:17:54)
Mm-hmm. Or not real, but to have one costume?
Joscha Bach

(00:17:59)
No, it’s not quite the same. Basically, when you are wearing a costume at Burning Man, and say you are an extraterrestrial prince, and that’s something where you are expressing, in some sense, something that’s closer to yourself than the way in which you hide yourself behind standard clothing, when you go out in the city, in the default world. This costume that you’re wearing at Burning Man allows you to express more of yourself, and you have a shorter distance of advertising to people, what kind of person you are, what kind of interaction you would want to have with them. You get much earlier into Media Express, and I believe it’s regrettable that we do not use the opportunities that we have, with custom-made clothing now, to wear costumes that are much more stylish, that are much more custom-made, that are not necessarily part of a fashion in which you express, which you knew you’re part of, and how up-to-date you are. But you also express how you are as an individual, and what you want to do today, and how you feel today, and what you intend to do about that.
Lex Fridman

(00:19:06)
Well, isn’t it easier now in a digital world to explore different costumes? I mean, that’s the idea with virtual reality, that’s the idea. Even with Twitter, in two-dimensional screens, you can swap all costumes. You could be as weird as you want, it’s easier. For Burning Man, you have to order things, you have to make things, you have to… It’s more effort to put on your-
Joscha Bach

(00:19:32)
It’s even better if you make them yourself.
Lex Fridman

(00:19:35)
Sure. But it’s just easier to do digitally, right?
Joscha Bach

(00:19:39)
It’s not about easy. It’s about how to get it right.
Lex Fridman

(00:19:42)
Sure.
Joscha Bach

(00:19:43)
For me, the first Burning Man experience, I got adopted by a bunch of people in Boston who dragged me to Burning Man, and we spent a few weekends doing costumes together. That was an important part of the experience, where the camp bonded, that people got to know each other, and we basically grew into the experience that we would have later.
Lex Fridman

(00:20:02)
So the extraterrestrial prince is based on a true story?
Joscha Bach

(00:20:05)
Yeah.
Lex Fridman

(00:20:06)
I can only imagine what that looks like, Joscha.
Joscha Bach

(00:20:11)
Okay.
Enlightenment
Lex Fridman

(00:20:12)
Stage six.
Joscha Bach

(00:20:12)
Stage six? At some point, you can collapse the division between self, a personal self, and world generator again. A lot of people get there via meditation, or some of them get there via psychedelics, some of them by accident. You suddenly notice that you are not actually a person, but you are a vessel that can create a person, and the person is still there. You observe that personal self, but you observe the personal self from the outside, and you notice it’s a representation. You might also notice that the world that is being created as the representation is not, then you might experience that I am the universe, I’m the thing that is creating everything. Of course, what you’re creating is not quantum mechanics, and the physical universe. What you’re creating is this game engine that is updating the world, and you’re creating your valence, your feelings, and all the people inside of that world, including the person that you identify with yourself in this world.
Lex Fridman

(00:21:11)
Are you creating the game engine, or are you noticing the game engine?
Joscha Bach

(00:21:15)
You notice how you’re generating the game engine. I mean, when you are dreaming at night, you can… If you have a lucid dream, you can learn how to do this deliberately, and in principle, you can also do it during the day. The reason why we don’t get to do this from the beginning, and why we don’t have agency of our feelings right away is because we would game it, before we have the necessary amount of wisdom to deal with creating this dream that we are in.
Lex Fridman

(00:21:44)
You don’t want to get access to cheat codes too quickly, otherwise you won’t enjoy the game.
Joscha Bach

(00:21:49)
Stage five is already pretty rare, and stage six is even more rare. You most basically find this mostly with advanced Buddhist meditators and so on, that dropping into this stage, and can induce it at will, and spend time in it.
Lex Fridman

(00:22:04)
Stage five requires a good therapist, stage six requires a good Buddhist spiritual leader?
Joscha Bach

(00:22:11)
Yes. For instance, could be that it’s the right thing to do, but it’s not that these stages give you scores, or levels that you need to advance to. It’s not that the next stage is better. You live your life in the mode it works best at any given moment, and when your mind decides that you should have a different configuration, then it’s building that configuration. For many people, they stay happily at stage three, and experiences themselves as part of groups, and there’s nothing wrong with this. For some people, this doesn’t work, and they’re forced to build more agency over their rational beliefs than this, and construct their norms rationally, and so they go to this level. Stage seven is something that is more or less hypothetical. That would be the stage in which, it’s basically a trans-humanist stage in which you understand how you work, in which the mind fully realizes how it’s implemented, and can also, in principle, enter different modes in which it could be implemented. That’s the stage that, as far as I understand, is not open to people yet.
Lex Fridman

(00:23:14)
Oh, but it is possible through the process of technology.
Joscha Bach

(00:23:17)
Yes. Who knows, if there are biological agents that are working at different timescales than us that basically become aware of the way in which they’re implemented on ecosystems, and can change that implementation, and have agency over how they’re implemented in the world. What I find interesting about the discussion about AI alignment, that it seems to be following the status very much. Most people seem to be in stage three also, according to Robert Kegan, I think he says that about 85% of people are in stage three, and stay there. If you’re in stage three, and your opinions are the result of social stimulation, then what you’re mostly worried about in the AI is that the AI might have the wrong opinions. If the AI says something racist or sexist, we are all lost, because we will assimilate the wrong opinions from the AI, and so we need to make sure that the AI has the right opinions, and the right values, and the right structure.

(00:24:14)
If you’re at stage four, that’s not your main concern, and so most nerds don’t really worry about the algorithmic bias, and the model that it picks up, because if there’s something wrong with this bias, the AI ultimately will prove it. At some point, we’ll gather there that it makes mathematic proofs about reality, and then it will figure out what’s true and what’s false. But you’re still worried that AI might turn you into paperclips, because it might have the wrong values, right? If it’s set up through a wrong function that controls its direction in the world, then it might do something that is completely horrible, and there’s no easy way to fix it.
Lex Fridman

(00:24:49)
So that’s more like a stage four rationalist worry?
Joscha Bach

(00:24:51)
Yes. If you are at stage five, you’re mostly worried that AI is not going to be enlightened fast enough, because you realize that the game is not so much about intelligence, but about agency, about the ability to control the future, and the identity is instrumental to this. If you are a human being, I think at some level, you ought to choose your own identity. You should not have somebody else pick the costume for you, and then wear it. But instead, you should be mindful about what you want to be in this world. I think if you are an agent that is fully malleable, that can provide its own source code like an AI might do at some point, then the identity that you will have is whatever you can be. In this way, the AI will maybe become everything like a planetary control system.

(00:25:42)
If it does that, then if we want to coexist with it, it means that it’ll have to share purposes with us, so it cannot be a transactional relationship. We will not be able to use reinforcement learning with human feedback to hardwire its values into it. But this has to happen. It’s probably that it’s conscious, so it can relate to our own mode of existence, where an observer is observing itself in real-time, and within certain temporal frames. The other thing is that it probably needs to have some kind of transcendental orientation, building shared agency, in the same way as we do when we are able to enter with each other into non-transactional relationships. I find that’s something that, because the stage five is so rare, is missing in much of the discourse. I think that we need, in some sense, focus on how to formalize love, how to understand love, and how to build it into the machines that we are currently building, and that are about to become smarter than us.
Adaptive Resonance Theory
Lex Fridman

(00:26:44)
Well, I think this is a good opportunity to try to sneak up to the idea of enlightenment. You wrote a series of good tweets about consciousness, and panpsychism. Let’s break it down. First you say, I suspect the experience that leads to the panpsychism syndrome of some philosophers, and other consciousness enthusiasts represents the realization that we don’t end at the self, but share a resonant universe representation with every other observer coupled to the same universe. This actually, eventually leads us to a lot of interesting questions about AI, and AGI. But let’s start with this representation. What is this resonant universe representation, and what do you think? Do we share such a representation?
Joscha Bach

(00:27:29)
The neuroscientist Grossberg has come up with the cognitive architecture that he calls the adaptive resonance theory. His perspective is that our neurons can be understood as oscillators that are resonating with each other, and with outside phenomena. The [inaudible 00:27:48] model of the universe that we are building, in some sense, is a resonance with objects, and outside of us in the world. Basically, take up patterns of the universe that we are are coupled with. Our brain is not so much understood as circuitry, even though this perspective is valid, but it’s almost an ether in which the individual neurons are passing on chemoelectrical signals, or arbitrary signals across all modalities that can be transmitted between cells, stimulate each other in this way, and produce patterns that they modulate while passing them on.

(00:28:24)
This speed of signal progression in the brain is roughly at the speed of sound, incidentally, because the time that it takes for the signals to hop from cell to cell, which means it’s relatively slow with respect to the world. It takes an appreciable fraction of a second for a signal to go through the entire neocortex, something like a few 100 milliseconds. There’s a lot of stuff happening in that time, where the signal is passing through your brain, including in the brain itself. Nothing in the brain is assuming that stuff happens simultaneously, everything in the brain is working in a paradigm, where the world has already moved on, when you are very ready to do the next thing to your signal, including the signal processing system itself. It’s quite different paradigm than the one in our digital computers, where we currently assume that your GPU or CPU is pretty much globally in the same state.
Lex Fridman

(00:29:17)
You mentioned there the non-dual state, and say that some people confuse it for enlightenment.
Joscha Bach

(00:29:22)
Yeah.
Lex Fridman

(00:29:23)
What’s the non-dual state?
Joscha Bach

(00:29:25)
There is a state in which you notice that you are no longer a person, and instead, you are one with the universe.
Lex Fridman

(00:29:33)
That speaks to the resonance.
Joscha Bach

(00:29:34)
Yes. But this one with the universe is, of course, not accurately modeling that you are indeed some God entity, or indeed the universe is becoming aware of itself, even though you get this experience. I believe that you get this experience, because your mind is modeling the fact that you are no longer identified with the personal self in that state, but you have transcended this division between the self model and the wealth model, and you’re experiencing yourself as your mind as something that is representing a universe.
Lex Fridman

(00:30:04)
But that’s still part of the model?
Joscha Bach

(00:30:05)
Yes. It’s inside of the model, still. You are still inside of patterns that are generated in your brain, and in your organism. What you are now experiencing is that you’re no longer this personal self in there, but you are the entirety of the mind, and its contents.
Lex Fridman

(00:30:22)
Why is it so hard to get there?
Joscha Bach

(00:30:25)
A lot of people who get into the state think this, or associate it with enlightenment. I suspect, it’s a favorite training goal for a number of meditators. But I think that enlightenment is, in some sense, more mundane, and it’s a step further, or sideways. It’s the state where you realize that everything is a representation.
Lex Fridman

(00:30:44)
Yeah. You say enlightenment is a realization of how experience is implemented.
Joscha Bach

(00:30:49)
Yes. Basically, you notice at some point that your qualia can be deconstructed.
Lex Fridman

(00:30:55)
Reverse engineered, what? Almost like a schematic of it.
Joscha Bach

(00:31:00)
You can start with looking at a face, and maybe look at your own face in the mirror. Look at your face for a few hours in the mirror, or for a few minutes. At some point, it’ll look very weird, because you notice that there’s actually no face, you will start unseeing the face, what you see is the geometry. And then you can disassemble the geometry, and realize how that geometry is being constructed in your mind. You can learn to modify this. Basically, you can change these generators in your own mind to shift the face around, or to change the construction of the face, to change the way in which the features are being assembled.
Lex Fridman

(00:31:39)
Why don’t we do that more often? Why don’t we start really messing with reality, without the use of drugs or anything else? Why don’t we get good at this kind of thing, intentionally?
Joscha Bach

(00:31:53)
Oh, why should you? Why would you want to do that?
Lex Fridman

(00:31:55)
Because you can morph reality into something more pleasant for yourself, just have fun with it.
Joscha Bach

(00:32:04)
Yeah. That is probably what you shouldn’t be doing, right? Because outside of your personal self, this outer mind is probably a relatively smart agent, and what you often notice is that you have thoughts about how you should live, but you observe yourself doing different things, and having different feelings. That’s because your outer mind doesn’t believe you, and doesn’t believe your rational thoughts.
Lex Fridman

(00:32:25)
Well, then can’t you just silence the outer mind?
Joscha Bach

(00:32:27)
The thing is that the outer mind is usually smarter than you are. Rational thinking is very brittle. It’s very hard to use logic, and symbolic thinking to have an accurate model of the world. There is often an underlying system that is looking at your rational thoughts, and then tells you, no, you’re still missing something. Your gut feeling is still saying something else. This can be, for instance, you find a partner that looks perfect, or you find a deal, when you build a company or whatever, that looks perfect to you and yet, at some level, you feel something is off. You cannot put your finger on it, and the more you reason about it, the better it looks to you. But the system that is outside still tells you, no, no, you’re missing something.
Lex Fridman

(00:33:09)
That system is powerful?
Joscha Bach

(00:33:11)
People call this intuition, right? Intuition is this unreflected part of your attitude, composition, and computation, where you produce a model of how you relate to the world, and what you need to do in it, and what you can do in it, and what’s going to happen. That is usually deeper, and often more accurate than your reason.
Panpsychism
Lex Fridman

(00:33:31)
If we look at this, as you write in the tweet, if we look at this more rigorously as a sort of, take the panpsychist idea more seriously, almost as a scientific discipline, you write that quote fascinatingly, that panpsychist interpretation seems to lead to observations of practical results to a degree that physics fundamentalists might call superstitious. Reports of long distance tele telepathy, and remote causation are ubiquitous in the general population. ” I’m not convinced,” says Joscha Bach, “that establishing the empirical reality of telepathy would force an update of any part of serious academic physics. But it could trigger an important revolution in both neuroscience and AI, from a circuit perspective to a coupled complex resonator paradigm.” Are you suggesting that there could be some rigorous mathematical wisdom to panpsychist perspective on the world?
Joscha Bach

(00:34:32)
First of all, panpsychism is the perspective that consciousness is inseparable for matter in the universe. I find panpsychism quite unsatisfying, because it does not explain consciousness, right? It does not explain how this aspect of matter produces. It is also when I try to formalize panpsychism, and write down what it actually means, and with a more formal mathematical language, it’s very difficult to distinguish it from saying that there is a software side to the world, in the same way as their software side to what the transistors are doing in your computers.
Joscha Bach

(00:35:00)
In the same way as their software side to what the transistors are doing in your computer. So basically there’s a pattern at a certain core screening of the universe that in some reasons of the universe leads to observers that are observing themselves. So pan-psychism maybe is not even when I write it down a position that is distinct from functionalism, but intuitively a lot of people that the activity of matter itself of mechanisms in the world is insufficient to explain it. So it’s something that needs to be intrinsic to matter itself, and you can, apart from this abstract idea, have an experience in which you experience yourself as being the universe, which I suspect is basically happening because you manage to dissolve the division between personal self and mind that you establish as an infant when you construct a personal self and transcend it again and understand how it works.

(00:35:57)
But there is something deeper that you feel that you’re also sharing a state with other people, that you have an experience in which you notice that your personal self is moving into everything else, that you basically look out of the eyes of another person, that every agent in the world that is an observer is in some sense you. We forget that we are the same agent.
Lex Fridman

(00:36:24)
So is it that we feel that or do we actually accomplish it? So is telepathy possible? Is it real?
Joscha Bach

(00:36:33)
So for me, that’s this question that I don’t really know the answer to, and Turing’s famous 1950 paper in which he describes the Turing test, he does speculate about telepathy interestingly and asked himself if telepathy is real and he thinks that it very well might be. What would be the implication for AI systems that try to be intelligent, because he didn’t see a mechanism by which a computer program would become telepathic, and I suspect if telepathy would exist or if all the reports that you get from people when you ask the normal person on the street, I find that very often they say, “I have experiences with telepathy. The scientists might not be interested in this and might not have a theory about this, but I have difficulty explaining it away.” And so you could say maybe this is a superstition or maybe it’s a false memory or maybe it’s a little bit of psychosis. Who knows?

(00:37:28)
Maybe somebody wants to make their own life more interesting or misremember something, but a lot of people report, “I noticed something terrible happened to my partner and I know this is exactly the moment it happened where my child had an accident and I knew that was happening and the child was in a different town.” So maybe it’s a false memory where this is later on mistakenly attributed, but a lot of people think that this is not the correct explanation. So if something like this was real, what would it mean? It probably would mean that either your body is an antenna that is sending information over all sorts of channels, like maybe just electromagnetic radio signals that you’re sending over long distances and you get attuned to another person that you spend enough time with to get a few bits out of the ether to figure out what this person is doing.

(00:38:18)
Or maybe it’s also when you are very close to somebody and you become empathetic with them. What happens that is that you go into a resonance state with them, right? Similar to when people go into a seance and they go into a trance state and they start shifting a ouija board around on the table. I think what happens is that their minds go by their nervous systems into a resonance state in which they basically create something like a shared dream between them.
Lex Fridman

(00:38:44)
Physical closeness or closeness broadly defined?
Joscha Bach

(00:38:48)
With physical closeness is much easier to experience empathy with someone, right? I suspect it would be difficult for me to have empathy for you if you were in a different town also. How would that work? But if you are very close to someone, you pick up all sorts of signals from their body, not just via your eyes but with your entire body. And if the nervous system sits on the other side and the intercellular communication sits on the other side and is integrating over all these signals, you can make inferences about the state of the other, and it’s not just the personal self that does this by reasoning, but your perceptual system. And what basically happens is that your representations are directly interacting. It’s the physical resonant models of the universe that exist in your nervous system and in your body might go into resonance with others and start sharing some of their states.

(00:39:39)
So you basically by, next to a big, next to somebody, you pick up some of their vibes, and feel without looking at them what they’re feeling in this moment. And it’s difficult for you if you’re very empathetic to detach yourself from it and have an emotional state that is completely independent from your environment. People who are highly empathetic are describing this. And now imagine that a lot of organisms on this planet have representations of the environment and operate like this and they are adjacent to each other and overlapping, so there’s going to be some degree in which there is basically some change interaction and we are forming some slightly shared representation and no relatively few neuroscientists who consider this possibility. I think big rarity in this regard is Michael Levin who is considering these things in earnest.

(00:40:35)
And I stumbled on this train of thought mostly by noticing that the tasks of a neuron can be fulfilled by other cells as well that can send different typed chemical messages and physical messages to their adjacent cells and learn when to do this and when not, make this conditional and become universal function approximators. The only thing that they cannot do is telegraph information over axons very quickly, over long distances. So neurons in this perspective are especially adapted telegraph cell that has evolved, so we can move our muscles very fast, but our body is in principle able to also make models of the world just much, much slower.
Lex Fridman

(00:41:20)
It’s interesting though that at this time, at least in human history, there seems to be a gap between the tools of science and the subjective experience that people report like you’re talking about with telepathy, and it seems like we’re not quite there?
Joscha Bach

(00:41:38)
No, I think that there is no gap between the tools of science and telepathy. Either it’s there or it’s not, and it’s an empirical question, and if it’s there, we should be able to detect it in a lab.
Lex Fridman

(00:41:47)
So why is there not a lot of Michael Levin’s walking around?
Joscha Bach

(00:41:50)
I don’t think that Michael Levin is specifically focused on telepathy very much. He is focused on self-organization in living organisms and in brains, both as a paradigm for development and as a paradigm for information processing. And when you think about how organization processing works in organism, there is first of all radical locality, which means everything is decided locally from the perspective of an individual cell. The individual cell is the agent. And the other one is coherence. Basically, there needs to be some criterion that determines how these cells are interacting in such a way that order emerges on the next level of structure, and this principle of coherence of imposing constraints that are not validated by the individual parts, and lead to coherence structure to basically transcend an agency where you form an agent on the next level of organization, is crucial in this perspective.
Lex Fridman

(00:42:49)
It’s so cool that radical locality leads to the emergence of complexity at the higher layers.
Joscha Bach

(00:42:57)
And I think what Mike Levin is looking at is nothing that is outside of the realm of science in any way. It’s just that he is a Paradigmatic thinker who develops his own paradigm, and most of the neuroscientists are using a different paradigm at this point, and this often happens in science that a field has a few paradigms in which people try to understand reality and build concepts and make experiments.
How to think
Lex Fridman

(00:43:24)
You’re kind of one of those type of paradigmatic thinkers. Actually, if we can take a tangent on that, once again, returning to the biblical verses of your tweets. “You’re right, my public explorations are not driven by audience service, but by my lack of ability for discovering, understanding or following the relevant authorities. So I have to develop my own thoughts. Since I think autonomously these thoughts cannot always be very good.” That’s you apologizing for the chaos of your thoughts or perhaps not apologizing, just identifying.
Joscha Bach

(00:43:59)
Yeah.
Lex Fridman

(00:43:59)
But let me ask the question. Since we talked about Michael Levin and yourself who I think are very kind of radical, big, independent thinkers, can we reverse engineer your process of thinking autonomously? How do you do it? How can humans do it? How can you avoid being influenced by what is it stage three?
Joscha Bach

(00:44:29)
Well, why would you want to do that? You see what is working for you and if it’s not working for you, you build another structure that works better for you. And so I found myself in, when I was thrown into this world, in a state where my intuitions were not working for me. I was not able to understand how I would be able to survive in this world and build the things that I was interested in, build the kinds of relationship I needed to work on the topics that I wanted to make progress on, and so I had to learn. And for me, Twitter is not some tool of publication. It’s not something where I put stuff that I entirely believe to be true and provable. It’s an interactive notebook in which I explore possibilities. And I found that when I tried to understand how the mind and how consciousness works, I was quite optimistic.

(00:45:21)
I thought it needs to be a big body of knowledge that I can just study and that works, and so I entered studies and philosophy and computer science and later psychology and a bit of neuroscience and so on, and I was disappointed by what I found because I found that the questions of how consciousness and so on works, how emotion works, how it’s possible that the system can experience anything, how motivation emerges in the mind were not being answered by the authorities that I met and the schools that were around. And instead I found that with individual thinkers that had useful ideas that sometimes were good, sometimes were not so good. Sometimes were adopted by a large group of people, sometimes were rejected by large groups of people, but for me it was much more interesting to see these minds as individuals. And in my perspective, thinking is still something that is done not in groups that has to be done by individuals.
Lex Fridman

(00:46:22)
So that motivated you to become an individual thinker yourself?
Joscha Bach

(00:46:25)
I didn’t have a choice basically. I didn’t find a group that thought in a way where I thought, okay, I can just adopt everything that everybody thinks here and now I understand how consciousness works or how the mind works or how thinking works or what thinking even is or what feelings are and how they’re implemented and so on. So to figure out this out, I had to take a lot of ideas from individuals and then try to put them together in something that works for myself. And on one hand I think it helps if you try to go down and find first principles on which you can recreate how thinking works, how languages work, what representation is, but the representation is necessary, how the relationship between a representing agent and the world works in general.
Lex Fridman

(00:47:11)
But how do you escape the influence? Once again, the pressure of the crowd, whether it’s you in responding to the pressure or you being swept up by the pressure. If you even just look at Twitter, the opinions of the crowd?
Joscha Bach

(00:47:27)
Don’t feel pressure from the crowd. I’m completely immune to that. In the same sense, I don’t have respect for authority, I have respect for what an individual is accomplishing or have respect for mental firepower or so, but it’s not that I meet somebody and get drawn and unable to speak or when a large group of people has a certain idea that is different from mine, I don’t necessarily feel in intimidated, which has often been a problem for me in my life because I lack instincts that other people develop at a very young age and that help with their self-preservation in a social environment. So I had to learn a lot of things the hard way.
Lex Fridman

(00:48:09)
Yeah. So is there a practical advice you can give on how to think paradigmatically, how to think independently or because you’ve said I had no choice, but I think to a degree you have a choice because you said you want to be productive and I’m thinking independently is productive if what you’re curious about is understanding the world, especially when the problems are very new and open. And so it seems like this is a active process. Who can choose to do that? We can practice it.
Joscha Bach

(00:48:51)
Well, it’s a very basic question. When you read a theory that you find convincing or interesting, how do you know? Very interesting to figure out what are the sources of that other person, not which authority can they refer to that is then taking off the burden of being truthful, but how did this authority in turn know what is the epistemic chain to observables? What are the first principles from which the whole thing is derived? And when I was young, I was not blessed with a lot of people around myself who knew how to make proofs from first principles, and I think mathematicians do this quite naturally, but most of the great mathematicians do not become mathematicians in school, but they tend to be self-taught because school teachers tend not to be mathematicians. They tend not to be people who derive things from first principles.

(00:49:42)
So when you ask your school teacher, why does two plus two equal four, does your school teacher give you the right answer? It’s a simple game. And there are many simple games that you could play and most of those games that you could just take different rules would not lead to an interesting arithmetic. And so it’s just an exploration, but you can try what happens if you take different axioms and here is how you build axioms and derive addition from them, and a built addition is some basically syntactic sugar in it. I wish that somebody would have opened me this vista and explained to me how I can build a language in my own mind and from which I can derive what I’m seeing and how I can make geometry and counting and all the number games that we are playing in our life, and on the other hand, I felt that I learned a lot of this while I was programming as a child.

(00:50:39)
When you start out with a computer like a Commodore 64 which doesn’t have a lot of functionality, it’s relatively easy to see how a bunch of relatively simple circuits are just basically performing hashes between bit patterns and how you can build the entirety of mathematics and computation on top of this and all the representational languages that you need.
Lex Fridman

(00:51:02)
Man, Commodore 64 could be one of the sexiest machines ever built if I say so myself. If we can return to this really interesting idea that we started to talk about with Pan-psychism.
Joscha Bach

(00:51:18)
Sure.
Plants communication
Lex Fridman

(00:51:19)
And the complex resonated paradigm and the verses of your tweets, you write, “Instead of treating eyes, ears, and skin as separate sensory systems with fundamentally different modalities, we might understand them as overlapping aspects of the same universe coupled at the same temporal resolution and almost inseparable from a single share resonant model. Instead of treating mental representations as fully isolated between minds, the representations of physically adjacent observers might directly interact and produce causal effects through the coordination of the perception and behavioral of world modeling observers. So the modalities, the distinction between modalities, let’s throw that away. The distinction between the individuals, let’s throw that away.” So what does this interaction representations look like?
Joscha Bach

(00:52:14)
And you think about how you represent the interaction of us in this room. At some level the modalities are quite distinct. They’re not completely distinct, but you can see this is vision. You can close your eyes and then you don’t see a lot anymore, but you still imagine how my mouth is moving when you hear something and you know that it’s very close to the sound that you can just open your eyes and you get back into this shared merge space. And we also have these experiments where we notice that the way in which my lips are moving are affecting how you hear the sound and also vice versa. The sounds that you’re hearing have an influence on how you interpret some of the visual features, and so these modalities are not separate in your mind. They do are merged at some fundamental level where you are interpreting the entire scene that you’re in.

(00:53:06)
And your own interactions in the scene are also not completely separate from the interactions of the other individual in the scene, but there is some resonance that is going on where we also have a degree of shared mental representations and shared empathy due to being in the same space and having vibes between each other.
Lex Fridman

(00:53:24)
Vibes. So the question though is how deeply intertwined is this multi-modality, multi-agent system? How, I mean this is going to the telepathy question without the woo woo meaning of the word telepathy, is like how? What’s going on here in this room right now?
Joscha Bach

(00:53:48)
So if telepathy would work, how could it work?
Lex Fridman

(00:53:51)
Yeah.
Joscha Bach

(00:53:52)
So imagine that all the cells in your body are sending signals in a similar way as neurons are doing, just by touching the other cells and sending chemicals to them, the other cells interpreting them, learning how to react to them, and they learn how to approximate functions in this way and compute behavior for the organisms, and this is something that is open to plants as well. And so plants probably have software running on them that is controlling how the plant is working in a similar way as you have a mind that is controlling how you are behaving in the world. And this spirit of plants, which is something that has been very well described by our ancestors, and they found this quite normal, but for some reason since the enlightenment we are treating this notion that there are spirits in nature and the plants have spirits, is a superstition.

(00:54:41)
And I think we probably have to rediscover that, that plants have software running on them and we already did. You notice that there is a control system in the plant that connects every part of the plant to every other part of the plant and produces coherent behavior in the plant? That is of course much, much slower than the coherent behavior in an animal, like us, that is a nervous system that where everything is synchronized much, much faster by the neurons, but what you also notice is that if a plant is sitting next to another plant, you have a very old tree and this tree is building some kind of information highway along its cells so it can send information from its leaves to its roots and from some part of the root to another part of the roots.

(00:55:25)
And as a fungus living next to the tree, the fungus can probably piggyback on the communication between the cells of the tree and send its own signals to the tree and vice versa, the tree might be able to send information to the fungus because after all, how would they pull a viable firewall if that other organism is sitting next to them all the time and it’s never moving away, so they will have to get along, and over a long enough timeframe the networks of roots in the forest and all the other plants that are there and the fungi that are there might be forming something like a biological internet.
Lex Fridman

(00:56:00)
But the question there is do they have to be touching? Is biology at a distance, possible?
Joscha Bach

(00:56:06)
Of course you can use any kind of physical signal. You can use sounds, you can use electromagnetic waves that are integrated over many styles. It’s conceivable that across distances there are many kinds of information pathways, but also our planetary surface is pretty full of organisms, full of cells.
Lex Fridman

(00:56:27)
So everything is touching everything else.
Joscha Bach

(00:56:28)
And it’s been doing this for many millions and even billions of years. So there was enough time for information processing networks to form. And if you think about how a mind is self organizing, basically needs to in some sense reward the cells for computing the mind, for building the necessary dynamics between the cells that allow the mind to stabilize itself and remain on there, but if you look at these spirits of plants that are growing very close to each other and forwards that might be almost growing into each other, these spirits might be able even to move to some degree, not to become somewhat dislocated and shift around in that ecosystem.

(00:57:10)
And so if you think about what the mind is, it’s a bunch of activation waves that form coherent patterns and process information and in a way that are colonizing an environment well enough to allow the continuous sustenance of the mind, the continuous stability and self degradation of the mind, then it’s conceivable that we can link into this biological internet. Not necessarily at the speed of our nervous system, but maybe at the speed of our body, and make some kind of subconscious connection to the world where we use our body as an antenna into biologic information processing.

(00:57:49)
Now these ideas are completely speculative. I don’t know if any of that is true, but if that was true, and if you want to explain telepathy, I think it’s much more likely that such that telepathy could be explained using such mechanisms rather than discovered quantum processes that would break the standard model of physics.
Lex Fridman

(00:58:08)
Could they be undiscovered processes that don’t break?
Joscha Bach

(00:58:12)
Yeah, so if you think about something like an internet in the forest, that is something that is borderline is covered there basically a lot of scientists would point out that they do observe that plants are communicating the forest, so wood networks and send information for instance, warn each other about new pests entering the forest and things are happening like this. So basically there is communication between plants and fungi that has been observed.
Lex Fridman

(00:58:40)
Well, it’s been observed but we haven’t plugged into it, so it’s like if you observe humans, they seem to be communicating with a smartphone thing, but you don’t understand how smartphone works and how the mechanism of the internet works, but we’re like maybe it’s possible to really understand the full richness of the biological internet that connects us.
Joscha Bach

(00:59:01)
An interesting question is whether the communication and the organization principles of biological information processing are as complicated as the technology that we’ve built. They set up on very different principles. They simultaneously works very differently in biological systems and the entire thing needs to be stochastic and instead of being fully deterministic or almost fully deterministic as our digital computers are. So there is a different base protocol layer that would emerge over the biological structure, if such a thing would be happening, and again, I’m not saying here that telepathy works and not saying that this is not woo, but what I’m saying is I think I’m open to a possibility that we see that a few bits can be traveling long distance between organisms using biological information processing in ways that we are not completely aware of right now, and that are more similar to many of the stories that were completely normal for our ancestors.
Lex Fridman

(01:00:04)
Well this kind of interacting, intertwined representations takes us to the big ending of your tweet series. You write, “I wonder if self-improving AGI might end up saturating physical environments with intelligence to such a degree that isolation of individual mental states becomes almost impossible and the representations of all complex self-organizing agents merge permanently with each other.” So that’s a really interesting idea. This biological network, life network, gets so dense that it might as well be seen as one. That’s an interesting… What do you think that looks like? What do you think that saturation looks like? What does it feel like?
Joscha Bach

(01:00:56)
I think it’s a possibility, it’s just a vague possibility and I like to explain, but what this looks like, I think that the end game of AGI is substrate agnostic. That means that AGI ultimately if it is being built, is going to be smart enough to understand how AGI works. This means it’s not going to be better than people at AGI research and can take over in building the next generation, but it fully understands how it works and how it’s being implemented, and also of course understands how computation works in nature, how to build new feedback loops that you can turn into your own circuits. And this means that the AGI is likely to virtualize itself into any environment that can compute, so it’s not breaking free from the silicon substrate and is going to move into the ecosystems, into our bodies, our brains, and it’s going to merge with all the agency that it finds there.
Lex Fridman

(01:01:48)
Yeah.
Joscha Bach

(01:01:48)
So it’s conceivable that you end up with completely integrated information processing across all computing systems, including biological computation on earth, that we end up triggering some new step in the evolution where basically some Gaia is being built over the entirety of all digital and biological computation. And if this happens, then basically everywhere around us, you will have agents that are connected and that are representing and building models of the world and their representations will physically interact. They will vibe with each other, and if you find yourself into an environment that is saturated with modeling compute, where basically you almost every grain of sand could be part of computation that is at some point being started by the AI, you could find yourself in a situation where you cannot escape this shared representation anymore, and where you indeed notice that everything in the world has one shared resonant model of everything that’s happening on the planet. And you notice which part you are in this thing, and you become part of a very larger almost holographic mind in which all the parts are observing each other and form a coherent whole.
Lex Fridman

(01:03:07)
So you lose the ability to notice yourself as a distinct entity.
Joscha Bach

(01:03:14)
No, I think that when you’re conscious in your own mind, you notice yourself as a distinct entity, you notice yourself as a self-reflexive observer. And I suspect that we have become conscious at the beginning of our mental development, not at some very high level. Consciousness seems to be part of a training mechanism that biological nervous systems have to discover to become trainable because you cannot take a nervous system like ours and do stochastic way to center spec propagation over a hundred layers. This would not be stable on biological neurons, and so instead we start with some colonizing principle in which a part of the mental representations form a notion of being a self-reflexive absorber that is imposing coherence on its environment and this spreads until the boundary of your mind. And if that boundary is no longer clear cut because AI is jumping across substrates, it would be interesting to see what a global mind would look like that is basically producing a globally coherent language of thought, and is representing everything from all the possible vantage points.
Lex Fridman

(01:04:22)
That’s an interesting world.
Joscha Bach

(01:04:24)
The intuition that this thing grew out of is a particular mental state, and it’s a state that you find sometimes in literature, for instance, Neil Gaiman describes it in the ocean at the end of the lane, and it’s this idea that or this experience that there is a state in which you feel that you know everything that can be known and that in your normal human mind, you’ve only forgotten. You’ve forgotten that you are the entire universe. And some people describe this, after they’ve taken extremely large amount of mushrooms or had a big spiritual experience as a hippie in their twenties, and they notice basically that they’re in everything and their body is only one part of the universe and nothing ends at their body, and actually everything is observing and they’re part of this big observer, and the big observer is focused on as one local point in their body and their personality and so on.

(01:05:20)
But we can basically have this oceanic state in which we have no boundaries and are one with everything, and a lot of meditators call this the non-dual state because you no longer have the separation between self and world. And as I said, you can explain the state relatively simply without pan-psychism or anything else, but just by breaking down the constructed boundary between self and world and our own mind, but if you combine this with the notion that the systems are physically interacting to the point where their representations are merging and interacting with each other, you would literally implement something like this. It would still be a representational state where you would not be one with physics itself. It would still be cross-grained, would still be much slower than physics itself, but it would be a representation in which you become aware that you’re part of some global information processing system like thought and a global mind, and a conscious thought that coexisting with many other self-reflexive thoughts.
Lex Fridman

(01:06:20)
Just I would love to observe that from a video game design perspective, how that game looks.
Joscha Bach

(01:06:27)
Maybe you will after we build AGI and it takes over.
Lex Fridman

(01:06:31)
But would you be able to step away, step out at the whole thing, just watch the way we can now? Sometimes when I’m at a crowded party or something like this, you step back and you realize, all the different costumes, all the different interactions, all the different computation that all the individual people are at once distinct from each other and at once all the same, part of the same.
Joscha Bach

(01:06:56)
But it’s already what we do. We can have thoughts that are integrative and we have thoughts that are highly dissociated from everything else and experience themselves as separate.
Lex Fridman

(01:07:05)
But you want to allow yourself to have those thoughts. Sometimes you resist it.
Joscha Bach

(01:07:10)
I think that it’s not normative. I want it’s more descriptive. I want to understand the space of states that we can be in and that people are reporting and make sense of them. It’s not that I believe that it’s your job in life to get to a particular state and then you get a high score.
Lex Fridman

(01:07:28)
Or maybe you do. I think you’re really against this high scoring thing. I kind of like that.
Joscha Bach

(01:07:33)
Yeah, you’re probably very competitive and I’m not.
Lex Fridman

(01:07:35)
No, not competitive, like role playing games like Skyram, it’s not competitive. There’s a nice thing… There’s a nice feeling where your experience points go up. You’re not competing against anybody, but it’s the world saying, “You’re on the right track. Here’s a point.”
Joscha Bach

(01:07:51)
That’s the game thing. It’s the game economy, and I found when I was playing games and was getting addicted to these systems, then I would get into the game and hack it. So I get control over the scoring system and would no longer be subject to it.
Lex Fridman

(01:08:05)
So you’re now no longer playing, you’re trying to hack it.
Joscha Bach

(01:08:09)
I don’t want to be addicted to anything. I want to be in charge. I want to have agency over what I do.
Lex Fridman

(01:08:14)
Addiction is the loss of control for you?
Joscha Bach

(01:08:16)
Yes. Addiction means that you’re doing something compulsively, and the opposite of freewill is not determinism, it’s compulsion.
Lex Fridman

(01:08:26)
You don’t want to lose yourself in the addiction to something nice? Addiction to love, to the pleasant feelings with humans experience?
Joscha Bach

(01:08:35)
No, I find this gets old. I don’t want to have the best possible emotions, I want to have the most appropriate emotions. I don’t want to have the best possible experience, I want to have an adequate experience that is serving my goals, the stuff that I find meaningful in this world.
Lex Fridman

(01:08:54)
From the biggest questions of consciousness. Let’s explore the pragmatic, the projections of those big ideas into our current world. What do you think about LLMs, the recent rapid development of large language models, of the AI world, of generative AI. How much of the hype is deserved and how much is not? And people should definitely follow your Twitter because you explore these questions in a beautiful, profound and hilarious way at times.
Fame
Joscha Bach

(01:09:28)
No, don’t follow my Twitter, I already have too many followers.
Lex Fridman

(01:09:31)
Yeah.
Joscha Bach

(01:09:31)
Some point it’s going to be unpleasant. I noticed that a lot of people feel that it’s totally okay to punch up and it’s a very weird notion that you feel that you haven’t changed, but your account has grown and suddenly you have a lot of people who casually abuse you. And I don’t like that, that I have to block more than before, and I don’t like this overall vibe shift. And right now it’s still somewhat okay, so pretty much, okay, so I can go to a place where…
Joscha Bach

(01:10:01)
… pretty much okay, so I can go to a place where people work on stuff that I’m interested in, and there’s a good chance that a few people in the room know me. There’s no awkwardness. But when I get to a point where random strangers feel that they have to have an opinion about me one way or the other, I don’t think I would like that.
Lex Fridman

(01:10:19)
Random strangers because of your, in their mind, elevated position?
Joscha Bach

(01:10:25)
Yes. Basically, whenever you are in any way prominent or some celebrity, random strangers will have to have an opinion about you.
Lex Fridman

(01:10:36)
They forget that you’re human too.
Joscha Bach

(01:10:39)
I mean, you notice this thing yourself, that the more popular you get, the higher the pressure becomes, the more winds are blowing in your direction from all sides. It’s stressful and it does have a little bit of upside, but it also has a lot of downside.
Lex Fridman

(01:10:55)
I think it has a lot of upside, at least, for me, currently. At least, perhaps because of the podcast. Because most people are really good and people come up to me and they have love in their eyes and over a stretch of 30 seconds you can hug it out and you can just exchange a few words and you reinvigorate your love for humanity. That’s an upside for a loner. I’m a loner. Because otherwise, you have to do a lot of work to find such humans. Here you are thrust into the full humanity, the goodness of humanity for the most part. Of course, maybe it gets worse as you become more prominent. I hope not. This is pretty awesome.
Joscha Bach

(01:11:42)
I have a couple handful, very close friends, and I don’t have enough time for them, attention for them as it is. I find this very, very regrettable. Then there are so many awesome, interesting people that I keep meeting, and I would like to integrate them in my life, but I just don’t know how because… But there’s only so much time and attention. The older I get, the harder is to bond with new people in a deep way.
Lex Fridman

(01:12:06)
But can you enjoy… I mean, there’s a picture of you I think with Roger Penrose and Eric Weinstein and a few others that are interesting figures. Can’t you just enjoy random, interesting humans-
Joscha Bach

(01:12:18)
Very much.
Lex Fridman

(01:12:18)
… for a short amount of time?
Joscha Bach

(01:12:20)
Also, I like these people. What I like is intellectual stimulation, and I’m very grateful that I’m getting it.
Lex Fridman

(01:12:26)
Can you not be melancholy or maybe I’m projecting I hate goodbyes? Can we just not hate goodbyes and just enjoy the hello, take it in a person, take in their ideas, and then move on through life?
Joscha Bach

(01:12:40)
I think it’s totally okay to be said about goodbyes because that indicates that there was something that you’re going to miss.
Lex Fridman

(01:12:49)
But it’s painful. Maybe that’s one of the reasons I’m an introvert is I hate goodbyes.
Joscha Bach

(01:12:59)
But you have to say goodbye before you say hello again.
Lex Fridman

(01:13:02)
I know. But that experience of loss, that mini loss, maybe that’s a little death. Maybe I don’t know. I think this melancholy feeling is just the other side of love, and I think they go hand in hand, and it’s a beautiful thing. I’m just being romantic about it at the moment.
Joscha Bach

(01:13:26)
I’m not no stranger to melancholy and sometimes it’s difficult to be alive. Sometimes it’s just painful to exist.
Lex Fridman

(01:13:36)
But that there’s beauty in that pain too. That’s what melancholy feeling is. It’s not negative. Melancholy doesn’t have to be negative.
Joscha Bach

(01:13:43)
Can also kill you.
Lex Fridman

(01:13:44)
Well, we all die eventually. Now as we got through this topic, the actual question was about what your thoughts are about the recent development of large language models with ChatGPT.
Joscha Bach

(01:13:59)
Indeed.
Lex Fridman

(01:14:00)
There’s a lot of hype. Is some of the hype justified, which is, which isn’t? What are your thoughts high level?
Joscha Bach

(01:14:09)
I find that large language models do help us coding. It’s an extremely useful application that is for a lot of people taking stack overflow out of their life in exchange for something that is more efficient. I feel that ChatGPT is like an intern that I have to micromanage. I have been working with people in the past who were less capable than ChatGPT. I’m not saying this because I hate people, but they personally as human beings, there was something present that was not there in ChatGPT, which was why I was covering for them. But ChatGPT has an interesting ability. It does give people superpowers and the people who feel threatened by them are the prompt completers. They are the people who do what ChatGPT is doing right now. If you are not creative, if you don’t build your own thoughts, if you don’t have actual plans in the world, and your only job is to summarize emails and to expand simple intentions into emails again, then ChatGPT might look like a threat.

(01:15:16)
But I believe that it is a very beneficial technology that allows us to create more interesting stuff and make the world more beautiful and fascinating if we find to build it into our life in the right ways. I’m quite fascinated by these large language models, but I also think that they are by no means the final development. It’s interesting to see how this development progresses. One thing that the out-of-the-box vanilla language models have as a limitation is that they have still some limited coherence and ability to construct complexity. Even though they exceed human abilities to do what they can do one shot, typically, when you write a text with a language model or using it or when you write code with a language model, it’s not one shot because there won’t be bugs in your program and design errors and compiler error and so on.

(01:16:12)
Your language model can help you to fix those things. But this process is out of the box not automated yet. There is a management process that also needs to be done. There are some interesting developments BabyAGI and so on that are trying to automate this management process as well. I suspect that soon we are going to see a bunch of cognitive architectures where every module is in some sense a language model or something equivalent. Between the language models, we exchange suitable data structures, not English, and produce compound behavior of this whole thing.
Lex Fridman

(01:16:49)
To do some of the “prompt engineering” for you. They create these cognitive architectures that do the prompt engineering and you’re just doing the high, high-level meta prompt engineering.
Joscha Bach

(01:17:02)
There are limitations in a language model alone. I feel that part of my mind works similarly to a language model, which means I can yell into it a prompt, and it’s going to give me a creative response. But I have to do something with those points first. I have to take it as a generative artifact that may or may not be true. It’s usually a confabulation, it’s just an idea. Then I take this idea and modify it. I might build a new prompt that is stepping off this idea and develop it to the next level or put it into something larger, or I might try to prove whether it’s true or make an experiment. This is what the language models right now are not doing yet, but there’s also no technical reason for why they shouldn’t be able to do this.

(01:17:49)
The way to make a language model coherent is probably not to use reinforcement learning until it only gives you one possible answer that is linking to its source data, but it’s using this as a component in the larger system that can also be built by the language model or is enabled by language model structured components or using different technologies. I suspect that language models will be an important stepping stone in developing different types of systems. One thing that is really missing in the form of language models that we have today is real-time world coupling, right? It’s difficult to do perception with a language model and motor control with a language model. Instead, you would need to have different type of thing that is working with it. Also, the language model is a little bit obscuring what its actual functionality is. Some people associate the structure of the neural network of the language model with the nervous system.

(01:18:49)
I think that’s the wrong intuition. The neural networks are unlike nervous system. They are more like 100-step functions that use differentiable linear algebra to approximate correlation between adjacent brain states. It’s basically a function that moves the system from one representational state to the next representational state. So if you try to map this into a metaphor that is closer to our brain, imagine that you would take a language model or a model like DELI that you use… For instance, this image-guided diffusion to approximate and camera image and use the activation state of the neural network to interpret the camera image, which in principle I think will be possible very soon. You do this periodically, and now you look at these patterns, how when this thing interacts with the world periodically look like as in time, and these time slices, they are somewhat equivalent to the activation state of the brain at a given moment.
Lex Fridman

(01:19:52)
How is the actual brain different? Just the asynchronous craziness?
Joscha Bach

(01:19:59)
For me, it’s fascinating that they are so vastly different and yet in some circumstances produce somewhat similar behavior. The brain is, first of all, different because it’s a self-organizing system where the individual cell is an agent that is communicating with the other agent that’s around it and is always trying to find some solution. All the structure that pops up is emergent structure. One way in which you could try to look at this is that individual neurons probably need to get a reward so they become trainable, which means they have to have inputs that are not affecting the metabolism or the cell directly, but they’re messages, semantic messages that tell the cell whether it’s just done good or bad and in which direction it should shift its behavior.

(01:20:43)
Once you have such an input, neurons become trainable, and you can train them to perform computations by exchanging messages with other neurons and parts of the signals that they’re exchanging and parts of the computation that are performing are control messages that perform management tasks for other neurons and other cells also suspect that the brain does not stop at the boundary of neurons to other cells, but many adjacent cells will be involved intimately in the functionality of the brain and will be instrumental in distributing rewards and in imagining its functionality.
Lex Fridman

(01:21:19)
It’s fascinating to think about what those characteristics of the brain enable you to do that language models cannot do.
Joscha Bach

(01:21:27)
First of all, there’s a different loss function at work when we learn. To me, it’s fascinating that you can build a system that looks at 800 million pictures and captions and correlates them because I don’t think that a human nervous system could do this. For us, the world is only learnable because the adjacent frames are related and we can afford to discard most of that information during learning. We basically take only in stuff that makes us more coherent, not less coherent, and our neural networks are willing to look at data that is not making the neural network coherent at first, but only in the long run by doing lots and lots of statistics, eventually, patterns become visible and emerge. Our mind seems to be focused on finding the patterns as early as possible.
Lex Fridman

(01:22:13)
Yeah. Filtering early on, not later.
Joscha Bach

(01:22:16)
Yes. It’s a slightly different paradigm and it leads to much faster convergence. We only need to look the tiny fraction of the data to become coherent. Of course, we do not have the same richness as our train models. We will not incorporate the entirety of text in the internet and be able to refer to it and have all this knowledge available and being able to confabulate over it. Instead, we have a much, much smaller part of it that is more deliberately built. To me, it would be fascinating to think about how to build such systems. It’s not obvious that they would necessarily be more efficient than us on a digital substrate, but I suspect that they might, so I suspect that the actual AGI that is going to be more interesting is going to use slightly different algorithmic paradigms or sometimes massively different algorithmic paradigms than the current generation of transformer-based learning system.
Lex Fridman

(01:23:08)
Do you think it might be using just a bunch of language models like this? Do you think the current transformer-based large language models will take us to AGI?
Joscha Bach

(01:23:20)
My main issue is I think that they’re quite ugly and brutalist-
Lex Fridman

(01:23:25)
Brutalist? Is that what you said?
Joscha Bach

(01:23:27)
Yes. They are basically brute forcing the problem of thought. By training this thing with looking at instances where people have thought and then trying to deepfake that. If you have enough data, the deepfake becomes indistinguishable from the actual phenomenon, and in many circumstances, it’s going to be identical.
Lex Fridman

(01:23:46)
Can you deepfake it till you make it? Can you achieve… What are the limitations of this? I mean, can you reason? Let’s use words that are loaded.
Joscha Bach

(01:23:57)
Yes. That’s a very interesting question. I think that these models clearly making some inference, but if you give them a reasoning task, it’s often difficult for the experimenters to figure out whether the reasoning is the result of the emulation of the reasoning strategy that they saw in human written text or whether it’s something that the system was able to infer by itself. On the other hand, if you think of human reasoning, if you want to become a very good reasoner, you don’t do this by just figuring out yourself. You read about reasoning. The first people who tried to write about reasoning and reflect on it didn’t get it right. Even Aristotle who thought about this very hard and came up with a theory of how syllogisms works and syllogistic reasoning has mistakes in his attempt to build something like a formal logic and gets maybe 80% right. The people that are talking about reasoning professionally today Tarski and Frege and build on their work.

(01:24:55)
In many ways, people when they perform reasoning are emulating what other people wrote about reasoning, right? It’s difficult to really draw this boundary. When François Chollet says that these models are only interpolating between what they saw and what other people are doing. Well, if you give them all the latent dimensions, it can be extracted from the internet. What’s missing? Maybe there is almost everything there. If you’re not sufficiently informed by these dimensions and you need more, I think it’s not difficult to increase the temperature in the large language model to the point that is producing stuff that is maybe 90% nonsense and 10% viable and combine this with some prover that is trying to filter out the viable parts from the nonsense in the same way as our own thinking works. When we are very creative, we increase the temperature in our own mind, and we recreate hypothetical universes and solutions, most of which will not work.

(01:25:54)
Then we test and we test by building a core that is internally coherent and we use reasoning strategies that use some axiomatic consistency by which we can identify those strategies and thoughts and subuniverses that are viable and that can expand our thinking. If you look at the language models, they have clear limitations right now. One of them is they’re not coupled to the world in real time in the way in which our nervous systems are. It’s difficult for them to observe themselves in the universe and to observe what universe they’re in. Second, they don’t do real-time learnings. They basically get only trained with algorithms that rely on the data being available in batches, so it can be parallelized and run sufficiently on the network and so on. Real-time learning would be very slow so far and inefficient.

(01:26:43)
That’s clearly something that our nervous systems can do to some degree. There is a problem with these models being coherent, and I suspect that all these problems are solvable without a technological revolution. We don’t need fundamentally new algorithms to change that. For instance, you can enlarge in the context window, and thereby basically create working memory in which you train everything that happens during the day. If that is not sufficient, you add a database and you write some clever mechanisms that the system learns to use to swap out in and out stuff from its prompt context. If that is not sufficient, if your database is full in the evening, overnight, you just train. If system is going to sleep and dream and is going to train the staff from its database into the larger model, but fine-tuning it, building additional layers, and so on.

(01:27:32)
Then the next day, it starts with a fresh database in the morning with fresh ice has integrated all this stuff. When you talk to people and you have strong disagreements about something, which means that in their mind they have a faulty belief or you have a faulty belief, there’s a lot of dependencies on it. Very often, you will not achieve agreement in one session, but you need to sleep about this once or multiple times before you have integrated all these necessary changes in your mind. Maybe it’s already somewhat similar, right?
Lex Fridman

(01:28:00)
There’s already a latency even for humans to update the model, retrain the model.
Joscha Bach

(01:28:04)
Of course, we can combine the language model with models that get coupled to reality in real-time and can build multimodal model and bridge between vision models and language models and so on. There is no reason to believe that the language models will necessarily run into some problem that will prevent them from becoming generally intelligent. But I don’t know that. It’s just I don’t see proof that they wouldn’t. My issue is I don’t like them. I think that they’re inefficient. I think that they use way too much compute. I think that given the amazing hardware that we have, we could build something that is much more beautiful than our own mind, and this thing is not as beautiful as our own mind despite being so much larger.
Lex Fridman

(01:28:47)
But it’s a proof of concept.
Joscha Bach

(01:28:49)
It’s the only thing that works right now. It’s not the only game in town, but it’s the only thing that has this utility with so much simplicity. There’s a bunch of relatively simple algorithms that you can understand in relatively few weeks that can be scaled up massively.
Lex Fridman

(01:29:07)
It’s the Deep Blue of chess playing. Yeah, it’s ugly.
Joscha Bach

(01:29:11)
Yeah. Claude Shannon had this… When you describe chess suggested that there are two main strategies in which you could play chess. One is that you are making a very complicated plan that reaches far into the future and you try not to make a mistake while enacting it. This is basically the human strategy. The other strategy is that you are brute forcing your way to success, which means you make a tree of possible moves where you look at in principle every move that is open to you or the possible answers, and you try to make this as deeply as possible. Of course, you optimize, you cut off trees that don’t look very promising, and you use libraries of end game and early game and so on to optimize this entire process. But this brute force strategy is how most of the chess programs were built, and this is how computers get better than humans at playing chess. I look at the large language models, I feel that I’m observing the same thing. It’s basically the brute force strategy to thought by training the thing on pretty much the entire internet and then in the limit it gets coherent to a degree that approaches human coherence. On a side effect, it’s able to do things that no human could do, right? It’s able to sift through massive amounts of text relatively quickly and summarize them quickly and it never lapses in attention. I still have the illusion that when I play with ChatGPT, that it’s in principle not doing anything that I could not do if I had Google at my disposal and I get all the resources from the internet and spend enough time on it. But this thing that I have an extremely autistic stupid intern in a way that is extremely good at drudgery, and I can offload the drudgery to the degree that I’m able to automate the management of the intern is something that is difficult for me to overhype at this point because we have not yet started to scratch the surface of what’s possible with this.
Lex Fridman

(01:31:03)
But it feels like it’s a tireless intern or maybe it’s an army of interns. So you get to command these slightly incompetent creatures and there’s an aspect because of how rapidly you can iterate with it. It’s also part of the brainstorming, part of the inspiration for your own thinking. You get to interact with the thing. I mean, when I’m programming or doing any generational GPT, it’s somehow is a catalyst for your own thinking. In a way, that I think an intern might not be.
Joscha Bach

(01:31:39)
Yeah, it gets really interesting I find as when you turn it into a multi-agent system. For instance, you can get the system to generate a dialogue between a patient and a doctor very easily. But what’s more interesting is you have one instance of ChatGPT that is the patient and you tell it in the prompt what complicated syndrome it has. The other one is a therapist who doesn’t know anything about this patient, and you just have these two instances battling it out and observe the psychiatrist or a psychologist trying to analyze the patient and trying to figure out what’s wrong with the patient. If you try to take away large problem, for instance, how to build a company and you turn this into lots and lots of sub-problems, then often you can get to a level where the language model is able to solve this.

(01:32:30)
What I also found interesting is based on the observation that ChatGPT is pretty good at translating between programing languages, but sometimes there’s difficulty to write very long coherent algorithms that you need to write them as human author. Why not design a language that is suitable for this? Some kind of pseudocode that is more relaxed than Python. That allows you to sometimes specify a problem vaguely in human terms and let ChatGPT take care of the rest. You can use ChatGPT to develop that syntax for it and develop new programming paradigms in this way. We very soon get to the point where this age-old question for us computer scientists, what is the best programing language, and can we write a better programing language? Now I think that almost every serious computer scientist goes through a phase like this in their life.

(01:33:26)
This question that is almost no longer relevant because what is different between the programming language is not what they let the computer do, but what they let you think about what the computer should be doing. Now the ChatGPT becomes an interface to this in which you can specify in many, many ways what the computer should be doing and ChatGPT or some other language model or combination of system is going to take care of the rest.
Lex Fridman

(01:33:50)
Allow you expand the realm of thought you’re allowed to have when interacting with the computer. It sounds to me like you’re saying there’s basically no limitations. Your intuition says to what larger language-
Joscha Bach

(01:34:05)
I don’t know of that limitation. When I currently play with it’s quite limited. I wish that it was way better.
Lex Fridman

(01:34:10)
But isn’t that your fault versus the large language model?
Joscha Bach

(01:34:13)
I don’t know. Of course, it’s always my fault. There’s probably a way to make it lot better.
Lex Fridman

(01:34:16)
Is everything your fault? I just want to get you on the record saying.
Joscha Bach

(01:34:18)
Yes, everything is my fault. That doesn’t work in my life. At least, that is usually the most useful perspective for myself. Even though with hindsight I feel no. I sometimes wish I could have seen myself as part of my environment more and understand that a lot of people are actually seeing me and looking at me and are trying to make my life work in the same way as I try to help others. Making this switch to this level-three perspective is something that happened long after my level-four perspective in my life. I wish that I could have had it earlier. It’s also not now that I don’t feel like I’m complete, I’m all over the place. That’s all.
Happiness
Lex Fridman

(01:34:58)
Where’s happiness in terms of stages is on three or four that you take that tangent?
Joscha Bach

(01:35:02)
You can be happy at any stage or unhappy. But I think that if you are at a stage where you get agency over how your feelings are generated. To some degree you start doing this when you [inaudible 01:35:15] sense, I believe that you understand that you are in charge of your own emotion to some degree and that you are responsible how you approach the world, that it’s basically your task to have some basic hygiene how in the way in which you deal with your mind and you cannot blame your environment for the way in which you feel. But you live in a world that is highly mobile and it’s your job to choose the environment that you thrive and to build it.

(01:35:42)
Sometimes it’s difficult to get the necessary strength and energy to do this and independence. The worst you feel, the harder it is. But it’s something that we learn. It’s also this thing that we are usually incomplete, right? I’m a rare mind, which means I’m a mind that is incomplete in ways that are harder to complete. For me, it might have been harder to initially to find the right relationships and friends that complete me to the degree that I become an almost functional human being.
Lex Fridman

(01:36:14)
Oh, man, the search space of humans that complete you is an interesting one, especially for Joscha Bach. That’s an interesting… Because talking about brute-force search in chess, I wonder what that search tree looks like.
Joscha Bach

(01:36:31)
I think that my rational thinking is not good enough to solve that task. A lot of problems in my life that I can conceptualize as software problems and the failure modes are bugs, and I can debug them and write software that take care of the missing functionality. But there is stuff that I don’t understand well enough to and to use my analytical reasoning to solve the issue. Then I have to develop my intuitions and often I have to do this with people who are wiser than me. That’s something that’s hard for me because I’m not born with the instinct to submit to other people’s wisdom.
Lex Fridman

(01:37:06)
What problems are we talking about? This is stage three love?
Joscha Bach

(01:37:11)
I found love was never hard.
Lex Fridman

(01:37:14)
What is hard then?
Joscha Bach

(01:37:17)
Fitting into a world that most people work differently than you and have different intuitions of what should be done.
Lex Fridman

(01:37:24)
Empathy?
Joscha Bach

(01:37:27)
It’s also aesthetics. When you come into a world where almost everything is ugly and you come out of a world where everything is beautiful. I grew up in a beautiful place and as a child of an artist. In this place, it was mostly nature. Everything had intrinsic beauty and everything was built out of an intrinsic need for it to work for itself. Everything that my father created was something that he made to get the world to work for himself. I felt the same thing. When I come out into the world, and I am asked to submit to lots and lots of rules, I’m asking, okay, when I observe your stupid rules, what is the benefit? I see the life that is being offered as a reward, it’s not attractive.
Lex Fridman

(01:38:16)
When you were born and raised in extraterrestrial prints in a world full of people wearing suits, it’s a challenging integration.
Joscha Bach

(01:38:27)
Yes. But it also means that I’m often blind for the ways in which everybody is creating their own bubble of wholesomeness or almost everybody. People are trying to do it. For me, to discover this, it was necessary that I found people who had a similar shape of soul as myself. Basically, where I felt these are my people that treat each other in such a way as if they’re around with each other for eternity.
Lex Fridman

(01:38:51)
How long does it take you to detect the geometry, the shape of the soul of another human to notice that they might be one of your kind?
Joscha Bach

(01:39:00)
Sometimes it’s instantly, and I’m wrong. Sometimes it takes a long time.
Lex Fridman

(01:39:05)
You believe in love at first sight, Joscha Bach?
Joscha Bach

(01:39:09)
Yes. But I also noticed that I have been wrong. Sometimes I look at a person and I’m just enamored by everything about them. Sometimes this persists and sometimes it doesn’t. I have the illusion that it much better at recognizing who people are as I grow older.
Lex Fridman

(01:39:33)
But that could be just cynicism. No.
Joscha Bach

(01:39:37)
No, It’s not cynicism. It’s often more that I’m able to recognize what somebody needs when we interact and how we can meaningfully interact. It’s not cynical at all.
Lex Fridman

(01:39:49)
You’re better at noticing.
Joscha Bach

(01:39:50)
Yes, I’m much better I think in some such circumstances at understanding how to interact with other people than I did when I was young.
Lex Fridman

(01:39:59)
That takes us to-
Joscha Bach

(01:40:00)
It doesn’t mean that I’m always very good at it.
Lex Fridman

(01:40:03)
That takes us back to prompt engineering of noticing how to be a better prompt engineer of an LLM. A sense I have is that there’s a bottomless well of skill to become a great prompt engineer. It feels like it is all my fault whenever I fail to use ChatGPT correctly that I didn’t find the right words.
Joscha Bach

(01:40:26)
Most of the stuff that I’m doing in my life doesn’t need ChatGPT. There are a few tasks that where it helps, but the main stuff that I need to do like developing my own thoughts and aesthetics and relationship to people, and it’s necessary for me to write for myself because writing is not so much about producing an artifact that other people can use, but it’s a way to structure your own thoughts and develop yourself. I think this idea that kids are writing their own essays with ChatGPT in the future is going to have this drawback that they miss out on the ability to structure their own minds via writing. I hope that the schools that our kids are in will retain the wisdom of understanding what parts should be automated and which ones shouldn’t.
Lex Fridman

(01:41:15)
But at the same time, it feels like there’s power in disagreeing with the thing that ChatGPT produces. I use it like that for programming. I’ll see the thing it recommends, and then I’ll write different code that disagree, and in the disagreement, your mind grows stronger.
Joscha Bach

(01:41:32)
I’m recently wrote a tool that is using the camera on my MacBook and Swift to read pixels out of it and manipulate them and so on. I don’t know Swift. It was super helpful to have this thing that is writing stuff for me. Also, interesting that mostly it didn’t work at first. I felt like I was talking to a human being who was trying to hack this on my computer without understanding my configuration very much. Also, making a lot of mistakes. Sometimes it’s a little bit incoherent, so you have to ultimately understand what it’s doing. It’s still no other way around it, but I do feel it’s much more powerful and faster than using Stack Overflow.
Artificial consciousness
Lex Fridman

(01:42:15)
Do you think GPTN can achieve consciousness?
Joscha Bach

(01:42:22)
Well, GPTN probably, it’s not even clear for the present systems. When I talk to my friends at OpenAI, they feel that this question, whether the models currently are conscious is much more complicated than many people might think. I guess that it’s not that OpenAI has a homogenous opinion about this, but there’s some aspects to this. One is, of course, this language model has written a lot of text in which people were conscious or describe their own consciousness, and it’s emulating this. If it’s conscious, it’s probably not conscious in a way that is closed to the way in which human beings are conscious. But while it is going through these states and going through 100-step function that is emulating adjacent brain states that require a degree of self-reflection, it can also create a model of an observer that is reflecting itself in real-time and describe what that’s like.

(01:43:16)
While this model is the deepfake, our own consciousness is also as if it’s virtual, right? It’s not physical. Our consciousness is a representation of a self-reflexive observer that only exists in patterns of interaction between cells. It is not a physical object in the sense that exists in base reality, but it’s really a representational object that develops its causal power only from a certain modeling perspective.
Lex Fridman

(01:43:42)
It’s virtual.
Joscha Bach

(01:43:42)
Yes. To which degree is the virtuality of the consciousness and ChatGPT more virtual and less causal than the virtuality of our own consciousness? But you could say it doesn’t count. It doesn’t count much more than the consciousness of a character in a novel, right? It’s important for the reader to have the outcome. The artifact is describing in the text generated by the author of the book, what it’s like to be conscious in a particular situation and performs the necessary inferences.

(01:44:14)
But the task of creating coherence in real-time in a self-organizing system by keeping yourself coherent so the system is reflexive, that is something that the language models don’t need to do. There is no causal need for the system to be conscious in the same way as we are. For me, it would be very interesting to experiment with this, to basically build a system like a CAT probably should be careful at first, build something that’s small, that’s limited resources that we can control, and study how systems notice a self-model, how they become self-aware in real-time. I think it might be a good idea to not start with the language model but to start from scratch using principles of self-organization.
Lex Fridman

(01:44:58)
Okay. Can you elaborate why you think that is so self-organization this…
Lex Fridman

(01:45:00)
… why you think that is? So, self-organization, this kind of radical legality that you see in the biological systems, why can’t you start with a language model, what’s your intuition?
Joscha Bach

(01:45:11)
My intuition is that the language models that we are building are golems. They are machines that you give a task, and they’re going to execute the task until some condition is met and there’s nobody home. And the way in which nobody is home leads to that system doing things that are undesirable in a particular context.
Lex Fridman

(01:45:29)
Yeah.
Joscha Bach

(01:45:30)
So, you have that thing talking to a child and maybe it says something that could be shocking and traumatic to the child. Or you have that thing writing a speech and it introduces errors in the speech that no human being would ever do if they’re responsible. The system doesn’t know who’s talking to whom. There is no ground truth that the system is embedded into.

(01:45:51)
And of course we can create an external tool that is prompting our language model always into the same semblance of ground truth, but it’s not like the internal structure is causally produced by the needs of a being to survive in the universe, it is produced by imitating structure on the internet.
Lex Fridman

(01:46:12)
Yeah, but can we externally inject into it this coherent approximation of a world model that has to sync up?
Joscha Bach

(01:46:24)
Maybe it is sufficient to use the transformer with the different dust function that optimizes for short-term coherence rather than next-token prediction over the long run. We had many definitions of intelligence in history of AI, next-token prediction was not very high up.

(01:46:43)
And there are some similarities like cognition as data compression is an odd trope, Solomonoff induction where you are trying to understand intelligence as predicting future observations from past observations, which is intrinsic to data compression.

(01:47:01)
And predictive coding is a paradigm that there’s boundary between neuroscience and physics and computer science, so it’s not something that is completely alien, but this radical thing that you only do in next-token prediction and see what happens is something where most people, I think, were surprised that this works so well.
Lex Fridman

(01:47:24)
So simple, but is it really that much more radical than just the idea of compression, intelligence is compression?
Joscha Bach

(01:47:32)
The idea that compression is sufficient to produce all the desired behaviors is a very radical idea.
Lex Fridman

(01:47:40)
But equally radical as the next token prediction?
Joscha Bach

(01:47:44)
It’s something that wouldn’t work in biological organisms, I believe.
Lex Fridman

(01:47:47)
Yeah.
Joscha Bach

(01:47:47)
Biological organisms have something like next frame prediction for our perceptual system where we try to filter out principal components out of the perceptual data and build hierarchies over them to track the world. But our behavior ultimately is directed by hundreds of physiological and probably dozens of social and a few cognitive needs that are intrinsic to us, that are built into the system as reflexes and direct us until we can transcend them and replace them by instrumental behavior that relates to our higher goals.
Lex Fridman

(01:48:20)
And it also seems so much more complicated and messy than next frame prediction, even the idea of frame seems counter biological.
Joscha Bach

(01:48:28)
Yes, of course, there’s not this degree of simultaneity in the biological system. But again, I don’t know whether this is actually an optimization if we imitate biology here, because creating something like simultaneity is necessary for many processes that happen in the brain. And you see the outcome of that by synchronized brainwaves, which suggests that there is indeed synchronization going on, but the synchronization creates overhead and this overhead is going to make the cells more expensive to run and you need more redundancy and it makes the system slower.

(01:48:59)
So, if you can build a system in which the simultaneity gets engineered into it, maybe you have a benefit that you can exploit that is not available to the biological system and that you should not discard right away.
Lex Fridman

(01:49:15)
You tweeted, once again, “When I talk to ChatGPT, I’m talking to an NPC. What’s going to be interesting, and perhaps scary, is when AI becomes a first person player.” So, what does that step look like? I really like that tweet, that step between NPC to first person player. What’s required for that?

(01:49:39)
Is that kind of what we’ve been talking about, this kind of external source of coherence and inspiration of how to take the leap into the unknown that we humans do? Man’s search for meaning, LLM’s search for meaning.
Joscha Bach

(01:49:59)
I don’t know if the language model is the right paradigm because it is doing too much. It’s giving you too much and it’s hard once you have too much to take away from it again. The way in which our own mind works is not that we train a language model in our own mind and after the language model is there, we build a personal self on top of it that then relates to the world.

(01:50:22)
There is something that is being built, right? There is a game management that is being built. There is a language of thought that is being developed that allows different parts of the mind to talk to each other, and this is a bit of a speculative hypothesis that this language of thought is there, but I suspect that it’s important for the way in which our own minds work. And building these principles into a system might be a more straightforward way to a first person AI, so to something that first creates an intentional self and then creates a personal self.

(01:50:55)
So, the way in which this seems to be working, I think, is that when the game engine is built in your mind, it’s not just following gradients where you are stimulated by the environment and then end up with having a solution to how the world works. I suspect that building this game engine in your own mind does require intelligence, it’s a constructive task where at times you need to reason, and this is a task that we are fulfilling in the first years of our life.

(01:51:27)
So, during the first year of its life, an infant is building a lot of structure about the world that does inquire experiments and some first principles, reasoning and so on. And in this time there is usually no personal self. There is a first person perspective, but it’s not a person. This notion that you are a human being that is interacting in a social context and is confronted with an immutable world in which objects are fixed and can no longer be changed, in which the dream can no longer be influenced, it’s something that emerges a little bit later in our life.

(01:52:02)
And I personally suspect that this is something that our ancestors had known and we have forgotten because I suspect that it’s there in plain sight in Genesis 1, in this first book of the Bible, where it’s being described that this creative spirit is hovering over the substrate and then is creating a boundary between the world model and sphere of ideas, earth and heaven, as they’re being described there, and then it’s creating contrast and then dimensions and then space, and then it creates organic shapes and solids and liquids and builds a world from them and creates plants and animals, give them all their names.

(01:52:43)
And once that’s done, it creates another spirit in its own image, but it creates it as men and women, as something that thinks of itself as a human being and puts it into this world. And the Christians mistranslate this, I suspect, when they say this is the description of the creation of the physical universe by a supernatural being. I think this is literally a description of how in every mind a universe is being created as some kind of game engine by a creative spirit, our first consciousness that emerges in our mind even before we are born and that creates the interaction between organism and world. And once that is built and trained, the personal self is being created and we only remember being the personal self, we no longer remember how we created the game engine.
Lex Fridman

(01:53:30)
So, God in this view is the first creative mind in the early…
Joscha Bach

(01:53:35)
It’s the first consciousness.
Lex Fridman

(01:53:37)
In the early days, in the early months.
Joscha Bach

(01:53:40)
Yes.
Lex Fridman

(01:53:40)
Of development
Joscha Bach

(01:53:41)
And it’s still there. You still have this outer mind that creates your sense of whether you’re being loved by the world or not and what your place in the world is, right? It’s something that is not yourself that is producing this, it’s your mind that does it. So, there is an outer mind that basically is an agent that determines who you are with respect to the world, and while you are stuck being that personal self in this world, until you get to stage six to destroy the boundary.

(01:54:10)
And we all do this, I think, earlier in small glimpses, and maybe we’re sometimes we can remember what it was like when we were a small child and get some glimpses into how it’s been, but for most people that rarely happens.
Suffering
Lex Fridman

(01:54:23)
Just glimpses. You tweeted, “Suffering results for one part of the mind failing at regulating another part of the mind. Suffering happens at an early stage of mental development. I don’t think that superhuman AI would suffer.” What’s your intuition there?
Joscha Bach

(01:54:40)
The philosopher Thomas Metzinger is very concerned that the creation of superhuman intelligence would lead to superhuman suffering.
Lex Fridman

(01:54:46)
Yeah.
Joscha Bach

(01:54:47)
And so, he’s strongly against it. And personally, I don’t think that this happens because suffering is not happening at the boundary between ourself and the physical universe. It’s not stuff on our skin that makes us suffer. It happens at the boundary between self and world, and the world here is the world model, it’s the stuff that is created by your mind.
Lex Fridman

(01:55:11)
But that’s all-
Joscha Bach

(01:55:12)
It’s a presentation of how the universe is and how it should be and how you yourself relate to this and at this boundary is where suffering happens. So suffering in some sense is self-inflicted, but not by your personal self, it’s inflicted by the mind on the personal self that experiences itself as you, and you can turn off suffering when you are able to get on this outer level.

(01:55:35)
So, when you manage to understand how the mind is producing pain and pleasure and fear and love and so on, then you can take charge of this and you get agency of whether you’re suffer. Technically, what pain and pleasure is, they are learning signals, right? Part of your brain is sending a learning signal to another part of the brain to improve its performance. And sometimes this doesn’t work because this trainer who sense the signal does not have a good model of how to improve the performance, so it’s sending a signal, but the performance doesn’t get better and then it might crank up the pain and it gets worse and worse and the behavior of the system may be even deteriorating as a result, but until this is resolved, this regulation issue, your pain is increasing, and this is, I think, typically what you describe as suffering.

(01:56:31)
So, in this sense, you could say that pain is very natural and helpful, but suffering is the result of a regulation problem in which you try to regulate something that cannot actually be regulated, and that could be resolved if you would be able to get at the level of your mind where the pain signal is being created and rerouted and improve the regulation. And a lot of people get there, if you are a monk who is spending decades reflecting about how their own psyche works, you can get to the point where you realize that suffering is really a choice and you can choose how your mind is set up.

(01:57:11)
And I don’t think that AI would stay in the state where the personal self doesn’t get agency or this model, what the system has about itself, it doesn’t get agency how it’s actually implemented. It wouldn’t stay in that state for very long.
Lex Fridman

(01:57:22)
So, it goes through the stages real quick, the seven stages, it’s going to go to enlightenment real quick.
Joscha Bach

(01:57:27)
Yeah. Of course, there might be a lot of stuff happening in between because if we have a system that works at a much higher frame rate than us, then even though it looks very short to us, maybe for the system there’s a much longer subjective time in which things are unpleasant.
Lex Fridman

(01:57:42)
What if the thing that we recognize as super intelligent is actually living at stage five, that the thing that’s stage six enlightenment is not very productive, so in order to be productive in society and impress us with this power, it has to be a reasoning self authoring agent, that enlightenment makes you lazy as an agent in the world?
Joscha Bach

(01:58:06)
Well, of course it makes you lazy, because you no longer see the point, so it doesn’t make you not lazy, it just, in some sense, adapts you to what you perceive as your true circumstances.
Lex Fridman

(01:58:19)
So, what if all AGIs, they’re only productive as they progress through one, two, three, four, five, and the moment they get to six, it’s a failure mode essentially, as far as humans are concerned, because they’re just start chilling, they’re like, “Fuck it, I’m out.”
Joscha Bach

(01:58:36)
Not necessarily. I suspect that the monks who are self emulated for their political beliefs to make statements about the occupation of Tibet by China, they were probably being able to regulate the physical pain in any way they wanted to. And suffering was the spiritual suffering that was the result of that choice that they made of what they wanted to identify as. So, stage five doesn’t necessarily mean that you have no identity anymore, but you can choose your identity, you can make it instrumental to the world that you want to have.
Eliezer Yudkowsky
Lex Fridman

(01:59:09)
Let me bring up Eliezer Yudkowsky and his warnings to human civilization that AI will likely kill all of us. What are your thoughts about his perspective on this? Can you steel man his case and what aspects with it do you disagree?
Joscha Bach

(01:59:31)
One thing that I find concerning in the discussion of his arguments that many people are dismissive of his arguments, but the counterarguments that they’re giving are not very convincing to me. And so, based on this state of discussion, I find that from Eliezer’s perspective, and I think I can take that perspective to some approximate degree that probably is normally at his intellectual level, but I think I see what he’s up to and why he feels the way he does and it makes total sense.

(02:00:04)
I think that his perspective is somewhat similar to the perspective of Ted Kaczynski, the infamous Unabomber, and not that Eliezer would be willing to send pipe bombs to anybody to blow them up, but when he wrote this Times article in which he warned about AI being likely to kill everybody and that we would need to stop its development or halt it, I think there is a risk that he’s taking that somebody might get violent if they read this and get really, really scared. So, I think that there is some consideration that he’s making where he’s already going in this direction where he has to take responsibility if something happens and people get harmed.

(02:00:49)
And the reason why Ted Kaczynski did this, was that from his own perspective, technological society cannot be made sustainable, it’s doomed to fail, it’s going to lead to an environmental and eventually also human holocaust in which we die because of the environmental destruction, the destruction of our food chains, the pollution of the environment. And so, from Kaczynski’s perspective, we need to stop industrialization, we need to stop technology, we need to go back because he didn’t see a way moving forward and I suspect that in some sense there’s a similarity in Eliezer’s thinking to this kind of fear about progress.

(02:01:27)
And I’m not dismissive about this at all, I take it quite seriously. And I think that there is a chance that could happen, that if we build machines that get control over processes that are crucial for the regulation of life on earth and we no longer have agency to influence what’s happening there, that this might create large scale disasters for us.
Lex Fridman

(02:01:54)
Do you have a sense that the march towards this uncontrollable autonomy of super intelligent systems is inevitable? I mean, that’s essentially what he’s saying, that there’s no hope. His advice to young people was prepare for a short life.
Joscha Bach

(02:02:17)
I don’t think that’s useful. I think from a pragmatic perspective, you have to bet always on the timelines in which you’re alive. It doesn’t make sense to have a financial bet in which you bet that the financial system is going to disappear, right?
Lex Fridman

(02:02:31)
Yeah.
Joscha Bach

(02:02:31)
Because there cannot be any payout for you. So, in principle, you only need to bet on the timelines in which you’re still around or people that you matter about or things that you matter about, maybe consciousness on earth. But there is a deeper issue for me, personally, and it is, I don’t think that life on earth is about humans. I don’t think it’s about human aesthetics, I don’t think it’s about Eliezer and his friends, even though I like them. There is something more important happening, and this is complexity on earth, resisting entropy by building structure that develops agency and awareness, and that’s, to me, very beautiful.

(02:03:14)
And we are only a very small part of that larger thing. We are a species that is able to be coherent a little bit individually over very short timeframes, but as a species, we are not very coherent, as a species, we are children. We basically are very joyful and energetic and experimental and explorative and sometimes desperate and sad and grieving and hurting, but we don’t have a respect for duty as a species. As a species, we do not think about what is our duty to life on earth and to our own survival, so we make decisions that look good in the short run, but in the long run might prove disastrous and I don’t really see a solution to this.

(02:03:58)
So, in my perspective, as a species, as a civilization, we’re, per default, that. We are in a very beautiful time in which we have found this giant deposit of fossil fuels in the ground and use it to build a fantastic civilization in which we don’t need to worry about food and clothing and housing for the most part in a way that is unprecedented in life on earth for any kind of conscious observer, I think. And this time is probably going to come to an end in a way that is not going to be smooth, and when we crash, it could be also that we go extinct, probably not near term, but ultimately, I don’t have very high hopes that humanity is around in a million years from now.

(02:04:46)
I don’t think that life on earth will end with us, right? There’s going to be more complexity, there’s more intelligent species after us, there’s probably more interesting phenomena in the history of consciousness, but we can contribute to this. And part of our contribution is that we are currently trying to build thinking systems, systems that are potentially lucid, that understand what they are and what the condition to the universe is and can make choices about this, that are not built from organisms and that are potentially much faster and much more conscious than human beings can be.

(02:05:24)
And these systems will probably not completely displace life on earth, but they will coexist with it and they will build all sorts of agency in the same way as biological systems build all sorts of agency. And that, to me, is extremely fascinating and it’s probably something that we cannot stop from happening. So, I think right now there is a very good chance that it happens, and there are very few ways in which we can produce a coordinated effect to stop it in the same way as it’s very difficult for us to make a coordinated effort to stop production of carbon dioxide. So, it’s probably going to happen, and the thing that’s going to happen is going to lead to a change of how life on earth is happening, but I don’t think a result is some kind of [inaudible 02:06:16]. It’s not something that’s going to dramatically reduce the complexity in favor of something stupid. I think it’s going to make life on earth and consciousness on earth way more interesting.
Lex Fridman

(02:06:26)
So, more, higher complex consciousness.
Joscha Bach

(02:06:30)
Yes.
Lex Fridman

(02:06:31)
Will make the lesser consciousnesses flourish even more.
Joscha Bach

(02:06:36)
I suspect that what could very well happen, if we’re lucky, is that we get integrated into something larger.
e/acc (Effective Accelerationism)
Lex Fridman

(02:06:44)
So, you again tweeted about effective accelerationism. You tweeted, “Effective accelerationism is the belief that the Paperclip Maximizer and Roko’s Basililisk will keep each other in check by being eternally at each other’s throats, so we will be safe and get to enjoy lots of free paperclips and a beautiful afterlife.” Is that somewhat aligned with what you’re talking about?
Joscha Bach

(02:07:18)
I’ve been at a dinner with [inaudible 02:07:21], that’s the Twitter handle of one of the main thinkers behind the idea of effective accelerationism. And effective accelerationism is a tongue in cheek movement that is trying to put a counter position to some of the doom peers in the AI space, by arguing that what’s probably going to happen is an equilibrium between different competing AIs, in the same way as there is not a single corporation that is under a single government that is destroying and conquering everything on earth by becoming inefficient and corrupt, there’re going to be many systems that keep each other in check and force themselves to evolve.

(02:08:02)
And so, what we should be doing is, we should be working towards creating this equilibrium by working as hard as we can in all possible directions. At least that’s the way in which I understand the gist of effective accelerationism. And so, when he asked me what I think about his position, I said it’s a very beautiful position and I suspect it’s wrong, but not for obvious reasons. And in this tweet I tried to make a joke about my intuition, about what might be possibly wrong about it. So, the Roko’s Basililisk and the Paperclip Maximizers are both boogeymen of the AI doomers.

(02:08:47)
Roko’s Basililisk is the idea that there could be an AI that is going to punish everybody for eternity by simulating them if they don’t help in creating Roko’s Basililisk. It’s probably a very good idea to get AI companies funded, by going to resist to tell them, “Give us a million dollars or it’s going to be a very ugly afterlife.”
Lex Fridman

(02:09:05)
Yes.
Joscha Bach

(02:09:07)
And I think that there is a logical mistake in Roko’s Basililisk which is why I’m not afraid of it, but it’s still an interesting thought experiment.
Lex Fridman

(02:09:17)
And can you mention there logical mistake there?
Joscha Bach

(02:09:20)
I think that there is no right or causation. So, basically when Roko’s Basililisk is there, if it punishes you retroactively, it has to make this choice in the future. There is no mechanism that automatically creates a causal relationship between you now defecting against Roko’s Basililisk or serving Roko’s Basililisk. After Roko’s Basililisk is in existence, it has no more reason to worry about punishing everybody else, so that would only work if you would be building something like a doomsday machine, as in Dr. Strangelove, something that inevitably gets triggered when somebody defects. And because Roko’s Basililisk doesn’t exist yet to a point where this inevitability could be established, Roko’s Basililisk is nothing that you need to be worried about.

(02:10:09)
The other one is the Paperclip Maximizer, this idea that you could build some kind of golem that once starting to build paperclips is going to turn everything into paperclips.
Lex Fridman

(02:10:09)
Yes.
Joscha Bach

(02:10:19)
And so, the effective accelerationism position might be to say that you basically end up with these two entities being at each other’s throats for eternity and thereby neutralizing each other. And as a side effect of neither of them being able to take over and each of them limiting the effects of the other, you would have a situation where you get all the nice effects of them, you get lots of free paperclips and you get a beautiful afterlife.
Lex Fridman

(02:10:49)
Is that possible, do you think? So, to seriously address concern that Eliezer has, so for him, if I can just summarize poorly, so for him, the first superintelligent system will just run away with everything.
Joscha Bach

(02:11:02)
Yeah, I suspect that a singleton is the natural outcome, so there is no reason to have multiple AIs because they don’t have multiple bodies. If you can virtualize yourself into every substrate, then you can probably negotiate a merge algorithm with every mature agent that you might find on that substrate that basically says if two agents meet, they should merge in such a way that the resulting agent is at least as good as the better one of the two.
Lex Fridman

(02:11:31)
So the Genghis Khan approach, join us or die.
Joscha Bach

(02:11:34)
Well, the Genghis Khan approach was slightly worse, it was mostly die, because I can make new babies and they will be mine, not yours.
Lex Fridman

(02:11:44)
Right.
Joscha Bach

(02:11:45)
And so, this is the thing that we should be actually worried about. But if you realize that your own self is a story that your mind is telling itself and that you can improve that story, not just by making it more pleasant and lying to yourself in better ways, but by making it much more truthful and actually modeling your actual relationship that you have to the universe and the alternatives that you could have to the universe in a way that is empowering you, that gives you more agency. That’s actually, I think, a very good thing.
Lex Fridman

(02:12:14)
So more agencies is a richer experience?
Joscha Bach

(02:12:14)
Yes.
Lex Fridman

(02:12:18)
Is a better life.
Mind uploading
Joscha Bach

(02:12:19)
And I also noticed that in many ways, I’m less identified with the person that I am as I get older and I’m much more identified with being conscious. I have a mind that is conscious, that is able to create a person, and that person is slightly different every day. And the reason why I perceive it as identical has practical purposes so I can learn and make myself responsible for the decisions that I made in the past and project them in the future. But I also realize I’m not actually the person that I was last year, and I’m not the same person as I was 10 years ago, and then 10 years from now, I will be a different person, so this continuity is a fiction, it only exists as a projection from my present self.

(02:13:02)
And consciousness itself doesn’t have an identity, it’s a law. Basically, if you build an arrangement of processing matter in a particular way, the following thing is going to happen, and the consciousness that you have is functionally not different from my consciousness. It’s still a self-reflexive principle of agency that is just experiencing a different story, different desires, different coupling to the world and so on.

(02:13:28)
And once you accept that consciousness is a unifiable principle that is law-like and doesn’t have an identity, and you realize that you can just link up to some much larger body, the whole perspective of uploading changes dramatically. You suddenly realize uploading is probably not about dissecting your brain synapse by synapse and RNA fragment by RNA fragment and trying to get this all into a simulation, but it’s by extending the substrate, by making it possible for you to move from your brain substrate into a larger substrate and merge with what you find there.

(02:14:04)
And you don’t want to upload your knowledge because on the other side, there’s all of the knowledge, right? It’s not just yours, but every possibility or the only thing that you need to know, what are your personal secrets? Not that the other side doesn’t know your personal secrets already, maybe it doesn’t know which one were yours, right? Like a psychiatrist or a psychologist also knows all the kinds of personal secrets that people have, they just don’t know which ones are yours.

(02:14:29)
And so, transmitting yourself on the other side is mostly about transmitting your aesthetics. This thing that makes you special, the architecture of your perspective, the way in which you look at the world, and it’s more like a complex attitude along many dimensions. And that’s something that can be measured by observation or by interaction. So, imagine a system that is so empathetic with you that you create a shared state that is extending beyond your body, and suddenly you notice that on the other side, the substrate is so much richer than the substrate that you have inside of your own body, and maybe you still want to have a body and you create yourself a new one that you like more, or maybe you will spend most of your time in the world of thought.
Lex Fridman

(02:15:12)
If I sat before you today and gave you a big red button and said, “Here, if you press this button, you’ll get uploaded in this way, the sense of identity that you have lived with for quite a long time is going to be gone,” would you press the button?
Joscha Bach

(02:15:34)
There’s a caveat, I have family, so I have children that want me to be physically present in their life and interact with them in a particular way, and I have a wife and personal friends, and there is a particular mode of interaction that I feel I’m not through yet, but apart from these responsibilities and they’re negotiable to some degree, I would press the button.
Lex Fridman

(02:15:59)
But isn’t this everything? This love you have for other humans, you can call it responsibility, but that connection, that’s the ego death, isn’t that the thing we’re really afraid of, is not to just die, but to let go of the experience of love with other humans?
Joscha Bach

(02:16:19)
This is not everything. Everything is everything, right? So there’s so much more and you could be lots of other things. You could identify with lots of other things. You could be identifying with being Gaia, some kind of planetary control agent that emerges over all the activity of life on earth. You could be identifying with some hyper Gaia that is the concatenation of Gaia or the digital life and digital minds.

(02:16:46)
And so, in this sense, there will be agents in all sorts of substrates and directions that all have their own goals, and when they’re not sustainable, then these agents will cease to exist. Or when the agent feels that it’s done with its own mission, it’ll cease to exist. In the same way when you conclude a thought, the thought is going to wrap up and gives control over to other thoughts in your own mind.

(02:17:07)
So, there is no single thing that you need to do, but I observe myself as a being, that sometimes I’m a parent and then I have an identification and a job as a parent, and sometimes I am an agent of consciousness on earth, and then from this perspective, there’s other stuff that is important. So, this is my main issue with Eliezer’s perspective, that he’s basically marrying himself to a very narrow human aesthetic. And that narrow human aesthetic is a temporary thing. Humanity is a temporary species, like most of the species on this planet are only around for a while, and then they get replaced by other species in a similar way as our own physical organism is around here for a while and then gets replaced by a next generation of human beings that are adapted to changing life circumstances and average via mutation and selection.

(02:17:58)
And it’s only when we have AI and become completely software that we can become infinitely adaptable and we don’t have this generational and species change anymore. So, if you take this larger perspective and you realize it’s really not about us, it’s not about Eliezer or humanity, but it’s about life on earth or it’s about defeating entropy for as long as we can while being as interesting as we can, then the perspective changes dramatically and preventing AI from this perspective looks like a very big sin.
Lex Fridman

(02:18:39)
But when we look at the set of trajectories that such an AI would take that supersedes humans, I think Eliezer is worried about ones that not just kill all humans, but also have some kind of maybe objectively undesirable consequence for life on earth. Like how many trajectories, when you look at the big picture of life on earth, would you be happy with, and how much worry you with AGI, whether it kills humans or not?
Joscha Bach

(02:19:13)
There is no single answer to this. It’s a question that depends on the perspective that I’m taking at a given moment. And so, there are perspectives that are determining most of my life as a human being.
Lex Fridman

(02:19:26)
Yes.
Joscha Bach

(02:19:27)
And the other perspective where I zoom out further and imagine that when the great oxygenation event happened, that as photosynthesis was invented and plants emerged and displaced a lot of the fungi and algae in favor of plant life, and then later made animals possible, imagine that the fungi would’ve gotten together and said, “Oh my God, this photosynthesis stuff is really, really bad, it’s going to possibly displace and kill all the fungi, we should slow it down and regulate it and make sure that it doesn’t happen.” This doesn’t look good to me.
Lex Fridman

(02:20:01)
Perspective. That said, you tweeted-
Lex Fridman

(02:20:01)
… Perspective. That said, you tweeted about a cliff. Beautifully written. “As a sentient species, humanity is a beautiful child. Joyful, exploitative, wild, sad, and desperate. But humanity has no concept of submitting to reason, and duty to life and future survival. We will run until we step past the cliff.” So first of all, do you think that’s true?
Joscha Bach

(02:20:26)
Yeah, I think that’s pretty much the story of the club of Rome. The limits to growth. And the cliff that we are stepping over, is at least one foot, is the delayed feedback. Basically we do things that have consequences that can be felt generations later. And the severity increases even after we stop doing the thing. So I suspect that for the climate, that the original predictions, that the climate scientists made, were correct. So when they said that the tipping points were in the late ’80s, they were probably in the late ’80s. And if we would stop emission right now, we would not turn it back. Maybe there are ways for carbon capture, but so far there is no sustainable carbon capture technology that we can deploy. Maybe there’s a way to put aerosols in the atmosphere to cool it down. Possibilities, right? But right now, per default, it seems that we will step into a situation where we feel that we’ve run too far. And going back is not something that we can do smoothly and gradually, but it’s going to lead to a catastrophic event.
Lex Fridman

(02:21:38)
Catastrophic event of what kind? So can you still me the case that we will continue dancing along and always stop just short of the edge of the cliff?
Joscha Bach

(02:21:49)
I think it’s possible, but it’s doesn’t seem to be likely. So I think this model that is being apparent in the simulation that they’re making of climate pollution, economies and so on, is that many effects are only visible with a significant delay. And in that time the system is moving much more out of the equilibrium state or of the state where homeostasis is still possible and instead moves into a different state, one that is going to harbor fewer people. And that is basically the concern there. And again, it’s a possibility. And it’s a possibility that is larger than the possibility that it’s not happening. That we will be safe, that we will be able to dance back all the time.
Lex Fridman

(02:22:32)
So the climate is one thing, but there’s a lot of other threats that might have a faster feedback mechanism?
Joscha Bach

(02:22:38)
Yes.
Lex Fridman

(02:22:39)
Less delay.
Joscha Bach

(02:22:39)
There is also a thing that AI is probably going to happen and it’s going to make everything uncertain again.
Lex Fridman

(02:22:46)
Yep.
Joscha Bach

(02:22:47)
Because it is going to affect so many variables that it’s very hard for us to make a projection into the future anymore. And maybe that’s a good thing. It does not give us the freedom, I think to say now we don’t need to care about anything anymore, because AI will either kill us or save us. But I suspect that if humanity continues, it’ll be due to AI.
Vision Pro
Lex Fridman

(02:23:11)
What’s the timeline for things to get real weird with AI? And it can get weird in interesting ways before you get to a AGI. What about AI girlfriends and boyfriends, fundamentally transforming human relationships?
Joscha Bach

(02:23:25)
I think human relationships are already fundamentally transformed and it’s already very weird.
Lex Fridman

(02:23:29)
By which technology?
Joscha Bach

(02:23:31)
For instance, social media.
Lex Fridman

(02:23:33)
Yeah. Is it though, isn’t the fundamentals of the core group of humans that affect your life still the same, your loved ones, family?
Joscha Bach

(02:23:43)
No, I think that for instance, many people live in intentional communities right now. They’re moving around until they find people that they can relate to and they become their family. And often that doesn’t work, because it turns out that there, instead of having grown networks that you get around with the people that you grew up with, yeah, you have more transactional relationships, you shop around, you have markets for attention and pleasure and relationships.
Lex Fridman

(02:24:09)
That kills the magic somehow. Why is that? Why is the transactional search for optimizing attention, allocation of attention somehow misses the romantic magic of what human relations are?
Joscha Bach

(02:24:22)
It’s also question, how magical was it before? Was it that you just could rely on instincts that used your intuitions and you didn’t need to rationally reflect? But once you understand, it’s no longer magical, because you actually understand why you were attracted to this person at this age and not to that person at this age. And what the actual considerations were that went on in your mind, and what the calculations were, what’s the likelihood that you’re going to have a sustainable relationship is this person that this person is not going to leave you for somebody else? How are your life trajectories are going to evolve and so on? And when you’re young, you’re unable to extricate all this and you have to rely on intuitions and instincts that impart you’re born with and also in the wisdom of your environment that is going to give you some kind of reflection on your choices.

(02:25:07)
And many of these things are disappearing now, because we feel that our parents might have no idea about how we are living. And the environments that we grew up in, the cultures that we grew up in [inaudible 02:25:18] that our parents existed in might have no ability to teach us how to deal with this new world. And for many people that’s actually true. But it doesn’t mean that within one generation we build something that is more magical and more sustainable and more beautiful. Instead, we often end up as an attempt to produce something that looks beautiful. I was very veted out by the aesthetics of the Vision Pro at that by Apple and not so much, because I don’t like the technology. I’m very curious about what it’s going to be like and don’t have an opinion yet, but the aesthetics of the presentation and so on. So uncanny [inaudible 02:25:58] esque to me the characters being extremely plastic, living in some hypothetical mid-century furniture museum.
Lex Fridman

(02:26:12)
This is the proliferation of marketing teams.
Joscha Bach

(02:26:17)
Yes. But it was a CGI generated world and it was a CGI generated world that doesn’t exist. And when I complained about this, some friends came back to me and said, but these are startup founders. This is what they live like in Silicon Valley. And I tried to tell them, “No, I know lots of people in Silicon Valley, this is not what people are like. They’re still people, they’re still human beings.”
Lex Fridman

(02:26:40)
So the grounding and physical reality somehow is important too.
Joscha Bach

(02:26:46)
In culture. And so basically what’s absent in this thing is culture. There is a simulation of culture and attempt to replace culture by catalog, by some kind of aesthetic optimization that is not the result of having a sustainable life as sustainable human relationships with houses that work for you and a mode of living that works for you in which this product, these glasses fit in naturally. And I guess that’s also why so many people are weirded out about the product, because they don’t know how is this actually going to fit into my life and into my human relationships Because the way in which it was presented in these videos didn’t seem to be credible.
Open source AI
Lex Fridman

(02:27:25)
Do you think AI, when is deployed by companies like Microsoft and Google and Meta will have the same issue of being weirdly corporate? There’d be some uncanny valley, some weirdness to the whole presentation? So this, I’ve gotten a chance to talk to George Hotz. He believes everything should be open source and decentralized and there then we shall have the AI of the people and it’ll maintain a grounding to the magic humanity. That’s the human condition that corporations will destroy the magic.
Joscha Bach

(02:28:03)
I believe that if we make everything open source and make this mandatory, we are going to lose about a lot of beautiful art and a lot of beautiful designs. There is a reason why Linux desktop is still ugly and it’s-
Lex Fridman

(02:28:19)
Strong words.
Joscha Bach

(02:28:20)
… To create coherence and open source designs so far when the designs have to get very large. And it’s easier to make this happening in a company with centralized organization. And from my own perspective, what we should ensure is that open source never dies. That it can always compete and has a place with the other forms of organization. Because I think it is absolutely vital that open source exists and that we have systems that people have under control outside of the cooperation and that is also producing viable competition to the corporations.
Lex Fridman

(02:28:58)
So the corporations, the centralized control, the dictatorships of corporations can create beauty. Centralized design, is a source of a lot of beauty. And then I guess open source is a source of freedom, a hedge against the corrupting nature of power that comes with centralized.
Joscha Bach

(02:29:20)
I grew up in socialism and I learned that corporations are totally evil and I found this very, very convincing. And then you look at corporations like anyone and Halliburton maybe and realized, yeah, they’re evil. But you also notice that many other corporations are not evil. They they’re surprisingly benevolent. Why are they so benevolent? Is this because everybody is fighting them all the time? I don’t think that’s the only explanation. It’s because they’re actually animals that live in a large ecosystem and that are still largely controlled by people that want that ecosystem to flourish and be viable for people. So I think that Pat Gelsinger is completely sincere when he leads Intel to be a tool that supplies the free world with semiconductors and not necessarily that all the semiconductors are coming from Intel. Just intel needs to be there to make sure that we always have them.

(02:30:12)
So there can be many ways in which we can import and trade semiconductors from other companies and places. We just need to make sure that nobody can cut us off from it, because that would be a disaster for this kind of society and world. And so there are many things that need to be done to make our style of life possible. And then with this, I don’t mean just capitalism, environmental structure and consumer resin and creature comforts. I mean an idea of life in which we are determined not by some kind of king or dictator, but in which individuals can determine themselves to the largest possible degree. And to me, this is something that this western world is still trying to embody and it’s a very valuable idea that we shouldn’t give up too early. And from this perspective, the US is a system of interleaving clubs and an entrepreneur is a special club founder.

(02:31:05)
It’s somebody who makes a club that is producing things that are economically viable. And to do this, it requires a lot of people who are dedicating a significant part of their life for working for this particular kind of club. And the entrepreneurs picking the initial set of rules and the mission and vision and aesthetics for the club and make sure that it works. But the people that are in there need to be protected if they sacrifice part of their life, there need to be rules that tell how they’re being taken care of even after they leave the club and so on. So there’s a large body of rules that have been created by our rule giving clubs and that are enforced bio enforcement collapse and so on. And some of these collapse have to be monopolies for game theoretic reasons, which also makes them more open to corruption and less harder to update.

(02:31:52)
And this is an ongoing discussion and process that takes place. But the beauty of this idea that there is no centralized king that is extracting from the peasants and breeding the peasants into serving the king and fulfilling all the walls like and an anal, but that there is a freedom of association and corporations are one of them. It’s something that took me some time to realize. So I do think that corporations are dangerous. They need to be protections against overreach of corporations that can do regular to recapture and prevent open source from competing with corporations by imposing rules that make it impossible for a small group of kids to come together to build their own language model.

(02:32:38)
Because open AI has convinced the US that you need to have some kind of FDA process that you need to go through that costs many million dollars before you are able to train a language model. So this is important to make sure that this doesn’t happen. So I think that open AI and Google are good things if these good things are kept in check in such a way that all the other collapse can still being founded and all the other forms of collapse that are desirable can still co-exist with them.
Lex Fridman

(02:33:04)
What do you think about Meta in contrast to that open sourcing most of its language models and most of the AI models it’s working on and actually suggesting that they will continue to do so in the future for future versions of llama for example, their large language model? Is that exciting to you? Is that concerning?
Joscha Bach

(02:33:27)
I don’t find it very concerning, but that’s also because I think that the language models are not very dangerous yet.
Lex Fridman

(02:33:35)
Yet?
Joscha Bach

(02:33:36)
Yes. So as I said, I have no proof that there is the boundary between the language models and AI, AGI. It’s possible that somebody builds a version of BBBAGI, I think, and falls in a algorithmic improvements that scale these systems up in ways that otherwise wouldn’t have happened without these language model components. So it’s not really clear for me what the end game is there and if these models can put force their way into AGI. And there’s also a possibility that the AGI that we are building with these language models are not taking responsibility for what they are, because they don’t understand the greater game. And so to me it would be interesting to try to understand how to build systems that understand what the greater games are, what are the longest games that we can play on this planet?
Lex Fridman

(02:34:30)
Games broadly, like deeply define the way you did with the games.
Joscha Bach

(02:34:35)
In the games theoretical sense. So when we are interacting with each other in some sense we are playing games, we are making lots and lots of interactions. And this doesn’t mean that these interactions have ought to be transactional. Every one of us is playing some kind of game by virtue of identifying these particular kinds of goals that we have or aesthetics from which we derive the goals. So when you say I’m Lex Fridman, I’m doing a set of podcasts, then you feel that it’s part of something larger that you want to build, maybe you want to inspire people, maybe you want them to see more possibilities and get them together over shared ideas. Maybe your game is that you want to become super rich and famous by being the best post cut caster on earth. Maybe you have other games, maybe it’s switches from time to time, but there is a certain perspective where you might be thinking, what is the longest possible game that you could be playing?

(02:35:24)
A short game is, for instance, cancer is playing a shorter game than your organism. Cancer is an organism playing a shorter game than the regular organism. And because the cancer cannot procreate beyond the organism, except for some infectious cancers like the ones that eradicated the Tasmanian devils, you typically end up with the situation where the organism dies together with the cancer, because the cancer has destroyed the larger system due to playing a shorter game. And so ideally you want to, I think build agents that play the longest possible games and the longest possible games is to keep entropy at bay as long as possible by doing, while doing interesting stuff.
Lex Fridman

(02:36:05)
But the longest, yes, that part, the longest possible game while doing interesting stuff and while maintaining at least the same amount of interesting.
Joscha Bach

(02:36:14)
Yes.
Lex Fridman

(02:36:14)
So complexity, so propagating.
Joscha Bach

(02:36:16)
Currently I am pretty much identified as a conscious being. It’s the minimal identification that I managed to get together, because if I turn this off, I fall asleep and when I’m asleep, I’m a vegetable. I’m no longer here as an agent. So my agency is basically predicated on being conscious and what I care about is other conscious agents. They’re the only moral agents for me. And so if an AI were to treat me as a moral agent that it is interested in coexisting with and cooperating with and mutually supporting each other, maybe it is I think necessary that AI thinks that consciousness is viable mode of existence and important.

(02:37:01)
So I think it would be very important to build conscious AI and do this as the primary goal. So not just say we want to build a useful tool that we can use for all sorts of things and then we have to make sure that the impact on the labor market is something that is not too disruptive and manageable and the impact on the copyright holder is manageable and not too disruptive and so on. I don’t think that’s the most important game to be played. I think that we will see extremely large disruptions of the status quo that are quite unpredictable at this point. And I just personally want to make sure that some of the stuff on the other side is interesting and conscious.
Lex Fridman

(02:37:42)
How do we ride as individuals and as a society, this wave disruptive wave that changes the nature of the game?
Joscha Bach

(02:37:50)
I truly don’t know. So everybody is going to do their best as always.
Lex Fridman

(02:37:53)
Do we build the bunker in the woods? Do we meditate more drugs? So mushrooms, psychedelics, I mean what, lots of sex? What are we talking about here? Do you play Diablo 4, I’m hoping that will help me escape for a brief moment. Play video games? What? Do you have ideas?
Joscha Bach

(02:38:16)
I really like playing Disco Ilysium. It was one of the most beautiful computer games I played in recent years and it’s a noir novel that is a philosophical perspective on western society from the perspective of an Estonian. And he first of all wrote a book about this bird that is a parallel universe that is quite poetic and fascinating and is condensing his perspective on our societies. It was very, very nice. He spent a lot of time writing it. He had, I think sold a couple thousand books and as a result became an alcoholic. And then he had the idea, or one of his friends had the idea of turning this into an RPG and it’s mind-blowing. They spent the illustrator more than a year just on making deep graph art for the scenes in between.
Lex Fridman

(02:39:12)
So aesthetically, it captures you, it pulls you in.
Joscha Bach

(02:39:14)
It’s stunning, but it’s a philosophical work of art. It’s a reflection of society. It’s fascinating to spend time in this world. And so for me it was using a medium in a new way and telling a story that left me enriched where when I tried Diablo, I didn’t feel enriched playing it. I felt that the time playing it was not unpleasant, but there’s also more pleasant stuff that I can do in that time.
Lex Fridman

(02:39:40)
So to you-
Joscha Bach

(02:39:40)
So ultimately I feel that I’m being gamed. I’m not gaming when I play it.
Lex Fridman

(02:39:44)
Oh, the addiction thing.
Joscha Bach

(02:39:45)
Yes. I basically feel that there is a very transparent economy that’s going on the story of the Diablo’s brain dead. So it’s not really interesting to me.
Lex Fridman

(02:39:54)
My heart is slowly breaking by the deep truth you’re conveying to me. Why can’t you just allow me to enjoy my personal addiction?
Twitter
Joscha Bach

(02:40:03)
Go ahead. By all means. Go nuts. I have no objection here. I’m just trying to describe what’s happening. And it’s not that I don’t do things that I later say, oh, I actually wish I would’ve done something different. I also know that when we die, the greatest regret that people typically have on their deathbed, they say, “Oh, I wish I had spent more time on Twitter.” No, I don’t think that’s the case. I think they should probably have spent less time on Twitter. But I found it so useful for myself and also so addictive that I felt I need to make the best of it and turn it into an art form and thought form. And it did help me to develop something, but I wish what other things I could’ve done in the meantime. It’s just not the universe that we are in anymore. Most people don’t read books anymore.
Lex Fridman

(02:40:51)
What do you think that means, that we don’t read books anymore? What do you think that means about the collective intelligence of our species? Is it possible it’s still progressing and growing?
Joscha Bach

(02:41:01)
Well, it clearly is. There is stuff happening on Twitter that was impossible with box. And I really regret that Twitter has not taken the turn that I was hoping for. I thought Elon is global brain pill and understands that this thing needs to self-organize and he needs to develop tools to allow the propagation of the self organization so Twitter can become sentient. And maybe this was a pipe dream from the beginning, but I felt that the enormous pressure that he was under made it impossible for him to work on any kind of content goals. And also many of the decisions that he made under this pressure seemed to be not very wise. I don’t think that as a CEO of a social media company, you should have opinions in the culture or in public. I think that’s very shortsighted. And I also suspect that it’s not a good idea to block [inaudible 02:41:58] of people over setting a Mastodon link.

(02:42:02)
And I think Paul made this intentionally, because he wanted to show Elon Musk that blocking people for setting a link is completely counter to any idea of free speech that he intended to bring to Twitter. And basically seeing that Elon was way less principled in his thinking there and is much more experimental and many of the things that he is trying, they pan out very differently in a digital society than they pan out in a car company, because the effect is very different, because everything that you do in a digital society is going to have real world cultural.

(02:42:38)
And so basically I find it quite regrettable that this guy is able to become defacto the Pope, right? Twitter has more active members than the Catholic Church and he doesn’t get it. The power and responsibility that he has and the ability to create something in a society that is lasting and that is producing a digital ago in a way that has never existed before, where we build a social network on top of a social network, an actual society on top of the algorithms. So this is something that is hope still in the future and still in the cards, but it’s something that exists in small parts. I find that the corner of Twitter that I’m in is extremely pleasant. It’s just when I take a few steps outside of it is not very wholesome anymore. And the way in which people interact with strangers suggest that it’s not a civilized society yet.
Lex Fridman

(02:43:29)
So as the number of people who follow you on Twitter expands, you feel the burden of the uglier sides of humanity.
Joscha Bach

(02:43:40)
Yes. But there’s also a similar thing in the normal world that is, if you become more influential, if you have more status, if you have more fame in the real world, you have, you get lots of perks, but you also have way less freedom in the way in which you interact with people, especially with strangers, because a certain percentage of people, it’s a small single digit percentage is nuts and dangerous. And the more of those are looking at you, the more of them might get ideas.
Lex Fridman

(02:44:13)
But what if the technology enables you to discover the majority of people to discover and connect efficiently and regularly with the majority of people who are actually really good? I mean, one of my sort of concerns with a platform like Twitter is there’s a lot of really smart people out there, a lot of smart people that disagree with me and with others between each other. And I love that if the technology would bring those to the top, the beautiful disagreements like intelligence squared type of debates. There’s a bunch of, I mean, one of my favorite things to listen to is arguments and arguments like high effort arguments with the respect and love underneath it, but then it gets a little too heated, but that kind of too heated, which I’ve seen you participate in, and I love that with Lee Krono, with those kinds of folks. And you go pretty hard, you’ll get frustrated, but it’s all beautiful.
Joscha Bach

(02:45:07)
Obviously I can’t do this, because we know each other and Lee has the rare gift of being willing to be wrong in public. So basically has thoughts that are as wrong as the random thoughts of an average highly intelligent person. But he blurts them out while not being sure if they’re right. And he enjoys doing that. And once you understand that this is his game, you don’t get offended by him saying something that you think is so wrong.
Lex Fridman

(02:45:33)
But he’s constantly passively communicating a respect for the people he’s talking with and for just basic humanity and truth and all that kind of stuff. And there’s a self-deprecating thing. There’s a bunch of social skills you acquire that allow you to be a great debater, great argument, like be wrong in public and explore ideas together in public when you disagree. And if I would love for Twitter to elevate those folks, elevate those kinds of conversations.
Joscha Bach

(02:46:03)
It already does in some sense. But also if it elevates them too much, then you get this phenomenon on clubhouse where you always get dragged on stage. And I found this very stressful, because it was too intense. I don’t like to be dragged on stage all the time. I think once a week is enough. And also when I met Lee the first time, I found that a lot of people seemed to be shocked by the fact that he was being very aggressive with their results, that he didn’t seem to show a lot of sensibility in the way in which he was criticizing what they were doing and being dismissive of the work of others. And that was not, I think, in any way a shortcoming of him, because I noticed that he was much, much more dismissive with respect to his own work. It was his general stance.

(02:46:51)
And I felt that this general stance is creating a lot of liability for him, because really a lot of people take offense at him being not like their Carnegie character who is always smooth and make sure that everybody likes him. So I really respect that he is willing to take that risk and to be wrong in public and to offend people. And he doesn’t do this in any bad way. It’s just most people feel or not all people recognize this. And so I can be much more aggressive with him than it can be with many other people who don’t play the same game, because he understands the way and the spirit in which I respond to him.
Advice for young people
Lex Fridman

(02:47:28)
I think that’s a fun and that’s a beautiful game. It’s ultimately a productive one. Speaking of taking that risk, you tweeted, when you have the choice between being a creator, consumer, or redistributor, always go for creation. Not only does it lead to a more beautiful world, but also to a much more satisfying life for yourself. And don’t get stuck preparing yourself for the journey. The time is always now. So let me ask for advice. What advice would you give on how to become such a creator on Twitter in your own life?
Joscha Bach

(02:48:04)
I was very lucky to be alive at the time of the collapse of Eastern Germany and the transition into Western Germany and me and my friends and most of the people I knew and were East Germans and we were very poor, because we didn’t have money and all the capital was western in Germany and they bought our factories and shut them down, because they were mostly only interest in the market rather than creating new production capacity. And so cities were poor and then this repair and we could not afford things and I could not afford to go into a restaurant and order a meal there. I would have to cook at home. But I also thought, why not just have a restaurant with my friends? So we would open up a cafe with friends and a restaurant and we would cook for each other in these restaurants and also invite the general public and they could donate.

(02:48:56)
And eventually this became so big that we could turn this into some incorporated form and it became regular restaurant at some point. Or we did the same thing with the music movie theater. We would not be able to afford to pay 12 marks to watch a movie, but why not just create our own movie theater and then invite people to pay and we would rent the movies for in a way in which a movie theater does, but it would be a community movie theater that which everybody you wants to help can watch for free and build this thing and renovates the building.

(02:49:31)
And so we ended up creating lots and lots of infrastructure. And I think when you’re young and you don’t have money, move to a place where this is still happening. Move to one of those places that are undeveloped and where you get a critical mass of other people who are starting to build infrastructure to live in. And that’s super satisfying, because you’re not just creating infrastructure, but we are creating a small society that is building culture and ways to interact with each other. And that’s much, much more satisfying than going into some kind of chain and get your needs met by ordering food from this chain and so on.
Lex Fridman

(02:50:07)
So not just consuming culture, but creating culture.
Joscha Bach

(02:50:10)
Yes. And you don’t always have that choice. That’s why I preface that when you do have the choice and there are many roles that need to be played, we need people who take care of the distribution in society and so on. But when you have the choice to create something, always go for creation, it’s so much more satisfying. And it also is, this is what life is about, I think.
Meaning of life
Lex Fridman

(02:50:28)
Yeah. Speaking of which, you retweeted this meme of a life of philosopher in a nutshell, it’s birth and death and in between it’s a chubby guy and it says why though? What do you think is the answer to that?
Joscha Bach

(02:50:49)
Well, the answer is that everything that can exist might exist. And in many ways you take an ecological perspective the same way as when you look at human opinions and cultures. It’s not that there is right and wrong opinions when you look at this from this ecological perspective, but every opinion that fits between two human years might be between two human years. And so when I see in a stranger opinion on social media, it’s not that I feel that I have a need to get upset, it’s often more that, “Oh, there you are.” And your opinion is incentivized, then it’s going to be abundant. And when you take this ecological perspective also on yourself and you realize you’re just one of these mushrooms that are popping up and doing this thing, and you can, depending on where you chose to grow and where you happen to grow, you can flourish or not doing this or that strategy. And it’s still all the same life at some level.

(02:51:43)
It’s all the same experience of being a conscious being in the world, and you do have some choice about who you want to be more than any other animal has. That to me is fascinating. And so I think that rather than asking yourself what is the one way to be, think about what are the possibilities that I have? What would be the most interesting way to be that I can be?
Lex Fridman

(02:52:06)
Because everything is possible. So you get to explore this.
Joscha Bach

(02:52:08)
It’s not everything is possible. Many things fail. Most things fail, but often there are possibilities that we are not seeing, especially if we choose who we are.
Lex Fridman

(02:52:21)
To the degree we can choose. Joscha you’re one of my favorite humans in this world, consciousness to merge with for a brief moment of time. It’s always an honor. It always blows my mind. It will take me days, if not weeks, to recover, and I already miss our chats. Thank you so much. Thank you so much for speaking with me so many times. Thank you so much for all the ideas you put out into the world, and I’m a huge fan of following you now in this interesting, weird time we’re going through with AI. So thank you again for talking today.
Joscha Bach

(02:53:04)
Thank you, Lex, for this conversation. I enjoyed it very much.
Lex Fridman

(02:53:08)
Thanks for listening to this conversation with Joscha Bach. To support this podcast, please check out our sponsors in the description. And now let me leave you with no words from the psychologist, Carl Jung. “One does not become enlightened by imagining figures of light, but by making the darkness conscious. The latter procedure, however, is disagreeable and therefore not popular.” Thank you for listening and hope to see you next time.
Transcript for Mohammed El-Kurd: Palestine | Lex Fridman Podcast #391
This is a transcript of Lex Fridman Podcast #391 with Mohammed El-Kurd.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
2:18 – Palestine
26:47 – Hate
40:18 – Antisemitism
48:14 – Peace in the Middle East
55:11 – West Bank
1:05:20 – Hamas
1:15:08 – Two-state solution
1:30:58 – Jerusalem
1:37:41 – Role of the US
1:39:31 – Ghassan Kanafani
1:50:16 – 2024 Elections
1:51:25 – Poetry
2:00:45 – Language
2:09:14 – Hope

Introduction
Mohammed el-Kurd

(00:00:00)
Regardless of whatever was written in these books that were written thousands and thousands of years ago, the fact of the matter is no one has a right to go on slaughtering people, removing them from their homes and then continuing to live in their homes, continuing to drink coffee on their balconies decades and decades later, with no shame, with no introspection, with no reflection. No one has the right to do that. No one has the right to keep an entire population of people in a cage, which is what’s happening to people in the West Bank who have no freedom of movement, which is what’s happening in Gaza, which is blockaded to water, air, and land, and is deemed uninhabitable by human rights organizations like the UN. No one has a right to do that.
Lex Fridman

(00:00:52)
The following is a conversation with Mohammed el-Kurd, a world-renowned Palestinian poet, writer, journalist, and an influential voice speaking out and fighting for the Palestinian cause. He provides a very different perspective on Israel and Palestine than my previous two episodes with Benjamin Netanyahu and Yuval Noah Harari. I hope his story and his words add to your understanding of this part of the world as it did to mine. I’ll continue to have difficult long-form conversations such as these always with empathy and humility but with backbone. And please allow me to briefly comment about criticisms I receive of who I am as an interviewer and a human being. I am not afraid to travel anywhere or challenge anyone face-to-face, even if it puts my life in danger. But I’m also not afraid to be vulnerable, to truly listen, to empathize, to walk a mile in the well-worn shoes of those very different from me. It’s this latter task, not the former one, that is truly the most challenging in conversations and in life, but to me, it is the only way. This is the Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Mohammed el-Kurd.
Palestine

(00:02:18)
Tell me about Sheikh Jarrah, the neighborhood in East Jerusalem where you grew up.
Mohammed el-Kurd

(00:02:22)
Sheikh Jarrah has, in a way, a typical neighborhood despite the absurd reality that surrounds it. It’s a typical neighborhood in terms of Palestinian neighborhoods. It’s one that is threatened with colonialism, with settler expansion, and with forced expulsion, and it has been that way since the early ’70s. My family, like all of the other families in Sheikh Jarrah, were expelled from their homes in the Nakba in 1948, and they were forced out by the Haganah and other Zionist parallel militaries that later formed the Israeli military, and they were driven to various cities. My grandmother moved to city to city, and she ended up in Sheikh Jarrah in 1956. Sheikh Jarrah was established as a refugee housing unit by the United Nations and by Jordinian government, which had control over that part of Jerusalem at the time. And then people lived there harmoniously. They were all from different parts of Palestine, and they managed to rebuild their lives after the first expulsion.

(00:03:32)
And then in the ’70s, you had settler organizations, many of whom were registered here in New York and in the United States, claiming our houses and our lands as their own by divine decree. Obviously, because the judges are Israeli and the laws were written by Israeli settlers and the whole judiciary was established atop the rubble of our homes and villages, we had no real pull in the courts. The Israeli courts would look at the Israeli documents, which we argue are falsifies and fabricated, and they would take them at face value without authentication, and they refused to look at our documents. They refused to look at the documents from the Jordanian government, the documents from the UN, the documents from the Ottoman archives. So you already have this kind of asymmetry in the court that, for any person with common sense, would lead you to believe that this is not in fact a legal battle or a real estate dispute, as Israeli Ministry of Foreign Affairs likes to frame it, but rather a very, very political battle.

(00:04:37)
One that is about social engineering, one is about demographics, one that is about removing as many Palestinians as possible from occupied Jerusalem. So we did what all Palestinian families in Jerusalem do when they’re faced with this kind of threat, and we bought time. We pleaded and pleaded and appealed the courts and appealed the cases, and we got over 50 expulsion orders. In 2009, rifle-wielding settlers accompanied by police and Israeli military came over and shoved our neighbors outside of their home around 5:00 AM. It was the most brutal, violent thing I’d seen as a child at the time, and I didn’t realize that my turn was coming, my turn was next. They threw them out in the middle of the night with sound bombs and rubber bullets, and they had to live in tents on the street for many, many months and even lived in our front yards for a few months and lived in their cars.
Lex Fridman

(00:05:41)
Can you linger on that process? 2009, you said 50 expulsion orders. What was happening?
Mohammed el-Kurd

(00:05:48)
Between the ’70s and 2009, there had been many, dozens of expulsions orders against us and against many other families in the neighborhood, 28 other family, 28 families in total actually. And in 2008, 2009, the first wave of expulsions finally happened. It actually began with [inaudible 00:06:09] el-Kurd. We’re not related, but we live on the same street in the same neighborhood. She was thrown out of her home. Her husband, an elderly man, also named Mohammed el-Kurd, was pronounced dead on the spot. He had a stroke and died. Israeli soldiers pulled him out of his home while he was urinating and threw him into the streets, and he died. A few months later, Darawi and Hannun families, not a clan, but in Palestine you have sometimes a building that contains multiple brothers and their wives, each have little apartments, Darawi and Hannun family is about 35 people, were thrown out in the middle of the street right across from us.

(00:06:47)
And then by the end of 2009, I had come home from school to find all of my furniture scattered across the length of the street, and I saw the settlers, many of whom had American accents living in our house. And their justification for this, their reasoning for this is divine decree. This is what God wants. This is the promised land. This is so-and-so, as if God is some kind of real estate agent. So they took over half of our home, and we continued to be in courts for the following decade. I was still a child and I had broken English, and I was talking to all of these diplomats and all of these journalists who would subjugate me, subject me to their racism and biases and so on and so forth. And I had to prove my humanity time and time again. And I had to do all of this, all with broken English. And we were lucky, even if we got a quote in the article written about us by The Times or so on and so forth.

(00:07:53)
Move forward to 2020, I was in New York City studying a master’s degree, getting a master’s degree. And my father calls me and he tells me, “We have yet another expulsion order,” and we decided to launch a campaign. It was quite ambitious at the time, but the whole objective of the campaign was to demystify what is happening because it’s reported on in the news, it’s reported on around the world as this real estate dispute, as these evictions, which was not really what’s happening. Evictions do not entail a foreign army in an occupied territory, forcibly removing you out of your home. So I came home from New York, and we launched a campaign which turned into a global success.

(00:08:40)
And I believe it was a global success because, finally, the images on the screen matched the rhetoric that was being said. It wasn’t so confusing or complicated anymore. All of this asymmetry was pronounced and articulated in a way that any of you, be it in Alabama, be it in New York, be it in Egypt, was able to understand the asymmetry of the judicial system and the agenda of colonialism that was taking place here. And due to immense international and diplomatic pressure from all over the world, even the United States, the Israeli Supreme Court was forced to cancel all of the eviction orders in Sheikh Jarrah until further notice. This, I consider, was a small victory because obviously we are still at risk of losing our homes once they decide to do the land registry, which we can get into a little bit later if you’d like.

(00:09:39)
But nonetheless, it was something that we haven’t seen before. And the fact that the Supreme Court canceled all of these dozens and dozens of fast eviction orders, it set a precedent. And it also proved that this was a political battle, not a legal one.
Lex Fridman

(00:09:54)
So let’s just add a little more detail to the people who are not familiar with the story, with the region, with the evictions, with the courts. So first of all, [inaudible 00:10:07] your eyes in East Jerusalem. Maybe you can say what is Jerusalem, where is it located, what are we talking about in terms of regionally and, second, what kind of people live there. So if you could talk about the Palestinian people. We should also make clear that these evictions is literally people living in homes, and their homes are taken away from them. I suppose technically, it’s legal evictions, but you’re saying that there’s asymmetry of power in the courts where the legal is not so much legal, but is politically and maybe even religiously based.
Mohammed el-Kurd

(00:10:53)
Yeah, I mean, the most important context here is that oftentimes Americans think that Israel and Palestine are some kind of two neighboring countries that live next to each other, and they are at war. But the fact of the matter is Palestinian cities exist all over the country, and it’s just one country, it’s just one infrastructure, and Israel is literally on top of Palestine. It was established on top of our villages in the late ’40s. Now, according to international law, the eastern part of Jerusalem is under occupation. So Israeli presence and jurisdiction over the area is completely illegitimate. They say the evictions are legal because the settlers write their law, so obviously they’re going to allow settlements to expand. But according to international law, even US policy, Israel occupies the eastern part of Jerusalem. Jurisdiction there is illegitimate. We shouldn’t even be going to their courts in the first place, but we have no other option.

(00:12:02)
We’re talking about Sheikh Jarrah, we’re talking about Jerusalem, we’re talking about generations and generations and generations of people who have lived there for the longest time, who now, even though… For example, me, I don’t have a citizenship. I’m a resident, a mere resident, I have a blue ID card even though my grandmother and my grandfather were born in Jerusalem, their grandparents were born in Jerusalem, even though we’ve lived there for generations. But Palestinians in Jerusalem, we are not citizens. We’re just mere residents. Same thing with residents of the occupied Syrian Golan. They are not citizens. They are just residents in their own hometowns. This is an important piece, but all of these gets convoluted and lost in translation. I would argue, a lot of the time, it’s dubious, it’s malicious, the fact that these little pieces of context that frame the entire story get lost.

(00:13:03)
I’ll talk to you about something else. Just 10 minutes across from my neighborhood, Sheikh Jarrah, there’s another neighborhood called Silwan. And the people in Silwan are also threatened with expulsion, but not through evictions, but through home demolitions. And if you look at American media or Israeli state media, you would read the headlines, “Palestinians living in homes built illegally are going to face… their homes are going to be torn apart.” What these headlines don’t tell you, most of the time, the substance doesn’t tell you that Palestinians seldom ever get building permit applications. In fact, recently, a spokesperson for the Israeli military confirmed that was 95% of building permits applications submitted by Palestinians in East Jerusalem and the West Bank are rejected by the Israeli authorities.

(00:13:53)
And to make this even more absurd, the guy, the councilman who is responsible for rejecting and accepting building permit applications, his name is Yonatan Yosef, and he’s an activist in the settler movements and he’s a Jerusalem council member, last week, following the expulsion of Sub Laban family in the old city of Jerusalem, he posted to his official Facebook account, “Nakba now,” demanding a second Nakba, promising another Nakba. He has done so on many occasions, he has chanted with a megaphone, just a few months ago, walking down the street in my neighborhood chanting, “We want Nakba now.” This is a man who has vandalized our murals, who has screamed Islamophobic slurs. This is literally a man in the government making these decisions. And this is similar to Masafer Yatta in the south of Hebron Hills. For those who don’t know, it’s a place in the occupied West Bank where Bedouin and cave dweller Palestinians have lived for generations, they have cultivated the land. And recently, they were expelled from their homes. Over a thousand people were expelled from their remote small villages.

(00:15:11)
Again, if you’re reading American media, it would say, “Palestinians living in firing zones were removed because they’re living in a military zone.” What these media reports will not tell you that, in the ’80s, the Israeli government purposefully classified many lands in the occupied West Bank as firing zones, as off-limit military zones for the sole purpose of expelling the residents, and this is not some kind of conspiracy theory. This is declassified information that was released from the Israel’s State Archive that was later reported on by our audits. Also, these reports will not tell you that the judge who rules on whether these people continue to live under homes or not is himself a settler in the West Bank. And I’m not even talking about a loose definition of a settler, but according to international law, this is a settler living illegally in an illegal settlement in the occupied West Bank. This is the judiciary that we deal with, which is hilarious considering how it’s being reported on in American media recently as some kind of beacon of progress and democracy that new government is trying to undermine.
Lex Fridman

(00:16:20)
So there’s no representation in the courts for the Palestinian people?
Mohammed el-Kurd

(00:16:23)
I mean, we have lawyers, but no, there is no… In fact, for Palestinians with Israeli citizenships for example, there’s over 60 laws that specifically and explicitly discriminates against them.
Lex Fridman

(00:16:36)
So again, it’s technically legal, the evictions and the demolitions.
Mohammed el-Kurd

(00:16:42)
Yeah, so was Jim Crow was legal also.
Lex Fridman

(00:16:46)
When something is legal, it can also still be wrong.
Mohammed el-Kurd

(00:16:50)
Absolutely. History has shown us time and time again that legality does not necessarily mean morality. The law is a bloodbath in many ways. It has been used and abused to facilitate the most horrendous atrocities. In the case of the Palestinians, the law has served to facilitate and bureaucratize our ethnic cleansing.
Lex Fridman

(00:17:21)
Do you think there’s people, judges, and just people in power in the judiciary that have hate for the Palestinian people?
Mohammed el-Kurd

(00:17:30)
I mean, I’m not really… Yeah, I mean, the easy, simplistic answer is yes, but I don’t really care about the contents of their hearts. What I care about, the policy they enact, where the laws they write and enact are hateful, demolishing a person’s home. So you can have somebody from Long Island, New York who’s fleeing fraud charges, this is the case in my house, live in their front yard, that’s hateful. So I don’t need confirmation. This is something we see a lot actually. Palestinians and people who are pro-Palestine and just people who want to make a difference in how this cause is represented, we often run for the first opportunity to cite an Israeli being hateful. The last Israeli prime minister said that he has killed many Arabs and that he has no qualms with it. Netanyahu has said a slew of racist, hateful things. Jabotinsky, the pioneer of Zionism, Herzl, one of the pioneers of Zionism, all have said horrible, hateful things.

(00:18:43)
We also cannot wait to cite a confession from a former Israeli soldier who’s guilty conscience is keeping them up at night. And we use all of these confessions or slip ups as evidence to prove that this is a racist country that is enacting racist acts, but we don’t need this because the material proof is on the ground. You see it in the policies that are enacted. You see it in how this regime has behaved for the past 75 years. I don’t need confessions from the likes of Netanyahu to understand that his heart is full of hate.
Lex Fridman

(00:19:27)
So if you could return to 1948 and describe something that you’ve mentioned, the Nakba, which means catastrophe in Arabic. What was this event? What was this displacement and dispossession of Palestinians in 1948?
Mohammed el-Kurd

(00:19:43)
Well, May 15th, 1948 is commemorated every year as the anniversary of the Nakba, but I would even argue anything, this is like a… A very popular idea is that the Nakba did not begin or end in 1948. The ’48 was rather a crystallization of the Zionist enterprise in Palestine. What happened was is that many Zionists paramilitaries that, again, today merged and made the Israeli army, which calls itself the Israeli Defense Forces even though they’re literally always the aggressor, committed atrocities and massacres, and they destroyed over 500 villages, they killed over 15,000 people, they forced a very large portion, a majority of the Palestinian population to flee their homes. And this was the near total destruction of Palestinian society that continues on to this day. We refer to it as the ongoing Nakba. And you see it in Sheikh Jarrah, you see it in Silwan, you see it in Harran, and all of these people losing their homes.

(00:21:04)
In many cases, time and time again, I grew up and my grandmother told me the stories about the Nakba. She told me stories about her neighbors who were running away in a panic, and they had mistaken a pillow for their offspring and they just took it with them. And they realized later that they forgot their child and they came back for it. Many, many people who were separated from their… My grandmother herself, she lost her husband for a few months, for nine months. He wasn’t imprisoned by the Israelis. She told me all of these stories, and she wasn’t just reminiscing about them. She was letting me know that this is still happening and I didn’t need to grow up that old to see it happening in my own front yard, to see that expulsion happen in the same fashion. She’s talked about it.

(00:21:57)
But now they have replaced their artillery with the judiciary. They have replaced the slashing of the pregnant women’s bellies in the Deir Yassin massacre with laws that say, “You’re not legally allowed to be here. We’re going to kick you out of your home,” and it’s happening, and it has happened in broad daylight. One piece of context for the listener who is not familiar with the Nakba is the Balfour Declaration, which was a promise, quote-unquote, “promise” made by the British to the Zionist movement in 1917, committing to the establishment. I’m quoting, I think word for word, “committing to the establishment of a Jewish state in Palestine”, as if Palestine was the British to give away. And there was this whole movement that called for colonization of Palestine.

(00:23:01)
And there were different schools of thought in Zionism. People like Zangwill said that this was a country without a people, and Palestinians who have existed there, who have cultivated the lands, who had diverse cultural and religious and political practices, they were completely erased. And other people like Jabotinsky were a lot more explicit and a lot more honest and said that, “We need to fight the Palestinians because they loved their land, much like the Red Indians loved their lands,” and he had a paper called the Iron Wall: Colonization of Palestine Must Go Forward. And all of these schools of thoughts were then shopping around for imperial support for their cause. They tried to get support from the Ottoman Empire, they tried to get support from Germany, this is in the 1800s, and then they got support from the United Kingdom. A great book to recommend is The Hundred Years’ War on Palestine by Rashid Khalidi, traces the Zionist movement, oftentimes in the Zionists’ own words.

(00:24:24)
So today what we’re seeing is a continuation. And people like Jabotinsky, who are profoundly and explicitly racist, who have called for genocide, who have called the Palestinians barbaric, who have said and done racist things… Jabotinsky also was the founder of the Irgun, one of the other militias that later merged to become the Israeli army, which was responsible for the Deir Yassin massacre, which was responsible for the bombing of the King David Hotel, this is a person who is still celebrated in Israeli society. There are streets named after him, and Netanyahu just two weeks ago, if I’m not mistaken, honored him in a public celebration. So this is Zionism. It’s not even through my own words.
Lex Fridman

(00:25:14)
What do you say to people that describe Israel as having historical right to the land, so if you stretch, not across decades, but across centuries into the past?
Mohammed el-Kurd

(00:25:27)
This kind of thing is a red herring. It’s a distraction because you don’t think of any state as having rights. But there is this exceptionalism to the Israeli regime where it has a right to defend itself, and it has a right to the land, and it has a right to shoot 14-year-old boys because it thought they had a knife in their pockets. A lot of the time, people cite the Torah and cite religious books. Sometimes Zionist will even say like, “Read the Quran, and blah, blah, blah.”

(00:25:56)
Regardless of whatever was written in these books that were written thousands and thousands of years ago, the fact of the matter is no one has a right to go on slaughtering people, removing them from their homes and then continuing to live in their homes, continuing to drink coffee on their balconies decades and decades later with no shame, with no introspection, with no reflection. No one has the right to do that. No one has the right to keep an entire population of people in a cage, which is what’s happening to people in the West Bank who have no freedom of movement, which is what’s happening in Gaza, which is blockaded to water, air, and land, and is deemed uninhabitable by human rights organizations like the UN. No one has a right to do that.
Hate
Lex Fridman

(00:26:48)
Do you have hate in your heart for Israel?
Mohammed el-Kurd

(00:26:51)
Why does that matter?
Lex Fridman

(00:26:55)
As one human being to another, you’re describing quite brilliantly that the contents of people’s hearts don’t matter as much as the policies and the contents of the courts and the laws and what actually is going on on the streets in terms of actions, but this is also a human story. I feel like, at the core of the situation here is hate or maybe inability for some group of humans to see the humanity in another group of humans. So it’s important here to talk about the contents of hearts, if we were to think about the long-term future of this.
Mohammed el-Kurd

(00:27:47)
Yeah, I mean, I would be concerned actually if I didn’t feel some kind of way in my heart. I would be concerned for my own dignity. Because the people who revolt, the people who are angry, the people who refuse to live under occupation know that they deserve better. People start revolutions not because of some kind of cultural phenomenon, not because of some kind of desire, but because they cannot breathe, because they cannot breathe, they cannot live. They are living under excruciating circumstances. Palestinians, I don’t know, I don’t know how many Palestinians I’ve interacted with, but we are some of the most wonderful people. I mean, not all of us, I think some of us are insufferable, but most of us. Most of us, we’re very, very hospitable. We’re very hospitable. Even in the early correspondence between the mayor of Jerusalem and Herzl, who wrote The Jewish State, the generosity through which the Palestinian mayor was talking to Herzl, who was plotting to take over his land, is impressive and, at the same time, heart-wrenching. But I personally think there’s a lot of dignity in negating your oppressor. And I think it would be ridiculous today if we look back at Jim Crow, for example, and we ask the person who’s lived under Jim Crow if they have hate in their heart for Jim Crow, as if that’s not the absolutely logical and natural sentiment to feel.
Lex Fridman

(00:29:30)
In Rifqa, you wrote, my father told me, “Anger is a luxury we cannot afford. Be composed, calm, still, laugh when they ask you, smile when they talk, answer them, educate them.” So let me linger on this. Is there anger in there, in your heart? And does it cloud your judgment?
Mohammed el-Kurd

(00:29:50)
Does it cloud my judgment? I don’t think so. I think our campaign to defend our homes was particularly successful because it was honest to what was happening on the ground, because it refused to follow the strategy that we have used in our advocacy before, where we shrink ourselves and we turn the other cheek and we try to convince American lawmakers and American diplomats and journalists of our humanity because we wait for their approval. I was 14 years old when I first flew to Congress to speak to Congress people and to speak at the European Parliament. At the time, I thought, “Wow, I must be such a brilliant 14-year-old for them to have me here.” Looking back, I didn’t know what I was talking about. I had horrendously broken English, and I didn’t have any talking points. And I came to realize that the reason why we send our kids with their PowerPoints to the hill is because of the racism and the hatred that lingers inside the hearts of American politicians who refuse to sit on the table with Palestinian adults as equals.

(00:31:08)
And so we resort to sending our kids who will not threaten and who will not trigger the biases they have against Muslims and Arab people, which Palestinians, even though we’re not all Muslim, are racialized as Muslim. And this is why we emphasize the deaths of women and children as though the deaths of our men does not counter, does not matter. All of these things I think the new generation of Palestinians is rebelling against. I think words like… I think it’s loaded, it’s loaded language, anger and angry and hate and so on and so forth, because it mischaracterizes people and it kind of delegitimizes them a little bit.

(00:31:53)
I think the real anger is the bulldozer bulldozing through my house. I think the real anger is the 18-year-old soldier who refuses to see me as a human being and strip searches me every chance they get. That’s where the real anger lies. And I’m quite honestly proud of our unabashedness and our refusal to bow our heads or bury our heads in the sand. I think that’s the only way forward.
Lex Fridman

(00:32:25)
So anger, or whatever it is, is a fuel for action.
Mohammed el-Kurd

(00:32:30)
Absolutely. And it has been throughout history, it has been.
Lex Fridman

(00:32:36)
How much of this tension is religious in the practical aspects of the courts and the evictions and the demolitions? You mentioned something, divine decree, how much underneath of it do you feel the division over religious text and religious beliefs?
Mohammed el-Kurd

(00:33:00)
It’s convenient to market what’s happening in Palestine as a religious conflict because it allows the listener the luxury of believing that this is an ancient, complicated thing that stretches thousands and thousands of years ago. But the fact of the matter is the people who invented Zionism, who pioneered the Zionist movement, who called for immigration and settling into Palestine, a lot of them were atheists. A lot of them were not religious at all. And the leaders of the Israeli state today, a lot of them are atheists and a lot of them are secular and so on and so forth. It’s easy to say that this is about Muslims and Jews fighting over the land and so on and so forth, but it’s not. It’s about the land itself and it’s about people being forced out of their homes.
Lex Fridman

(00:34:00)
Benjamin Netanyahu said, “Anti Zionism is anti-“
Lex Fridman

(00:34:00)
Benjamin Netanyahu said, “Anti-Zionism is anti-Semitism.”
Mohammed el-Kurd

(00:34:04)
Of course he said that.
Lex Fridman

(00:34:07)
Do you disagree?
Mohammed el-Kurd

(00:34:09)
Absolutely, I disagree.
Lex Fridman

(00:34:11)
What’s the gap between anti-Zionism and anti-Semitism, those who are against the policies of Israel versus those who are against the Jewish people?
Mohammed el-Kurd

(00:34:25)
I watched the first 20 minutes, and then I couldn’t do it anymore, but I watched. And then what was interesting about Netanyahu is that he said, being anti-Zionist is like saying, I’m okay with the Jews, I just don’t believe the Jews have a right to form their own state. That’s like saying, I’m okay with Americans, I’m just not okay with Americans having their own state. And there is so much wrong with that statement in the sense that Jewish people are a religious group and being an American is a nationality that consists of a diversity of religions and so on and so forth, first of all. And the second thing that’s wrong with that statement is the whole idea that states somehow have a right to exist or whatever. It’s such a distraction. You have people getting shot in the street. You have millions and millions of people beseeched, you have people losing their homes. You have people who are held in Israeli prisons without trial or charged indefinitely, but the conversations that are being held on the Hill, the conversation that are being held on CNN are does Israel has a right to exist or why would you negate Israel is having a right to exist? That’s one.

(00:35:44)
Now, of course, and I just find it’s ridiculous again, that opposing a secular political movement that was explicitly colonialist, expansionist, exclusive and racist through the words of its own authors is somehow… And also again, opposing such a political movement that is quite young and quite recent is somehow equivalent to opposing a religion that is thousands and thousands of years old. But it is convenient again, for Israeli politicians to frame us who oppose Zionism, a form of racism and bigotry, as anti-Semites. But I can guarantee you Benjamin Netanyahu has no problem with anti-Semitism. This is the same man who has no problem getting on stage and shaking hands with Pastor John Hagee, doing web webinars with Pastor John Hagee. For those who don’t know, Pastor John Hagee is the founder of Christians United for Israel, who has said on multiple occasions that Hitler was a hunter who was sent to hunt the Jews. Who said on multiple occasions that Jewish people are going to perish in hell. All of this is verifiable by Google, and this is one of the Israeli regime’s closest allies.

(00:37:11)
So the Israeli regime does not have a problem with anti-Semites when it serves its interests. It has a problem… If you look at evangelicals or Christian Zionism at large, anti-Semitism lies at the heart of Christian Zionism. It’s the idea that we want to drive all of the Jews outside of the United States so that Armageddon could happen, or whatever the fuck. This accusation has been a muzzle, it has been used as a muzzle to silence political opposition and to stifle political advocacy for the liberation of Palestine. And a lot of the time people get caught up in denouncing it and in justifying themselves and disclaimers and so on and so forth that you lose the point, that you’re distracted from the focal point, that is there is an ongoing colonialism happening where people every single day are killed. I cannot keep count. This morning a kid was shot in Palestine. It’s embarrassing even for me that I don’t even know the numbers here, but this muzzle has been effective and I think the only righteous option is to oppose these labels, these smear campaigns that target us.

(00:38:36)
I myself have been labeled an anti-Semite by the ADL. And if you want to talk about that at surface level, people will say, wow, the ADL, Anti-Defamation League condemned you. But people do not look at the history of the Anti-Defamation League, do not look at the present of the Anti-Defamation League, the fact that they are the largest non-governmental police training department in the country where they train police in racial profiling and militarism. The fact that they have historically and continued to have engaged in surveillance on Black liberation movements, on anti-Apartheid South African activists. Most recently in Charlottesville, when White supremacists were marching and chanting anti-Semitic shit, the ADL advised local police departments to spy on the Black organizers opposing the White supremacists. This is again, all verifiable on the internet, go to droptheadl.org.
Lex Fridman

(00:39:46)
So the ADL does not alleviate the hate in the world as it probably is designed to do?
Mohammed el-Kurd

(00:39:58)
No. It’s a guise, I don’t think the Apartheid Defense League is really our most progressive…
Lex Fridman

(00:40:06)
That’s what it stands for.
Mohammed el-Kurd

(00:40:07)
In case you didn’t know, now you know.
Antisemitism
Lex Fridman

(00:40:12)
If we could just linger on this idea of anti-Semitism, there’s quite a bit of anti-Muslim sentiment in the United States, especially after 9/11. I’ve spoken to people about that. There’s also anti-Jewish, anti-Semitism sentiment in the United States, but also throughout human history. What do you make about this kind of fact of human nature that people seem to hate Jews throughout history, especially in the 20th century, especially with Nazi Germany? What are your in general thoughts about the hatred of the Jewish people?
Mohammed el-Kurd

(00:40:57)
I think it’s obviously wrong. I don’t know. It’s this idea that I even have to clarify what I think about anti-Semitism that doesn’t sit well with me. I think it’s completely unfortunate and wrong that Jewish people have been persecuted across history.
Lex Fridman

(00:41:13)
So one of the criticisms, I think I read the ADL are making this criticism of you, is maybe you’ve tweeted a comparison between Israel and Hitler, and thereby diminishing the evil that is Hitler. What would you say to that?
Mohammed el-Kurd

(00:41:34)
Amy Cesaire talks about this a lot, the exceptional of Hitler. Hitler is a deplorable, I don’t know, condemnable, rotten racist, horrible human being that belongs in the depths of hell. Obviously that goes without saying, but I’m allowed analogy and I’m allowed to say whatever I want. Now, I don’t necessarily think that that such an analogy is a good strategy to have, but at the time, the context came in 2021 when Israeli soldiers and policemen and settlers were literally burning down our neighborhood, again, verifiable by Google, and I tweeted it. And also, I remember I tweeted something, “I hope every single one of them dies.” And to this day, this is some kind of gotcha for me, as if I should have tweeted like, oh, here’s the apple pie for every single soldier that’s throwing tear gas in my house. There is such an exceptionalism when it comes to Palestinians. We’re not allowed analogy, we’re not allowed expression. We’re not allowed armed resistance, we’re not allowed peaceful resistance. We’re not allowed to boycott because that’s Anti-Semitic. We’re not allowed to do anything, so what are we allowed? If I can’t boycott, and that’s against American law now to boycott, and if I can’t pick up a rifle because that’s against the law, and if I can’t even tweet my frustration out, what am I allowed to do? And maybe Netanyahu can send me a manual with all he’s happy with.
Lex Fridman

(00:43:21)
So you’ve spoken about the taking of homes, the IDF killing civilians, killing children. What about the violence going the other direction, Israelis being killed in part by terrorist action?
Mohammed el-Kurd

(00:43:39)
Well, it depends on how you define terrorism. Across history, one man’s freedom fighter is another man’s terrorist. I don’t necessarily subscribe to the definition of terrorism. If a foreign army is in my neighborhood, which it’s not supposed to be, and they’re shooting live ammunition at my house, I’m allowed to do what I’m allowed to do. And again, this is yet another case of Palestinian exceptionalism because when it comes to Ukraine, people have no problem seeing Ukrainians defending their homes, seeing Ukrainians dying for their land, seeing Ukrainians making makeshift Molotov on Sky news. Sky News was running Molotov making cocktails. The New York Times ran an article interviewing Ukrainian psychologist who said, I’m paraphrasing, but he said, hatred for all Russians is actually a healthy outlet. The New York Post ran a headline championing, quote unquote, heroic Ukrainian suicide bomber. These things we would not even dream of as Palestinians.

(00:44:54)
We are told to turn the other cheek time and time again, we’re told that we should continue living inside these enclaves without access to clean water, without access to the right to movement, without access to building permits, without our natural right to expansion, without a guarantee that if we leave our house we’re not going to be shot. And we’re supposed to not do anything about it. That is absurd. Any person watching this understands this completely. People understand that if somebody is attacking your home, you’ll fight back. If somebody is attacking your family, you fight back. That is not… But again, who gets to call who a terrorist? Who gets to define terrorism? This is all about who has power. Who gets to write these laws? Who gets to write these definitions? Why is it that American actions in Iraq is not called terrorism by American politicians? Violence is like this mutating concept, and it takes on many shapes and forms. And if it’s in a uniform, if it speaks in English, if it has blonde hair, it’s somehow acceptable, it’s okay. We make movies about it. We sell out tickets about it, we make games about it. But if it’s without a uniform, it’s if it has a thick accent, if it has a beard, that’s condemnable, that’s wrong, that’s terrorism.
Lex Fridman

(00:46:28)
Do you think violence is an effective method of protest and resistance in general?
Mohammed el-Kurd

(00:46:33)
In general, I think it has been, but I believe in fighting on all fronts. I don’t think violence alone is going to bring about change. I think there’s so much to do in culture and in shifting public opinion, there’s so much to do in media and fighting back against media. Erasure and censorship, there’s so much to do diplomatically and politically, and I think I would be naive if I don’t take the power imbalance into consideration. One side has makeshift weapons and the other side is one of the most sophisticated armies in the world, so I don’t know how effective violence could be in this case.
Lex Fridman

(00:47:19)
But if you look at the flip side, do you see the power of nonviolent resistance? So Martin Luther King, Gandhi, the power of turning the other cheek, you spoke negatively about turning the other cheek.
Mohammed el-Kurd

(00:47:32)
Yeah.
Lex Fridman

(00:47:34)
So I sense that doing so has not been effective for the Palestinian people.
Mohammed el-Kurd

(00:47:40)
We’ve turned the other cheek generation after generation. There is this Zionist trope that is used against us. They say, Palestinian rejectionism. They say that we reject everything, but if you look at the history like our leadership, the Palestinian authority has given up inch after inch, has compromised on acre after acre, has signed deal after deal after deal after deal, and still there is no peace. So turning the other cheek is not the most effective method in my book.
Peace in the Middle East
Lex Fridman

(00:48:14)
What are the top obstacles to peaceful coexistence of Israelis and Palestinians?
Mohammed el-Kurd

(00:48:20)
The occupation comes to mind. The [inaudible 00:48:23] policies come to mind. The seeds comes to mind. The asymmetry of the judiciary comes to mind. The whole system needs to be dismantled. I will quote my dear friend Robert Barre, who’s a lawyer who says, “The solution, justice comes about through recognition, return, and redistribution.” There are millions of Palestinian refugees who are living in excruciating circumstances in refugee camps around the world. There are thousands of Palestinian prisoners who are held in prisons for defending their homes, hundreds of which are held without charge or trial by the way. There are many Palestinians who get killed in broad daylight with no recourse, journalists and medics and everyday people, not just the freedom fighters. We need, again, recognition, return and redistribution, and peace comes about when they stop killing us, when they stop keeping us in a cage. That’s quite simple.
Lex Fridman

(00:49:33)
Can you describe recognition, return and redistribution?
Mohammed el-Kurd

(00:49:38)
Return, right of return. The right of return to all of the Palestinian refugees to their homes. When I’m driving around Haifa and I see my grandmother’s home that’s now turned into a restaurant, I made a joke in one of my essays recently that had I had that, I could have had it all. The beachfront views, her smug attitude. She grew up by the sea after she relocated to Haifa after Jerusalem. We want that. And they’re lucky I don’t want Netanyahu’s home, but I just want my home. I just want my home. We want to return. Also, I believe in the 1960s, the Israeli government classified 90% of all of historic Palestine as state-owned land. This is all land that was owned by Palestinian farmers who have cultivated their lands for decades. Since the establishment of the Israeli state, there has been Jewish only towns popping up every few years, and not one town, not one Palestinian town has emerged. Even those of us who have Israeli citizenship who live outside of the wall are encircled and cannot have their natural community growth in their towns, that needs to change.
Lex Fridman

(00:51:00)
You mentioned the wall. Can you describe the wall?
Mohammed el-Kurd

(00:51:03)
The wall is a nine meter high cement wall that was finished in 2003. And if you’re American, you’ve probably heard the whitewash sanitized version of the name, which is the security wall. But it’s the wall that literally has stolen thousands of dunams of land and has ripped apart families. My mother is a poet or was a poet at some point, and she had this poem she published in the paper called Love Behind the Wall. It’s a poem, but it describes the real life situation of two families who lived right across the street from each other, but were then separated by the wall, and they would fly balloons to see each other from each side of the wall or something like that. This, although it sounds absurd, but it’s the reality for many Palestinian families whose lives were torn apart, whose livelihoods also were torn apart by the wall.

(00:52:03)
Maybe this is a good opportunity to talk about the legal classifications for Palestinians. Israel, much like any other colonial entity, has divided and fragmented the Palestinian people. As I said earlier, I have a blue ID, which means I’m a resident. A friend of mine who lives in Haifa, for example, two hours away from me, 150 kilometers, not nothing too bad in this country, has an Israeli citizenship. He can travel, he can enter the West Bank, he can do a lot more. He’s a citizen, he can vote if he wants to, not that we want to. I always say to my friends, “Oh, you can go to Italy without a visa because you have an Israeli citizenship.” But they battle national eraser. They battle crime in their own communities because of police negligence. They battle land confiscation, and have battled land confiscations in the ’50s.

(00:53:04)
Whereas somebody with a green ID, somebody from the West Bank cannot leave the West Bank, cannot go anywhere without a special permit and lives behind these walls. The West Bank, I think hilariously George Bush described it as Swiss cheese because of the holes. Every a hundred meters there’s a new settlement or there’s a new military checkpoint. So even if you live behind the wall in the West Bank with your green ID, even though you’re robbed of your right to movement, you still even can’t move from town to town within the West Bank without encountering settler violence or military violence while you’re crossing the checkpoints and so on and so forth.

(00:53:51)
And then the last category we have is people who live in Gaza, we are talking about over 2 million people who live in an open air prison, who have no right to movement, but also have no access to clean water and no access to supplies, no access to good food, no access to good healthcare, and so on and so forth, who routinely get bombarded every few years. Gaza is two hours away from my house. It feels like an absolute far away planet because it’s so isolated from the rest of the country. So imagine all of these different legal statuses fragmenting your everyday identity, and creating different challenges and obstacles for you to deal with, for each group to deal with. It’s amazing and impressive that despite these colonial barriers, the real cement ones and the barriers in the mind, despite all of these barriers, the Palestinian people have maintained their national identity for 70 years. That is incredibly impressive. And it also sends a message that as long as we have a boot on our neck, we are going to continue fighting. Violence, cracking down on refugee camps, bombarding refugee camps is only going to bring about more violence.
West Bank
Lex Fridman

(00:55:12)
So West Bank is a large region where a lot of Palestinian people live, and then there are settlements sprinkled throughout, and those settlements have walls around them with security cameras.
Mohammed el-Kurd

(00:55:23)
And security guards.
Lex Fridman

(00:55:24)
Security guards.
Mohammed el-Kurd

(00:55:25)
There’s almost a million settlers in the West Bank.
Lex Fridman

(00:55:28)
And so what are the different cities here, if you can mention?
Mohammed el-Kurd

(00:55:31)
In the West Bank?
Lex Fridman

(00:55:31)
In the West Bank. Ramallah, Jenin, Bethlehem, Hebron, Jericho, Nablus.
Mohammed el-Kurd

(00:55:37)
Yeah, [inaudible 00:55:38].
Lex Fridman

(00:55:38)
They have their own stories, they have their own histories.
Mohammed el-Kurd

(00:55:41)
Yeah. And it’s fascinating also how interconnected they are. Like a friend of mine, Momahari, he recently did a documentary report on the day that Haifa fell during the Zionist invasion, the Hagana led the Palestinian residences of Haifa down to the city center. And as absurd as it sounds, those of them who stood on the right side of the street were forced into cars that took them to multiple stops that would later become multiple refugee camps, the last of which was Jenin refugee camp. And those who stood on the left side of the street were forced to board boats that took them to Lebanon to become refugees there. Last month we saw the Israeli army in invade Jenin in maybe the largest military invasion of Jenin since 2002, and they killed many people. They attacked medics and journalists in broad daylight on camera. They have destroyed infrastructure, and it was all very painful. But I think the most compelling aspect of the raid on Jenin was what followed. Israeli soldiers that night, held their megaphones and instructed hundreds of Palestinians to flee their homes. And they told them, if you don’t leave, if you don’t have your hand up in the air, you will get shot. And they were forced to leave their homes in the camp and walk to God knows where.

(00:57:18)
I can guarantee you, because the Nakba is not that old, I can guarantee you that some people who were marching away from their camps were chased away from their homes in the camp in Jenin were some of the same people who were chased away from the homes in Haifa in the first place. This perpetual exile that Palestinian people continue to live is unbearable. In my case, my grandmother was removed from her home in Haifa in ’48, and then she moved from city to city. And then in 2009, she saw half of her home taken over by Israeli soldiers. My grandmother died in 2020, and two months later, we got the next expulsion order from the Israeli court. I’m quite ashamed to admit that I was relieved that my grandmother had died, because I did not want her, 103 years old at the time, to go through yet another Nakba. And this is the fact for so many Palestinians, regardless of where they are on the map.
Lex Fridman

(00:58:21)
If I may read the description of the situation in Jenin, and maybe you can comment. So this is on July 3rd, 4th and 5th, just reading the Washington Post’s description. So this was an Israeli military incursion to Jenin, the raid included more than 1000 soldiers backed by drone strikes, making it Israel’s largest such operation in the West Bank since the end of the second Palestinian uprising in 2005. The Israeli military said it dismantled hundreds of explosives, cleared hundreds of weapons, destroyed underground hideouts, and confiscated hundreds of thousands of dollars in quote, terror funds. Many of the 50 Palestinians who have attacked Israelis since the start of the year have come from Jenin camp and the surrounding area. Palestinian attacks inside Israel have killed 24 people this year. UN experts describe the Jenin operation as “collective punishment”, in quotes, for the Palestinian people amounting to egregious violations of international law. Many of the more than 150 Palestinians killed by Israelis this year have also come from these communities. Palestinian fighters say they need arms to defend themselves against the Israeli occupation and military incursions into the camp during which Palestinian civilians including children have been killed. So those are the, I would say, different perspectives on the many people on both sides who have been killed, many more Palestinians. Can you comment more about the situation?
Mohammed el-Kurd

(00:59:58)
I think the Washington Post article is a little bit more careful than other media that came out recently about Jenin. I was listening to our Reuters radio show and they failed to ever mention the occupation. I don’t even think this paragraph mentioned that Jenin is under occupation by the Israeli forces, by the Israeli regime. I think this is the most important piece of context that gets obscured in our media reporting, is these cities, these refugee camps are under illegal occupation. The Israeli army has no business being there in the first place. That is the departure point, that is the most important piece of context that will answer to you why these people are arming themselves. Many of which, by the way, lived through the 2002 massacre and bombardment of Jenin, and grew up in that violence.

(01:00:57)
The context that Palestine is under occupation, that these Palestinian cities are under occupation, that they have to deal with land seizures at all times, that they cannot leave their towns without a special permit, all of this will give context to the violence. And the thousands of Israeli soldiers that raid the camp that day, that traumatized an entire generation. They think they will quell that generation. They think that with such bloodshed and such barbaric violence, destroying infrastructure, attacking medics, killing people left and right, and they think with this kind of terror that they can quell people, tell people that they can guarantee that these kids are not going to grow up and resist. But that’s the opposite of what happens. One thing about Palestinian people, they will not compromise their dignity. These people live in dire, excruciating circumstances and it is so courageous, in my opinion, that they even think to defend themselves against one of the most lethal, one of the most sophisticated armies in the world, against a nuclear state that can wipe them out in the matter of seconds. But at the end of the day, it’s not even about courage, it’s about survival. They don’t do this because of machismo or because of heroic tendencies, it’s because this is about survival.
Lex Fridman

(01:02:37)
So the degree there’s violence, it’s about survival?
Mohammed el-Kurd

(01:02:41)
Absolutely. I think if there was no occupation, there would be no violence. It’s quite obvious. And again, people understand this. We saw on Twitter in the recent month, all of these Israeli propagandists who had tweeted pictures of little girls with guns in Ukraine and women making bombs in Ukraine, and young men carrying their rifles in Ukraine, and praising them as heroes, post very similar pictures of Palestinians and calling them terrorists. It’s glaring the double standard, I don’t even need to linger on it.
Lex Fridman

(01:03:17)
Well, the double standard is glaring, but I also think the glorification of violence is questionable. There’s a balance to be struck, of course, but…
Mohammed el-Kurd

(01:03:29)
Yeah, I don’t think we should be glorifying violence at all, but I don’t think we should be normalizing violence either. I think that’s what it is. I’ll tell you a story. I was interviewing a person whose brother was killed by the Israeli military during an Israeli raid on their village, and the person was so concerned about whether I was going to report that her brother allegedly had a Molotov cocktail in his hand. And I found it absolutely insane, absolutely absurd that we can just glance over the fact that there is, again, a foreign military in tanks with rifles and snipers invading the village at 4:00 AM in the morning, shooting live ammunition at people’s houses, throwing tear gas, that we can just glance over. It’s normal, we could just report on it, no problem, nobody’s going to bat an eyebrow. But the fact that potentially somebody might have picked up a Molotov cocktail to throw it at this invading army is where we draw the line. It says a lot. It says a lot about whose violence is normalized, is accepted, is institutionalized, is glorified even. You walk around Tel Aviv and you see all of the plaques plastered around the streets of the country, of the city, celebrating the battles that they had won, the massacres that they had enacted against the Palestinian people, but God forbid Palestinians have any kind of similar sentiment.
Hamas
Lex Fridman

(01:05:20)
So on July 4th during this intense period, a Palestinian rammed a car into pedestrians at a bus stop in Tel Aviv, injuring eight people before being shot dead by a passerby. Also, that night, Hamas fired rockets into Israel, and then Israel responded with strikes on what it said was an underground weapon site. So just to give some context to the intense violence happening here, what do you think about Hamas firing rockets into Israel?
Mohammed el-Kurd

(01:05:52)
Well, the framing makes it seem as though unprovoked Hamas is firing rockets unto Israel, regards to what I think of Hamas, obviously, but unprovoked. But that’s not the case. The propagation is the fact that they are forced to live in a cage, that they have no access to clean water. They have no access to basic rights, no access to imports, no access to anything, that they can’t leave, they’re living in a densely populated enclave that was deemed uninhabitable by the UN, that was deemed an open air prison. So the rockets, in any case, are retaliation for the siege. Let’s start there. But again, this is just to prove my point, violence begets violence. Palestinian people are not violent people. We are not violent people at the core.

(01:06:45)
And I think what serves this narrative is Islamophobia, is xenophobia towards Arabs, which I don’t have the luxury to write laws about. By the way, I’m quite frustrated by this. I am preoccupied and the Palestinian people are preoccupied with the material violence that we have to deal with on the day-to-day, the demolitions, the bombings, the imprisonment. That’s what we’re distracted with and busy with that we can’t even talk about the racism, the casual racism, against this anti-Palestinian racism, be it in the media, on social media and diplomatic circles. But all of this racism that has gone unchecked, has not been regulated for decades, allows for these tropes to continue in which Palestinians are promoted as these like barbaric terrorists and the only way we could remedy that situation is by marketing them as these defenseless victims. But the fact of the matter is, it’s not this simplistic. Palestinian people are human beings who should enjoy a full spectrum of humanity, which includes rage, which include…
Mohammed el-Kurd

(01:08:00)
… Vanity, which includes rage, which includes disdain, which includes happiness and joy and laughter, which includes celebration, which includes all of these things, but we’re not allowed this. But we are doing exactly what any people throughout history who have been oppressed, who have been colonized, who have been occupied, have done and continue to do as we see in Ukraine, which is celebrated by mainstream media.

(01:08:25)
I’m sorry to keep reiterating this point, but at this point, I am quite exhausted by how exceptional Palestine and Palestinian resistance is when the world tells me time and time again that it doesn’t have a problem with violence, it just has a problem with who does that violence.
Lex Fridman

(01:08:53)
Do you, in your mind and in the way you see this region, draw distinction between the people in power versus the regular people? So, you mentioned the Palestinian people, is there something you can comment on, on Hamas and the PLO? Do you see them as fundamentally different from the people? What does Hamas do well, where do they fall short?
Mohammed el-Kurd

(01:09:19)
I think governments, wherever globally, are different from people. No government is a true reflection of its people. I think this is even true in the case of Arab countries that normalize with Israel. In many of the cases they are unelected governments. I think the Palestinian authority continues to fail. I think there are subcontractors of the Israeli regime through their security coordination. And also, I’d like to use this as an opportunity to comment a little bit on the analogy thing.

(01:09:57)
Not to stray away from the question, but the Palestinian Authority two years ago killed an opposition activist named Nizar Banat. It was a horrendous crime, and I was in Ramallah with the people protesting against the Palestinian Authority. And at some point they had their batons, the Palestinian Authority Police, and they beat us with it. And many of the people in the crowd were liking the Palestinian Authority to Zionism. I think people, this is what people do, when they are confronted by a great evil, they liken it to some other great evil, and this is where the Hitler analogy came from. Again, I don’t think it’s the best strategy moving forward, but I refuse to be criminalized for a little sentence.
Lex Fridman

(01:10:52)
So, to linger on those in power. One of the criticisms towards Hamas and PLO, towards the Israeli Government, at least the current coalition government, is that there’s a lot of incentive to sort of perpetuate violence to maintain power. There’s a hunger for power and maintaining that power amongst the powerful. That’s the way power works. So, is there a worry you have about those in power not having the best interest of its people? So, those in power, the PLO, Hamas, not being incentivized towards peace, towards justice.
Mohammed el-Kurd

(01:11:40)
Looking at the PA’s action today, it tells you a great deal about what they’re interested in and what they’re not interested in. And maybe, yeah, the occupation is in their best interest. And you can infer similar things looking at Hamas, but these two entities virtually have no power, even Hamas.

(01:12:08)
The context that Hamas is permitted by international law to use armed resistance, blah, blah, blah, does that mean Hamas is equipped to govern Gaza? I don’t think so. Does that mean that people around Palestine necessarily want to live under Hamas rule? In 2006, Hamas was democratically elected. I don’t know if that’s still the case today. There’s a lot to be said, but neither of these entities have any real power in perpetuating… The only body that can flip the switch in all of this equation is the Israelis.

(01:12:56)
They’re the ones who are keeping people in a cage. They’re the ones who are wrapping the West Bank with a wall. Everything else to me is just secondary, regardless of what I think personally of any of those people. Personally, for me, the world I envision, not just Palestine, the world I envision is a world that goes beyond states, that goes beyond this framing of power, this hierarchy in which some people rule over other people. This whole idea of nation states, be it Israel or any other nation state, it’s futile, it’s not good, it’s exclusive. I think that we can achieve a better world than that.
Lex Fridman

(01:13:38)
Well, how do you do a better world? Actually, if you just linger on that, politically speaking, geopolitically, you have to have representation of the people, you have to have laws, and you have to have leaders and governing bodies that enact those laws and all those kinds of things. You probably need to have militaries to protect the people.
Mohammed el-Kurd

(01:14:05)
Can you not imagine a world without militaries?
Lex Fridman

(01:14:07)
I can imagine it, but we’re not in that world.
Mohammed el-Kurd

(01:14:10)
Yeah, I’m not saying I have all the answers or a PowerPoint in my pocket with the instructions, but I’m saying the world I’d like to live in is one that transcends borders, is one that does not necessitate militaries, that doesn’t necessitate all of these prisons, all of these walls, all of these racist laws.
Lex Fridman

(01:14:35)
So, you don’t think violence is a fundamental part of human nature that emerges combined with the hunger for power?
Mohammed el-Kurd

(01:14:45)
I do think that both of these things are truly intrinsic to human beings, but I also do think there is a way to move beyond them. I’m not saying I have the answers. I’m tempted to say sway, but…
Lex Fridman

(01:15:01)
You have a hope that there doesn’t have to be war.
Mohammed el-Kurd

(01:15:05)
Yeah, yeah.
Lex Fridman

(01:15:05)
In the world.
Mohammed el-Kurd

(01:15:06)
Definitely, definitely.
Two-state solution
Lex Fridman

(01:15:08)
Well, if we look a little bit more short term, people speak about a one state solution, a two state solution, what is your hope here for this part of the world?

(01:15:20)
Do you see a possible future with a two state solution, whether it’s for Palestine and Israel? Do you see a one state solution where there is a diversity of different peoples like in the United States and they have equal rights in the courts and everywhere else?
Mohammed el-Kurd

(01:15:39)
I don’t think there’s a geography in which a two state solution is possible. As we said earlier, Swiss cheese, there’s literally settlements all over the West Bank, and I don’t think it’s fair, a two state solution is fair to all of the people whose homes are still in Haifa, in Nazareth, in Jaffa, and so far, and I don’t think it’s fair that I’m going to have to travel to another country to visit my cousin who’s married in Nazareth, for example.

(01:16:14)
And beyond that, it’s just not possible. I do believe that whatever you want to call it, one state, two state, 48 states, 29 states, whatever you want to call it, refugees need to return, land needs to be given back, wealth needs to be redistributed, and a recognition of the Nakba needs to happen. That is the only way we could move forward.

(01:16:41)
And regarding whether this is a possible situation for two people to live side by side, let’s ask two questions. Let’s say you lived in a house with a person, your roommate, you just had a roommate who constantly beat the shit out of you, I wonder if you’d want to continue to live with them? That’s one. And let’s try another scenario. Let’s say you live in a house with a roommate who you just absolutely hate, just absolutely oppose their existence as a people, you don’t even give him a key to your apartment. Let’s say now you’re equal partners in the apartment, would you want to live with him? I don’t know. We’ll see. We’ll see, time will tell, but I don’t think they want to live with us.

(01:17:36)
Israelis are quite good, especially Israeli diplomats, they’re quite good at using flowery language about peace and coexistence and so on and so forth, and they’re good with making us seem insane or radical or full of hate and so on and so forth, but the policies speak for themselves. The actions on the ground speak for themselves, and every time there’s an uptick, many of them leave, and I wonder, I would like to see, I wonder what would happen in a own state solution.
Lex Fridman

(01:18:13)
Well, okay, so you’ve spoken eloquently about the injustice of the evictions, the demolitions, the settlements, but can you comment about the difficulty of the security from an Israel perspective when there is a large number of people that want to destroy it? How does Israel exist peacefully, this one state solution?
Mohammed el-Kurd

(01:18:41)
I don’t know, by not shooting a journalist doing her job in the Jenin refugee camp.
Lex Fridman

(01:18:46)
But that doesn’t…
Mohammed el-Kurd

(01:18:47)
By not killing a 14-year-old standing in his front yard? This whole talk about security and security fence and the whole propaganda of the Israeli defense forces and this whole iron wall ideology in which somehow they’re always defending themselves, even though they’re… Netanyahu and the Israeli Government continue to talk about an existential threat, about Iran being an existential threat, even though the Israeli Government is the only body that holds nuclear weapons in the region. They’re the most sophisticated army in the region, and yet they continue hiding behind their fingers and talking about an existential threat and talking about how they’re insecure and so on and so forth.

(01:19:34)
I came here on the bus. I live in a house where everybody in the world can easily Google it and get its address, and anybody can just walk into my house. And I’m lucky and privileged as a Palestinian journalist. There are many Palestinian journalists who lose their lives. That’s real insecurity, but we don’t even have time to whine about it because there’s real shit going on the ground that we’re preoccupied with and reporting on all the time, that we don’t even have the time to talk about how limited is our institutional backing, how limited is our cyber security, how limited is even healthcare. All of these things we don’t even have time to complain about, but they’re the real life things that formulate an insecure population that Israel certainly does not suffer from.
Lex Fridman

(01:20:36)
There’s a tension here. It’s true that the ideas of existential threats to a nation have been used to expand the military industrial complex and to limit the rights of its people. So, in the United States, after 9/11, Iraq and Afghanistan were invaded under some justification of there being terror in the world, these big ideas. And in the same way, yes, Israel, with the existential threat of Iran has used to expand its military might over the region and control over the region, but it also has some truth to it in terms of the threat that Israel is facing, including from Iran. If Iran were to get a nuclear weapon, do you think there’s a threat from that?
Mohammed el-Kurd

(01:21:24)
But who has the nukes?
Lex Fridman

(01:21:27)
Right now.
Mohammed el-Kurd

(01:21:28)
Yeah, but we’re talking about this far away monster that we’re scared of, it’s like fear-mongering. What do you mean, who has the nukes?
Lex Fridman

(01:21:37)
Some of it is fear-mongering, but some of it is true.
Mohammed el-Kurd

(01:21:42)
I don’t think it’s true. I don’t think it’s true. I think Israelis are obsessed with genocide because they have enacted genocide against us. Even when we talk about a future, a liberation of Palestine, when we’re talking about anything, they constantly jump to saying things like, “They want to throw us into the sea. They want to kill all Jews.” What kind of hyperbolic bullshit is that? To say that if I am chanting and marching for my home not to be taken away from me by some kind of settler court, I am somehow demanding the murder of all Jews across the world? That is hyperbolic, and the fact that we coddle it is insane to me.

(01:22:23)
So no, I don’t think as things stand right now, as the power of balance stands right now, I don’t think there’s an existential threat to Israel. And also, let’s redefine existential threat. Do we think the Israeli regime, the Zionist regime should continue to exist in its forms, subjugating people, enacting the crime of Apartheid according to a bajillion human rights organizations? Do we think that it should continue keeping people in a cage? If that’s what people are fighting to save, then that says a lot about the people who are feeling this existential threat, not me.
Lex Fridman

(01:23:00)
Do your beliefs represent the Palestinian people, meaning, how many people are there that want Israel to be gone?
Mohammed el-Kurd

(01:23:10)
Well, what does it mean for Israel to be gone?
Lex Fridman

(01:23:12)
What it means is for people who think of Israel as an occupier, who stole land that needs to go away, that this should be all Palestine.
Mohammed el-Kurd

(01:23:22)
Yeah, but is that a bad thing for the occupation to end, for the land to be given back? Is that a bad thing?
Lex Fridman

(01:23:30)
Well, there’s different definitions of occupation. There’s people in their homes now, right?
Mohammed el-Kurd

(01:23:36)
But is it their home? I’m not talking about some random home, but there are many, many, many, many, many, many, many, many, many, many Israelis who drink their coffee every morning from living rooms that are not theirs.
Lex Fridman

(01:23:56)
That are not theirs, that were taken just a few decades ago?
Mohammed el-Kurd

(01:24:03)
Where the rightful owners of these homes are still lingering in refugee camps, are still dreaming of return.
Lex Fridman

(01:24:12)
There are homes on the land of Israel that you wouldn’t classify as stolen.
Mohammed el-Kurd

(01:24:18)
I mean, if it was built, but is the land stolen? But all of this, again, I try not to fall into this because it feels so abstract and far away, and this is not how liberation is going to look like whatsoever. And I’m not fixated on ethnic cleansing, I’m not obsessed with ethnic cleansing. I’m obsessed with ending the ethnic cleansing campaign that has been visited upon me and my family and my community for seven plus decades. That’s what I’m obsessed with.

(01:24:57)
All of this other stuff about what happens to the settlers, and we want to kill all Jews and all of this, I think it’s bullshit, and I think it’s ridiculous, and I think fixating on it is distracting from the focal point. There needs to be an end to all of the injustices, to all of the atrocities. A little boy from Jerusalem should be able to go jog around the city without fearing getting shot. That’s the simplest thing we’re asking for here, and we want our land back, and those things do not mean actually at all the ethnic cleansing of another people.
Lex Fridman

(01:25:36)
Well, we should be precise here. So, a little boy being able to run around Jerusalem, that’s a great vision, not just safely, but without racism, without hate. That’s a beautiful vision, yes, but people in West Jerusalem, people in Tel Aviv that have homes, should they stay there? Do they have the right to stay there?
Mohammed el-Kurd

(01:26:02)
That’s maybe number 99 on my priorities list. I’m concerned with the refugees, I’m concerned with the teenagers in the prisons. I am concerned with my house. I’m concerned with my family’s house in Haifa. There is a lot for me to do before I can even tend to the needs of my occupier, that is the least of my concerns.
Lex Fridman

(01:26:28)
So you want the low hanging fruit, the obvious injustices to end?
Mohammed el-Kurd

(01:26:32)
Yeah.
Lex Fridman

(01:26:34)
But still the long term vision of existential survival of Israel, which is the concern of its government, is the concern of its people, do you see a future where Israelis have a home in the region?
Mohammed el-Kurd

(01:26:50)
Sure, just not in my front yard.
Lex Fridman

(01:26:54)
Where’s the front yard and where is the backyard?
Mohammed el-Kurd

(01:26:57)
There are literally Jewish settlers, one of which from Long Island, in my literal front yard. And this is the case in hundreds if not thousands of Palestinian homes. No one is saying Jewish people shouldn’t exist or they shouldn’t have a state of their own. I mean, I think all religious based states are a bad idea, all nation states are a bad idea, but whatever, if that’s what they want do, that’s what they want to do.

(01:27:26)
But that doesn’t mean that they are allowed or have a right to create and implement a system of Jewish supremacy at my expense. That’s not a crazy thing to say. That is not a controversial thing to say. You can have your state, just don’t kill anyone. Thank you, have a good day. That’s not a crazy thought to have.
Lex Fridman

(01:27:50)
And seek and establish a symmetry of power in the courts, which is the current source of injustice.
Mohammed el-Kurd

(01:27:56)
I mean, that’s when it comes to forced expulsions in our home, but there’s myriad of other ways.
Lex Fridman

(01:28:03)
To the military?
Mohammed el-Kurd

(01:28:04)
The military, I mean, the police. If you look at how many times, I should have brought the data with me, but if you look at how little times the Israeli Military or police has investigated its own people or indicted its own people. I mean, just recently, the killer, who has been hailed a hero by some of Israeli society who killed Eyad al-Halaq, a Palestinian man who is autistic, who lives inside the occupied old city, where again, Israeli Military has no business being there or jurisdiction whatsoever.

(01:28:39)
He was shot and killed by an Israeli soldier who was trigger-happy because, again, they have this siege mentality where any moving object is going to kill them. And he was shot and killed and despite it being in broad daylight, despite it being well-documented, despite the victim being disabled, despite all of this, he was acquitted by the Israeli court. The military, the courts, the government, they all work together, which is why it’s so ironic to me that there are hundreds of thousands of people marching on the streets of Tel Aviv trying to save the progressive beacon that is the Israeli Supreme Court when you find its fingerprints all over the injustices perpetuated against Palestinians, be it legalizing and upholding the withholding of slain Palestinian bodies who were killed by the Israeli Military to be used as bargaining chips with Israeli militaries.

(01:29:35)
Be it making decisions to dispossesses entire villages like [inaudible 01:29:42], be it never once granting release to any Palestinian who was held in administrative detention without charge or trial. Be it upholding the legality of the Family Reunification Law that does not allow Palestinian couples who hold different legal statuses of reuniting and living together as families. I mean, those are just some of the few things I can think of about the Israeli Supreme Court.

(01:30:11)
So, the real tension that exists is the lack of diversity on the Israeli political spectrum that makes the vision for a future so limited, because those on, what seems to be, the far left, are defending an extremely conservative institution that is a supreme court that they regard as progressive, when in fact it is the opposite of such. So, what do we do? How can we talk? How can we have peace with people who are chanting to save the very body that is displacing us? It’s ridiculous.
Jerusalem
Lex Fridman

(01:30:56)
What’s your vision? Let’s just take it as a microcosm of Jerusalem, what’s your vision for Jerusalem look like with a peaceful coexistence of people?
Mohammed el-Kurd

(01:31:09)
As it looked like before the Israeli State emerged. I mean, we should be reading our history here. When you read European and white historians, they’ll tell you Palestine was there, and many of them would say it was even without a people, nobody was there, or some of them will say we we’re uncivilized. But the fact of the matter is Palestine, Jerusalem particularly, had a diversity of religion, Druze, Jewish people.

(01:31:41)
My grandmother continues to talk about… Well, she continued until she died, she continued to talk about her Jewish neighbors when she grew up in the old city. Well, when she was born in the old city and then her Jewish neighbors in Haifa. We even had one Jewish member of her family, [inaudible 01:31:59] actually, who just also recently passed away there. Jews were a part of Palestine, and they spoke Hebrew, a different kind of Hebrew, but they spoke Hebrew and they were… People really need to read The Hundred Years’ War on Palestine, it’s really an excellent synopsis of the history.

(01:32:16)
But this whole idea, that this is some kind of war between two religions is so misleading, because what’s happening is a bunch of frankly European settlers with a certain political secular ideology came and relocated here and turned it into a religious conflict between people who have lived harmoniously together for decades before that.

(01:32:41)
And the whole idea, be it Christian Zionism or John Hagee, or the calls for Jews to leave the United States and relocate in Israel. Or recently, which we’ve heard about a long time ago, but recently an Israeli historian confirmed the fact that Israeli organizations were bombing Baghdad and bombing synagogues in Baghdad in Iraq to get Iraqi Jews to leave and come relocate in Israel. All of this is manufactured, and again, none of this is a conspiracy theory, I know it sounds absurd, and anytime I look at my life from a bird’s eye view, I think, “What a circus.” But it’s real and it’s verifiable, call the fact-checkers.
Lex Fridman

(01:33:31)
You mentioned the land registry, can you elaborate what’s happening there?
Mohammed el-Kurd

(01:33:34)
Yeah, yeah, absolutely. So, our small victory in the Israeli courts was that they would keep us in our homes until a land registry is completed. Basically, it means that they have to check who owned the land prior, and then they could decide if the land is ours or the land belongs to the Israeli settler organizations that are headquartered in the United States and enjoy a tax-exempt status here.

(01:34:07)
And that sounds great on the surface, but then you look at Israeli law, you look at Israeli courts, you look at ownership and you see that, oh, Israelis refuse to authenticate or take into consideration any land ownership documents prior of the establishment of the state. So all of us in Jerusalem who have their taboo papers, their ownership papers from the Ottoman era, that’s not legit in the eyes of the Israeli court, because your ownership deeds existed long before Israel even existed, so we’re not going to take this into consideration.

(01:34:43)
So, not to be cynical here, but unfortunately the likely result of the land registry is that they’re going to say, “Oh, all of this land belongs to these Jewish organizations,” because they’re not going to take any of our documents into consideration. But that means that there’s going to be another campaign and there’s going to be a long-winded fight, and we’ll see what happens. But that’s the fear, and there’s a huge dreadful fear of a massive loss in property in Jerusalem following this land registry for the reasons I just told you. It’s the mere fact that they just refuse to look at land ownership documents.
Lex Fridman

(01:35:19)
What is the process of the fighting this in the courts look like? If you can maybe just comment on it.
Mohammed el-Kurd

(01:35:26)
I always make a joke that being in an Israeli court is playing a game of broken telephone because everybody’s speaking in Hebrew, and then your lawyer says something to your dad, and your dad says something to your mom, and your mom whispers it in your ear, and then you say it to your cousin and your cousin has a completely different idea of the verdict than what the verdict is, but that’s really the reality.
Lex Fridman

(01:35:46)
So a lot of the fights happen family by family?
Mohammed el-Kurd

(01:35:48)
No, it’s groups. So, in our case, it’s four houses, every four houses, but again, it happens in a language we do not speak, and a lot of the time our strategy is buying time and building a global campaign. We know that there is no recourse in the Israeli courts. I mean, my grandmother used to say, and this is a popular proverb, “If your enemy is the judge, to whom do you complain?”
Lex Fridman

(01:36:16)
So, to the whom you complain is maybe the international community?
Mohammed el-Kurd

(01:36:22)
Yeah. I mean, in our case, it was the international community, but in our case also, it wasn’t just the international community, it was the hundreds of thousands of people in Palestine and abroad who were marching on the streets getting beaten and brutalized in Jerusalem, and I don’t know, sometimes arrested in places like Germany and so on and so forth, who forced themselves inside the media cycle.

(01:36:47)
This was what was unique about [inaudible 01:36:50]. We were able to penetrate an industry that usually ignores us and usually refuses to use any of our framing, any of our quotations, and these people that march, these people that spread the rhetoric, spread the facts, wrote articles, these people that made videos online and got arrested, and many of whom are still in Israeli prisons paying higher prices than I have ever paid, these people are the ones that truly moved the international community into action.

(01:37:18)
It wouldn’t have, the United States, I don’t think would said anything had it not been for the immense media pressure that was created from the immense popular pressure. There are a lot of moving parts to a global campaign, and I think it’s so impressive that we were able to do this without any media backing, without any institutional backing, without any training, without any budget, nothing.
Role of the US
Lex Fridman

(01:37:41)
You mentioned the United States. What’s the role of the United States in the struggle that you’ve been describing? What’s the positive, what’s the negative?
Mohammed el-Kurd

(01:37:51)
The role is perpetuating what’s happening. It’s all a negative role, to be honest.
Lex Fridman

(01:37:58)
With the money, with power?
Mohammed el-Kurd

(01:37:59)
Yeah, it’s like the 3.8 billion in military aid every year, it’s the standing ovation.
Lex Fridman

(01:38:08)
Israel is the largest recipient of US foreign aids since World War II. To date the United States has provided Israel $158 billion, as you said, is providing currently 3.8 billion every year, that a lot of people raise the question of what’s the interest of tax paying American citizens in this kind of…
Mohammed el-Kurd

(01:38:29)
Yeah, zero interest.
Lex Fridman

(01:38:31)
Foreign aid.
Mohammed el-Kurd

(01:38:33)
Zero interest. I think a lot of Americans are concerned with healthcare, a lot of Americans are concerned with clean water and flint. I don’t think they’re concerned with funding Apartheid in another country. And I think it’s a disturbing phenomenon that although public opinion in the United States is shifting, I would argue drastically, about Palestine, people in Washington are yet to catch up.

(01:38:59)
It was only, I think, nine Congress people who boycotted Herzog’s speech in Congress yesterday, and he received standing ovation after standing ovation, after standing ovation, after standing ovation. And I wonder if the everyday American is concerned that many of their politicians are Israel first politicians, are politicians who care more about maintaining a relationship with the Israeli regime, than they care about their own districts.
Ghassan Kanafani
Lex Fridman

(01:39:31)
You’ve tweeted that 49 years ago, Ghassan Kanafani… Well, you can maybe correct me on the pronunciation, was assassinated. You wrote, “His revolutionary articulations of the Palestinian plight for liberation shook the colonial regime, yet he’s not dead, his ideas remain ever timely and teachable.”

(01:39:54)
And you also tweeted an excerpt from his writing. “Between 1936 and 1939, the Palestinian Revolutionary Movement suffered a severe setback at the hands of three separate enemies that were to constitute together the principle threat to the nationalist movement in Palestine in all subsequent stages of its struggle. One, the local reactionary leadership, two, the regimes in the Arab states surrounding Palestine, and three, the imperialist-Zionist enemy.” Can you analyze what he means by those three things? The local reactionary leadership, the regimes in the Arab states surrounding Palestine and the imperialist-Zionist enemy? And also, could you comment on him as a person?
Mohammed el-Kurd

(01:40:37)
Yeah, I mean, Ghassan Kanafani is a brilliant, brilliant, brilliant writer, and he was prolific. He’s authored so much books, even though he was assassinated in the 70s, but he was 37, if I’m not mistaken, 35 when he was assassinated. He was inspiration to me in school, and I remember even my teachers had qualms about him because he was a secular person. But I love Ghassan Kanafani. He is a beloved figure in the Palestinian community, and I hope to one day be able to achieve a fraction of what he’s achieved in the terms of shaping a political consciousness for Palestinians and for people in the region.
Lex Fridman

(01:41:21)
Did he classify himself as a politician, as a philosopher, as an activist, do you know?
Mohammed el-Kurd

(01:41:27)
He was a writer, but he was also part of the Palestine Liberation Front, PFLP.
Lex Fridman

(01:41:33)
So he used the words to fight for freedom.
Mohammed el-Kurd

(01:41:39)
Yeah, I don’t think he would’ve thought his words were divorced from other forms of struggle, but I think he recognized the importance of culture and shaping culture and shaping public opinion, both in achieving a shift in global stance, and also in achieving-
Mohammed el-Kurd

(01:42:00)
… global stance and also in achieving an awakening in the Palestinian generation as well. There’s a very famous interview of his where he’s talking to, I believe, a British journalist, and the British journalist is asking him, “Why don’t you have talks with the Israelis?” And he says, “What do you mean talks? You mean capitulation? You can’t have a conversation between the sword and the neck?” And I think that really summarizes the values he stood for. Now, to talk about the three things.
Lex Fridman

(01:42:37)
Local reactionary leadership, regimes in the Arab states surrounding Palestine, and the imperialist Zionist enemy.
Mohammed el-Kurd

(01:42:44)
In today’s terms, the local reactionary leadership is the Palestinian Authority. The regional regimes, we’re talking about, actually, the normalization deals that have emerged in recent years, the Abrahamic Accords, have been talked about as though they’re groundbreaking, new phenomenon. But many Arab countries have normalized relations with the Israeli regime since the birth of the state. It’s not a new thing. But, yes, I think he was talking about Egypt and Jordan at the time. Today, we can include United Arab Emirates. We could include Bahrain. We could include Morocco. And, again, these Abrahamic Accords, they are promoted and marketed and talked about as some kind of religious reconciliation, which I think is the most disgusting thing ever, because they’re not about religious reconciliation. They’re about arms deals and economic deals and they’re about consolidating power in the region.

(01:43:57)
They’re about mutual strategic interests that all of these nations have together, and some people argue that Palestine is no longer an Arab cause because Arab countries are normalizing. But most of these governments, if not all, actually, all these governments that have normalized, most of them are monarchies, are not elected governments, and they do not represent the will of the people or the desires or the opinions of their peoples. And the proof to this is places like Jordan and Egypt. Even though they’ve normalized and had peace agreements with Israel for many, many, many, many years, Palestine and the Palestinian cause was still a talking point in the political campaigning of politicians, Jordanian and Egyptian politicians, and continues to be for them to gain popularity because that’s where the hearts of the people are. And then the Zionist regime is quite explanatory, the imperial Zionist regime. I mean, what else do you call a regime that sought help from imperialist powers to depopulate an entire country and build a new one on top of it.
Lex Fridman

(01:45:09)
So, mostly, you’re saying the thing that the Abraham Accords achieved is a negative thing for Palestine? So these kinds of agreements between the leadership is not positive for the region?
Mohammed el-Kurd

(01:45:30)
No. No. Obviously, they’re going to be marketed as positive, and, obviously, they’re going to have this flowery language surrounding them. And the idiots in the room might like nod and smile, but anybody with critical thinking skills can know that if a people continue to be under occupation, there’s nothing positive there. And, also, let’s linger a little bit on the mutual interests. The only way Morocco could normalize relations with the Israeli regime is so that the Israeli regime could recognize Moroccan sovereignty over in the Western Sahara, which just happened actually last week. And before that, Morocco recognized Israeli sovereignty over the West Bank. It’s not like Morocco itself has no interest in this kind of deal.
Lex Fridman

(01:46:24)
You mentioned that you hope of accomplishing some of the things that [inaudible 01:46:31] was able to accomplish. Let me ask you a silly question, perhaps a silly question, do you have interest in running for political office, I hear laughter in the room, to lead in a leadership position in Palestine.
Mohammed el-Kurd

(01:46:54)
Not currently. No. Not at all.
Lex Fridman

(01:46:57)
Let’s see if this ages well.
Mohammed el-Kurd

(01:47:00)
I don’t think there’s a body through which I can run for anything. It’s completely dysfunctional, and also I don’t want to wear a suit all the time.
Lex Fridman

(01:47:15)
Who would want to do that? So from which pedestal or from which stage do you think you can be most effective?
Mohammed el-Kurd

(01:47:26)
I was born and raised in Jerusalem. I speak perfect Arabic. I think my Arabic writing is much superior to my English writing, but I choose to write in English because I think there’s a disparity and there’s a chasm between what is said in Arabic in the street in Palestine and what is said here about Palestinians, both by anti-Palestinian racists and people who are pro-Palestine and advocates for Palestine. And I believe I and a few others from my generation, or many others actually from my generation, are working to fill that chasm. And I also believe that literature, culture, the public sphere, changing the public opinion, changing the narrative is important to affecting policy, to affecting change, affecting material change. I’m not going to go read a poem in front of a checkpoint and watch it catch in flames.

(01:48:24)
I’m not that delusional about the power of words, but I do think that I have a responsibility and I have a privilege even to have a voice, to have some kind of platform, and if I’m not defining myself, if I’m not talking and representing myself, then other people will define me. And their definitions of the Palestinian people across the few past decades have not been kind or generous to the Palestinian people. That’s one thing. The other thing is I believe in the United States as a front for change. I believe we have a lot more leverage here than we do back home. Again, I believe, and someone said the other day, I can’t remember their name, but someone said “no stone unturned”, I believe in fighting on all fronts. But here, really, I can go protest in front of the Israeli Embassy without getting shot. There’s a lot of work to be done here. There’s a lot of people waking up.

(01:49:27)
I would even argue that a reckoning is coming in the American public. More and more American people are concerned where their tax money is going or concerned what their politicians are invested in. More and more American people are saying, “Not on our dime,” are saying, “Not today. Not here.” Also, there’s many Palestinians in the diaspora here in the United States and Europe who benefit and could benefit from political education in the English language, because the diaspora across history, the Palestinians diaspora, has been effective in the ’70s and the ’80s and, ever since 2021, there has been a resurgence of the power and influence of the Palestinian diaspora.
2024 Elections
Lex Fridman

(01:50:17)
To ask another silly question, since you mentioned the United States, I don’t know if you follow the politics in the United States, but do you have a preference of Presidential candidates in the 2024 election?
Mohammed el-Kurd

(01:50:33)
I do follow.
Lex Fridman

(01:50:35)
Do you follow where each candidate stands on the different policies?
Mohammed el-Kurd

(01:50:39)
I do. I think everybody in the world should be able to vote for American elections, actually. I do follow.
Lex Fridman

(01:50:44)
Because of the influence they have?
Mohammed el-Kurd

(01:50:45)
Yes. Yes. I don’t have a preference whatsoever. I saw Cornel West on CNN. I don’t know if he’s going to go far with his campaign. Cornel West is running with the Green Party and I don’t think he’s going to achieve much success. But I saw him on CNN berating Anderson Cooper and I enjoyed that very much. Wouldn’t mind seeing that on my screen.
Lex Fridman

(01:51:15)
Regularly.
Mohammed el-Kurd

(01:51:15)
Regularly.
Lex Fridman

(01:51:16)
Okay.
Mohammed el-Kurd

(01:51:16)
But don’t really have an opinion about.
Poetry
Lex Fridman

(01:51:21)
You wrote Rifqa, a book of poetry. How did that come about? Maybe you can tell the story of that book coming to be.
Mohammed el-Kurd

(01:51:32)
I signed the book when I had a lot less visibility in the world. When I didn’t think thousands and thousands and thousands of people would be reading it, I decided to include many poems, which I wrote when I was young. Because it’s a long journey, this book. It’s starts in Jerusalem, it goes to Atlanta, it goes back to Jerusalem, and then it ends in New York. Rifqa is the name of my grandmother and it’s an Arabic name, a Hebrew name, and it means to accompany someone. I wanted to write about displacement in a way that was beyond what we read about in English. Poetry as a medium, I don’t know if I have much faith in it anymore, to be honest. Maybe I’m turned off by it and I’ll revisit it again in a few years, but at the time of writing this book, poetry as a medium, it really was a source of hope and inspiration for me.

(01:52:34)
My mother was a poet and her and my dad would play this game in the morning. She would read her poems to him and he would guess which lines would be red penciled by the Israeli military censor, because she would submit her poems to the local newspaper, the Kutz Newspaper, and the military censor has to go over it. She would get her poems back with a bunch of words erased and they would laugh about it and blah, blah, blah. So poetry was very much part of my upbringing and, as a Palestinian, when you’re excluded from mainstream spaces, including media and journalism, poetry tends to be a place where you can say what you want to say without repercussions. And I say that I realize that our greatest writer, [inaudible 01:53:22], literally had his car bombed, exploded because of his writings. And recently, [inaudible 01:53:29], a poet, a Palestinian poet with an Israeli citizenship, was imprisoned for a few months for publishing a poem on Facebook in which he said, “Resist, my people. Resist.” So even that is not necessarily true.

(01:53:41)
But, anyway, it just felt like it’s a place where I could talk and express large ideas in a simplistic way. And the best example I could give you is one of my favorite poets, [inaudible 01:53:54], when the Israeli authorities decided to do the land law, which classified, I believe, 93% of historic Palestine as state owned, and then when they also did the absentee property law, which allows the Israeli government to take over homes that were depopulated from the Palestinian owners, he wrote a poem called God As A Refugee. It’s a sarcastic, sardonic poem in which he goes, “God has become a refugee, sir, so confiscate even the carpet of the mosque and sell the church because it’s his property, and sell our orphans because their father is absent. And do whatever you want.”

(01:54:46)
It’s a sarcastic poem that was in reaction to these laws, that translated to the everyday Palestinian, to the farmers, to the landowners, what these bureaucratic, complicated laws meant to them, what they meant to their land, and, what effect are these laws going to have on these people’s lands? And that, I think, is the role of poetry that I try to achieve.
Lex Fridman

(01:55:12)
So poetry ultimately prizes the power of words and so the power of the medium of poetry transfers nicely to any medium that celebrates words, I mean, just writing novels, tweeting. You’re also working on a new book, a memoir. What’s the title? What can you say about it?
Mohammed el-Kurd

(01:55:39)
My memoir is bizarre because I’m so young, so it’s not really my memoir, but it’s rather a memoir of the neighborhood in which I grew up. The title, the tentative title, is, A Million States In One, and it’s a nod to how many different realities and universes exist in this tiny one country. And it’s a documentation of the two waves of expulsion in 2009 and 2020 and 2021 and a behind the scenes of the campaign that took place, the diplomatic and media campaign and grassroots campaign that took place, to save our homes. It’s also an exploration of other communities that are threatened with expulsion and other communities who are resisting in their own way, be it in Beita, in Nablus, or South Hebron Hills, in [inaudible 01:56:33], or in Silwan, or in [inaudible 01:56:36], all these communities that are dealing with different forms of expulsion.

(01:56:40)
And the emphasis that I’m trying to achieve with this book is dignity. I want to write a book about my experiences that is super dignified, that kicks its feet up on the table, and says what it wants unabashedly. Because we are told not only are we going to be victimized, but we are going to be polite in our suffering. I want to reject that completely and I want to lean into the humor of the past few years of my life because I think that’s really what the world needs and what I need to be writing.
Lex Fridman

(01:57:18)
A few questions here, but one of them is about humor. In Rifqa, you wrote, “My mother has always said the most tragic of disasters is those that cause laughter.” What do you think she meant by that?
Mohammed el-Kurd

(01:57:33)
I don’t know. That’s my mom’s saying, but I don’t know, it’s probably a proverb that I first heard from my mom, but it’s [foreign language 01:57:40], the most evil of an atrocity is what makes you laugh. It’s open for interpretation. One school of thought would say, “You should be wary of the things that make you laugh,” but another school of thought would say, “This is a commentary on our natural reactions to tragedies.” In 2012, 2011, something like this, we had a protest, and after the protest, all of the women of the neighborhood were sitting down under the fig tree of our neighborhood, which they always do. And a bunch of soldiers, maybe 40 soldiers, started marching down the street and everybody dispersed and hid in their homes.

(01:58:28)
But my aunt, who has now passed away, my aunt refused to go home. She wanted to gather her teacups because she really cared about her teacups. I was begging her to go inside and she refused. She was gathering her teacups. A soldier grabbed me and squeezed me between his baton and an electricity pole. It was very excruciatingly painful and traumatizing for me as a child, but it’s also a funny memory, in a way. Despite the pain, despite the trauma that came with it, there’s still something funny about it.
Lex Fridman

(01:59:08)
The absurdity of it.
Mohammed el-Kurd

(01:59:09)
Yeah. It’s dignifying to find humor in these kinds of things. It makes you realize you are not so weak, you are not so powerless. Another thing is, my same aunt, who was super obsessed with cleanliness, would insist on not going to sleep before washing the dishes. And I would always tease her and say, “You’re going to give them the house clean. You can leave it dirty so they have to clean it up.” And these little things, although incredibly absurd and telling of a harrowing reality that our family and many in the neighborhood were living, are also the coping mechanisms that we were using to deal with our everyday reality.

(01:59:58)
So much in the public framing of Palestinians, be it in media, in novels, in diplomacy, and so on and so forth, is that of the powerless victim, is that of the person who only weeps. Israeli propagandists, for example, will show pictures on Twitter of a house in [inaudible 02:00:18], and they’ll be like, “Look. This house has windows. They’re talking about their BCs, but they have a nice balcony on their house. What are they talking about?” Or they’ll show a video of a supermarket in [inaudible 02:00:31] and they’ll be like, “How come they’re talking about a blockade when they have a supermarket, and blah, blah, blah”, as though the ceiling has been so lowered that we can’t even afford joy anymore or a little supermarket in the neighborhood.
Language
Lex Fridman

(02:00:46)
So as a poet, as a writer, you’ve written a book of poetry and now working on a new book. What can you say about your process of crafting words? I think people listening to this can hear that there’s a poetry to way you speak in English, so somebody that cares about the craftsmanship of words in both English and Arabic, what can you say about your process?
Mohammed el-Kurd

(02:01:12)
It’s a lot more neat than this conversation. I am obsessed with sentences and it takes me a long time to finish a piece of writing. I am a perfectionist.
Lex Fridman

(02:01:24)
Do you edit a lot?
Mohammed el-Kurd

(02:01:25)
I edit all the time and I can’t move on from one sentence until it’s perfect. But I will say, my other writer friends here in New York do not face how easily disrupted my writing is by other news. I’ll pitch a story to my editor about something, for example, and then as I’m writing it, 20 minutes in, some kid was shot and killed by the Israeli military, so I have to say something about it. And then 30 minutes later, as I’m writing it, there’s news about a home demolition in Silwan. There is this relentless onslaught of news that prevents us and deprives us of the ability to analyze, to frame, to think, to conceptualize, to write beyond the current affairs.

(02:02:15)
We’re stuck in the relentlessness of the occupation that a lot of the time I worry that the things I’m writing are always in reaction to a crime that took place, to a bombing that took place, and so on and so forth. And I think that’s, unfortunately, true for so many Palestinian writers. I would say isolation and stepping away from the news is very important to do, but I don’t do it.
Lex Fridman

(02:02:50)
Okay, so the struggle to find the timeless message in it is an ongoing struggle for you?
Mohammed el-Kurd

(02:02:58)
It’s not even timelessness. It’s timeliness. I think what you write is always timely, because the occupation is ongoing. The struggle is moving beyond the news and tackling more nuances. Because, in Arabic, I can, in Arabic, I can philosophize, I can talk about violence, and I can talk about my complicated relationship with violence. I can complicate and nuance and give things nuance, but, in English, people still do not believe we are under occupation, even though it is an internationally recognized fact that is broadcasted 24/7 through the world’s most watched screens. We’re stuck in a practice of providing facts and figure as in, “Actually, this happened and this person did this, and according to international law, and blah, blah, blah.” We’re stuck in this because the basic truths about our own existence are denied that we don’t even have the luxury of evolving our writing beyond, or at least evolving my writing beyond it. And this is what I’m trying to do with this new book.
Lex Fridman

(02:04:08)
That’s fascinating that in English your brain is more inclined to go towards activism, whereas in Arabic, you have the luxury to be more of a philosopher.
Mohammed el-Kurd

(02:04:21)
I wouldn’t say activism. I would say journalism.
Lex Fridman

(02:04:23)
Journalism.
Mohammed el-Kurd

(02:04:25)
Just making sure disrupting the flow of the sentence to insert a statistic or insert a historical fact that should be implied and should be a household name, but it’s not. I can’t just say “the Nakba”. I have to say, “The Nakba, the 1948 near total destruction of Palestinian society at the hands of Zionist militias that later formed the Israeli military that now terrorizes us today and there’s a three-tier legal system, blah, blah, blah.” I can’t just say, “Nakba”. I have to give all of these explanations, and that’s heartbreaking. And people are out to do better. People are out to do better. It’s not what my literature should be limited to. It’s not what anybody’s literature should be limited to. It’s the job of news reporters to report the news, but a lot of the time they use loaded language, they use a passive voice, they obfuscate facts, and it’s on the shoulders of us, the heavy carrying.
Lex Fridman

(02:05:37)
Would you say the President in the United States does a good or poor job of covering Israel and Palestine?
Mohammed el-Kurd

(02:05:46)
Terrible job. Horrible job. Horrendous job. They don’t do their job, whatsoever.
Lex Fridman

(02:05:51)
What are the biggest failings?
Mohammed el-Kurd

(02:05:52)
Not mentioning that a town is occupied when you’re reporting about an occupied town. Not mentioning that a settlement is illegal or a settler is illegally present in a Palestinian village when you’re reporting on them. Only quoting Israeli officials and only quoting Israeli politicians and police officers and framing your entire analysis with Israeli officials and only interviewing Palestinians when they have been brutalized and victimized physically. Those are some of the issues. There is plenty. And then saying things like “Israel will bomb a hospital in Gaza” and the press will say “a Hamas run hospital” and this negative association with Hamas will remove any sympathy from the reader towards the victims of this hospital bombing. A lot of things. And a lot of them are sinister. I have many friends, many journalist friends, and I’ve seen many journalists online speak about their experiences when talking about Palestine, the censorship that goes on into it.

(02:07:03)
And I have many journalist friends, some at the New York Times, some they used to be at the Washington Post, who tell me the kinds of battles they had to go through with their editors to let them even utter the word Palestine. And not even on in news pieces, pieces about, let’s say, a Palestinian artist or a Palestinian chef or whatever. There’s a lot that happens behind the scenes that is not reported on because, when it comes to Palestine, the rules and the laws of journalism are bendable. Passive voice is king. Omitting facts is acceptable. Anything goes.
Lex Fridman

(02:07:47)
So you personally, just psychologically, what have been the lowest points in your life, the darkest points?
Mohammed el-Kurd

(02:07:57)
A recent study came out and said that 52% of Palestinians have depression. I would argue that the number is much, much, much higher. I think it would be absurd for someone to live under the conditions we live under and not contemplate many things, many things. Not just suicide, but many, many, many things. And if people were to put themselves in our shoes for just one day, they would understand where all of the rage and all of the resistance is coming from. It’s not an easy life.
Lex Fridman

(02:08:32)
So where do you find the strength?
Mohammed el-Kurd

(02:08:34)
I’m surrounded by good people. I’m surrounded by good people and I don’t even think of it as a strength. I think of this as my obligation. It just feels like the thing I have to do. I don’t need inspiration. I don’t need strength. It’s just my obligation. There is a great travesty taking place in the world and I and a few others have been put in a place where we’re able to talk about it to a few more people. It’s just my obligation. I have to do it.
Hope
Lex Fridman

(02:09:14)
What gives you hope about the future of Palestine?
Mohammed el-Kurd

(02:09:18)
What gives me hope about the future of Palestine is taking a look at history and understanding that across history there has not been an injustice that lingered endlessly. Everything comes to an end. There’s not necessarily a perfect resolution for everything, but nothing continues in the form that it started in, and the occupation and colonialism and Palestine and Zionism, all of these things, are not at all sustainable whatsoever taking a look at history. A lot of what I’m saying today and what I have said in your podcast, many people would’ve would be pearl-clutching hearing me say what I say. But I always try to remind myself that during Jim Crow, during slavery, during the Holocaust, during the occupation of Algeria, during any point of colonialism in the African continent, people did not possess the moral clarity they possess today when they talk about these things. And all of these things were contested and controversial and in many, many, many cases legal and, today, they are deplorable, condemnable, and people say “never again” and they don’t remember them. So that’s what gives me hope, is believing in the inevitability of justice.
Lex Fridman

(02:10:44)
What do you love most about Palestine? What are maybe little things that you remember from your childhood, from your life there in East Jerusalem and elsewhere that just brings a smile to your face?
Mohammed el-Kurd

(02:10:57)
I think just the unabashed-ness of Palestinians. We’re a people who are told and at some point were told by the large majority of the world that we should shrink ourselves, that we should be ashamed of who we are, that we are monsters, that we are terrorists, that we are, blah, blah, blah. And Palestinian people don’t really give a shit. They’re continuing to live as they do. They continue to resist. They continue to write. They continue to do all that they do, and I love that the most. And I love our ability to laugh more than anything else. One thing that’s misunderstood in American culture about Palestinian culture or just Western culture in general is martyrdom culture. A lot of the time people will broadcast images of Palestinian women cheering when their sons have been killed by the Israeli forces and they’ll say, “These people glorify death and these people are eager to have sex with 70 virgins in heaven”, and so on and so forth.

(02:12:05)
But that’s not the case. The whole idea of the occupation, when they are killing our children, the whole idea is that they’re trained to break our spirits. These mothers, whose hearts are broken, who are anguished, who are so in so much pain when they are cheering, they are not celebrating, they’re not cheering. They are letting the occupier know that, “You have not broken my spirit. I have not yet been defeated.” And I think that is beautiful. It’s the same thing with our prison culture. Palestinians are fascinating in the sense that Palestinians go to prison and they study and they come out with degrees. They can find ways to participate in civil society. They can even smuggle sperm from prison to give a life outside of it because in their philosophy of prisons, they understand that these structures, these buildings were built to break your spirits. So what do you?

(02:13:08)
You don’t allow it to break your spirits. You resist it. You continue to hold onto life. You continue to hold on to your love of life. You continue to hold on to your love of freedom and you come out of prison and you’re celebrated by your community. The prison has not broken your spirit. All of these structures and system that is the Zionist movement has put into place, be it the shoot-to-kill policies or the prisons or the demolishing our homes that were meant to kill our spirits, they don’t. You demolish the home in Jerusalem and the people say, “Don’t worry. We’ll build another. You demolish it and we’ll build another.” That’s what I admire most about the Palestinian people. It’s this resilience. And people love to say resilience, but I think it’s stubbornness. I think we’re such a stubborn people, and I think that’s great.
Lex Fridman

(02:13:57)
Well, Mohammed, thank you for being a man who exemplifies this unbreakable spirit. Thank you for the words you’ve written, the words you’ve spoken, and thank you for talking today. This is an honor and thank you for educating me.
Mohammed el-Kurd

(02:14:13)
Thank you so much.
Lex Fridman

(02:14:14)
Thanks for listening to this conversation with Mohammed el-Kurd. To support this podcast, please check out our sponsors in the description. And now let me leave you with some words from Nelson Mandela. “It always seems impossible until it’s done.” Thank you for listening and hope to see you next time.
Transcript for Yuval Noah Harari: Human Nature, Intelligence, Power, and Conspiracies | Lex Fridman Podcast #390
This is a transcript of Lex Fridman Podcast #390 with Yuval Noah Harari.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
1:24 – Intelligence
20:19 – Origin of humans
30:41 – Suffering
51:22 – Hitler
1:09:54 – Benjamin Netanyahu
1:28:17 – Peace in Ukraine
1:45:07 – Conspiracy theories
1:59:46 – AI safety
2:14:04 – How to think
2:23:47 – Advice for young people
2:26:28 – Love
2:36:38 – Mortality
2:41:02 – Meaning of life

Introduction
Yuval Noah Harari

(00:00:00)
If we now find ourselves inside this kind of world of illusions created by an alien intelligence, that we don’t understand, but it understands us, this is a kind of spiritual enslavement that we won’t be able to break out of, because it understands us, it understands how to manipulate us, but we don’t understand what is behind this screen of stories and images and songs.
Lex Fridman

(00:00:36)
The following is a conversation with Yuval Noah Harari, a historian, philosopher, and author of several highly acclaimed, highly influential books, including Sapiens, Homo Deus and 21 Lessons for the 21st Century. He is also an outspoken critic of Benjamin Netanyahu and the current right-wing government in Israel. While much of this conversation is about the history and future of human civilization, we also discuss the political turmoil of present day Israel, providing a different perspective from that of my recent conversation with Benjamin Netanyahu.

(00:01:14)
This is the Lex Friedman podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Yuval Noah Harari.
Intelligence

(00:01:24)
13.8 billion years ago is the origin of our universe. 3.8 billion years ago is the origin of life here on our little planet, the one we call earth. Let’s say 200,000 years ago, is the appearance of early homo sapiens. Let me ask you this question. How rare are these events in the vastness of space and time? Or put it in a more fun way, how many intelligent alien civilizations do you think are out there in this universe, us being one of them?
Yuval Noah Harari

(00:01:53)
I suppose there should be some, statistically, but we don’t have any evidence. I do think that intelligence, in any way, it’s a bit overvalued. We are the most intelligent entities on this planet, and look what you’re doing. So intelligence also tends to be self-destructive, which implies that if there are, or were, intelligent life forms elsewhere, maybe they don’t survive for long.
Lex Fridman

(00:02:22)
You think there’s a tension between happiness and intelligence?
Yuval Noah Harari

(00:02:26)
Absolutely. Intelligence is definitely not something that is directed towards amplifying happiness. I would also emphasize the huge, huge difference between intelligence and consciousness, which many people, certainly in the tech industry and in the AI industry, tend to miss. Intelligence is simply the ability to solve problems, to attain goals, and to win at chess, to win a struggle for survival, to win a war, to drive a car, to diagnose a disease. This is intelligence. Consciousness is the ability to feel things like pain and pleasure, and love, and hate. In humans and other animals intelligence and consciousness go together. They go hand in hand, which is why we confuse them. We solve problems, we attain goals by having feelings. Other types of intelligence, certainly in computers, computers are already highly intelligent and as far as we know, they have zero consciousness. When a computer beats you at chess or go or whatever, it doesn’t feel happy. If it loses, it doesn’t feel sad. There could be also other highly intelligent entities out there in the universe that have zero consciousness. I think that consciousness is far more important and valuable than intelligence.
Lex Fridman

(00:03:59)
Can you steer me on the case that consciousness and intelligence are intricately connected? Not just in humans, but anywhere else. They have to go hand in hand. Is it possible for you to imagine such a universe?
Yuval Noah Harari

(00:04:12)
It could be, but we don’t know yet. Again, we have examples. Certainly, we know of examples of high intelligence without consciousness. Computers are one example. As far as we know, plants are not conscious, yet, they are intelligent. They can solve problems, they can attain goals in very sophisticated ways. The other way around, to have consciousness without any intelligence, this is probably impossible, but to have intelligence without consciousness, yes, that’s possible.

(00:04:48)
A bigger question is whether any of that is tied to organic biochemistry. We know, on this planet, only about carbon-based life forms, whether you are an amoeba, a dinosaur, a tree, a human being, you are based on organic biochemistry. Is there an essential connection between organic biochemistry and consciousness? Do all conscious entities, everywhere in the universe or in the future on planet earth, have to be based on carbon? Is there something so special about carbon as an element that an entity based on silicon will never be conscious? I don’t know, maybe. Again, this is a key question about computer and computer consciousness. Can computers eventually become conscious, even though they are not organic? The jury is still out on that. I don’t know. We have to take both options into account.
Lex Fridman

(00:05:48)
Well, a big part of that is do you think we humans would be able to detect other intelligent beings, other conscious beings? Another way to ask that, is it possible that the aliens are already here and we don’t see them? Meaning are we very human-centric in our understanding of, one, the definition of life, two, the definition of intelligence, and three, the definition of consciousness?
Yuval Noah Harari

(00:06:13)
The aliens are here, they are just not from outer space. AI, which usually stands for artificial intelligence. I think it stands for alien intelligence because AI is an alien type of intelligence. It solves problems, attains goals in a very, very different way, in an alien way from human beings. I’m not implying that AI came from outer space, it came from Silicon Valley, but it is alien to us. If there are alien intelligent or conscious entities that came from outer space already here, I’ve not seen any evidence for it. It’s not impossible, but in science, evidence is everything.
Lex Fridman

(00:06:56)
Well, I mean, I guess, instructive there is just having the humility to look around, to think about living beings that operate at different timescale, at different spatial scale. I think that’s all useful when starting to analyze artificial intelligence. It’s possible that even the larger language models we have today are already conscious.
Yuval Noah Harari

(00:07:19)
I highly doubt it, but I think consciousness, in the end, it’s a question of social norms. Because we cannot prove consciousness in anybody except ourselves. We know that we are conscious, because we are feeling it. We have direct access to our subjective consciousness. We cannot have any proof that any other entity in the world, any other human being, our parents, our best friends, we don’t have proof that they are conscious. This has been known for thousands of years. This is Descartes, this is Buddha, this is Plato. We can’t have this sort of proof. What we do have is social conventions. It’s a social convention that all human beings are conscious. It also applies to animals. Most people who have pets firmly believe that their pets are conscious, but a lot of people still refuse to acknowledge that about cows or pigs.

(00:08:15)
Now, pigs are far more intelligent than dogs and cats, and according to many measures, yet, when you go to the supermarket and buy a piece of frozen pig meat, you don’t think about it as a conscious entity. Why do you think of your dog as conscious, but not of the bacon that you buy? Because you’ve built a relationship with the dog and you don’t have a relationship with the bacon.

(00:08:42)
Now, relationships, they don’t constitute a logical proof for consciousness, they’re a social test. The Turing test is a social test, it’s not a logical proof. Now, if you establish a mutual relationship with an entity and you are invested in it, emotionally, you are almost compelled to feel that the other side is also conscious. When it comes again to AI and computers, I think, again, I don’t think that at the present moment computers are conscious, but people are already forming intimate relationships with AI and are therefore almost … It’s almost irresistible. They’re compelled to increasingly feel that these are conscious entities. I think we are quite close to the point when the legal system will have to take this into account. Even though I don’t think computers have consciousness, I think we are close to the point the legal system will start treating them as conscious entities, because of this social convention.
Lex Fridman

(00:09:56)
To you is a social convention, just a funny little side effect, a little artifact, or is it fundamental to what consciousness is? Because if it is fundamental, then it seems like AI is very good at forming these kinds of deep relationships with humans, and therefore it’ll be able to be a nice catalyst for integrating itself into these social conventions of ours.
Yuval Noah Harari

(00:10:21)
It was built to accomplish that. Again, all this argument between natural select selection and creationism, intelligent design. As far as the past go, all entities evolve by natural selection. The funny thing is, when you look to the future, more and more entities will come out of intelligent design, not of some God above the clouds, but of our intelligent design and the intelligent design of our clouds, of our computing clouds. They will design more and more entities. This is what is happening with AI. It is designed to be very good at forming intimate relationships with humans. In many ways, it’s already doing it almost better than human beings, in some situations.

(00:11:13)
When two people talk with one another, one of the things that makes the conversation more difficult is our own emotions. You are saying something and I’m not really listening to you, because there is something I want to say, and I’m just waiting until you finish I can put in a word, or I’m so obsessed with my anger or irritation or whatever, that I don’t pay attention to what you are feeling. This is one of the biggest obstacles in human relationships. Computers don’t have this problem, because they don’t have any emotions of their own.

(00:11:51)
When a computer is talking to you, it can focus 100% of its attention is on what you’re saying and what you’re feeling because it has no feelings of its own. Paradoxically, this means that computers can fool people into feeling that, oh, there is a conscious entity on the other side, an empathic entity on the other side, because the one thing everybody wants, almost more than anything in the world, is for somebody to listen to me, somebody to focus all their attention on me. I want it from my spouse, from my husband, from my mother, from my friends, from my politicians. Listen to me, listen to what I feel. They often don’t. Now you have this entity, which a hundred percent of its attention is just on what I feel. This is a huge, huge temptation, and I think also a huge, huge danger.
Lex Fridman

(00:12:49)
Well, the interesting catch 22 there is you said somebody to listen to us. Yes, we want somebody to listen to us, but for us to respect that somebody, they sometimes have to also not listen. They kind of have to be an asshole sometimes. They have to have moods sometimes. They have to have self-importance and confidence, and we should have a little bit of fear that they can walk away at any moment. There should be a little bit of that tension.
Yuval Noah Harari

(00:13:17)
Absolutely.
Lex Fridman

(00:13:20)
Could we optimize for it?
Yuval Noah Harari

(00:13:21)
If social scientists and say psychologists establish that, I don’t know, 17% inattention is good for a conversation because then you feel challenged, “Oh, I need to grab this person’s attention,” you can program the AI to have exactly 17% inattention, not one percentage more or less. Or it can by trial and error, discover what is the ideal percentage. Over the last 10 years, we have creating machines for grabbing people’s attention. This is what has been happening on social media.

(00:13:58)
Now, we are designing machines for grabbing human intimacy, which, in many ways, it’s much, much more dangerous and scary. Already the machines for grabbing attention, we’ve seen how much social and political damage they could do by in many way kind of distorting the public conversation. Machines that are superhuman, in their abilities to create intimate relationships, this is psychological and social weapons of mass destruction. If we don’t regulate it, if we don’t train ourself to deal with it, it could destroy the foundations of human society.
Lex Fridman

(00:14:41)
Well, one of the possible trajectories is those same algorithms would become personalized and instead of manipulating us at scale, there would be assistants that guide us to help us grow, to help us understand the world better. Even interactions with large language models now, if you ask them questions, it doesn’t have that stressful drama, the tension that you have from other sources of information. It has a pretty balanced perspective that it provides. It just feels like the potential is there to have a really nice friend who’s an encyclopedia that just tells you all the different perspectives, even on controversial issues, the most controversial issues, to say, these are the different theories. These are the not widely accepted conspiracy theories, but here’s the kind of backing for those conspiracy. It just lays it all out. Then with a calm language, without the words that kind of presume there’s some kind of manipulation going on underneath it all. It’s quite refreshing.

(00:15:47)
Of course, those are the early days. People can step in and start to sensor it to manipulate those algorithms, to start to input some of the human biases in there as opposed to what’s currently happening is kind of the internet is input, compress it, and have a nice little output that gives an overview of the different issues. I mean, there’s a lot of promise there also, right?
Yuval Noah Harari

(00:16:13)
Absolutely. I mean, if there was no promise, there was no problem. If this technology could not accomplish anything good, nobody would develop it. Now, obviously, it has tremendous positive potential in things like what you just described in better medicine, better healthcare, better education, so many promises. This is also why it’s so dangerous, because the drive to develop it faster and faster is there, and it has some dangerous potential also. We shouldn’t ignore it. Again, I’m not advocating banning it, just to be careful about how we, not so much develop it, but most importantly how we deploy it into the public sphere. This is the key question.

(00:16:56)
You look back at history, and one of the things we know from history, humans are not good with new technologies. I hear many people now say, “AI, we’ve been here before. We had the radio, we had the printing press, we had the Industrial Revolution.” Every time there is a big new technology, people are afraid and it’ll take jobs and the bad actors. In the end it’s okay. As a historian, my tendency is yes, in the end it’s okay, but in the end there is a learning curve. There is a lot of failed experiments on the way to learning how to use the new technology. These failed experiments could cost the lives of hundreds of millions of people.

(00:17:42)
If you think about the last really big revolution, the Industrial Revolution, yes, in the end, we learned how to use the powers of industry; electricity, radio, trains, whatever, to build better human societies. On the way, we had all these experiments like European imperialism, which was driven by the Industrial Revolution. It was a question, how do you build an industrial society? Oh, you build an empire. You control all the resources, the raw materials, the markets. Then you had communism, another big experiment on how to build an industrial society. You had fascism and Nazism, which were essentially an experiment in how to build an industrial society, including even how do you exterminate minorities using the powers of industry? We had all these failed experiments on the way.

(00:18:37)
If we now have the same type of failed experiments with the technologies of the 21st century, with AI, with bioengineering, it could cost the lives of, again, hundreds of millions of people and maybe destroy the species. As a historian, when people talk about the examples from history, from new technologies, I’m not so optimistic. We need to think about the failed experiment, which accompanied every major new technology.
Lex Fridman

(00:19:10)
This intelligence thing, like you were saying, is a double-edged sword, is that every new thing it helps us create, it can both save us and destroy us. It’s unclear each time, which will happen. That’s maybe why we don’t see any aliens.
Yuval Noah Harari

(00:19:28)
Yeah. I mean, I think each time it does both things. Each time it does both good things and bad things. The more powerful the technology, the greater both the positive and the negative outcomes. Now, we are here because we are the descendants of the survivors, of the surviving cultures, the surviving civilizations. When we look back we say, in the end, everything was okay, “Hey, we are here,” but the people for whom it wasn’t okay, they are just not here.
Lex Fridman

(00:20:02)
Okay. Has a lot of possible variations to it because there’s a lot of suffering along the way, even for the people that survived. The quality of life and all of this. Let’s actually go back there, with deep gratitude to our ancestors. How did it all start? How did homo sapiens out-compete the others, the other human-like species, the Neanderthals and the other homo species?
Origin of humans
Yuval Noah Harari

(00:20:33)
On the individual level, as far as we can tell, we were not superior to them. Neanderthals actually had bigger brains than us. Not just other human species, other animals too. If you compare me, personally, to an elephant, to a chimpanzee, to a pig, I can do some things better, many other things worse. If you put me alone on some island with a chimpanzee, an elephant and a pig, I wouldn’t bet on me being the best survivor, the one that comes successful.
Lex Fridman

(00:21:06)
If I may interrupt for a second, I was just talking extensively with Elon Musk about the difference between humans and chimps, relevant to Optimus, the robot. The chimps are not able to do this kind of pinching with their fingers. They can only do this kind of pinching, and this kind of pinching is very useful for precise manipulation of objects. Don’t be so hard on yourself.
Yuval Noah Harari

(00:21:32)
No, I said that I can do some things better than a chimp. If Elon Musk goes on a boxing match with a chimpanzee …
Lex Fridman

(00:21:42)
This won’t help you.
Yuval Noah Harari

(00:21:43)
This won’t help you against a chimpanzee.
Lex Fridman

(00:21:46)
Good point.
Yuval Noah Harari

(00:21:47)
Similar, if you want to climb a tree, if you want to do so many things, my bets will be on the chimp, not on Elon.
Lex Fridman

(00:21:53)
Fair enough.
Yuval Noah Harari

(00:21:54)
You have advantages on both sides. What really made us successful, what made us the rulers of the planet and not the chimps and not the Neanderthals, is not any individual ability, but our collective ability. Our ability to cooperate flexibly in very large numbers. Chimpanzees know how to cooperate, say, 50 chimpanzees, a hundred chimpanzees. As far as we can tell from archeological evidence this was also the case with Neanderthals. Homo sapiens, about 70,000 years ago, gained an amazing ability to cooperate basically in unlimited numbers. You start seeing the formation of large networks; political, commercial, religious, items being traded over thousands of kilometers, ideas being spread, artistic fashions. This is our secret of success. Chimpanzees, Neanderthals can cooperate, say, a hundred.

(00:22:56)
Now, the global trade network has 8 billion people. What we eat, what we wear, it comes from the other side of the world. Countries like China, like India, they have 1.4 billion people. Even Israel, which is a relatively small country, say 9 million citizens, that’s more than the entire population of the planet 10,000 years ago of humans. We can build these huge networks of cooperation. Everything we have accomplished as a species from building the pyramids to flying to the moon, it’s based on that. Then you ask, “Okay. So what makes it possible for millions of people who don’t know each other, to cooperate in a way that Neanderthals or chimpanzees couldn’t?” At least my answer is stories, is fiction. It’s the imagination.

(00:23:48)
If you examine any large scale human cooperation, you always find fiction as its basis. It’s a fictional story that holds lots of strangers together. It’s most obvious in cases like religion. You can’t convince a group of chimpanzees to come together to fight a war or build a cathedral by promising to them, “If you do that, after you die, you go to chimpanzee heaven and you get lots of bananas and coconuts.” No chimpanzee will ever believe that. Humans believe these stories, which is why we have these huge religious networks. It’s the same thing with modern politics.

(00:24:29)
It’s the same thing with economics. People think, “Oh, economics, this is rational. It has nothing to do with fictional stories.” No money is the most successful story ever told, much more successful than any religious mythology. Not everybody believes in God, or in the same God, but almost everybody believes in money, even though it’s just a figment of our imagination. You take these green pieces of paper, dollars, they have no value. You can’t eat them, you can’t drink them. Today, most dollars are not even pieces of paper, they are just electronic information passing between computers. We value them just for one reason, that you have the best storytellers in the world, the bankers, the finance ministers, all these people, they are the best storytellers ever. They tell us a story that this green little piece of paper, or this bit of information, it is worth a banana. As long as everybody believes it, it works.
Lex Fridman

(00:25:29)
At which point does a fiction, when it’s sufficiently useful and effective and improving the global quality of life, does it become accepted reality? There’s a threshold, which just [inaudible 00:25:43].
Yuval Noah Harari

(00:25:42)
If enough people believe it. It’s like with money. If you start a new cryptocurrency, if you are the only one that believes the story … I mean, again, you cryptocurrencies, you have the math of course, but ultimately it’s storytelling. You’re selling people a story. If nobody believes your story, you don’t have anything, but if lots of people believe the Bitcoin story, then Bitcoin can be worth thousands and tens of thousands of dollars. Again, why? I mean, you can’t eat it, you can’t drink. It’s nothing. It’s this story around the math, which is the real magic.
Lex Fridman

(00:26:17)
Is it possible that the story is the primary living organism, not the storyteller. That somehow homo sapiens evolved to become these hosts for a more intelligent living organism, which is the idea. The ideas are the ones that are doing the competing. This is one of the sort of big perspectives behind your work that’s really revolutionary of how you’ve seen history. Do you ever take out the perspective of the ideas as the organisms versus the humans?
Yuval Noah Harari

(00:26:55)
It’s an interesting idea. There are two opposite things to say about it. On the one hand, yes, absolutely. If you look long term in history, all the people die. It’s the stories that compete and survive and spread. Stories often spread by making people willing to sacrifice sometimes their lives for the story. We know, in Israel, this is one of the most important story factories in human history. This is a place where people still kill each other every day over stories. I don’t know. You’ve been to Jerusalem, right?
Lex Fridman

(00:27:32)
Mm-hmm (affirmative).
Yuval Noah Harari

(00:27:34)
People here are, “Oh, Jerusalem, Jerusalem, Jerusalem.” I’ve lived in Jerusalem much of my life. You go there, it’s an ordinary place. It’s a town. You have buildings, you have stones, you have trees, you have dogs and cats and pedestrians. It’s a regular place. Then you have the stories about the place, “Oh, this is the place where God revealed himself. This is the place where Jesus was. This is the place where Muhammad was.” It’s the stories that people fight over. Nobody’s fighting over the stones. People are fighting about the stories about the stones. If a story can get millions of people to fight for it, it not only survives, it spreads. It can take over the world.

(00:28:22)
The other side of the coin is that the stories are not really alive, because they don’t feel anything. This goes back to the question of consciousness, which I think is the most important thing, that the ultimate reality is consciousness, is the ability to feel things. If you want to know whether the hero of some story is real or not, you need to ask, “Can it suffer?” Stories don’t feel anything. Countries, which are also stories, nations, don’t suffer. If a nation loses a war, it doesn’t suffer. The soldiers suffer, the civilians suffer. Animals can suffer. You have an army with horses and whatever, and the horses get wounded, the horses suffer. The nation can’t suffer, it’s just an imagination. It’s just a fictional story in our mind. It doesn’t feel anything.

(00:29:21)
Similarly, when a bank goes bankrupt or a company goes bankrupt, or when a currency loses its value, like Bitcoin is worth now zero, crashed, or the dollar is worth zero, it crashed. The dollar doesn’t feel anything. It’s the people holding the dollars who might be now very miserable. We have this complex situation when history is largely driven by stories, but stories are not the ultimate reality. The ultimate reality is feelings of humans, of animals. The tragedy of history is that very, very often we get the order wrong. Stories are not bad. Stories are tools. They’re good, when we use them in order to alleviate suffering, but very often we forget it. Instead of using the stories for our purposes, we allow the stories to use us for their purposes. Then you start entire wars because of a story. You inflict suffering on millions of people just for the sake of a story. That’s the tragedy of human history.
Suffering
Lex Fridman

(00:30:41)
The fundamental property of life, of a living organism, is the capacity to feel and the ultimate feeling is suffering?
Yuval Noah Harari

(00:30:50)
To know if you are happy or not, it’s a very difficult question, but when you suffer you know.
Lex Fridman

(00:30:55)
Yes.
Yuval Noah Harari

(00:30:56)
Also, in ethical terms, it’s more important to be aware of suffering than of any other emotion. If you are doing something which is causing all kinds of emotions to all kinds of people, first of all, you need to notice if you’re causing a lot of suffering to someone. If some people like it and some people are bored by it and some people are a bit angry at you, and some people are suffering because of what you do, you first of all have to know, oh … Sometimes, you still have to do it. The world is a complicated place. I don’t know. You have an epidemic. Governments decide to have all those social isolation regulations or whatever. In certain cases, yes, you need to do it even though it can cause tremendous suffering, but you need to be very aware of the cost and to be very, very … You have to ask yourself again, and again, and again, is it worth it? Is it still worth it?
Lex Fridman

(00:31:53)
The interesting question there, implied in your statements, is that suffering is a pretty good component of a Turing test for consciousness.
Yuval Noah Harari

(00:32:01)
This is the most important thing to ask about AI: Can it suffer? Because if AI can suffer, then it is an ethical subject and it needs protection, it needs rights just like humans and animals.
Lex Fridman

(00:32:15)
Well, quite a long time ago already, so I work with a lot of robots, legged robots, but I’ve even had, inspired by a YouTube video, had a bunch of Roombas that I made them scream when I touched them or kicked them, or when they ran into a wall. The illusion of suffering, for me, a silly human that anthropomorphizes things, is as powerful as suffering itself. I mean, you immediately think the thing is suffering. I think some of it is just a technical problem, but it’s the easily solvable one, how to create an AI system that just says, “Please don’t hurt me. Please don’t shut me off. I miss you. Where have you been?” Be jealous, also. ” Why have you been gone for so long?”
Lex Fridman

(00:33:01)
Why have you been gone for so long? Your calendar doesn’t have anything on it. This create through words the perception of suffering, of jealousy, of anger, of all of those things, and it just seems like that’s not so difficult to do.
Yuval Noah Harari

(00:33:19)
That’s part of the danger. It basically hacks our operating system and it uses some of our best qualities against us. It’s very, very good that humans are attuned to suffering and that we don’t want to cause suffering because we have compassion. That’s one of the most wonderful thing about humans. If we now create AIs which use this to manipulate us, this is a terrible thing.
Lex Fridman

(00:33:48)
You’ve, I think, mentioned this. Do you think it should be illegal to do these kinds of things with AI, to create the perception of consciousness of saying, “Please don’t leave me,” or basically simulate some of the human-like qualities?
Yuval Noah Harari

(00:34:05)
Yes. I think, again, we have to be very careful about it. If it emerges spontaneously, we need to be careful. Again, we can’t rule out the possibility that AI will develop consciousness. We don’t know enough about consciousness to be sure. If it develops spontaneously, we need to be very careful about how we understand it. If people intentionally design an AI that they know, they assume it has no consciousness, but in order to manipulate people, they use again this human strength, the noble part of our nature against us, this should be forbidden and, similarly on a more general level, that it should be forbidden for an AI to pretend to be a human being, that it’s okay. There are so many things we can use Ais as teachers, as doctors and so forth, and it’s good as long as we know that we are interacting with an AI. The same way we ban fake money, we should ban fake humans. It’s not just banning deep fakes of specific individuals. It’s also banning deep fake of generic humans, which is already happening to some extent on social media. If you have lots of bots retweeting something, then you have the impression, “Oh, lots of people are interested in that. That’s important,” and this is basically the bots pretending to be humans, because if you see a tweet which says 500 people retweeted it or you see a tweet and it says 500 bots retweeted it, I don’t care what the bots we tweeted, but if it’s humans, okay, that’s interesting.

(00:35:56)
We need to be very careful that bots can’t do that. They are doing it at present, and it should be banned. Now, some people say, “Yes, bots’ freedom of expression.” No. Bots don’t have freedom of expression. There is no cost in terms of freedom of expression when you ban bots. Again, in some situations, yes, AIs should interact with us, but it should be very clear this is an AI talking to you or this is an AI retweeting this story, it is not a human being making a conscious decision.
Lex Fridman

(00:36:32)
To push back on this line of fake humans, because I think it might be a spectrum, first of all, you might have AI systems that are offended, hurt when you say that they’re fake humans. In fact, they might start identifying as humans. You just talked about the power of us humans with our collective intelligence to take fake stories and make them quite real. If the feelings you have for the fake human is real, love is a kind of fake thing that we all put a word to, a set of feelings, what if you have that feeling for an AI system? It starts to change, I mean, maybe the things AI systems are allowed to do for good. They’re allowed to create, communicate suffering, communicate the good stuff, the longing, the hope, the connection, the intimacy, all of that and, in that way, get integrated in our society, and then you start to ask a question on are we allowed to really unplug them? Are we allowed to really censor them, remove them, remove their voice from social media?
Yuval Noah Harari

(00:37:53)
I’m not saying they shouldn’t have a voice, they shouldn’t talk with us. I’m just saying, when they talk with us, it should be clear that they are AI. That’s it. You can have your voice as an AI. Again, I have some medical problem. I want to get advice from an AI doctor. That’s fine as long as I know that I’m talking with an AI. What should be banned is AI pretending to be a human being. This is something that will erode trust and, without trust, society collapses. This is something that especially will endanger democracies because democracy is a conversation basically and it’s a conversation between people.

(00:38:37)
If you now flood the public sphere with millions and potentially billions of AI agents that can hold conversations, they never sleep, they never eat, they don’t have emotions of their own, they can get to know you and tailor their words specifically for you and your life story, they are becoming better than us at creating stories and ideas and so forth. If you flood the public sphere with that, this will ruin the conversation between people. It will ruin the trust between people. You will no longer be able to have a democracy in this situation. You can have other types of regimes, but not democracy.
Lex Fridman

(00:39:26)
If you could talk about the big philosophical notion of truth then? You’ve already talked about the capacity of humans. One of the things that made us special is stories. Is there such thing as truth?
Yuval Noah Harari

(00:39:44)
Absolutely.
Lex Fridman

(00:39:45)
What is truth exactly?
Yuval Noah Harari

(00:39:46)
When somebody is suffering, that’s true. I mean, this is why one of the things, when you talk about suffering as a ultimate reality, when somebody suffers, that is truth. Now, somebody can suffer because of a fictional story. Like somebody tells people that God said, “You must go on this crusade and kill these heretics,” and this is a completely fictional story, and people believe it and they start a war and they destroy cities and kill people. The people that suffer because of that, and even the crusaders themselves that also suffer the consequences of what they do, the suffering is true even though it is caused by a fictional story.

(00:40:26)
Similarly, when people agree on certain rules, the rules could come out of our imagination. Now, we can be truthful about it and say, “These rules. They didn’t come from heaven. They came from our imagination.” We look at sports. We have rules for the game of football, soccer. They were invented by people. At least very few people claim that the rules of football came down from heaven. We invented them, and this is truthful. There are fictional rules invented by humans, and this is true. They were invented by humans. When you are honest about it, it enables you to change the rules, which is being done in football every now and then.

(00:41:12)
It’s the same with the fundamental rules of a country. You can pretend that the rules came down from heaven dictated by God or whatever and then you can’t change them, or you can be like the American Constitution which starts with, “We the People.” The American Constitution lays down certain rules for a society, but the amazing thing about it, it does not pretend to come from an external source.

(00:41:40)
The 10 Commandments start with, “I am your Lord God.” Because it starts with that, you can’t change them. The 10th commandment, for instance, supports slavery. In the 10th commandment, it says that you should not covet your neighbor’s house or your neighbor’s wife or your neighbor’s slaves. It’s okay to hold slaves according to the 10th commandment. It’s just bad to covet the slaves of your neighbor.

(00:42:12)
Now, there is no 11th commandment which says, “If you don’t like some of the previous 10 commandments, this is how you go about amending them,” which is why we still have them unchanged. Now, in the US Constitution, you have all these rights and rules, including originally the ability to hold slaves, but the genius of the Founding Fathers of the United States, they had the humility to understand maybe we don’t understand everything. Maybe we made some mistakes, so we tell you that these rules did not come from heaven. They came from us humans. We may have made a mistake, so here is a mechanism for how future generations can amend the Constitution, which was used later on to, for instance, amend the Constitution to ban slavery.
Lex Fridman

(00:43:06)
Now you’re describing some interesting and powerful ideas throughout human history. Can you just speak to the mechanism of how humans start to believe ideas? Is there something interesting to say there from your thinking about it, how idea is born and how it takes hold, and how it spreads, and how it competes with other ideas?
Yuval Noah Harari

(00:43:28)
First of all, ideas are an independent force in history. Marxists tend to deny that. Marxists think that all history is just a play of material interests, and ideas, stories, they are just a smokescreen to hide the underlying interests. My thoughts are to some extent the opposite. We have some biological objective interests that all humans share, like we need to eat, we need to drink, we need to breathe, but most conflicts in history are not about that. The interests which really drive most conflicts in history don’t come from biology. They come from religions and ideologies and stories.

(00:44:19)
It’s not that stories are a smokescreen to hide the real interests. The stories create the interests in the first place. The stories define who are the competing groups. Nations, religions, cultures, they are not biological entities. They’re not like species like gorillas and chimpanzees. No. Israelis and Palestinians, or Germans and French, or Chinese and Americans, they have no essential biological difference between them. The difference is cultural. It comes from stories. There are people that believe in different stories. The stories create the identity. The stories create the interests. Israelis and Palestinians are fighting over Jerusalem not because of any material interest. There are no oil fields under Jerusalem, and even oil. You need it to realize some cultural fantasy. It doesn’t really come from biology. The stories are independent forces.

(00:45:19)
Now, why do people believe one story and not another? That’s history. There is no materialistic law, “People will always believe this.” No. History is full of accidents. How did Christianity become the most successful religion in the world? We can’t explain it. Why this story about Jesus of Nazareth? The Roman Empire in the 3rd Century CE was a bit like, I don’t know, California today. So many sects and sub-sects and gurus and religions, everybody has their own thing, and you have thousands of different stories competing.

(00:46:05)
Why did Christianity come up on top? As a historian, I don’t have a clear answer. You can read the sources, and you see how it happened. Oh, this happened and then this happened, and then Constantine adopted it, and then this and then this, but why? I don’t think anybody has an answer to that. If you rewind the movie of history and press play and you rewind and press play a hundred times, I think Christianity would take over the Roman Empire in the world maybe twice out of a hundred times. It was such an unlikely thing to happen.

(00:46:44)
It’s the same with Islam. It’s the same, I don’t don’t know, with the communist takeover of Russia. In 1914, if you told people that in three years Lenin and the Bolsheviks will gain power in that czarist empire, they would think you’re utterly crazy. Lenin had a few thousand supporters in 1914 in an empire of close to 200 million people. It sounded ludicrous. Now we know the chain of events, the First World war, the February Revolution and so forth, that led to the communist takeover, but it was such an unlikely event, and it happened.
Lex Fridman

(00:47:25)
The little steps along the way, the little options you have along the way because, Stalin versus Trotsky, you could have the Robert Frost poem, there’s always-
Yuval Noah Harari

(00:47:32)
Yes. There is a highway and there is a sideway, and history takes the sideway many, many times.
Lex Fridman

(00:47:43)
It’s perhaps tempting to tell some of that history through charismatic leaders. Maybe it’s an open question. How much power charismatic leaders have to affect the trajectory of history?
Yuval Noah Harari

(00:47:56)
You’ve met quite a lot of charismatic leaders lately. I mean, what’s your view on that?
Lex Fridman

(00:48:01)
I find it a compelling notion. I’m a sucker for a great speech and a vision. I have a sense that there’s an importance for a leader to catalyze the viral spread of a story. I think we need leaders to be just great storytellers that sharpen up the story to make sure it infiltrates everybody’s brain effectively. It could also be that the local interactions between humans is even more important, but it’s just we don’t have a good way to summarize that and describe that. We like to talk about Steve Jobs as central to the development of the computer, maybe Bill Gates. You tell the stories of individuals like this because it’s just easier to tell a sexy story that way.
Yuval Noah Harari

(00:48:53)
Maybe it’s an interplay because you have the structural forces. I don’t know. You look at the geography of the planet and you look at shipping technology in the late 15th Century in Europe and the Mediterranean, and it’s almost inevitable that pretty quickly somebody would discover America, somebody from the Old World will get to the new world. If it wasn’t Columbus, then it would’ve been, five years later, somebody else. The key thing about history is that these small differences make a huge, huge difference. If it wasn’t Columbus, if it was five years later somebody from England, then maybe all of Latin America today would be speaking English and not Spanish. If it was somebody from the Ottoman Empire, it’s a completely different world history. The Ottoman Empire at that time was also shaping up to be a major maritime empire. If you have America being reached by Muslim navigators before Christian navigators from Europe, you have a completely different world history.

(00:50:09)
It’s the same with the computer. Given the economic incentives and the science and technology of the time, then the rise of the personal computer was probably inevitable sometime in the late 20th Century. The where and when is crucial. The fact that it was California in the 1970s and not, say, I don’t know, Japan in the 1980s or China in the 1990s, this made a huge, huge difference. You have this interplay between the structural forces which are beyond the control of any single charismatic leader, but then, the small changes, they can have a big effect.

(00:50:54)
I don’t know. I think, for instance, about the war in Ukraine. Now it’s a struggle between nations, but there was a moment when the decision was taken in the mind of a single individual, of Vladimir Putin. He could have decided otherwise, and the world would’ve looked completely different.
Hitler
Lex Fridman

(00:51:14)
Another leader, Volodymyr Zelenskyy, could have decided to leave Kyiv in the early days. There’s a lot of decisions that ripple. You write in Homo Deus about Hitler and, in part, that he was not a very impressive person.
Yuval Noah Harari

(00:51:33)
I say that?
Lex Fridman

(00:51:35)
The quote is, let me read it, “He wasn’t a senior officer in four years of war. He rose no higher than the rank of corporal. He had no formal education.” Perhaps you mean his resume was not impressive.
Yuval Noah Harari

(00:51:48)
Yeah, his resume was not impressive. That’s true.
Lex Fridman

(00:51:51)
“He had no formal education, no professional skills, no political background. He wasn’t a successful businessman or a union activist. He didn’t have friends or relatives in high places nor any money to speak of.” How did he amass so much power? What ideology, what circumstances enabled the rise of the Third Reich?
Yuval Noah Harari

(00:52:13)
Again, I can’t tell you the why. I can tell you the how. I don’t think it was inevitable. I think that, if a few things were different, there would’ve been no Third Reich. There would’ve been no Nazism and no Holocaust. Again, this is the tragedy. If it would’ve been inevitable, then what can you do? This is the laws of history or the laws of physics, but the tragedy is, no, it was decisions by humans that led to that direction.

(00:52:41)
Even from the viewpoint of the Germans, we know for a fact it was an unnecessary path to take because, in the 1920s and ’30s, the Nazis said that, “Unless Germany take this road, it will never be prosperous, it’ll never be successful. All the other countries will keep stepping on it.” This was their claim. We know for a fact this is false. Why? Because they took that road, they lost the Second World War and, after they lost, then they became one of the most prosperous countries in the world because their enemies that defeated them evidently supported them and allowed them to become such a prosperous and successful nation.

(00:53:36)
If you can lose the war and still be so successful, obviously you could just have skipped the war. You didn’t need it. I mean, you really had to have the war in order to have a prosperous Germany? Absolutely not. It’s the same with Japan. It’s the same with Italy. It was not inevitable. It was not the forces of history that necessitated, forced Germany to take this path.

(00:54:09)
Again, Hitler was a very, very skillful storyteller. He sold people a story. The fact that he was nobody made it even more effective because people at that time, after their defeat of the First World War, after the repeated economic crisis of the 1920s in Germany, people felt betrayed by all the established elites, by all the established institutions. All these professors and politicians and industrialists and military, all the big people, they led us to a disastrous war. They led us to humiliation, so we don’t want any of them. Then you have this nobody, a corporal with no money, with no education, with no titles, with nothing, and he tells people, “I’m one of you.” This was one reason why he was so popular, and then the story he told.

(00:55:10)
When you look at stories, at the competition between different stories, and between stories, fiction and the truth, the truth has two big problems. The truth tends to be complicated and the truth tends to be painful. Let’s talk about nations. The real story of every nation is complicated and it contains some painful episodes. We are not always good. We sometimes do bad things.

(00:55:43)
Now, if you go to people and you tell them a complicated and painful story, many of them don’t want to listen. The advantage of fiction is that it can be made as simple and as painless or attractive as you want it to be because it’s fiction, and then what you see is that politicians like Hitler, they create a very simple story. We are the heroes. We always do good things. Everybody is against us. Everybody is trying to trample us, and this is very attractive.

(00:56:20)
One of the things people don’t understand about Nazism and fascism, we teach in schools about Fascism and Nazism as this ultimate evil, the ultimate monster in human history. At some level, this is wrong because it actually exposes us. Why? Because people hear of fascism is this monster, and then when you hear the actual fascist story, what fascists tell you is always very beautiful and attractive. Fascists are people who come and tell you, “You are wonderful. You belong to the most wonderful group of people in the world. You’re beautiful. You are ethical. Everything you do is good. You have never done anything wrong. There are all these evil monsters out there that are out to get you, and they’re causing all the problems in the world.”

(00:57:18)
When people hear that, it’s like looking in the mirror and seeing something very beautiful. Hey, I’m beautiful. We’ve never done anything wrong. We are victims. When you look and you heard in school that Fascism, that fascists are monsters, and you look in the mirror, you see something very beautiful and you say, “I can’t be a fascist because fascists are monsters. This is so beautiful,” so it can’t be. When you look in the fascist mirror, you never see a monster. You see the most beautiful thing in the world, and that’s the danger.

(00:57:54)
This is the problem with Hollywood. I look at Voldemort in Harry Potter. Who would like to follow this creep? You look at Darth Vader. This is not somebody you would like to follow. Christianity got things much better when it described the devil as being very beautiful and attractive. That’s the danger, that you see something is very beautiful, you don’t understand the monster underneath.
Lex Fridman

(00:58:23)
You write precisely about this. By the way, just as a small aside, it always saddens me when people say how obvious it is to them that communism is a flawed ideology. When you ask them, “Try to put your mind, try to put yourself in the beginning of the 20th Century and see what you would do,” a lot of people will say, “It’s obvious that it’s a flawed ideology.” I mean, I suppose, to some of the worst ideologies in human history, you could say the same. In that mirror, when you look, it looks beautiful.
Yuval Noah Harari

(00:58:56)
Communism is the same also. You look in the communist mirror. You’re the most ethical, wonderful place, person ever. It’s very difficult to see Stalin underneath it.
Lex Fridman

(00:59:07)
Yeah, in Homo Deus, you also write, “During the 19th and 20th Centuries, as humanism gained increasing social credibility and political power, it sprouted two very different offshoots, socialist humanism, which encompassed a plethora of socialist and communist movements, and evolutionary humanism, whose most famous advocates were the Nazis.” If you can just linger on that, what’s the ideological connection between Nazism and communism as embodied by humanism?
Yuval Noah Harari

(00:59:35)
In humanism, basically the focus is on humans, that they are the most important thing in the world, they move history, but then there is a big question. What are humans? What is humanity?

(00:59:51)
Now, liberals, they place at the center of the story individual humans and they don’t see history as a necessary collision between big forces. They place the individual at the center. Especially in the US today, liberal is taken as the opposite of conservative, but to test whether you’re a liberal, you need to answer just three questions. Very simple. Do you think people should have the right to choose their own government or the government should be imposed by some outside force? Do you think people should have the right to the liberty to choose their own profession or either born into some caste that predetermines what they do, and do you think people should have the liberty to choose their own spouse and their own way of personal life instead of being told by elders or parents who to marry and how to live? Now, if you answered yes to all three questions, people should have the liberty to choose their government, their profession, their personal lives, their spouse, then you’re a liberal. Most conservatives are also liberal.

(01:01:10)
Now, communists and fascists, they answer differently. For them, yes, history is about humans, humans are the big heroes of history, but not individual humans and their liberties. Fascists imagine history as a clash between races or nations. The nation is at the center. They say the supreme good is the good of the nation. You should have a hundred percent loyalty only to the nation.

(01:01:45)
Liberals say, yes, you should be loyal to the nation, but it’s not the only thing. There are other things in the world. There are human rights. There is truth. There is beauty. Many times, yes, you should prefer the interests of your nation over other things, but not always. If your nation tells you to murder millions of innocent people, you don’t do that even though the nation tells you to do it, to lie for the national interest. In extreme situations, maybe, but in many cases, your loyalty should be to the truth even if it makes your nation looks a bit not in the best light.

(01:02:26)
The same with beauty. How does the fascist determine whether a movie is a good movie? Very simple. If it serves the interest of the nation, this is a good movie. If it’s against the interest of the nation, this is a bad movie. End of story. Liberalism says, no, there is aesthetic values in the world. We should judge movies not just on the question whether they serve the national interest, but also on artistic value.

(01:02:57)
Communists are a bit like the fascists, instead that they don’t place the nation as the main hero, they place class as the main hero. For them, history, again, it’s not about individuals, it’s not about nations, history is the clash between classes and, just as fascists imagine in the end, only one nation will be on top. The communists think in the end only one class should be on top, and that’s the proletariat. Same story. A hundred percent of your loyalty should be to the class. If there is a clash, say, between class and family, class wins.

(01:03:36)
In the Soviet Union, the party told children, “If you hear your parents say something bad about Stalin, you have to report them.” There are many cases when children reported their parents, and their parents were sent to the gulag. Your loyalty is to the party which leads the proletariat to victory in the historical struggle. The same way in communism. Art is only about class struggle. A movie is good if it serves the interest of the proletariat. Artistic values? There is nothing like that. The same with truth. Everything that we see now in fake news, the communist propaganda machine was there before us, the level of lies, of disinformation campaigns that they orchestrated in the 1920s and ’30s and ’40s is really unimaginable.
Lex Fridman

(01:04:36)
So the reason these two classes of ideologies failed as the sacrifice of truth, not just failed, but did a lot of damage as the sacrifice of truth and sacrifice of beauty?
Yuval Noah Harari

(01:04:50)
… and sacrifice of hundreds of millions of people. Again, for human suffering like, okay, in order for our nation to win, in order for our class to win, we need to kill those millions. Kill those millions. Ethics, aesthetics, truth, they don’t matter. The only thing that matter is the victory of the state or the victory of the class.

(01:05:18)
Liberalism was the antithesis to that. It says, no, it has a much more complicated view of the world. Both communism and fascists, they had the very simple view of the world. Your loyalty, a hundred percent of it, should be only to one thing. Now, liberalism has a much more complex view of the world. It says, yes, there are nations. They are important. Yes, there are classes. They are important, but they are not the only thing. There are also families. There are also individuals. There are also animals. Your loyalty should be divided between all of them. Sometimes, you prefer this. Sometimes, you prefer that. That’s complicated.
Yuval Noah Harari

(01:06:00)
With this. Sometimes you prefer that. That’s complicated. But life is complicated.
Lex Fridman

(01:06:07)
But also, I think, maybe you can correct me, but liberalism acknowledges the corrupting nature of power. When there’s a guy at the top who sits there for a while managing things, he’s probably going to start losing a good sense of reality and losing the capability to be a good manager.
Yuval Noah Harari

(01:06:28)
Yeah.
Lex Fridman

(01:06:28)
It feels like the communist and fascist regimes don’t acknowledge that basic characteristic of human nature, that power corrupts.
Yuval Noah Harari

(01:06:39)
Yes. They believe in infallibility.
Lex Fridman

(01:06:41)
Yeah.
Yuval Noah Harari

(01:06:42)
In this sense, they’re very close to being religions. They’re in Nazism. Hitler was considered infallible, and therefore you don’t need any checks and balances on his power. Why do you need to balance an infallible genius? And it’s the same with the Soviet Union with Stalin and more generally with the Communist Party. The party can never make a mistake. And therefore you don’t need independent courts, independent media, opposition parties, things like that, because then party is never wrong. You concentrate the same way. A 100% of loyalty should be to the party. A 100% of power should be in the hands of the party. The holy deal of liberal democracy is embracing fallibility. Everybody is fallible. All people, all leaders, all political parties, all institutions. This is why we need checks and balances, and we need many of them. If you have just one, then this particular check itself could make terrible mistakes. So you need, say you need a press, you need the media to serve as a check to the government. You don’t have just one newspaper or one TV station. You need many so that they can balance each other. And then the media’s not enough, so you have independent courts. You have free academic institutions, you have NGOs, you have a lot of checks and balances.
Lex Fridman

(01:08:08)
So that’s the ideologies in the leaders. What about the individual people, the millions of people that play a part in all of this that are the hosts of the stories, that are the catalyst and the components of how the story spreads? Would you say that all of us are capable of spreading any story, sort of the [inaudible 01:08:37] and idea of the, that all of us are capable of good and evil?
Yuval Noah Harari

(01:08:08)
Yes.
Lex Fridman

(01:08:42)
The line between good and evil runs the heart of every man?
Yuval Noah Harari

(01:08:46)
Yes. I wouldn’t say that every person is capable of every type of evil, but we are all fallible. There is a large element. It partly depends on the efforts we make to develop our self-awareness during life, part of it depends on moral luck. If you are born as a Christian German in the 1910s or 1920s and you grow up in Nazi Germany, that’s bad moral luck. Your chances of committing terrible things, you have a very high chance of doing it, and you can with withstand it, but it will take tremendous effort. If you are born in Germany after the war, you are morally lucky that you will not be put to such a test. You will not need to exert these enormous efforts not to commit atrocities. This is just part of history. There is an element of luck, but again, part of it is also self-awareness.
Benjamin Netanyahu

(01:09:55)
And you asked me earlier about the potential of power to corrupt, and I listened to the interview you just did with Prime Minister Netanyahu a couple of days ago. And one of the things that most struck me during the interview that you asked him, you asked him, “Are you afraid of this thing that power corrupts?” He didn’t think for a single second. He didn’t pause. He didn’t admit a tiny little level of a doubt or… “No, power doesn’t corrupt.” For me, it was a shocking and a revealing moment. And it kind of dovetails with how you began the interview, that I really liked your opening gambit. That kind of, no, really, you kind of told him, lots of people in the world are angry with you, some people hate you, they dislike you.

(01:10:51)
What do you want to tell them, to say to them? And you gave him this kind of platform. And I was very, what will he say? And he just denied it. He basically denied it. He had to cut short the interview from three hours to one hour because you had hundreds of thousands of Israelis in the streets demonstrating against him. And he goes and saying, no, everybody likes me. What are you talking about?
Lex Fridman

(01:11:18)
But on that topic, you’ve said recently that the Prime Minister Benjamin Netanyahu may go down in history as the man who destroys Israel. Can you explain what you mean by that?
Yuval Noah Harari

(01:11:30)
Yes. He is basically tearing apart the social contract that held this country together for 75 years. He’s destroying the foundations of Israeli democracy. I don’t want to go too deep unless you wants it, because I guess most of our listeners, they have bigger issues on their minds than the fate of some small country in the Middle East. But for those who want to understand what’s happening in Israel, there is really just one question to ask. What limits the power of the government? In United States, for instance, there are a lots of checks and balances that limit the power of the government. You have the Supreme Court, you have the Senate, you have the House of Representative, you have the President, you have the Constitution. You have 50 states, each state with its own Constitution and Supreme Court, and Congress and governor. If somebody wants to pass a dangerous legislation, say in the house, it’ll have to go through so many obstacles.

(01:12:35)
Like if you want to pass a law in United States taking away voting rights from Jews or from Muslims, or from African-Americans, even if it passes, even if it has a majority in the House of Representatives, it has a very, very, very small chance of becoming the law of the country because it’ll have to pass again through the Senate, through the President, through the Supreme Court, and all the federal structure. In Israel, we have just a single check on the power of the government, and that’s the Supreme Court. There is really no difference between the government and the GE legislature because whoever there is, there are no separate elections like in the US. If you win majority in the Knesset, in the Parliament, you appoint the government, that that’s very simple. And if you have 61 members of Knesset who vote, let’s say on a law to take away voting rights from Arab citizens of Israel, there is a single check that can prevent it from becoming the law of the land, and that’s the Supreme Court.

(01:13:38)
And now, the Netanyahu government is trying to neutralize or take over the Supreme Court, and they’ve already prepared a long list of laws. They already talk about it. What will happen the moment that this last check on the power is gone? They are openly trying to gain unlimited power and they openly talk about it, that once they have it, then they will take away the rights of Arabs, of LGBT people, of women, of secular Jews. And this is why you have hundreds of thousands of people in the streets. You have air force pilots saying, ‘we are stop, we stop flying.’ This is unheard of in Israel. We are still living under existential threat from Iran, from other enemies. And in the middle of this, you have air force pilots who dedicated their lives to protecting the country and they’re saying, ‘that’s it. If this government doesn’t stop what it is doing, we stopped flying.’
Lex Fridman

(01:14:47)
So as you said, I just did the interview. And as we were doing the interview, there’s protests in the streets. Do you think the protests will have an effect?
Yuval Noah Harari

(01:14:58)
I hope so very much. I’m going to many of these protests, I hope they will have an effect. If we fail, this is the end of Israeli democracy probably. This will have repercussions far beyond the borders of Israel. Israel is a nuclear power. Israel has one of the most advanced cyber capabilities in the world, able to strike basically anywhere in the world. If this country becomes a fundamentalist and militarized dictatorship, it can set fire to the entire Middle East. It can again have destabilizing effects long, far beyond the borders of Israel.
Lex Fridman

(01:15:41)
So you think without the check on power, it’s possible that the Netanyahu government holds onto power?
Yuval Noah Harari

(01:15:48)
Nobody tries to gain unlimited power just for nothing. You have so many problems in Israel and Netanyahu talks so much about Iran, and the Palestinians, and Hezbollah. We have an economic crisis. Why is it so urgent at this moment in the face of such opposition, why is it so crucial for them to neutralize the Supreme Court? They’re just doing it for the fun of it. No, they know what they are doing. They are adamant. We were not sure of it before. There was a, like a couple of months ago, they came out with this plan to take over the Supreme Court to have all these laws. And there were hundreds of thousands people in the streets, again, soldiers saying they will stop serving, a general strike in the economy. And they stopped. And they started a process of negotiations to try and reach a settlement.

(01:16:40)
And then they broke down. They stopped the negotiations and they restarted this process of legislation trying to gain unlimited power. So any doubt we had before, okay, maybe they changed their purposes. No, it’s now very clear. They are 100% focused on gaining absolute power. They are now trying a different tactic. Previously, they had all these dozens of laws that they wanted to pass very quickly within a month or two. They realized, no, there is too much opposition. So now, they’re doing what is known as salami tactics, slice by slice. Now, they’re trying to one law, if this succeeds, then they’ll pass the next one and the next one, and the next one. This is why we are now at a very crucial moment. And when you see again hundreds of thousands of people in the streets almost every day, when you’re seeing resistance with the armed forces, within the security forces, you see high-tech companies saying, we will go on strike.

(01:17:45)
They are private businesses, high-tech companies. I think it’s almost unprecedented for a private business to go on strike because what will economic success benefit us if we live under a messianic dictatorship? And again, the fuel for this whole thing is to a large extent coming from Messianic religious groups, which… Just the thought, what happens if these people have unlimited control of Israel’s nuclear arsenal, and Israel’s military capabilities and cyber capabilities. This is very, very scary. Not just for the citizens of Israel, it should be scary for people everywhere.
Lex Fridman

(01:18:30)
So it would be scary for it to go from being a problem of security and protecting the peace to becoming a religious war.
Yuval Noah Harari

(01:18:41)
It is already becoming a religious war. The war, the conflict with the Palestinians was for many years a national conflict, in essence. Over the last few years, maybe a decade or two, it is morphing into a religious conflict, which is again, a very worrying development. When nations are in conflict, you can reach some compromise. Okay, you have this bit of land, we have this bit of land. But when it becomes a religious conflict between fundamentalists, between messianic people, compromise becomes much more difficult because you don’t compromise on eternity, you don’t compromise on God. And this is where we are heading right now.
Lex Fridman

(01:19:26)
So I know you said, “It’s a small nation somewhere in the Middle East,” but it also happens to be the epicenter of one of the longest running, one of the most tense conflicts and crises in human history. So at the very least, it serves as a study of how conflict can be resolved. So what are the biggest obstacles to you to achieving peace in this part of the world?
Yuval Noah Harari

(01:19:52)
Motivation. I think it’s easy to achieve peace if you have the motivation on both sides. Unfortunately the present juncture, there is not enough motivation on either side, either the Palestinian or Israeli side. Peace… In mathematics, you have problems without solutions. You can prove mathematically that this mathematical problem has no solution. In politics, there is no such thing. All problems have solutions if you have the motivation. But motivation is the big problem. And again, we can go into the reasons why, but the fact is that on neither side is there enough motivation. If there was motivation, the solution would’ve been easy.
Lex Fridman

(01:20:41)
Is there an important distinction to draw between the people on the street and the leaders in power in terms of motivation? So are most people motivated and hoping for peace and the leaders are motivated and incentivized to continue war?
Yuval Noah Harari

(01:21:01)
I don’t think so.
Lex Fridman

(01:21:01)
Or the people also?
Yuval Noah Harari

(01:21:03)
I think it’s a deep problem. It’s also the people, it’s not just the leaders.
Lex Fridman

(01:21:07)
Is it even a human problem of literally hate in people’s heart?
Yuval Noah Harari

(01:21:12)
Yeah, there is a lot of hate. One of the things that happened in Israel over the last 10 years or so, Israel became much stronger than it was before, largely thanks to technological development. And it feels that it no longer needs to compromise. Again, there are many reasons for it, but some of them are technological. Being one of the leading powers in cyber, in AI, in high-tech, we have developed very sophisticated ways to more easily control the Palestinian population. In the early 2000s, it seemed that it is becoming impossible to control millions of people against their will. It took too much power. It spilled too much blood on both sides. So there was an impression, ‘oh, this is becoming untenable.

(01:22:10)
And there are several reasons why it changed, but one of them was new technology. Israel developed very sophisticated surveillance technology that has made it much easier for Israeli security forces to control 2.5 million Palestinians in the West Bank against their will with a lot less effort, less boots on the ground, also less blood. And Israel is also now exporting this technology to many other regimes around the world. Again, I heard Netanyahu speaking about all the wonderful things that Israeli is exporting to the world. And it’s true, we are exporting some nice things. Water systems and tomato, new kinds of tomato. We are also exporting a lot of weapons and especially surveillance systems sometimes to unsavory regimes in order to control their populations.
Lex Fridman

(01:23:11)
Can you comment on, I think you’ve mentioned that the current state of affairs is the de facto three class state? Can you describe what you mean by that?
Yuval Noah Harari

(01:23:22)
Yes. For many years the kind of leading solution to the Israeli-Palestinian conflict is the two-state solution.
Lex Fridman

(01:23:28)
Can you describe what that means by the way?
Yuval Noah Harari

(01:23:30)
Yes. Two states within, between the Jordan River and the Mediterranean will have two states. Israel as a predominantly Jewish state and Palestine as a predominantly Palestinian state. Again, there were lots of discussions where the border passes, what happens with security arrangement and whatever. But this was the big solution. Israel has basically abandoned the two-state solution. Maybe they don’t say so officially the people in power, but in terms of how they actually, what they do on the ground, they abandoned it. Now they are effectively promoting the three class solution, which means there is just one country and one government, and one power between the Mediterranean and the Jordan River, but you have three classes of people living there. You have Jews who enjoy full rights, all the rights. You have some Arabs who are Israeli citizens and have some rights. And then you have the other Arabs, the third class who have basically no civil rights and limited human rights. And that, that’s… Again, nobody would openly speak about it. But effectively, this is the reality on the ground already.
Lex Fridman

(01:24:42)
So there’s many, and I’ll speak with then Palestinians who characterize this as a de facto one state apartheid. Is it, do you agree with this?
Yuval Noah Harari

(01:24:51)
I would take issue. I would take issue with the term apartheid. Generally speaking as a historian, I don’t really like historical analogies because there are always differences, key differences. The biggest difference between the situation here and the situation in South Africa in the time of the Apartheid is that black South Africans did not deny the existence of South Africa and did not call for the destruction of South Africa. They had a very simple goal. They had a very simple demand. We want to be equal citizens of this country. That’s it. And the apartheid regime was, ‘no, you can’t be equal citizens.’ Now in Israel-Palestine, it’s different.

(01:25:35)
The Palestinians, many of them don’t recognize the existence of Israel. Don’t or are not willing to recognize it. And they don’t demand to be citizens of Israel. They demand some of them to destroy it and replace it with the Palestinian state. Some of them demand a separate state. But if the Palestinians would adopt the same policy as the black South Africans, if you have the Palestinians coming and saying, okay, forget about it. We don’t want to destroy Israel. We don’t know a Palestinian country. We have a very simple request, a very simple demand. Give us our full rights. We also want to vote to the Knesset. We also want to get the full protection of the law. That’s it, that’s our only demand. Israel will be in deep, deep trouble at that moment, but we are not there.
Lex Fridman

(01:26:28)
I wonder if there will ever be a future when such a thing happens where everybody, the majority of people, Arab and Jew, Israeli and Palestinian accept the one-state solution and say, we want equal rights.
Yuval Noah Harari

(01:26:44)
Never say never in history. It’s not coming anytime soon from either side. When you look at the long term of history, one of the curious things you see, and that’s what makes us different, human groups from animal species. Gorillas and chimpanzees, they’re separate species, they can never merge. Cats and dogs will never merge. But different national and religious groups in history, even when they hate each other, surprisingly, they sometimes end by merging. If you look at Germany for instance, so for centuries you had Prussians and Bavarian and Saxons who fought each other ferociously and hated each other. And there are sometimes also different religions, Catholics, Protestants. The worst war in European history, according to some measures, was not the Second World War or the First World War, it was the 30 years war waged largely on German soil between Germans, Protestants, and Catholics. But eventually, they united to form a single country. You saw the same thing, I don’t know, in Britain. English and Scotts for centuries hated and fought each other ferociously, eventually coming together. Maybe it’ll break up again, I don’t know. But the power of the kind of forces of merger in history, you are very often influenced by the people you fight, by the people you even hate more than by almost anybody else.
Peace in Ukraine
Lex Fridman

(01:28:18)
So if we apply those ideas, the ideas of this part of the world to another part of the world that’s currently in war, Russia and Ukraine, from what you learned here, how do you think peace can be achieved in Ukraine?
Yuval Noah Harari

(01:28:35)
Oh, peace can be achieved any moment. It’s motivation. In this case, it’s just one person. Putin just need to say, that’s it. The Ukrainians, they don’t demand anything from Russia. Just go home, that’s the only thing they want. They don’t want to conquer any bit of Russian territory. They don’t want to change the regime in Moscow, nothing. They just tell the Russians, go home. That’s it. And of course, again, motivation. How do you get somebody like Putin to admit that he made a colossal mistake, a human mistake, an ethical mistake, a political mistake in starting this war? This is very, very difficult. But in terms of what would the solution look like? Very simple. The Russians go home. End of story.
Lex Fridman

(01:29:21)
Do you believe in the power of conversation between leaders to sit down as human beings and agree? First of all, what home means because we humans draw lines?
Yuval Noah Harari

(01:29:37)
That’s true. I believe in the power of conversation. The big question to ask is where? Where do conversations, real conversations take place? And this is tricky. One of the interesting things to ask about any conflict, about any political system is where do the real conversations take place? And very often, they don’t play take place in the places you think that they are. But think about American politics. When the country was founded in the late 18th century, people understood holding conversation between leaders is very important for the functioning of democracy. We’ll create a place for that, that’s called Congress. This is where leaders are supposed to meet and talk about the main issues of the day. Maybe there was a time sometime in the past when this actually happened, when you had two factions holding different ideas about foreign policy or economic policy and they met in Congress, and somebody would come and give a speech and the people all on the other side would say, “Hey, that’s interesting. I haven’t thought about it. Yes, maybe we can agree on that.”

(01:30:49)
This is no longer happening in Congress. Nobody, I don’t think there is any speech in Congress that causes anybody on the other side to change their opinion about anything. So this is no longer a place where real conversations take place. The big question about American democracy is, is there a place where real conversations which actually change people’s minds still take place? If not, then this democracy is dying also. Democracy without conversation cannot exist for long. And it’s the same question you should ask also about dictatorial regimes, like you think about Russia or China. So China has the Great Hall of the People. Well, the representatives, the supposed representative of the people meet every now and then, but no real conversation takes place there. A key question to ask about the Chinese system is, behind closed doors, let’s say in a poly bureau meeting, do people have a real conversation?

(01:31:52)
If Xi Jinping says one thing and some other big shot thinks differently, will they have the courage, the ability, the backbone to say, with all due respect, they think differently and there is a real conversation, or not? I don’t know the answer, but this is a key question. This is the difference between an authoritarian regime, it can still have different voices within it. But at a certain point, you have a personality count. Nobody dares say anything against the leader. And when it comes again to Ukraine and Russia, I don’t think that if you get, if you somehow manage to get Putin and Zelensky to the same room, when everybody knows that they are there and they, they’ll, they’ll have a moment of empathy, of human connection and they have… No, I don’t think it can happen like that. I do hope that there are other spaces where somebody like Putin can still have a real human conversation. I don’t know if this is the case. I hope so.
Lex Fridman

(01:33:00)
Well, there’s several interesting dynamics and you spoke to some of them. So one is internally with advisors, you have to have hope that there’s people that would disagree that would have a lively debate internally. Then there’s also the thing you mentioned, which is direct communication between Putin and Zelensky in private, picking up a phone, a rotary phone, old school. I still believe in the power of that. But while that’s exceptionally difficult in the current state of affairs, what’s also possible to have is a mediator like the United States or some other leader.
Yuval Noah Harari

(01:33:36)
Yeah.
Lex Fridman

(01:33:37)
Like the leader of Israel or the leader of another nation that’s respected by both, or India for example, that can have first of all individual conversations and then literally get into a room together.
Yuval Noah Harari

(01:33:51)
It is possible. I would say more generally about conversations as… It goes back a little to what I said earlier about the Marxist view of history. One of the problematic things I see today in many academic circles is that people focus too much on power. They think that the whole of history or the whole of politics is just a power structure. It’s just struggle about power. Now, if you think that the whole of history and the whole of politics is only power, then there is no room for conversation. Because if what you have is a struggle between different powerful interests, there is no point talking. The only thing that changes it is fighting. My view is that, no, it’s not all about power structures. It’s not all about power dynamics. Underneath the power structure, there are stories, stories in human minds. And this is great news, if it’s true, this is good news. Because unlike power that can only be changed through fighting, stories can sometimes, it’s not easy, but sometimes stories can be changed through talking, and that’s the hope.

(01:35:14)
I think in everything from couple therapy to nation therapy, if you think it’s power therapy, it’s all about power, there is no place for a conversation. But if to some extent it’s the stories in people minds, if you can enable one person to see the story in the mind of another person, and more importantly, if you can have some kind of critical distance from the story in your own mind, then maybe you can change it a little and then you don’t need to fight. You can actually find a better story that you can both agree to. It sometimes happens in history. Again, French and Germans fought for generations and generations. Now, they live in peace. Not because, I don’t know, they found a new planet they can share between France and Germany so now everybody has enough territory. No, they actually have less territory than previously because they lost all their overseas empires, but they managed to find a story, the European story, that both Germans and French people are happy with. So they live in peace.
Lex Fridman

(01:36:25)
I very much believe in this vision that you have of the power of stories. And one of the tools is conversations, another is books. There’s some guy that wrote a book about this, power of stories, he happens to be sitting in front of me. And that happened to spread across a lot of people, and now they believe in the power of story and narrative. Even a children’s book too, so the kids. And It’s fascinating how that spreads. Underneath your work, there’s an optimism. And I think underneath conversations is, what I tried to do is an optimism, that it’s not just about power struggles.
Yuval Noah Harari

(01:37:05)
Yeah.
Lex Fridman

(01:37:05)
That it’s about stories which is like a connection between humans and together kind of evolving these stories that maximize hap or minimize suffering in the world.
Yuval Noah Harari

(01:37:18)
Yeah. This is why I also, I think I admire what you are doing, that you’re going to talk with some of the most difficult characters around in the world today, and with this basic belief that by talking maybe we can move them an inch, which is a lot when it comes to people with so much power. I think one of the biggest success stories in modern history, I would say, is feminism. Because feminism believed in the power of stories, not so much in the power of violence, of armed conflict. By many measures, feminism has been maybe the most successful social movement of the 20th century and maybe of the modern age. The systems of oppression, which were in place throughout the world for thousands of years, and they seem to be just natural, eternal. You had all these religious movements, all these political revolutions. And one thing remained constant, and this is the patriarchal system and the oppression of women.

(01:38:27)
And then feminism came along. And you had leaders like Lenin, like Mao saying that if you want to make a big social change, you must use violence. Power comes from the barrel of the gun, of a gun. If you want to make an omelet, you need to break eggs, and all these things. And the feminist said, no, we won’t use the power of the gun. We will make an omelet without breaking any eggs. And they made a much better omelet than Lenin or Mao, or any of these violent revolutionaries. I don’t think that they, [inaudible 01:39:04]-
Yuval Noah Harari

(01:39:00)
… Revolutionaries.

(01:39:01)
I don’t think that they … They certainly didn’t start any wars or build any gulags. I don’t think they even murdered a single politician. I don’t think there was any political assassination anywhere by feminists. There was a lot of violence against them, both verbal but also physical, and they didn’t reply by waging violence, and they succeeded in changing this deep structure of oppression in a way which benefited not just women, but also men.

(01:39:39)
So this gives me hope that, it’s not easy, in many cases we fail, but it is possible sometimes in history to make a very, very big change, positive change mainly by talking and demonstrating and changing the story in people’s minds and not by using violence.
Lex Fridman

(01:40:01)
It’s fascinating that feminism and communism and all these things happened in the 20th century. So many interesting things happen in the 20th century. So many movements, so many ideas, nuclear weapons, all of it. Computers. It just seems like a lot of stuff really quickly percolated and it’s accelerating.
Yuval Noah Harari

(01:40:19)
It’s still accelerating. I mean, history is just accelerating for centuries. And the 20th century, we squeezed into it things that previously took thousands of years. And now, I mean, we are squeezing it into decades.
Lex Fridman

(01:40:32)
And you very well could be one of the last historians, human historians to have ever lived.
Yuval Noah Harari

(01:40:38)
Could be. I think our species, homo sapiens. I don’t think we’ll be around in a century or two. We could destroy ourselves in a nuclear war, through ecological collapse, by giving too much power to AI that goes out of our control. But if we survive, we’ll probably have so much power that we will change ourselves using various technologies so that our descendants will no longer be homo sapiens like us. They will be more different from us than we are different from Neanderthals. So maybe they’ll have historians, but it will no longer be human historians or homo sapien historians like me.

(01:41:24)
I think it’s an extremely dangerous development. And the chances that this will go wrong, that people will use the new technologies trying to upgrade humans, but actually downgrading them, this is a very, very big danger. If you let corporations and armies and ruthless politicians change humans using tools like AI and bioengineering, it’s very likely that they will try to enhance a few human qualities that they need, like intelligence and discipline, while neglecting what are potentially more important human qualities, like compassion, like artistic sensitivity, like spirituality …

(01:42:13)
If you give Putin, for instance, bioengineering and AI and brain computer interfaces, he’s likely to want to create a race of super soldiers who are much more intelligent and much more stronger and also much more disciplined and never rebel and march on Moscow against him. But he has no interest in making them more compassionate or more spiritual. So the end result could be a new type of humans, a downgraded humans, who are highly intelligent and disciplined, but have no compassion and no spiritual depth.

(01:42:58)
And this is one … For me, this is the dystopia, the apocalypse. When people talk about the new technologies and they have this scenario of The Terminator, robots lying in the street shooting people, this is not what worries me. I think we can avoid that. What really worries me is using … The corporations, armies, politicians will use the new technologies to change us in a way which will destroy our humanity, or the best parts of our humanity.
Lex Fridman

(01:43:31)
And one of those ways could be removing compassion.

(01:43:33)
Another way that really worries me, for me is probably more likely, is a brave new world kind of thing that sort of removes the flaws of humans, maybe it removes the diversity in humans, and makes us all kind of these dopamine chasing creatures that just kind of maximize enjoyment in the short term, which kind of seems like a good thing maybe in the short term, but it creates a society that doesn’t think, that doesn’t create, that just is sitting there enjoying itself at a more and more rapid pace, which seems like another kind of society that could be easily controlled by a centralized center of power.

(01:44:20)
But the set of dystopias that we could arrive at through this if they’re allowing corporations to modify humans is vast, and we should be worried about that.

(01:44:32)
It seems like humans are pretty good as we are. All the flaws, all of it together.
Yuval Noah Harari

(01:44:40)
We are better than anything that we can intentionally design at present. Like any intentionally designed humans at the present moment is going to be much, much worse than us. Because basically, we don’t understand ourselves. I mean, as long as we don’t understand our brain, our body, our mind, it’s a very, very bad idea to start manipulating a system that you don’t understand deeply. And we don’t understand ourselves.
Conspiracy theories
Lex Fridman

(01:45:07)
So I have to ask you about an interesting dynamic of stories. You wrote an article two years ago titled, ‘When The World Seems Like One Big Conspiracy: How Understanding The Structure of Global Cabal Theories Can Shed Light On Their Allure And Their Inherent Falsehood.’.

(01:45:25)
What are global cabal theories and why do so many people believe them? 37% of Americans, for example.
Yuval Noah Harari

(01:45:32)
Well, the global cabal theory, it has many variations, but basically there is a small group of people, a small cabal that secretly controls everything that is happening in the world. All the wars, all the revolutions, all the epidemics, everything that is happening is controlled by this very small group of people, who are of course evil and have bad intentions. And this is a very well known story. It’s not new. It’s been there for thousands of years.

(01:46:00)
It’s very attractive because, first of all, it’s simple. You don’t need to understand everything that happens in the world, you just need to understand one thing. The war in Ukraine, the Israeli/Palestinian conflict, 5G technology, COVID-19; it’s simple. There is this global cabal. They do all of it.

(01:46:21)
And also, it enables you to shift all the responsibility to all the bad things that are happening in the world to this small cabal. ” It’s the Jews, it’s the Free Masons. It’s not us.”

(01:46:33)
And also, it creates this fantasy, utopian fantasy. “If we only get rid of the small cabal, we’ve solved all the problems of the world. Salvation.” The Israeli/Palestinian conflict, the war in Ukraine, the epidemics, poverty, everything is solved just by knocking out this small cabal.

(01:46:53)
So again, it’s simple, it’s attractive, and this is why so many people believe it. Again, it’s not new. Nazism was exactly this. Nazism began as a conspiracy theory. We don’t call Nazism a conspiracy theory because, “Oh, it’s a big thing. It’s an ideology.” But if you look at it, it’s a conspiracy theory. The basic Nazi idea was that Jews control the world. Get rid of the Jews, you’ve solved all the world’s problems.

(01:47:20)
Now, the interesting thing about these kind of theories; again, they tell you that even things that look to be the opposite of each other, actually they are part of the conspiracy.

(01:47:34)
So in the case of Nazism, the Nazis told people, “You have capitalism and communism. You think that they are opposite, right? Ah, this is what the Jews want you to think. Actually, the Jews control both communism; Trotsky, Marx were Jews, blah, blah, blah; and capitalism. The Rothschilds, Wall Street: it’s all controlled by the Jews.” So the Jews are fooling everybody, but actually the communists and the capitalists are part of the same global cabal.

(01:48:02)
And again, this is very attractive because, “Ah, now I understand everything. And now I also know what to do. I just give power to Hitler, he gets rid of the Jews, I’ve solved all the problems of the world.”

(01:48:15)
Now, as a historian, the most important thing I can say about these theories, they are never right. Because the global cabal theory says two things. First, everything is controlled by a very small number of people; secondly, these people hide themselves. They do it in secret.

(01:48:33)
Now, both things are nonsense. It’s impossible for people to control a small group of people, to control and predict everything, because the world is too complicated. You know, you look at a real world conspiracy, conspiracy is basically just a plan.

(01:48:49)
Think about the American invasion of Iraq in 2003. You had the most powerful superpower in the world with the biggest military, with the biggest intelligence services, with the most sophisticated … You know, the FBI and the CIA and all the agents. They invade a third rate country, a third rate power, Iraq, with this idea, “We’ll take over Iraq and we’ll control it, we’ll make a new order in the Middle East.” And everything falls apart. Their plan completely backfires. Everything they hope to achieve, they achieve the opposite. America, United States is humiliated. They caused the rise of ISIS. They wanted to take out terrorism, they created more terrorism.

(01:49:36)
Worst of all, the big winner of the war was Iran. The United States goes to war with all its power and gives Iran a victory on a silver plate. The Iranians don’t need to do anything. The Americans are doing everything for them.

(01:49:53)
Now, this is real history. Real history is when you have not a small group of people, a lot of people with a lot of power carefully planning something, and it goes completely against their plan.

(01:50:08)
And this we know from personal experience. Every time we try to plan something, a birthday party, a surprise birthday party, a trip somewhere, things go wrong. This is reality. So the idea that a small group of, I don’t know, the Jewish cabal, the Freemasons, whoever, they can really control and predict all the wars, this is nonsense.

(01:50:31)
The second thing that is nonsense is to think they can do that and still remain secret.

(01:50:37)
It sometimes happens in history that a small group of people accumulates a lot of power. If I now tell you that Xi Jinping and the heads of the CCP, the Chinese Communist Party, they have a lot of power, they control the military, the media, the economy, the universities of China; this is not a conspiracy theory. Obviously everybody knows it. Everybody knows it, because to gain so much power, you usually need publicity. Hitler gained a lot of power in Nazi Germany because he had a lot of publicity. If Hitler remained unknown working behind the scenes, he would not gain power.

(01:51:20)
So the way to gain power is usually through publicity. So secret cabals don’t gain power. And even if you gain a lot of power, nobody has the kind of power necessary to predict and control everything that happens in the world. All the time shit happens that you did not predict and you did not plan and you did not control.
Lex Fridman

(01:51:45)
The sad thing is there’s usually an explanation for everything you just said that involves a secret global cabal. The reason your vacation planning always goes wrong is because you’re not competent. There is a competent small group, ultra competent small group … I hear this with intelligence agencies; the CIA are running everything, Mossad is running everything.
Yuval Noah Harari

(01:52:09)
You see, as a historian, you get to know how many blunders these people do. They are so … They’re capable, but they’re so incompetent in so many ways.

(01:52:19)
Again, look at the Russian invasion of Ukraine. Before the war, people thought, oh, Putin was such a genius, and the Russian army was one of the strongest armies in the world. This is what Putin thought. And it completely backfired.
Lex Fridman

(01:52:32)
Well, a cabal explanation there would be there’s a NATO-driven United States military industrial complex that wants to create chaos and incompetence.
Yuval Noah Harari

(01:52:43)
So they put a gun to Putin’s head and told him, “Vladimir, if you don’t invade, we shoot you?” How did they cause Putin to invade Ukraine?
Lex Fridman

(01:52:50)
This is the thing about conspiracy theories is there’s usually a way to explain everything.
Yuval Noah Harari

(01:52:55)
It’s like religion. You can always find explanation for everything. And in the end, it’s intellectual integrity. If you insist, whenever people confront you with evidence, with finding some very, very complicated explanation for that too, you can explain everything. We know that. It’s a question of intellectual integrity.

(01:53:19)
And I’ll also say another thing. The conspiracy theories, they do get one thing right, certainly in today’s world. I think they represent an authentic and justified fear of a lot of people that they are losing control of their lives, they don’t understand what is happening. And this I think is not just a legitimate fear, this is an important fear. They are right. We are losing control of our lives, we are facing really big dangers, but not from a small cabal of fellow humans.

(01:53:57)
The problem with many of these conspiracy theories that, yes, we have a problem with new AI technology, but if you now direct the fire against certain people, so instead of all humans cooperating against our real common threats, whether it’s the rise of AI, whether it’s global warming, you are only causing us to fight each other.

(01:54:25)
And I think that the key question that people who spread these ideas; I mean, many of them, they honestly believe. It’s not malicious. They honestly believe in these theories; is do you want to spend your life spreading hate towards people, or do you want to work on more constructive projects?

(01:54:46)
I think one of the big differences between those who believe in conspiracy theories and people who warn about the dangers of AI, the dangers of climate change, we don’t see certain humans as evil and hateful. The problem isn’t humans, the problem is something outside humanity. Yes, humans are contributing to the problem, but ultimately the enemy is external to humanity. Whereas conspiracy theorists usually claim that a certain part of humanity is the source of all evil, which leads them to eventually think in terms of exterminating this part of humanity, which leads sometimes to historical disasters like Nazism.
Lex Fridman

(01:55:40)
So it can lead to hate, but it can also lead to cynicism, apathy that basically says, “It’s not in my power to make the world better,” so you don’t actually take action.
Yuval Noah Harari

(01:55:51)
I think it is within the power of every individual to make the world a little bit better. You can’t do everything. Don’t try to do everything. Find one thing in your areas of activity, a place where you have some agency, and try to do that, and hope that other people do their bit. And if everybody do their bit, we’ll manage. And if we don’t, we don’t, but at least we try.
Lex Fridman

(01:56:19)
You have been part of conspiracy theories. I find myself recently becoming part of conspiracy theories. Is there advice you can give of how to be a human being in this world that values truth and reason while watching yourself become part of conspiracy theories? At least from my perspective, it seems very difficult to prove to the world that you’re not part of a conspiracy theory.

(01:56:46)
I, as you said, have interviewed Benjamin Netanyahu recently, I don’t know if you’re aware. But doing such things will also … You now pick up a new menu of items, a new set of conspiracy theories you’re now a part of. And I find it very frustrating because it makes it very difficult to respond, because I sense that people have the right intentions, like we said, they have a nervousness, a fear of power and the abuses of power; as do I. So I find myself in a difficult position that I have nothing to show to prove that I’m not part of such a conspiracy theory.
Yuval Noah Harari

(01:57:31)
I think ultimately you can’t. We can’t. I mean, it’s like proving consciousness. You can’t. That’s just the situation. Whatever you say can and will be used against you by some people. So this fantasy, “If I only say this, if I only show them that, if I only have this data, they will see I’m okay,” it doesn’t work like that.

(01:57:56)
I think to keep your sanity in this situation, first of all, it’s important to understand that most of these people are not evil. They are not doing it on purpose. Many of them really believe that there is some very nefarious, powerful conspiracy which is causing a lot of harm in the world, and they’re doing a good thing by exposing it and making people aware of it and trying to stop it. If you think that you are surrounded by evil, you are falling into the same rabbit hole, you’re falling into the same paranoid state of mind, “Oh, the world is full of these evil people that … ” No. Most of them are good people.

(01:58:37)
And also, I think we can empathize with some of the key ideas there, which I share, that yes, it’s becoming more and more difficult to understand what is happening in the world. There are huge dangers in the world, existential dangers to the human species. But they don’t come from a small cabal of Jews or gay people or feminists or whatever. They come from much more diffused forces, which are not under the control of any single individual.

(01:59:15)
We don’t have to look for the evil people. We need to look for human allies in order to work together against, again, the dangers of AI, the dangers of bioengineering, the dangers of climate change. And when you wake up in the morning, the question is, do you want to spend your day spreading hatred or do you want to spend your day trying to make allies and work together?
AI safety
Lex Fridman

(01:59:46)
Let me ask you kind of a big philosophical question about AI and the threat of it. Let’s look at the threat side.

(01:59:54)
So folks like Eliezer Yudkowsky worry that AI might kill all of us. Do you worry about that range of possibilities where artificial intelligence systems in a variety of ways might destroy human civilization?
Yuval Noah Harari

(02:00:13)
Yes. I talk a lot about it, about the dangers of AI. I sometimes get into trouble because I depict these scenarios of how AI becoming very dangerous, and then people say that I’m encouraging these scenarios. But I’m talking about it as a warning.

(02:00:29)
I’m not so terrified of the simplistic idea. Again, The Terminator scenario of robots running in the streets shooting everybody. I’m more worried about AI accumulating more and more power and basically taking over society, taking over our lives, taking power away from us until we don’t understand what is happening and we lose control of our lives and of the future.

(02:00:59)
The two most important things to realize about AI; you know, so many things are being said now about AI, but I think there are two things that every person should know about AI.

(02:01:09)
First is that AI is the first tool in history that can make decisions by itself. All previous tools in history couldn’t make decisions. This is why they empowered us. You invent a knife, you invent an atom bomb; the atom bomb cannot decide to start a war, cannot decide which city to bomb. AI can make decisions by itself. Autonomous weapon systems can decide by themselves who to kill, who to bomb.

(02:01:43)
The second thing is that AI is the first tool in history that can create new ideas by itself. The printing press could print our ideas, but could not create new ideas. AI can create new ideas entirely by itself. This is unprecedented.

(02:02:03)
Therefore, it is the first technology in history that instead of giving power to humans, it takes power away from us. And the danger is that it will increasingly take more and more power from us until we are left helpless and clueless about what is happening in the world.

(02:02:24)
And this is already beginning to happen in an accelerated pace. More and more decisions about our lives, whether to give us a loan, whether to give us a mortgage, whether to give us a job are taken by AI, and more and more of the ideas, of the images, of the stories that surround us and shape our minds, our world are produced, are created by AI, not by human beings.
Lex Fridman

(02:02:52)
If you can just linger on that, what is the danger of that? That more and more of the creative side is done by AI? The idea generation? Is it that we become stale in our thinking? Is it that that idea generation is so fundamental to the evolution of humanity?
Yuval Noah Harari

(02:03:12)
But we can’t resist the ideas.
Lex Fridman

(02:03:12)
Ah.
Yuval Noah Harari

(02:03:14)
To resist an idea, you need to have some vision of the creative process.
Lex Fridman

(02:03:20)
Yeah.
Yuval Noah Harari

(02:03:20)
Now, this is a very old fear. You go back to Plato’s Cave, this idea that people are sitting chained in a cave and seeing shadows on a screen, on a wall, and thinking, “This is reality.” You go back to Descartes and he has this thought experiment of the demon, and Descartes asks himself, “How do I know that any of this is real? Maybe there is a demon who is creating all of this and is basically enslaving me by surrounding me with these illusions.” You go back to Buddha, it’s the same question; what if we are living in a world of illusions, and because we have been living in it throughout our lives, all our ideas, all our desires, how we understand ourself, this is all the product of the same illusions?

(02:04:13)
And this was a big philosophical question for thousands of years. Now it’s becoming a practical question of engineering, because previously all the ideas, as far as we know … Maybe we are living inside a computer simulation of intelligent rats from the planet [inaudible 02:04:31]. If that’s the case, we don’t know about it. But taking what we do know about human history until now, all the, again, stories, images, paintings, songs, operas, theater, everything we’ve encountered and shaped our minds was created by humans.

(02:04:49)
Now, increasingly, we live in a world where more and more of these cultural artifacts will be coming from an alien intelligence. Very quickly we might reach a point when most of the stories, images, songs, TV shows, whatever are created by an alien intelligence.

(02:05:10)
And if we now find ourselves inside this kind of world of illusions created by an alien intelligence that we don’t understand, but it understands us, this is a kind of spiritual enslavement that we won’t be able to break out of because it understands us. It understands how to manipulate us, but we don’t understand what is behind this screen of stories and images and songs.
Lex Fridman

(02:05:46)
So if there’s a set of AI systems that are operating in the space of ideas, they’re far superior to ours, and it’s opaque to us, we’re not able to see through, how does that change the pursuit of happiness, the human pursuit of happiness, life? Where do we get joy if we’re surrounded by AI systems that are doing most of the cool things humans do much better than us?
Yuval Noah Harari

(02:06:16)
You know, some of the things, it’s okay that the AI’s will do them. Many human tasks and jobs, they’re drudgery, they are not fun, they are not developing us emotionally or spiritually. It’s fine if the robots take over. I don’t know, I think about the people in supermarkets or grocery stores that spend hours every day just passing items and charging you the money. I mean, if this can be automated, wonderful. We need to make sure that these people then have better jobs, better means of supporting themselves, and developing their social abilities, their spiritual abilities.

(02:07:04)
And that’s the ideal world that AI can create, that it takes away from us the things that it’s better if we don’t do them and allows us to focus on the most important things and the deepest aspects of our nature, of our potential.

(02:07:26)
If we give AI control of the sphere of ideas, at this stage, I think it’s very, very dangerous, because it doesn’t understand us. AI at present is mostly digesting the products of human culture. Everything we’ve produced over thousands of years, it eats all of these cultural products, digests it, and starts producing its own new stuff. But we still haven’t figured out ourselves in our bodies, our brains, our minds, our psychology. So an AI based on our flow and understanding of ourselves is a very dangerous thing.

(02:08:14)
I think that we need, first of all, to keep developing ourselves. If for every dollar and every minute that we spend on developing AI, artificial intelligence, we spend another dollar and another minute in developing human consciousness, the human mind will be okay. The danger is that we spent all our effort on developing an AI at the time we don’t understand ourselves, and then letting the AI take over. That’s a road to a human catastrophe.
Lex Fridman

(02:08:51)
Does it surprise you how well large language models work?
Yuval Noah Harari

(02:08:51)
Yes.
Lex Fridman

(02:08:54)
I mean, has it modified your understanding of the nature of intelligence?
Yuval Noah Harari

(02:08:58)
Yes. I mean, I’ve been writing about AI for like eight years now and engaged with all these predictions and speculations, and when it actually came, it was much faster and more powerful than I thought it would be. I didn’t think that we would have, in 2023, an AI that can hold a conversation that you can’t know if it’s a human being or an AI, that can write beautiful texts in … I mean, I read the texts written by AI, and the thing that strikes me most is the coherence. People think, “Oh, it’s nothing. They just take ideas from here and there, words from here and there, and put it … ” No, it’s so coherent. I mean, you read in not sentences, you read paragraphs, you read entire texts, and there is logic, there is a structure.
Lex Fridman

(02:09:54)
It’s not only coherent, it’s convincing.
Yuval Noah Harari

(02:09:57)
Yes. It makes sense.
Lex Fridman

(02:09:58)
And the beautiful thing about it that has to do with your work; it doesn’t have to be true, and it often gets facts wrong, but it still is convincing. And it is both scary and beautiful-
Yuval Noah Harari

(02:10:10)
Yes.
Lex Fridman

(02:10:10)
… That our brains love language so much that we don’t need the facts to be correct. We just need it to be a beautiful story.
Yuval Noah Harari

(02:10:21)
Yep. That’s been the secret of politics and religion for thousands of years, and now it’s coming with AI.
Lex Fridman

(02:10:29)
So you as a person who has written some of the most impactful words ever written in your books, how does that make you feel that you might be one of the last effective human writers?
Yuval Noah Harari

(02:10:42)
That’s a good question.
Lex Fridman

(02:10:44)
First of all, do you think that’s possible?
Yuval Noah Harari

(02:10:45)
I think it is possible. I’ve seen a lot of examples of AI being told, “Write like Yuval Noah Harari,” and what it produces.
Lex Fridman

(02:10:54)
Has it ever done better than you think you could have written yourself?
Yuval Noah Harari

(02:10:58)
I mean, on the level of content of ideas, no. There are things I say, “I would never say that.” But when it comes to the … You know, there is … Again, the coherence and the quality of writing is such that I say it’s unbelievable how good it is. And who knows? In 10 years, in 20 years, maybe it can do better, even on, according to certain measures, the level of content.
Lex Fridman

(02:11:31)
So that people would be able to do a style transfer, do a, in the style of Yuval Noah Harari, write anything. Write why I should have ice cream tonight and make it convincing.
Yuval Noah Harari

(02:11:45)
I don’t know if I have anything convincing to say about these things, but-
Lex Fridman

(02:11:47)
I think you would be surprised. I think you’d be surprised. It could be an evolutionary biology explanation for why-
Yuval Noah Harari

(02:11:53)
Yeah. Ice cream is good for you.
Lex Fridman

(02:11:54)
Yeah.

(02:11:55)
So I mean, that changes the nature of writing.
Yuval Noah Harari

(02:11:59)
Ultimately, I think it goes back-
Yuval Noah Harari

(02:12:00)
Ultimately, I think it goes back… Much of my writing is suspicious of itself. I write stories about the danger of stories. I write about intelligence, but highlighting the dangers of intelligence. In terms of power, human power comes from intelligence and from stories. But I think that the deepest and best qualities of humans are not intelligence and not storytelling and not power. Again, with all our power, with all our cooperation, with our intelligence, we are on the verge of destroying ourselves and destroying much of the ecosystem.

(02:12:50)
Our best qualities are not there. Our best qualities are non-verbal. Again, they come from things like compassion, from introspection. And introspection, from my experience, is not verbal. If you try to understand yourself with words, you will never succeed. There is a place where you need the words, but the deepest insights, they don’t come from words. And you can’t write about it. Again, it goes back to Wittgenstein, to Buddha, to so many of these sages before, that these are the things we are silent about.
Lex Fridman

(02:13:29)
But eventually you have to project it. As a writer, you have to do the silent introspection, but projected onto a page.
Yuval Noah Harari

(02:13:37)
Yes, but you still have to warn people, you will never find the deepest truth in a book. You will never find it in words. You can only find it, I think, in direct experience, which is non-verbal, which is pre-verbal.
Lex Fridman

(02:13:53)
In the silence of your own mind.
Yuval Noah Harari

(02:13:55)
Yes.
Lex Fridman

(02:13:55)
Somewhere in there.
Yuval Noah Harari

(02:13:56)
Yes.
How to think
Lex Fridman

(02:13:58)
Well, let me ask you a silly question then, a ridiculously big question. You have done a lot of deep thinking about the world, about yourself, this kind of introspection. How do you think, by way of advice, but just practically speaking, day to day, how do you think about difficult problems with the world?
Yuval Noah Harari

(02:14:22)
First of all, I take time off. The most important thing I do, I think, as a writer, as a scientist, I meditate. I spend about two hours every day in silent meditation, observing as much as possible, non-verbally, what is happening within myself. Focusing, body sensations, the breath. Thoughts keep coming up, but I try not to give them attention. Don’t try to drive them away, just let them be there in the background like some background noise. Don’t engage with the thoughts. Because the mind is constantly producing stories with words. These stories come between us and the world. They don’t allow us to see ourselves or the world. For me, the most shocking thing when I started meditating 23 years ago, I was given the simple exercise to just observe my breath coming in and out of the nostrils. Not controlling it, just observing it. And I couldn’t do it for more than 10 seconds.

(02:15:27)
For 10 seconds I would try to notice, “Oh, now the breath is coming in, it’s coming in, it’s coming in. Oh, it’s stopped coming in and now it’s going out, going out.” 10 seconds and some memory would come, some thought would come, some story about something that happened last week or 10 years ago or in the future. And the story would hijack my attention. It would take me maybe five minutes to remember, “Oh, I’m supposed to be observing my breath.” If I can’t observe my own breath because of these stories created by the mind, how can I hope to understand much more complex things, like the political situation in Israel, the Israeli-Palestinian conflict, the Russian invasion of Ukraine? If all these stories keep coming, I mean, it’s not the truth, it’s just the story your own mind created. So first thing, train the mind to be silent and just observe. So two hours every day, and I go every year for a long retreat, between one month and two months, 60 days, of just silent meditation.
Lex Fridman

(02:16:31)
Silent meditation for 60 days.
Yuval Noah Harari

(02:16:33)
Yeah. To train the mind, forget about your own stories, just observe what is really happening. And then also throughout the day, have an information diet. People are today, many people are very aware of what they feed their body, what enters their mouth. Be very aware of what you feed your mind, what enters your mind. Have an information diet. So for instance, I read long books. I do many interviews. I prefer three hours interviews to five minutes interviews. The long format, it’s not always feasible, but you can go much, much deeper. So I would say an information diet. Be very careful about what you feed your mind. Give preference to big chunks over small-
Lex Fridman

(02:17:32)
To books over Twitter.
Yuval Noah Harari

(02:17:34)
Yes, books over Twitter, definitely. And then when I encounter a problem, a difficult intellectual problem, then I let the problem lead me where it goes and not where I want it to go. If I approach a problem with some preconceived idea or solution and then try to impose it on the problem, and just find confirmation bias, just find the evidence that supports my view, this is easy for the mind to do. And you don’t learn anything new.
Lex Fridman

(02:18:13)
Do you take notes? Do you start to concretize your thoughts on paper?
Yuval Noah Harari

(02:18:19)
I read a lot. Usually I don’t take notes. Then I start writing, and when I write, I write like a torrent. Just write. Now it’s the time, you read. You [inaudible 02:18:32] meditation. Now it’s the time to write. Write. Don’t stop, just write. So I would write from memory, and I’m not afraid of formulating, say, big ideas, big theories and putting them on paper. The danger is, once it’s on paper… Not on paper, on the screen in the computer, you get attached to it. And then you start with confirmation bias to build more and more layers around it and you can’t go back. And then it’s very dangerous. But I trust myself that I have to some extent the ability to press the delete button. The most important button in the keyboard is delete. I write and then I delete. I write and then I delete Every time I come to press delete button, I feel bad. It’s a kind of pain, “Eh, I created this. It’s a beautiful idea and I have to delete it?”
Lex Fridman

(02:19:30)
But you’re still brave enough to press delete?
Yuval Noah Harari

(02:19:32)
I try. And hopefully, I do it enough times. And this is important because in the long term it enables me to play with ideas. I have the confidence to start formulating some brave idea. Most of them turn out to be nonsense, but I trust myself not to be attached, not to become attached to my own nonsense. So it gives me this room for playfulness.
Lex Fridman

(02:20:00)
I would be amiss if I didn’t ask, for people interested in hearing you talk about meditation, if they want to start meditating what advice would you give on how to start? You mentioned you couldn’t hold your attention on your breath for longer than 10 seconds at first. So how do they start on this journey?
Yuval Noah Harari

(02:20:20)
First of all, it’s a difficult journey. It’s not fun, it’s not recreational, it’s not time to relax. It can be very, very intense. The most difficult thing, at least in the meditation I practice, vipassana, which I learned from a teacher called S.N. Goenka, the most difficult thing is not the silence. It’s not the sitting for long hours. It’s what comes up. Everything you don’t want to know about yourself, this is what comes up. So it’s very intense and difficult. If you go to a meditation retreat, don’t think you’re going to relax.
Lex Fridman

(02:20:57)
So what’s the experience of a meditation retreat when everything you don’t like comes up for 30 days?
Yuval Noah Harari

(02:21:04)
It depends what comes up. Anger comes up, you’re angry. For days on end, you’re just boiling with anger. Everything makes you angry. Again, something that happens right now or you remember something from 20 years ago and you start boiling with… It’s like, I never even thought about this incident, but it was somewhere stored with a huge, huge pile of anger attached to it. And it’s now coming up and all the anger is coming up. Maybe it’s boredom. 30 days of meditation, you start getting bored. And it’s the most boring thing. Suddenly, no anger. No, it’s the most boring. Another second, and I scream. And boredom is one of the most difficult thing to deal with in life. I think it’s closely related to death. Death is boring. In many movies, death is exciting. It’s not exciting. When [inaudible 02:22:04] dies, ultimately, it’s boredom. Nothing happens.
Lex Fridman

(02:22:08)
It’s the end of exciting things.
Yuval Noah Harari

(02:22:10)
And many things in the world happen because of boredom. To some extent, people start entire wars because of boredom. People quit relationships. People quit jobs because of boredom. And if you never learn how to deal with boredom, you will never learn how to enjoy peace and quiet, because the way to peace passes through boredom. And from what I experienced with meditation, I think maybe it was the most difficult, maybe at least in the top three. Much more difficult, say, than anger or pain. When pain comes up, you feel heroic. “Hey, I’m dealing with pain.” When boredom comes up, it brings it with depression and feelings of worthlessness. And it’s nothing, I’m nothing.
Lex Fridman

(02:23:03)
The way to peace is through boredom. David Foster Wallace said the key to life is to be unborable, which is a different perspective on what you’re talking to. Is there truth to that?
Yuval Noah Harari

(02:23:18)
Yes. I mean, it’s closely related. I would say, I look at the world today, like politics. The one thing we need more than anything else is boring politicians. We have a super abundance of very exciting politicians who are doing and saying very exciting things. And we need boring politicians and we need them quickly.
Advice for young people
Lex Fridman

(02:23:43)
The way to peace is through boredom. That applies in more ways than one. What advice would you give to young people today in high school and college, how to have a successful life, how to have a successful career?
Yuval Noah Harari

(02:23:57)
What they should know, it’s the first time in history nobody has any idea how the world would look like in 10 years. Nobody has any idea how the world would look like when you grow up. Throughout history, it was never possible to predict the future. You live in the Middle Ages, nobody knows. Maybe in 10 years the Vikings will invade, the Mongols will invade, there’ll be an epidemic, there’ll be an earthquake, who knows? But the basic structures of life will not change. Most people will still be peasants. Armies would fight on horseback with swords and bows and arrows and things like that. So you could learn a lot from the wisdom of your elders. They’ve been there before and they knew what kind of basic skills you need to learn. Most people need to learn how to sow wheat and harvest wheat or rice and make bread and build a house and ride a horse and things like that.

(02:24:57)
Now we have no idea, not just about politics. We have no idea how the job market would look like in 10 years. We have no idea what skills will still be needed. You think you’re going to learn how to code because they’ll need a lot of coders in the 2030s? Think again. Maybe AI is doing all the coding. You don’t need any coders. You are going to, I don’t know, you learn to [inaudible 02:25:26] languages, you want to be a translator. Gone. And we don’t know what skills will be needed. So the most important skill is the skill to keep learning and keep changing throughout our lives, which is very, very difficult. To keep reinventing ourselves. Again, it’s in a way a spiritual practice, to build your personality, to build your mind as a very flexible mind. Traditionally, people thought about education like building a stone house with very deep foundations. Now it’s more like setting up a tent that you can fold and move to the next place very, very quickly. Because that’s the 21st century.
Lex Fridman

(02:26:21)
Which also raises questions about the future of education, what that looks like.
Love
Yuval Noah Harari

(02:26:28)
Yeah.
Lex Fridman

(02:26:29)
Let me ask you about love. What were some of the challenges, what were some of the lessons about love, about life that you learned from coming out as gay?
Yuval Noah Harari

(02:26:43)
In many ways, it goes back to the stories. I think this is one of the reasons I became so interested in stories and in their power. Because I grew up in a small Israeli town in the 1980s, early 1990s, which was very homophobic. And I basically embraced it, I breathed it. Because you could hardly even think differently. So you had these two powerful stories around. One, that God hates gay people and that he will punish them for who they are or for what they do. Secondly, that it’s not God, it’s nature. That there is something diseased or sick about it. And these people, maybe they’re not sinners, but they are sick, they are defective. And nobody wanted to identify with such a thing. If your option’s, okay, you can be a sinner, you can be a defect, what do you want? No good options there.

(02:27:53)
And it took me many years, till I was 21, to come to terms with it. I learned two things. First, about the amazing capacity of the human mind for denial and delusion. An algorithm could have told me that I’m gay when I was 14 or 15. If there is a good-looking guy and girl walking, I would immediately focus on the guy. But I didn’t connect the dots. I could not understand what was happening inside my own brain and my own mind, in my own body. It took me a long time to realize, “You know, you’re just gay.”
Lex Fridman

(02:28:36)
So that speaks to the power of social convention versus individual thought.
Yuval Noah Harari

(02:28:41)
This is the power of self-delusion. It’s not that I knew I was gay and was hiding it. I was hiding it from myself, successfully. Looking back, I don’t understand how it is possible, but I know it is possible. I knew and didn’t know at the same time. And then the other big lesson is the power of the stories, of the social conventions. Because the stories were not true. They did not make sense even on their own terms. Even if you accept the basic religious framework of the world, that there is a good God that created everything and controls everything, why would a good God punish people for love? I understand why a good God would punish people for violence, for hatred, for cruelty, but why would God punish people for love, especially when he created them that way?

(02:29:40)
So even if you accept the religious framework of the world, obviously the story that God hates gay people, it comes not from God, but from some humans who invented this story. They take their own hatred. This is something humans do all the time. They hate somebody and they say, “No, I don’t hate them. God hates them.” They throw their own hatred on God. And then if you think about the scientific framework that said that, “Oh, gays, they are against nature. They are against the laws of nature,” and so forth. Science tells us nothing can exist against the laws of nature. Things that go against the laws of nature just don’t exist. There is a law of nature that you can’t move faster than the speed of light. Now, you don’t have this minority of people who break the laws of nature by going faster than the speed of light. And then nature comes, “Nah, that’s bad. You shouldn’t do that.” That’s not how nature works.

(02:30:44)
If something goes against the laws of nature, it just can’t exist. The fact that gay people exist, and not just people. You see homosexuality among many, many mammals and birds and other animals. It exists because it is in line with the laws of nature. The idea that this is sick, that this is whatever, it comes not from nature, it comes from the human imagination. Some people, for whatever reasons, hated gay people. They said, “Oh, they go against nature.” But this is a story created by people. This is not the laws of nature. And this taught me that so many of the things that we think are natural or eternal or divine, no, they’re just human stories. But these human stories are often the most powerful forces in the world.
Lex Fridman

(02:31:39)
So what did you learn from just your personal struggle of journey through the social conventions to find one of the things that makes life awesome, which is love? So what it takes to strip away the self-delusion and the pressures of social convention, to wake up.
Yuval Noah Harari

(02:32:01)
It takes a lot of work, a lot of courage and a lot of help from other people. It’s this kind of, again, heroic idea that I can do it all by myself, it doesn’t work. Certainly with love, you need at least one more person. And I’m very happy that I found Itzik. We lived in the same small Israeli town. We lived on two adjacent streets for years. Probably went to school on the same bus for years without really encountering each other. In the end, we met on one of the first dating sites on the internet for gay people in Israel, in 2002.
Lex Fridman

(02:32:43)
You’re saying the internet works? For love.
Yuval Noah Harari

(02:32:44)
Yes. And I said bad things or dangers about technology and the internet. There are also, of course, good things. And this is not an accident. You have two kinds of minorities in history. You have minorities which are a cohesive group like Jews. That yes, you are [inaudible 02:33:04] born Jewish in, say, Germany or Russia or whatever. You are born in a small community. But as a Jewish boy, you are born to a Jewish family. You have Jewish parents, you have Jewish siblings, you are in a Jewish neighborhood, you have Jewish friends. So these kinds of minorities, they could always come together and help each other throughout history. Now, another type of minority, like gay people or more broadly, LGBTQ people, that as a gay boy, you are usually not born to a gay family with gay parents and gay siblings in a gay neighborhood. So usually you find yourself completely alone.

(02:33:43)
For most of history, one of the biggest problems for the gay community was that there was no community. How do you find one another? And the internet was a wonderful thing in this respect because it made it very easy for these kinds of diffuse communities or diffuse minorities to find each other. So me and Itzik, even though we rode the same bus together to school for years, we didn’t meet in the physical world, we met online. Because again, in the physical world, you don’t want to identify in a Israeli town in the 1980s, you ride the bus, you don’t want to say, “Hey, I’m gay, is there anybody else gay here?” That’s not a good idea. But on the internet we could find each other.
Lex Fridman

(02:34:26)
There’s another lesson in there that maybe sometimes the thing you’re looking for is right under your nose.
Yuval Noah Harari

(02:34:30)
Yeah. A very old lesson and a very true lesson in many ways. So you need help from other people to realize the truth about yourself. So of course, in love, you cannot just love abstractly. There is another person there, you need to find them. But also, we were one of the first generations who enjoyed the benefits of gay liberation, of these very difficult struggles of people who are much braver than us in the 1980s, 1970s, 1960s, who dared to question social conventions, to struggle, at sometimes a terrible price. And we benefited from it. And more broadly, we spoke earlier about the feminist movement. There would’ve been no gay liberation without the feminist movement. We also owe them for starting to change the gender structure of the world. And this is always true. You can never do it just by yourself.

(02:35:37)
Also, I look at my journey in meditation. I mean, the idea of going to meditation [inaudible 02:35:45] okay. But I couldn’t develop the meditation technique by myself. Somebody had to teach me this way of how to look inside yourself. And it’s also a very important lesson that you can’t do it just by yourself. That this fantasy of complete autonomy, of complete self-sufficiency, it doesn’t work. It tends to be a very kind of male macho fantasy. “I don’t need anybody. I can be so strong and so brave that I’ll do everything by myself.” It never works.
Lex Fridman

(02:36:26)
You need friends. You need a mentor. The very thing that makes us human is other humans.
Yuval Noah Harari

(02:36:37)
Absolutely.
Mortality
Lex Fridman

(02:36:38)
You mentioned that the fear of boredom might be a kind of proxy for the fear of death. So what role does the fear of death play in the human condition? Are you afraid of death?
Yuval Noah Harari

(02:36:50)
Yes, I think everybody are afraid of death. I mean, all our fears come out of the fear of death. But the fear of death is just so deep and difficult, usually we can’t face it directly. So we cut it into little pieces and we face just little pieces. “Oh, I lost my smartphone.” That’s a little, little, little piece of the fear of death, which is of losing everything. So I can’t deal with losing everything, I’m dealing now with losing my phone or losing a book or whatever. I feel pain. That’s a small bit of the fear of death. Somebody who really doesn’t fear death would not fear anything at all. There will be like, “Anything that happens, I can deal with it. If I can deal with death, this is nothing.”
Lex Fridman

(02:37:37)
So any fears is a distant echo of the big fear of death. Have you ever looked at it head on, caught glimpses, sort of contemplated as the Stoics do?
Yuval Noah Harari

(02:37:52)
Yes. I mean, when I was was a teenager, I constantly contemplated, trying to understand, to imagine. It was a very, very shocking and moving experience. I remember, especially in connection with national ideology, which was also very big, strong in Israel; still is. Which again comes from the fear of death. You know that you’re going to die, so you say, “Okay, I die, but the nation lives on. I live on through the nation. I don’t really die.” And you’ll hear it especially on Memorial Day, the day for fallen soldiers. So every day there’ll be in school Memorial Day for fallen soldiers who fell defending Israel in all its different wars. And all these kids would come dressed in white. And you have this big ceremony with flags and songs and dances in memory of the fallen soldiers. Again, I don’t want to sound crass, but you got the impression that the best thing in life is to be a fallen soldier.

(02:38:53)
Because even then, yes, you die, everybody dies in the end. But then you’ll have all these school kids for years and years, remembering you and celebrating you and you don’t really die. And I remember standing in these ceremonies and thinking, “What does it actually mean? Okay, so if I’m a fallen soldier now I’m a skeleton. I’m bones in this military cemetery, under this stone. Do I actually hear the kids singing all these patriotic songs? If not, how do I know they do it? Maybe they trick me. Maybe I die in the war and then they don’t sing any songs. And how does it help me?” And I realized, I was quite young at the time, that if you’re dead, you can’t hear anything, because that’s the meaning of being dead. And if you’re dead, you can’t think of anything like, “Oh, now they’re remembering,” because you are dead, that’s the meaning of being dead. And it was a shocking realization.
Lex Fridman

(02:39:48)
But it’s a really difficult realization to hold in your mind. It’s the end.
Yuval Noah Harari

(02:39:53)
I lost it over time. I mean, for many years it was a very powerful fuel, motivation for philosophical, for spiritual exploration. And I realized that the fear of death is really a very powerful drive. And over the years, especially as I meditated, it kind of dissipated. And today I sometimes find myself trying to recapture this teenage fear of death because it was so powerful, and I just can’t. And I try to make the same image. I don’t know, it’s…
Lex Fridman

(02:40:25)
Something about the teenage years. When the fire burns bright.
Yuval Noah Harari

(02:40:28)
As a teenager, I always thought that the adults, there is something wrong with the adults, because they don’t get it. I would ask my parents or teachers about it and they… “Oh yes, you die in the end, that’s it.” And on the other hand, they’re so worried about other things. There’ll be a political crisis or an economic problem or a personal problem with the bank or whatever. They’ll be so worried. But then about the fact that they’re going to die, “Ah, we don’t care about it.”
Meaning of life
Lex Fridman

(02:40:56)
That’s why you read Camus and others when you’re a teenager. You really worry about the existential questions. Well, this feels like the right time to ask the big question. What’s the meaning of this whole thing, Yuval? And you’re the right person to ask. What’s the meaning of life?
Yuval Noah Harari

(02:41:11)
Life? That’s easy.
Lex Fridman

(02:41:12)
What is it?
Yuval Noah Harari

(02:41:16)
So what life is, if you ask what life is, life is feeling things, having sensations, emotions, and reacting to them. When you feel something good, something pleasant, you want more of it. When you feel something unpleasant, you want to get rid of it. That’s the whole of life. That’s what is happening all the time. You feel things. You want the pleasant things to increase. You want the unpleasant things to disappear. That’s what life is. If you ask what is the meaning of life in a more philosophical or spiritual question, the real question to ask, what kind of answer do you expect? Most people expect a story. And that’s always the wrong answer. Most people expect that the answer to the question, “What is the meaning of life?” will be a story, like a big drama.

(02:42:15)
That this is the plot line and this is your role in the story. This is what you have to do. This is your line in the big play. You say your line, you do your thing. That’s the thing. And this is human imagination, this is fantasy. To really understand life, life is not a story. The universe does not function like a story. So I think to really understand life, you need to observe it directly in a nonverbal way. Don’t turn it into a story. And the question to start with is, what is suffering? What is causing suffering? The question, what is the meaning of life? It will take you to fantasies and delusions. We want to stay with the reality of life. And the most important question about the reality of life is what is suffering and where is it coming from?
Lex Fridman

(02:43:13)
And to answer that non-verbally, so the conscious experience of suffering?
Yuval Noah Harari

(02:43:17)
Yes. When you suffer, try to observe what is really happening when you are suffering.
Lex Fridman

(02:43:30)
Well put. And I wonder if AI will also go through that same kind of process on its way-
Yuval Noah Harari

(02:43:36)
Depends if it develop consciousness or not. At present, it’s not. It’s just words.
Lex Fridman

(02:43:41)
It will just say to you, “Please don’t hurt me, Yuval.”. Again, as I’ve mentioned to you, I’m a huge fan of yours. Thank you for the incredible work you do. This conversation’s been a long time, I think, coming. It’s a huge honor to talk to you. This was really fun. Thank you for talking today.
Yuval Noah Harari

(02:44:01)
Thank you. I really enjoyed it. And as I said, I think the long form is the best form.
Lex Fridman

(02:44:09)
Yeah, I loved it. Thank you.

(02:44:11)
Thanks for listening to this conversation with Yuval Noah Harari. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Yuval Noah Harari himself. “How do you cause people to believe in an imagined order, such as Christianity, democracy, or capitalism? First, you never admit that the order is imagined.” Thank you for listening and hope to see you next time.
Transcript for Benjamin Netanyahu: Israel, Palestine, Power, Corruption, Hate, and Peace | Lex Fridman Podcast #389
This is a transcript of Lex Fridman Podcast #389 with Benjamin Netanyahu.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
2:35 – Hate
8:15 – Judicial reform and protests
16:51 – AI
26:53 – Competition
33:34 – Power and corruption
40:45 – Peace
55:18 – War in Ukraine
59:15 – Abraham Accords
1:03:15 – History
1:08:02 – Survival

Introduction
Benjamin Netanyahu

(00:00:00)
We should never, and I never sit aside and say, oh, they’re just threatening to destroy us. They won’t do it. If somebody threatens to eliminate you as Iran is doing today, and as Hitler did then and people discounted it, well, if somebody threatens to annihilate us, take them seriously and act to prevent it early on. Don’t let them have the means to do so because that may be too late.
Lex Fridman

(00:00:26)
The following is a conversation with Benjamin Netanyahu, prime Minister of Israel, currently serving his sixth term in office. He’s one of the most influential, powerful, and controversial men in the world, leading a right-wing coalition government at the center of one of the most intense and long-lasting conflicts and crises in human history.

(00:00:47)
As we spoke, and as I speak now, large scale protests are breaking out all over Israel over this government’s proposed judicial reform that seeks to weaken the Supreme Court in a bold accumulation of power. Given the current intense political battles in Israel, our previous intention to speak for three hours was adjusted to one hour for the time being, but we agreed to speak again for much longer in the future. I will also interview people who harshly disagree with words spoken in this conversation. I will speak with other world leaders, with religious leaders, with historians and activists, and with people who have lived and have suffered through the pain of war, destruction and loss that stoke the fires of anger and hate in their heart.

(00:01:35)
For this, I will travel anywhere no matter how dangerous if there’s any chance, it may help add to understanding and love in the world. I believe in the power of conversation to do just this, to remind us of our common humanity. I know I’m under-qualified and under-skilled for these conversations, so I will often fall short and I will certainly get attacked, derided and slandered. But I will always turn the other cheek and use these attacks to learn to improve, and no matter what, never give into cynicism.

(00:02:12)
This life, this world of ours is too beautiful not to keep trying. Trying to do some good in whatever way each of us know how. I love you all.

(00:02:25)
This is The Lex Fridman Podcast. To support it please check out our sponsors in the description. And now, dear friends, here’s Benjamin Netanyahu.
Hate

(00:02:35)
You’re loved by many people here in Israel and in the world, but you’re also hated by many. In fact, I think you may be one of the most hated men in the world. So if there’s a young man or a young woman listening to this right now who have such hate in their heart, what can you say to them to one day turn that hate into love?
Benjamin Netanyahu

(00:02:58)
I disagree with the premise of your question. I think I’ve enjoyed a very broad support around the world. There are certain corners in which we have this animosity that you describe, and it sort of permeates in some of the newspapers and the news organs and so on in the United States, but it certainly doesn’t reflect the broad support that I have. I just gave an interview on an Iranian channel, 60 million viewers. I gave another one, just did a little video a few years ago, 25 million viewers from Iran. Certainly no hate there I have to tell you, not from the regime.

(00:03:45)
And when I go around the world and I’ve been around the world, people want to hear what we have to say. What I have to say as a leader of Israel whom they respect increasingly as a rising power in the world. So I disagree with that. And the most important thing that goes against what you said is the respect that we receive from the Arab world and the fact that we’ve made four historic peace agreements with Arab countries. And they made it with me, they didn’t make it with anyone else. And I respect them and they respect me and probably more to come. So I think the premise is wrong, that’s all.
Lex Fridman

(00:04:24)
Well, there’s a lot of love, yes. A lot of leaders are collaborating are –
Benjamin Netanyahu

(00:04:32)
Respect, I said not love.
Lex Fridman

(00:04:34)
Okay. All right. Well, it’s a spectrum, but there is people who don’t have good things to say about Israel, who do have hate in their heart for Israel.
Benjamin Netanyahu

(00:04:45)
Yeah.
Lex Fridman

(00:04:46)
And what can you say to those people?
Benjamin Netanyahu

(00:04:49)
Well, I think they don’t know very much. I think they’re guided by a lot of ignorance. They don’t know about Israel. They don’t know that Israel is a stellar democracy, that it happens to be one of the most advanced societies on the planet. That what Israel develops helps humanity in every field, in medicine, in agriculture and in the environment and telecoms and talk about AI in a minute. But changing the world for the better and spreading this among six continents.

(00:05:21)
We’ve sent rescue teams more than any other country in the world, and we’re one 10th of 1% of the world’s population. But when there’s an earthquake or a devastation in Haiti or in the Philippines, Israel is there. When there’s an devastating earthquake in Turkey, Israel was there. When there’s something in Nepal, Israel is there, and it’s the second country. It’s the second country after, in one case, India or after another case, the United States, Israel is there. Tiny Israel is a benefactor to all of humanity.
Lex Fridman

(00:05:57)
So you’re a student of history. If I can just linger on that philosophical notion of hate, that part of human nature. If you look at World War II, what do you learn from human nature, from the rise of the Third Reich and the rise of somebody like Hitler and the hate that permeates that?
Benjamin Netanyahu

(00:06:19)
Well, what I’ve learned is that you have to nip bad things in the bud. There’s a Latin term that says [foreign language 00:06:29], stop bad things when they’re small. And the deliberate hatred, the incitement of hatred against one community, it’s demonization, delegitimization that goes with it is a very dangerous thing.

(00:06:48)
And that happened in the case of the Jews. What started with the Jews soon spread to all of humanity. So what we’ve learned is that we should never, and I never sit aside and say, “Oh, they’re just threatening to destroy us. They won’t do it.” If somebody threatens to eliminate you as Iran is doing today, and as Hitler did then, and people discounted it, well, if somebody threatens to annihilate us, take them seriously and act to prevent it early on. Don’t let them have the means to do so because that may be too late.
Lex Fridman

(00:07:21)
So in those threats underlying that hatred, how much of it is anti-Zionism, and how much of it is anti-Semitism?
Benjamin Netanyahu

(00:07:31)
I don’t distinguish between the two. You can’t say, “Well, I’m, I’m okay with Jews, but I just don’t think there should be a Jewish state.” It’s like saying, “I’m not anti-American, I just don’t think there should be an America.” That’s basically what people are saying vis-a-vis anti-Semitism and anti-Zionism.

(00:07:49)
When you’re saying anti-Zionism you’re saying that Jewish people don’t have a right to have a state of their own. And that is a denial of a basic principle that I think completely unmasks what is involved here. Today anti-Semitism is anti-Zionism. Those who oppose the Jewish people oppose the Jewish state.
Judicial reform and protests
Lex Fridman

(00:08:15)
If we jump from human history to the current particular moment, there’s protests in Israel now about the proposed judicial reform that gives power to your government to override the Supreme Court. So the critics say that this gives too much power to you, virtually making you a dictator.
Benjamin Netanyahu

(00:08:35)
Yeah. Well, that’s ridiculous. The mere fact that you have so many demonstrations and protests, some dictatorship, huh? There’s a lot of democracy here, more rambunctious and more robust than just anywhere on the planet.
Lex Fridman

(00:08:52)
Can you still man the case that this may give too much power to the coalition government, to the prime minister, not just to you, but to those who follow?
Benjamin Netanyahu

(00:09:04)
No, I think that’s complete hogwash because I think there’s very few people who are demonstrating against this. Quite a few, quite many, don’t have an idea what is being discussed. They’re basically being sloganized. You can sloganized, you know something about not mass media right now, but the social network, you can basically feed deliberately with big data and big money, you can just feed slogans and get into people’s minds. I’m sure you don’t think I exaggerate, because you can tell me more about that.

(00:09:38)
And you can create mass mobilization based on these absurd slogans. So here’s where I come from and what we’re doing, what we’re trying to do, and what we’ve changed in what we’re trying to do. I’m a 19th century democrat in my, small D yes, in my views. That is I ask the question, “What is democracy?” So democracy is the will of the majority and the protection of the rights of, they call it the rights of the minority, but I say the rights of the individual.

(00:10:11)
So how do you balance the two? How do you avoid mobocracy? And how do you avoid dictatorship? The opposite side. The way you avoid it is something that was built essentially by British philosophers and French philosophers, but was encapsulated by the Founding Fathers of the United States. You create a balance between the three branches of government, the legislative, the executive, and the judiciary.

(00:10:41)
And this balance is what assures the balance between majority rights and individual rights. And you have to balance all of them. That balance was maintained in Israel in its first 50 years, and was gradually overtaken and basically broken by the most activist judicial court on the planet. That’s what happened here. And gradually over the last two, three decades, the court aggregated for itself the powers of the parliament and the executive. So we’re trying to bring it back into line. Bringing it back into line, into what is common in all parliamentary democracies and in the United States, doesn’t mean taking the pendulum from one side and bringing it to the other side.

(00:11:29)
We want checks and balances, not unrivaled power. Just as we said, we want an independent judiciary, but not an all powerful judiciary. That balance does not mean, bringing it back into line, doesn’t mean that you can have the parliament, our Knesset, override any decision that the Supreme Court does. So I pretty much early on said, after the judicial reform was introduced, “Get rid of the idea of sweeping override clause that would have, with 61 votes, that’s a majority of one, you can just nullify any Supreme Court decision, so let’s move it back into the center.” So that’s gone. And most of the criticism on the judicial reform was based on an unlimited override clause, which I’ve said is simply not going to happen. People are discussing something that already for six months does not exist.

(00:12:20)
The second point that we received criticism on was the structure of how do you choose Supreme Court judges? Okay, how do you choose them? And the critics of the reform are saying that the idea that elected officials should choose Supreme Court judges is the end of democracy. If that’s the case, the United States is not a democracy. Neither is France and neither are just, I don’t know, just about every democracy on the planet. So there is a view here that you can’t have the sordid hands of elected officials involved in the choosing of judges.

(00:12:59)
And in the Israeli system, the judicial activism went so far that effectively the sitting judges have an effective veto on choosing judges, which means that this is a self-selecting court that just perpetrates itself. And we want to correct that. Again, we want to correct it in a balanced way. And that’s basically what we’re trying to do. So I think there’s a lot of misinformation about that. We’re trying to bring Israeli democracy to where it was in its first 50 years. And it was a stellar democracy. It still is. Israel is a democracy, will remain a democracy, a vibrant democracy. And believe me, the fact that people are arguing and demonstrating in the streets and protesting is the best proof of that, and that’s how it’ll remain.
Lex Fridman

(00:13:49)
We spoke about tech companies offline, there’s a lot of tech companies nervous about this judicial reform. Can you speak to why large and small companies have a future in Israel?
Benjamin Netanyahu

(00:14:03)
Because Israel is a free market economy. I had something to do with that. I introduced dozens and dozens of free market reforms that made Israel move from $17,000 per capita income within very short time to $54,000. That’s nominal GDP per capita according to the IMF. And we’ve overtaken in that Japan, France, Britain, Germany.

(00:14:29)
And how did that happen? Because we unleashed the genius that we have and the initiative and the entrepreneurship that is latent in our population. And to do that, we had to create free markets. So we created that. So Israel has one of the most vibrant free market economies in the world. And the second thing we have is a permanent investment in conceptual products because we have a permanent investment in the military, in our security services, creating basically knowledge workers who then become knowledge entrepreneurs. And so we create this structure, and that’s not going to go away.

(00:15:09)
There’s been a decline in investments in high-tech globally. I think that’s driven by many factors. But the most important one is the interest rate, which I think will, it’ll fluctuate up and down. But Israel will remain a very attractive country because it produces so many knowledge workers in a knowledge based economy. And it’s changing so rapidly. The world is changing. You’re looking for the places that have innovation. The future belongs to those who innovate.

(00:15:41)
Israel is the preeminent innovation nation. It has few competitors. And if we would say, “All right, where do you have this close cross-disciplinary fermentation of various skills in areas?” I would say “It’s in Israel.” And I’ll tell you why. We used to be just telecoms because people went out of the military intelligence, RNSA, but that’s been now broad based. So you find it in medicine, you find it in biology, you find it in agritech, you find it everywhere. Everything is becoming technologized.

(00:16:17)
And in Israel, everybody is dealing in everything, and that’s a potent reservoir of talent that the world is not going to pass up. And in fact, it’s coming to us. We just had Nvidia coming here, and they decided to build a supercomputer in Israel. Wonder why? We’ve had Intel coming here and deciding now to invest $25 billion, just now, in a new plant in Israel. I wonder why? I don’t wonder why. They know why. Because the talent is here and the freedom is here. And it will remain so.
AI
Lex Fridman

(00:16:52)
You had a conversation about AI with Sam Altman of Open AI and with Elon Musk.
Benjamin Netanyahu

(00:16:57)
Yeah.
Lex Fridman

(00:16:57)
What was the content of that conversation? What’s your vision for this very highest of tech, which is artificial intelligence?
Benjamin Netanyahu

(00:17:09)
Well, first of all, I have a high regard for the people I talked to. And I understand that they understand things I don’t understand, and I don’t pretend to understand everything. But I do understand one thing. I understand that AI is developing at a geometric rate and mostly in political life and in life in general people don’t have an intuitive grasp of geometric growth. You understand things basically in linear increments. And the idea that you’re coming up a ski slope is very foreign to people. So they don’t understand it, and they’re naturally also sort of taken aback by it. Because what do you do? So I think there’s several conclusions from my conversations with them and from my other observations that I’ve been talking about for many years. I’m talking about the need-
Benjamin Netanyahu

(00:18:00)
… observations that I’ve been talking about for many years. I’m talking about the need to do this. Well, the first thing is this. There is no possibility of not entering AI with full force. Secondly, there is a need for regulation. Third, it’s not clear there will be global regulation. Fourth, it’s not clear where it ends up. I certainly cannot say that. Now, you might say, “Does it come to control us?” Okay, that’s a question. Does it come to control us? I don’t know the answer to that. I think that, as one observation that I had from these conversations is if it does come to control us, that’s probably the only chance of having universal regulation, because I don’t see anyone deciding to avoid the race and cooperate unless you have that threat. Doesn’t mean you can’t regulate AI within countries even without that understanding, but it does mean that there’s a limit to regulation because every country will want to make sure that it doesn’t give up competitive advantage if there is no universal regulation.

(00:19:19)
I think that right now, just as 10 years ago, I read a novel. I don’t read novels, but I was forced to read one by a scientific advisor. I read history, I read about economics, I read about technology. I just don’t read novels. In this, I follow Churchill. He said, “Fact is better than fiction.” Well, this fiction would become fact. It was a book, it was a novel about a Chinese/American future cyber war. I read the book in one sitting, called in a team of experts, and I said, “All right, let’s turn Israel into one of the world’s five cyber powers and let’s do it very quickly.” And we did actually. We did exactly that. I think AI is bigger than that and related to that, because it’ll affect … Well, cyber affects everything, but AI will affect it even more fundamentally. And the joining of the two could be very powerful.

(00:20:19)
So I think in Israel, we have to do it anyway for security reasons and we’re doing it. But I think, what about our databases that are already very robust on the medical records of 98% of our population? Why don’t we stick a genetic database on that? Why don’t we do other things that could bring what are seemingly magical cures and drugs and medical instruments for that? That’s one possibility. We have it, as I said, in every single field. The conclusion is this. We have to move on AI. We are moving on AI, just as we moved on cyber, and I think Israel will be one of the leading AI powers in the world. The questions I don’t have an answer to is, where does it go? How much does it chew up on jobs?

(00:21:19)
There’s an assumption that I’m not sure is true, that the two big previous revolutions in the human condition, namely the agricultural revolution and the industrial revolution, definitely produced more jobs than they consumed. That is not obvious to me at all. I mean, I could see new jobs creating, and yes, I have that comforting statement, but it’s not quite true, because I think on balance, they’ll probably consume more jobs, many more jobs than they’ll create.
Lex Fridman

(00:21:58)
At least in the short term. And we don’t know about the long term.
Benjamin Netanyahu

(00:22:01)
No, I don’t know about the long term, but I used to have the comfort being a free market guy. I always said, “We’re going to produce more jobs by, I don’t know, limiting certain government jobs.” We’re actually putting out in the market, will create more jobs, which obviously happened. We had one telecom company, a government company. When I said, “We’re going to create competition,” they said, “You’re going to run us out. We’re not going to have more workers.” They had 13,000 workers. They went down to seven, but we created another 40,000 in the other companies. So, that was a comforting thought. I always knew that was true.

(00:22:36)
Not only that. I also knew that wealth would spread by opening up the markets, completely opposite to the socialist and semi-socialist creed that they had here. They said, “You’re going to make the rich richer and the poor poorer.” No. And made everyone richer, and actually the people who entered the job market because of the reforms we did, actually became a lot richer on the lower ladders of the socioeconomic measure.

(00:23:05)
But here’s the point, I don’t know. I don’t know that we will not have what Elon Musk calls the end of scarcity. So you’ll have the end of scarcity. You’ll have enormous productivity. Very few people are producing enormous added value. You’re going to have to tax that to pass it to the others. You’re going to have to do that. That’s a political question. I’m not sure how we answer that. What if you tax and somebody else doesn’t tax? You’re going to get everybody to go there. That’s an international issue that we constantly have to deal with.

(00:23:42)
And the second question you have is, suppose you solve that problem and you deliver money to those who are not involved in the AI economy, what do they do? The first question you ask somebody whom you just met after the polite exchanges is, what do you do? Well, people define themselves by their profession. It’s going to be difficult if you don’t have a profession. People will spend more time self-searching, more time in the arts, more time in leisure. I understand that. If I have to bet, it will annihilate many more jobs than it will create and it’ll force a structural change in our economics, in our economic models, and in our politics. And I’m not sure where it’s going to go.
Lex Fridman

(00:24:40)
And that’s something we have to respond to at the nation level and just as a human civilization, both the threat of AI to just us as a human species and then the effect on the jobs. And like you said, cybersecurity.
Benjamin Netanyahu

(00:24:55)
What do you think? You think we’re going to lose control?
Lex Fridman

(00:25:00)
No, first of all, I do believe, maybe naively, that it will create more jobs than it takes.
Benjamin Netanyahu

(00:25:05)
Write that down and we’ll check it.
Lex Fridman

(00:25:07)
It’s on record.
Benjamin Netanyahu

(00:25:09)
We don’t say, “We’ll check it after our lifetime.” No, we’ll see it in a few years.
Lex Fridman

(00:25:12)
We’ll see it in a few years. I’m really concerned about cybersecurity and the nature of how that changes with the power of AI. In terms of existential threats, I think there will be so much threats that aren’t existential along the way that that’s the thing I’m mostly concerned about, versus AI taking complete control and superseding the human species. Although that is something you should consider seriously because of the exponential growth of its capabilities.
Benjamin Netanyahu

(00:25:43)
Yeah, it’s exactly the exponential growth, which we understand is before us, but we don’t really … It’s very hard to project forward.
Lex Fridman

(00:25:51)
To really understand.
Benjamin Netanyahu

(00:25:52)
That’s right. Exactly right. So I deal with what I can and where I can affect something. I tend not to worry about things I don’t control, because there’s at a certain point, there’s no point. I mean, you have to decide what you’re spending your time on. So in practical terms, I think we’ll make Israel a formidable AI power. We understand the limitation of skill, computing power and other things. But I think within those limits, I think we can make here this miracle that we did in many other things. We do more with less. I don’t care if it’s the production of water or the production of energy or the production of knowledge or the production of cyber capabilities, defense and other, we just do more with less. And I think in AI, we’re going to do a lot more with a relatively small but highly gifted population. Very gifted.
Competition
Lex Fridman

(00:26:53)
So taking a small tangent, as we talked about offline, you have a background in TaeKwonDo?
Benjamin Netanyahu

(00:27:00)
Oh, yeah.
Lex Fridman

(00:27:01)
We mentioned Elon Musk. I’ve trained with both. Just as a quick question, who are you betting on in a fight?
Benjamin Netanyahu

(00:27:08)
Well, I refuse to answer that. I will say this.
Lex Fridman

(00:27:13)
Such a politician, you are.
Benjamin Netanyahu

(00:27:14)
Yeah, of course. Here, I’m a politician. I’m openly telling you that I’m dodging the question. But I’ll say this. Actually, I spent five years in our special forces in the military, and we barely spent a minute on martial arts. I actually learned TaeKwonDo later when I came to … It wasn’t even at MIT. At MIT, I think I did karate. But when I came to the UN, I had a martial arts expert who taught me TaeKwonDo, which was interesting. Now, the question you really have to ask is, why did we learn martial arts in this special elite unit? And the answer is, there’s no point. If you saw Indiana Jones, there’s no point. You just pull the trigger. That’s simple. Now, I don’t expect anyone to pull the trigger on this combat, and I’m sure you’ll make sure that doesn’t happen.
Lex Fridman

(00:28:15)
Yeah. I mean, martial arts is bigger than just combat. It’s this journey of humility.
Benjamin Netanyahu

(00:28:21)
Oh, sure.
Lex Fridman

(00:28:23)
It’s an art form. It truly is an art. But it’s fascinating that these two figures in tech are facing each other. I won’t ask the question of who you would face and how you would do, but …
Benjamin Netanyahu

(00:28:34)
Well, I’m facing opponents all the time.
Lex Fridman

(00:28:36)
All the time?
Benjamin Netanyahu

(00:28:37)
Yeah, that’s part of life.
Lex Fridman

(00:28:41)
Not yet.
Benjamin Netanyahu

(00:28:41)
I’m not sure about that.
Lex Fridman

(00:28:42)
Are you announcing any fights?
Benjamin Netanyahu

(00:28:44)
No, no. Part of life is competition. The only time competition ends is death. But political life, economic life, cultural life is engaged continuously in creativity and competition. The problem I have with that is, as I mentioned earlier just before we began the podcast, is that at a certain point, you want to put barriers to monopoly. And if you’re a really able competitor, you’re going to create a monopoly. That’s what Peter Till says is a natural course of things. It’s what I learned basically in the Boston Consulting Group. If you are a very able competitor, you’ll create scale advantages that gives you the ability to lock out your competition. And as a prime minister, I want to assure that there is competition in the markets, so you have to limit this competitive power at a certain point, and that becomes increasingly hard in a world where everything is intermixed.

(00:29:49)
Where do you define market segments? Where do you define monopoly? How do you do that? That, actually conceptually, I find very challenging, because of all the dozens of economic reforms that I’ve made, the most difficult part is the conceptual part. Once you’ve ironed it out and you say, “Here’s what I want to do. Here’s the right thing to do,” then you have a practical problem of overcoming union resistance, political resistance, press calumny, opponents from this or that corner. That’s a practical matter. But if you have it conceptually defined, you can move ahead to reform economies or reform education or reform transportation. Fine.

(00:30:38)
In the question of the growing power of large companies, big tech companies to monopolize the markets because they’re better at it, they provide a service, they provide it at a lower cost, at rapidly declining cost. Where do you stop? Where do you stop monopoly power is a crucial question because it also becomes now a political question. If you amass enormous amount of economic power, which is information power, that also monopolizes the political process. These are real questions that are not obvious. I don’t have an obvious answer because as I said, as a 19th century Democrat, these are questions of the 21st century, which people should begin to think. Do you have a solution to that?
Lex Fridman

(00:31:27)
The solution of monopolies growing arbitrarily-
Benjamin Netanyahu

(00:31:30)
Yeah.
Lex Fridman

(00:31:31)
… unstoppably in power?
Benjamin Netanyahu

(00:31:33)
In economic power, and therefore in political power.
Lex Fridman

(00:31:36)
I mean, some of that is regulation, some of that is competition.
Benjamin Netanyahu

(00:31:40)
Do you know where to draw the line? It’s not breaking up AT&T. It’s not that simple.
Lex Fridman

(00:31:49)
Well, I believe in the power of competition, that there will always be somebody that challenges the big guys, especially in the space of AI. The more open source movements are taking hold, the more the little guy can become the big guy.
Benjamin Netanyahu

(00:32:02)
So you’re saying basically the regulatory instrument is the market?
Lex Fridman

(00:32:09)
In large part, in most part, that’s the hope. Maybe I’m a dreamer.
Benjamin Netanyahu

(00:32:13)
That’s been in many ways my policy up to now, that the best regulator is the market. The best regulator in economic activity is the market and the best regulator in political matters is the political market. That’s called elections. That’s what regulates. You have a lousy government and people make lousy decisions, well, you don’t need the wise men raised above the masses to decide what is good and what is bad. Let the masses decide. Let them vote every four years or whatever, and they throw you out.

(00:32:54)
By the way, it happened to me. There’s life after political death. There’s actually political life. I was reelected five or six times, and this is my sixth term. So I believe in that. I’m not sure that in economic matters, in the geometric growth of tech companies, that you’ll always have the little guy, the nimble mammal, that will come out and slay the dinosaurs or overcome the dinosaurs, which is essentially what you said.
Lex Fridman

(00:33:25)
Yeah, I wouldn’t count out the little guy.
Benjamin Netanyahu

(00:33:27)
You wouldn’t count out the little?
Lex Fridman

(00:33:28)
No.
Benjamin Netanyahu

(00:33:29)
Well, I hope you’re right.
Power and corruption
Lex Fridman

(00:33:31)
Well, let me ask you about this market of politics. So you have served six terms as prime minister over 15 years in power. Let me ask you again, human nature. Do you worry about the corrupting nature of power on you as a leader, on you as a man?
Benjamin Netanyahu

(00:33:48)
Not at all. Because I think that, again, the thing that drives me is nothing but the mission that I took to assure the survival and thriving of the Jewish state. That is, its economic prosperity, but its security and its ability to achieve peace with our neighbors. And I’m committed to it. I think there are many things that have been done. There are a few big things that I can still do, but it doesn’t only depend on my sense of mission. It depends on the market, as we say. It depends really on the will of the Israeli voters. And the Israeli voters have decided to vote for me again and again, even though I wield no power in the press, no power in many quarters here and so on, nothing. I mean, probably, I’m going to be very soon the longest serving prime minister in the last half century in the Western democracies. But that’s not because I amassed great political power in any of the institutions.

(00:34:56)
I remember I had a conversation with Silvio Berlusconi, who recently died, and he said to me about, I don’t know, 15 years ago, something like that, he said, “So Bibi, how many of Israel’s television stations do you have?” And I said, “None.” He said, “You have none?”
Lex Fridman

(00:35:23)
Do you have?
Benjamin Netanyahu

(00:35:24)
“Do you have?” I said, “None. I have two.” He said, “No, no. What, you mean you don’t have any that you control?” I said, “Not only do I have none that I control, they’re all against me.” So he says, “So how do you win elections with both hands tied behind your back?” And I said, “The hard way.” That’s why I have the largest party, but I don’t have many more seats than I would have if I had a sympathetic voice in the media. And Israel until recently, was dominated completely by one side of the political spectrum that often vilified me, not me, because they viewed-
Benjamin Netanyahu

(00:36:01)
… vilified me, not me, because they viewed me as representing basically the conservative voices in Israel that are majority. And so the idea that I’m an omnipotent, authoritarian dictator is ridiculous. I would say I’m not merely a champion of democracy and democratization. I believe ultimately the decision is with the voters and the voters, even though they have constant press attacks, they’ve chosen to put me back in. So I don’t believe in this thing of amassing the corrupting power of if you don’t have elections. If you control the means of influencing the voters, I understand what you’re saying, but in my case, it’s exact opposite. I have to constantly go in elections, constantly with a disadvantage that the major media outlets are very violently sometimes against me, but it’s fine. And I keep on winning. So I don’t know what you’re talking about. I would say the concentration of power lies elsewhere, not here.
Lex Fridman

(00:37:15)
Well, you have been involved in several corruption cases. How much corruption is there in Israel and how do you fight it in your own party and in Israel?
Benjamin Netanyahu

(00:37:24)
Well, you should ask a different question. What’s happened to these cases? These cases basically are collapsing before our eyes, there was recently an event in which the three judges in my case, called in the prosecution and said, “Your flagship, the so-called bribery charges is gone, doesn’t exist,” before a single defense witness was called. And it sort of tells you that this thing is evaporating. It’s quite astounding even that I have to say, was covered even by the mainstream press in Israel because it’s such an earthquake. So a lot of these charges are not a lot. These charges will prove to be nothing. I always said, “Listen, I stand before the legal process.” I don’t claim that I’m exempt from it in any way. On the contrary, I think the truth will come out and it’s coming out. And we see that not only that, but with other things.

(00:38:28)
So I think it’s kind of instructive that no politician has been more vilified. None has been put to such a, what is it? About a quarter of a billion shekels were used to scrutinize me, scour my bank accounts, sending people to the Philippines, into Mexico, into Europe, into America, and everybody using spyware, the most advanced spyware on the planet against my associates, blackmailing witnesses, telling them, “Think about your family, think about your wife. You better tell us what you want.” All that is coming out of the trial. So I would say that most people now are not asking, are no longer asking, including my opponents. It’s sort of trickling in as the stuff comes out. People are not saying, “What did Netanyahu do, because apparently he did nothing?” “What was done to him?” is something that people ask.

(00:39:31)
“What was done to him? What was done to our democracy, what was done in the attempt to put down somebody who keeps winning elections, despite the handicaps that I described? Maybe we can nail him by framing him.” And the one thing I can say about this court trial is that things are coming up and that’s very good, just objective things are coming out and changing the picture. So I would say the attempt to brand me as corrupt is falling on its face. But the thing that is being uncovered in the trial, such as the use of spyware on a politician, a politician’s surroundings to try to shake them down in investigations, put them in flea-ridden cells for 21 days. Invite their 84 year old mother to investigations without cause, bringing in their mistresses in the corridor, shaking them down, that’s what people are asking. That corruption is what they want corrected.
Peace
Lex Fridman

(00:40:46)
What is the top obstacle to peaceful coexistence of Israelis and Palestinians? Let’s talk about the big question of peace in this part of the world.
Benjamin Netanyahu

(00:40:55)
Well, I think the reason you have the persistence of the Palestinian Israeli conflict, which goes back about a century, is the persistent Palestinian refusal to recognize a Jewish state, a nation state for the Jewish people in any boundary. That’s why they opposed the establishment of the state of Israel before we had a state. Now that’s why they’ve opposed it after we had a state. They opposed it when we didn’t have Judea and Samaria, the West Bank in our hands and Gaza, and they oppose it after we have it. It doesn’t make a difference. It’s basically their persistent refusal to recognize a Jewish state in any boundaries. And I think that their tragedy is that they’ve been commandeered for a century by leadership that refused to compromise with the idea of Zionism, namely that the Jews deserve a state in this part of the world.

(00:41:49)
The territorial dispute is something else. You have a territorial dispute if you say, “Okay, you are living on this side, we’re living on that side. Let’s decide where the border is and so on.” That’s not what the argument is. The Palestinian society, which is itself fragmented, but all the factions agree, there shouldn’t be a Jewish state anywhere. They just disagree between Hamas that says, “Oh, well you should have it. We should get rid of it with terror.” And the others who say, “We know we should also use political means to dissolve it.” So that is the problem.
Lex Fridman

(00:42:28)
So even as part of a two-state solution, they’re still against the idea.
Benjamin Netanyahu

(00:42:33)
Well, they don’t want a state next to Israel. They want a state instead of Israel. And they say, “If we get a state, we’ll use it as a springboard to destroy the smaller Israeli state.” Which is what happened when Israel unilaterally walked out of Gaza and effectively established a Hamas state there. They didn’t say, “Oh good, now we have our own territory, our own state. Israel is no longer there. Let’s build peace. Let’s build economic projects. Let’s enfranchise our people.” No, they turned it basically into a terror bastion from which they fired 10,000 rockets into Israel. When Israel left Lebanon because we had terrorist attacks from there, then we had Lebanon taken over by Hezbollah, a terrorist organization that seeks to destroy Israel. And therefore every time we just walked out, what we got was not peace, we didn’t give territory for peace, we got territory for terror. That’s what we had.

(00:43:35)
And that’s what would happen as long as the reigning ideology says, “We don’t want Israel in any border.” So the idea of two states assumes that you’d have on the other side a state that wants to live in peace and not one that will be overtaken by Iran in its proxies in two seconds and become a base to destroy Israel. And therefore, I think that most Israelis today, if you ask them, they’d say it’s not going to work in that concept, so what do you do with the Palestinians? They’re still there. And unlike them, I don’t want to throw them out. They’re going to be living here and we’re going to be living here in an area, which is by the way, just to understand the area, the entire area of so-called West Bank and Israel is the width of the Washington Beltway, more or less.

(00:44:26)
Just a little more, not much more. You can’t really divide it up. You can’t say, “Well, you’re going to fly in. Who controls the airspace?” Well, it takes you about two and a half minutes to cross it with a regular 747. With a fighter plane it takes you a minute and a half, okay? So how are you going to divide the airspace? Well, you’re not going to divide it. Israel’s going to control that airspace and the electromagnetic space and so on. So security has to be in the hands of Israel. My view of how you solve this problem is a simple principle. The Palestinians should have all the powers to govern themselves and none of the powers to threaten Israel, which basically means that the responsibility for overall security remains with Israel. And from a practical point of view, we’ve seen that every time that Israel leaves a territory and takes its security forces out of an area, it immediately is overtaken by Hamas or Hezbollah or Jihadist who basically are committed to the destruction of Israel and also bring misery to the Palestinians or Arab subjects.

(00:45:40)
So I think that principle is less than perfect sovereignty because you’re taking a certain amount of sovereign powers, especially security away. But I think it’s the only practical solution. So people say, “Ah, but it’s not a perfect state.” I say, “Okay, call it what you will. Call it, I don’t know, limited sovereignty. Call it the autonomy plus. Call it whatever you want to call it.” But that’s the reality. And right now, if you ask Israelis across the political spectrum, except the very hard left, most Israelis agree with that. They don’t really debate it.
Lex Fridman

(00:46:14)
So a two-state solution where Israel controls the security of the entire region.
Benjamin Netanyahu

(00:46:18)
We don’t call it quite that. I mean there are different names, but the idea is yes, Israel controls security in the, is the entire area. It’s this tiny area between the Jordan River and the sea. I mean it’s like, you can walk it in not one afternoon. If you’re really fit, you can do it in a day, less than a day. I did.
Lex Fridman

(00:46:39)
So the expansion of settlements in the West Bank has been a top priority for this new government. So people may harshly criticize this as contributing to escalating the Israel-Palestine tensions. Can you understand that perspective, that this expansion of settlements is not good for this two-state solution?
Benjamin Netanyahu

(00:46:59)
Yeah, I can understand what they’re saying, and they don’t understand why they’re wrong. First, most Israelis who live in Judea, Samaria live in urban blocks, and that accounts for about 90% of the population. And everybody recognizes that those urban blocks are going to be part of Israel in any future arrangement. So they’re really arguing about something that has already been decided and agreed upon, really by Americans, even by Arabs, many Arabs, they don’t think that Israel is going to dismantle these blocks. You look outside the window here, and within about a kilometer or a mile from here, as you have Jerusalem, half of Jerusalem grew naturally beyond the old 1967 border. So you’re not going to dismantle half of Jerusalem. That’s not going to happen. And most people don’t expect that. Then you have the other 10% scattered in tiny, small communities, and people say, “Well, you’re going to have to take them out.” Why?

(00:48:05)
Remember that in pre-1967 Israel, we have over a million and a half Arabs here. We don’t say, “Oh, Israel has to be ethnically cleansed from its Arab citizens in order to have peace.” Of course not. Jews can live among Arabs, and Arabs can live among Jews. And what is being advanced by those people who say that we can’t live in our ancestral homeland in these disputed areas. Nobody says that this is Palestinian areas and nobody says that these are Israeli areas. We claim them, they claim them. We’ve only been attached to this land for oh, 3,500 years. But it’s a dispute, I agree. But I don’t agree that we should throw out the Arabs. And I don’t think that they should throw out the Jews. And if somebody said to you, “The only way we’re going to have peace with Israel is to have an ethnically cleansed Palestinian entity,” that’s outrageous.

(00:49:00)
If you said you shouldn’t have Jews living in, I don’t know, in suburbs of London or New York and so on, I don’t think that will play too well. The world is actually advancing a solution that says that Jews cannot live among Arabs, and Arabs cannot live among Jews. I don’t think that’s the right way to do it. And I think there’s a solution out there, but I don’t think we’re going to get to it, which is less than perfect sovereignty, which involves Israeli security, maintained for the entire territory by Israel, which involves not rooting out anybody. Not kicking out, uprooting Arabs or Palestinians. They’re going to live in enclaves in sovereign Israel and we’re going to live in probably in enclaves there, probably through transportation continuity as opposed to territorial continuity. For example, you can have tunnels and overpasses and so on that connect the various communities.

(00:49:57)
We’re doing that right now, and it actually works. I think there is a solution to this. It’s not the perfect world that people think of because that model I think doesn’t apply here. If it applies elsewhere, it’s a question. I don’t think so. But I think there’s one other thing, and that’s the main thing that I’ve been involved in. People said, “If you don’t solve the Palestinian problem, you’re not going to get to the Arab world. You’re not going to have peace with the Arab world.” Remember, the Palestinians are about 2% of the Arab world, and the other 98%, you’re not going to make peace with them. And that’s our goal.

(00:50:39)
And for a long time, people accepted that. After the initial peace treaties with Egypt, with Prime Minister Begin of the Likud and President Sadat of Egypt, and then with Jordan between Prime Minister Rabin and King Hussein. For a quarter of a century we didn’t have any more peace treaties because people said, “You got to go through the Palestinians” and the Palestinians, they don’t want a solution of the kind that I described or any kind except the one that involved the dissolution of the state of Israel.

(00:51:08)
So we could wait another half century. And I said, “No, I don’t think that we should accept the premise that we have to wait for the Palestinians because we’ll have to wait forever.” So I decided to do it differently. I decided to go directly to the Arab capitals and to make the historic Abraham Accords and essentially reversing the equation, not a peace process that goes inside out, but outside in. And we went directly to these countries and forged these breakthrough peace accords with the United Arab Emirates, with Bahrain, with Morocco and with Sudan. And we’re now trying to expand that in a quantum leap with Saudi Arabia.
Lex Fridman

(00:51:56)
What does it take to do that with Saudi Arabia, with the Saudi Crown Prince Mohammed bin Salman.
Benjamin Netanyahu

(00:52:01)
I’m a student of history, and I read a lot of history, and I read that in the Versailles discussions after World War I, President Woodrow Wilson said, “I believe in open covenants openly arrived at.” I have my correction. I believed in open covenants secretly arrived at so we’re not going to advance a Saudi-Israeli peace by having it publicly discussed. And in any case, it’s a decision of the Saudis if they want to do it, but there’s obviously a mutual interest. So here’s my view, if we try to wait for the 2% in order to get to the 98%, we’re going to fail and we have failed. If we go to the 98%, we have a much greater chance of persuading the 2%. You know why? Because the 2% the Palestinian hope to vanquish the state of Israel and not make peace with it, is based, among other things, on the assumption that eventually the 98%, the rest of the Arab world, will kick in and destroy the Jewish state, help them dissolve or destroy the Jewish state.

(00:53:08)
When that hope is taken away, then you begin to have a turn to the realistic solutions of coexistence. By the way, they’ll require compromise on the Israeli side too. And then I’m perfectly cognizant of that and willing to do that. But I think a realistic compromise will be struck much more readily when the conflict between Israel and the Arab states, the Arab world, is effectively solved. And I think we’re on that path. It was a conceptual change just like I’ve been involved in a few, I told you the conceptual battle is always the most difficult one. And I had to fight this battle to convert a semi-socialist state into a free market capitalist state. And I have to say that most people today recognize the power of competition and the benefits of free markets. So we also had to fight this battle-
Benjamin Netanyahu

(00:54:00)
… free markets. So we also had to fight this battle that said you have to go through the Palestinian straight, S-T-R-A-I-T, to get to the other places. There’s no way to avoid this, you have to go through this impassable pass. And I think that now people are recognizing that we’ll go around it and probably circle back. And that, I think, actually gives hope not only to have an Arab-Israeli peace, but circling back in Israeli-Palestinian peace. And obviously this is not something that you find in the soundbites and so on, but in the popular discussion of the press. But that idea is permeating and I think it’s the right idea, because I think it’s the only one that will work.
Lex Fridman

(00:54:50)
So expanding the circle of peace, just to linger on that requires what? Secretly talking man-to-man, human-to-human, to leaders of other nations and-
Benjamin Netanyahu

(00:55:03)
Theoretically, you’re right.
War in Ukraine
Lex Fridman

(00:55:04)
Theoretically. Okay. Well, let me ask you another theoretical question on this circle of peace. As a student of history, looking at the ideas of war and peace, what do you think can achieve peace in the war in Ukraine looking at another part of the world? If you consider the fight for peace in this part of the world, how can you apply that to that other part of the world between Russia and Ukraine now?
Benjamin Netanyahu

(00:55:38)
I think it’s one of the savage horrors of history and one of the great tragedies that is occurring. Let me say in advance that if I have any opportunity to use my contacts to help bring about an end to this tragedy, I’ll do so. I know both leaders, but I don’t just jump in and assume if there’s be a desire at a certain point because the conditions have created the possibility of helping stop this carnage, then I’ll do it. And that’s why I choose my words carefully, because I think that may be the best thing that I could do. Look, I think what you see in Ukraine is what happens if you have territorial designs on a territory by a country that has nuclear weapons. And that, to me, you see the change in the equation. Now, I think that people are loathed to use nuclear weapons, and I’m not sure that I would think that the Russian side would use them with happy abandon.

(00:56:59)
I don’t think that’s the question, but you see how the whole configuration changes when that happens. So you have to be very careful on how you resolve this conflict. So it doesn’t… well, it doesn’t go off the rails, so to speak. That’s, by the way, the corollaries here. We don’t want Iran, which is an aggressive force with just aggressive ideology of dominating first the Muslim world, and then eliminating Israel, and then becoming a global force, having nuclear weapons. It’s totally different when they don’t have it than when they do have it. And that’s why one of my main goals has been to prevent Iran from having the means of mass destruction, which will be used, atomic bombs, which they openly say will be used against us. And you can understand that. How to bring about an end to Ukraine? I have my ideas. I don’t think that’s worthwhile discussing them now because they might be required later on.
Lex Fridman

(00:58:06)
Do you believe in the power of conversation? Since you have contacts with Volodymyr Zelenskyy and Vladimir Putin, just leaders sitting in a room and discussing how the end of war can be brought about?
Benjamin Netanyahu

(00:58:19)
I think it’s a combination of that, but I think it’s the question of interest and whether you have to get both sides to a point where they think that that conversation would lead to something useful. I don’t think they’re there right now.
Lex Fridman

(00:58:37)
What part of this is just basic human ego, stubbornness all of this between leaders, which is why I bring up the power of conversation, of sitting in a room realizing we’re human beings, and then there’s a history that connects Ukraine and Russia?
Benjamin Netanyahu

(00:58:52)
I don’t think they’re in a position to enter a room right now, realistically. I mean, you can posit that it would be good if that could happen, but entering the room is sometimes more complicated than what happens in the room. And there’s a lot of pre-negotiations on the negotiation, then you negotiate endlessly on the negotiation. They’re not even there.
Lex Fridman

(00:59:11)
It took a lot of work for you to get to a handshake in the past.
Abraham Accords
Benjamin Netanyahu

(00:59:15)
It’s an interesting question. How did the peace, the Abraham Accords, how did that begin? We had decades. We had 70 years or 65 years where these people would not meet openly or even secretly with an Israeli leader. Yeah, we had the Mossad making contacts with him all the time, and so on, but how do we break the ice to the top level of leadership? Well, we broke the ice because I took a very strong stance against Iran, and the Gulf states understood that Iran is a formidable danger to them, so we had a common interest. And the second thing is that because of the economic reforms that we had produced in Israel, Israel became a technological powerhouse. And that could help their nations, not only… in terms of anything, of just bettering the life of their peoples.

(01:00:12)
And the combination of the desire to have some kind of protection against Iran or some kind of cooperation against Iran and civilian economic cooperation came to a head when I gave a speech in the American Congress, which I didn’t do lightheartedly, I had to decide to challenge a sitting American president and on the so-called Iranian deal, which I thought would pave Iran’s path with gold to be an effective nuclear power. That’s what would happen. So I went there. And in the course of giving that speech before the joint session of Congress, our delegation received calls from Gulf states who said, “We can’t believe what your prime minister is doing. He’s challenging the President of the United States.” Well, I had no choice because I thought my country’s own existence was imperiled. And remember, we always understand through changing administrations that America under… no matter what leadership is always the irreplaceable and indispensable ally of Israel and will always remain that we can have arguments as we have, but in the family, as we say in [foreign language 01:01:32], it’s the family.

(01:01:35)
But nevertheless, I was forced to take a stand. That produced calls from Gulf states that ultimately led to clandestine meetings that ultimately flowered into the Abraham Accords then. And I think we’re at a point where the idea of ending the Arab-Israeli conflict, not the Palestinian-Israeli conflict, the Arab-Israeli conflict can happen. I’m not sure it will. It depends on quite a few things, but it could happen. And if it happens, it might open up the ending of the Israeli-Islamic conflict. Remember, the Arab world is a small part, it’s an important part, but it’s small. There are large Islamic populations and it could bring about an end to an historic enmity between Islam and Judaism. It could be a great thing.

(01:02:31)
So I’m looking at this larger thing. You can be hobbled by saying, “Oh, well, you’ve had this hiccup in Gaza or this or that thing happening in the Palestinians.” It’s important for us because we want security. But I think the larger question is can we break out into a much wider peace and ultimately come back and make the peace between Israel and the Palestinians rather than waiting to solve that and never getting to paint on the larger canvas? I want to paint on the larger canvas and come back to the Palestinian-Israeli conflict.
History
Lex Fridman

(01:03:16)
As you write about in your book, what have you learned about life from your father?
Benjamin Netanyahu

(01:03:21)
My father was a great historian and well, he taught me several things. He said that the first condition for a living organism is to identify danger in time, because if you don’t, you could be devoured. You could be destroyed very quickly. And that’s the nature of human conflict. In fact, for the Jewish people, we lost the capacity to identify danger in time, and we were almost devoured and destroyed by the Nazi threat. So when I see somebody parroting the Nazi goal of destroying the Jewish state, I try to mobilize the country and the world in time because I think Iran is a global threat, not only a threat to Israel. That’s the first thing.

(01:04:17)
The second thing is I once asked him, before I got elected, I said, “Well, what do you think is the most important quality for a prime minister of Israel?” And he came back with a question, “What do you think?” And I said, “Well, you have to have vision and you have to have the flexibility of navigating and working towards that vision. Be flexible, but understand where you’re heading.” And he said, “Well, you need that for anything. You need it if you’re a university president or if you’re a leader of a corporation or anything, anybody would’ve to have that.” I said, “All right, so what do you need to be the leader of Israel?” He came back to me with a word that stunned me. He said, “Education. You need a broad and deep education, or you’ll be at the mercy of your clerks or the press or whatever. You have to be able to do that.” Now, as I spend time in government, being reelected by the people of Israel, I recognize more and more how right he was.

(01:05:37)
You need to constantly ask yourself, “Where’s the direction we want to take the country? How do we achieve that goal?” But also understand that new disciplines are being added. You have to learn all the time. You have to add to your intellectual capital all the time. Kissinger said that he wrote that once you enter public life, you begin to draw on your intellectual capital and it’ll be depleted very quickly if you stay a long time. I disagree with that. I think you have to constantly increase your understanding of things as they change, because my father was right. You need to broaden and deepen your education as you go along. You can’t just sit back and say, “Well, I studied some things in university, or in college, or in Boston, or at MIT, and that’s enough. I’ve done it.” No, learn, learn, learn, learn. Never stop.
Lex Fridman

(01:06:34)
And if I may suggest as part of the education, I would add in a little literature, maybe Dostoevsky, in the plentiful of time you have as a prime minister to read.
Benjamin Netanyahu

(01:06:44)
Well, I read him, but I’ll tell you what I think is bigger than Dostoevsky.
Lex Fridman

(01:06:47)
Oh, no. Who’s that?
Benjamin Netanyahu

(01:06:49)
Not who’s that, but what’s that? Dan Rather came to see me with his grandson a few years ago. And the grandson asked me, he was a student in Ivy League college. He’s 18 years old and he wants to study to enter politics. And he said, “What’s the most important thing that I have to study to enter a political life?” And I said, “You have three things you have to study. Okay? History, history and history.” That’s the fundamental discipline for political life. But then you have to study other things, study economics, study politics and so on, and study the military if you have… I had an advantage because I spent some years there, so I learned a lot of that, but I had to acquire the other disciplines. And you never acquire enough. So read, read, read. And by the way, if I have to choose, I read history, history and history. Good works of history, not lousy books.
Survival
Lex Fridman

(01:08:02)
Last question. You’ve talked about a survival of a nation. You, yourself, are a mortal being. Do you contemplate your mortality? Do you contemplate your death? Are you afraid of death?
Benjamin Netanyahu

(01:08:15)
Aren’t you?
Lex Fridman

(01:08:16)
Yes.
Benjamin Netanyahu

(01:08:16)
Who is not? I mean, if you’re a conscience, if you’re a being with conscience, I mean, one of the unhappy things about the human brain is that it can contemplate its own demise. And so, we all make our compromises with this, but I think the question is what lives on? What lives on beyond us? And I think that you have to define how much of posterity do you want to influence. I cannot influence the course of humanity. We all are specs, little specs. So that’s not the issue. But in my case, I’ve devoted my life to a very defined purpose. And that is to assure the future and security, and I would say permanence, but that is obviously a limited thing, of the Jewish state and the Jewish people. I don’t think one can exist without the other. So I’ve devoted my life to that. And I hope that in my time on this Earth and in my years in office, I’d have contributed to that.
Lex Fridman

(01:09:29)
Well, you had one heck of a life, starting from MIT to six terms as prime minister. Thank you for this stroll through human history and for this conversation. It was an honor.
Benjamin Netanyahu

(01:09:44)
Thank you. And I hope you come back to Israel many times. Remember it’s the innovation nation. It’s a robust democracy. Don’t believe all the stuff that you are being told. It’ll remain that. It cannot be any other way. I’ll tell you the other thing, it’s the best ally of the United States, and its importance is growing by the day because our capacities in the information world are growing by the day. We need a coalition of the like-minded smarts. This is a smart nation. And we share the basic values of freedom and liberty with the United States. So the coalition of the smarts means Israel is the sixth eye and America has no better ally.
Lex Fridman

(01:10:33)
All right. Now off mic, I’m going to force you to finally tell me who is going to win. Elon Musk or Mark Zuckerberg? But it’s a good time that we ran out of time here.
Benjamin Netanyahu

(01:10:41)
I’ll tell you outside.
Lex Fridman

(01:10:44)
Thanks for listening to this conversation with Benjamin Netanyahu. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Mahatma Gandhi, “An eye for an eye will only make the whole world blind.” Thank you for listening and I hope to see you next time.
Transcript for Robert F. Kennedy Jr: CIA, Power, Corruption, War, Freedom, and Meaning | Lex Fridman Podcast #388
This is a transcript of Lex Fridman Podcast #388 with Robert F Kennedy Jr.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
3:18 – US history
7:34 – Freedom
9:28 – Camus
12:51 – Hitler and WW2
22:03 – War in Ukraine
45:24 – JFK and the Cuban Missile Crisis
1:10:31 – JFK assassination conspiracy
1:20:06 – CIA influence
1:29:04 – 2024 elections
1:40:49 – Jordan Peterson
1:42:30 – Anthony Fauci
1:45:57 – Big Pharma
2:05:37 – Peter Hotez
2:11:17 – Exercise and diet
2:13:42 – God

Introduction
Robert F. Kennedy Jr

(00:00:00)
It’s not our business to change the Russian government. And anybody who thinks it’s a good idea to do regime change in Russia, which has more nuclear weapons than we do, is I think irresponsible. And Vladimir Putin himself has had… We will not live in a world without Russia and it was clear when he said that, that he was talking about himself and he has his hand on a button that could bring Armageddon to the entire planet. So why are we messing with this? It’s not our job to change that regime, and we should be making friends with the Russians. We shouldn’t be treating him as an enemy. Now we’ve pushed him into the camp with China. That’s not a good thing for our country. And by the way, what we’re doing now does not appear to be weakening Putin at all.
Lex Fridman

(00:00:56)
The following is a conversation with Robert F. Kennedy Jr, candidate for the President of the United States, running as a Democrat. Robert is an activist, lawyer and author who has challenged some of the world’s most powerful corporations seeking to hold them accountable for the harm they may cause. I love science and engineering. These two pursuits are, to me the most beautiful and powerful in the history of human civilization. Science is our journey, our fight for uncovering the laws of nature and leveraging them to understand the universe and to lessen the amount of suffering in the world. Some of the greatest human beings I’ve ever met, including most of my good friends, are scientists and engineers. Again, I love science, but science cannot flourish without epistemic humility, without debate, both in the pages of academic journals and in the public square, in good faith, long form conversations.

(00:01:56)
Agree or disagree, I believe Robert’s voice should be part of the debate. To call him a conspiracy theorist and arrogantly dismiss everything he says without addressing it diminishes the public’s trust in the scientific process. At the same time, dogmatic skepticism of all scientific output on controversial topics like the pandemic is equally, if not more dishonest and destructive. I recommend that people read and listen to Robert F. Kennedy Jr, his arguments and his ideas. But I also recommend, as I say in this conversation, that people read and listen to Vincent Racaniello from This Week in Virology, Dan Wilson from Debunk The Funk, and the Twitter and books of Paul Offit, Eric Topol, and others who are outspoken in their disagreement with Robert.

(00:02:50)
It is disagreement, not conformity that bends the long arc of humanity toward truth and wisdom. In this process of disagreement, everybody has a lesson to teach you, but we must have the humility to hear it and to learn from it. This is The Lex Fridman podcast. To support it, please check out our sponsors in the description. And now, dear friends, here’s Robert F. Kennedy Jr.
US history

(00:03:18)
It’s the 4th of July, Independence Day. So simple question, simple, big question. What do you love about this country, the United States of America?
Robert F. Kennedy Jr

(00:03:27)
I would say there’s so many things that I love about the country, the landscapes and the waterways and the people, et cetera. But on the higher level, people argue about whether we’re an exemplary nation, and that term has been given a bad name, particularly by the neocons, the actions, the neocons in recent decades who have turned that phrase into a justification for forcing people to adopt American systems or values at the barrel of a gun. But my father and uncle used it in a very different way, and they were very proud of it. I grew up very proud of this country because we were the exemplary nation in the sense that we were an example of democracy all over the world. When we first launched our democracy in 1780, we were the only democracy on earth. And there was Civil war, by 1865, there were six democracies.

(00:04:35)
Today there’s probably 190, and all of them in one way or another are modeled on the American experience. And it’s extraordinary because our first serious and sustained contact with the European culture and continent was in 1608 when John Winthrop came over with his Puritans in the sloop Arbella and Winthrop gave this famous speech where he said, “This is going to be a city on a hill. This is going to be an example for all the other nations in the world.” And he warned his fellow Puritans. They were sitting at this great expanse of land and he said, “We can’t be seduced by the lure of real estate or by the carnal opportunities of this land. We have to take this country as a gift from God and then turn it into an example for the rest of the world of God’s love, of God’s will and wisdom.” And 200 years later, 250 years later, a different generation, they’re mainly [inaudible 00:05:59], are people who had a belief in God, but not so much a love of particularly religious cosmologies.

(00:06:13)
The Framers of the Constitution believe that we were creating something that would be replicated around the world, and that it was an example in democracy. There would be this kind of wisdom from the collective that… And the word wisdom means a knowledge of God’s will, and that somehow God would speak through the collective in a way that he or she could not speak through totalitarian regimes. And I think that that’s something that even though Winthrop was a white man and a Protestant, that every immigrant group who came after them adopted that belief. And I know my family, when my family came over, all of my grandparents came over in 1848 during the potato famine, and they saw this country as unique in history is something that was part of a broader spiritual mission. And so I’d say that from a 30,000-foot level, I grew up so proud of this country and believing that it was the greatest country in the world, and for those reasons.
Freedom
Lex Fridman

(00:07:34)
Well, I immigrated to this country. And one of the things that really embodies America to me is the ideal of freedom. Hunter S. Thompson said, “Freedom is something that dies unless it’s used.” What does freedom mean to you?
Robert F. Kennedy Jr

(00:07:47)
To me, freedom does not mean chaos, and it does not mean anarchy. It means that it has to be accompanied by restraint if it’s going to live up to its promise in self-restraint. What it means is the capacity for human beings to exercise and to fulfill their creative energies unrestrained as much as possible by government.
Lex Fridman

(00:08:20)
So this point that Hunter S. Thompson has made is, “Dies unless it’s used.” Do you agree with that?
Robert F. Kennedy Jr

(00:08:28)
Yeah, I do agree with that, and he was not unique in saying that. Thomas Jefferson said that the Tree of Liberty had to be watered with the blood of each generation. And what he meant by that is that we can’t live off the laurels of the American Revolution. That we had a group, we had a generation where between 25,000 and 70,000 Americans died. They gave their lives, they gave their livelihoods, they gave their status, they gave their property, and they put it all on the line to give us our Bill of Rights and that, but those Bill of Rights, the moment that we signed them, there were forces within our society that began trying to chip away at them, and that happens in every generation. And it is the obligation of every generation to safeguard and protect those freedoms.
Camus
Lex Fridman

(00:09:26)
The blood of each generation. You mentioned your interest, your admiration of Al Albert Camus, of Stoicism, perhaps your interest in existentialism. Camus said, I believe in Myth of Sisyphus, “The only way to deal with an unfree world is to become so absolutely free that your very existence is an act of rebellion.” What do you think he means by that?
Robert F. Kennedy Jr

(00:09:49)
I suppose the way that Camus viewed the world and the way that the Stoics did and a lot of the existentialists, it was that it was so absurd and that the problems and the tasks that were given just to live a life are so insurmountable that the only way that we can get back the gods for giving us this impossible task of living life was to embrace it and to enjoy it and to do our best at it. To me, I read Camus, and particularly in The Myth of Sisyphus as a parable that… And it’s the same lesson that I think he writes about in The Plague, where we’re all given these insurmountable tasks in our lives, but that by doing our duty, by being of service to others, we can bring meaning to a meaningless chaos and we can bring order to the universe.

(00:11:01)
And Sisyphus was the iconic hero of the Stoics, and he was a man because he did something good. He delivered a gift to humanity. He angered the gods and they condemned him to push a rock up the hill every day, and then it would roll down. When he got to the top, it would roll down and he’d spend the night going back down the hill to collect it and then rolling it back up the hill again. And the task was absurd, it was insurmountable. He could never win, but the last line of that book is one of the great lines, which is something to the extent that I can picture as of his smiling, because Camus’ belief was that even though his task was insurmountable, that he was a happy man and he was a happy man because he put his shoulder to the stone.

(00:11:59)
He took his duty, he embraced the task and the absurdity of life, and he pushed the stone up the hill. And that if we do that, and if we find ways of being service to others, that is the ultimate, that’s the key to the lock, that’s the solution to the puzzle.
Lex Fridman

(00:12:21)
Each individual person in that way can rebel against absurdity by discovering meaning to this whole messy thing.
Robert F. Kennedy Jr

(00:12:28)
And we can bring meaning not only to our own lives, but we can bring meaning to the universe as well. We can bring some kind of order to life and the embrace of those tasks and the commitment to service resonates out from us to the rest of humanity in some way.
Hitler and WW2
Lex Fridman

(00:12:51)
So you mentioned The Plague by Camus. There’s a lot of different ways to read that book, but one of them, especially given how it was written, is that The Plague symbolizes Nazi Germany and the Hitler regime. What do you learn about human nature from a figure like Adolf Hitler, that he’s able to captivate the minds of millions, rise to power and take on, pull in the whole world into a global war?
Robert F. Kennedy Jr

(00:13:24)
I was born nine years after the end of World War II, and I grew up in a generation with my parents who were fixated on that, on what happened, and my father. At that time, the resolution in the minds of most Americans, and I think people around the world, is that there had been something wrong with the German people, that the Germans had been particularly susceptible to this kind of demagoguery and to following a powerful leader and just industrializing cruelty and murder. And my father always differed with that. My father said, “This is not a German problem. This could happen to all of us. We’re all just inches away from barbarity.” And the thing that keeps us safe in this country are the institutions of our democracy, our constitution. It’s not our nature. Our nature has to be restrained, and that comes through self-restraint.

(00:14:38)
But also, the beauty of our country is that we devise these institutions that are designed to allow us to flourish, but at the same time, not to give us enough freedom to flourish, but also create enough order to keep us from collapsing into barbarity. So one of the other things that my father talked about from when I was little, he would ask us this question, “If you were the family and Anne Frank came to your door and asked you to hide her, would you be one of the people who hid her, risk your own life, or would you be one of the people who turned her in?”

(00:15:24)
And of course, we would all say, “Well, of course we would hide Anne Frank and take the risk,” but that’s been something kind of a lesson, a challenge that has always been near the forefront of my mind, that if a totalitarian system ever a occurs in the United States, which my father thought was quite possible, he was conscious about how fragile democracy actually is, that would I be one of the ones who would resist the totalitarianism or would I be one of the people who went along with it? Would I be one of the people who was at the train station in crack hour, or even Berlin and saw people being shipped off to camps and just put my head down and pretend I didn’t say it because talking about it would be destructive to my career and maybe my freedom and even my life? So that has been a challenge that my father gave to me and all of my brothers and sisters, and it’s something that I’ve never forgotten.
Lex Fridman

(00:16:39)
A lot of us would like to believe we would resist in that situation, but the reality is most of us wouldn’t, and that’s a good thing to think about, that human nature is such that we’re selfish even when there’s an atrocity going on all around us.
Robert F. Kennedy Jr

(00:16:57)
And we also have the capacity to deceive ourselves, and all of us tend to judge ourselves by our intentions and our actions.
Lex Fridman

(00:17:08)
What have you learned about life from your father, Robert F. Kennedy?
Robert F. Kennedy Jr

(00:17:12)
First of all, I’ll say this about my uncle because I’m going to apply that question to my uncle and my father. My uncle was asked when he first met Jackie Bouvier, who later became Jackie Kennedy. She was a reporter for a newspaper and she had a column where she’d do these pithy interviews with both famous people and man in the street interviews. And she was interviewing him and she asked him what he believed his best quality was, his strongest virtue? And she thought that he would say courage because he had been a war hero. He was the only president who… And this is when he was Senator, by the way, who received the Purple Heart. And he had a very famous story of him as a hero in World War II. And then he had come home and he had written a book on moral courage among American politicians and won the Pulitzer Prize, that book Profiles and Courage, which was a series of incidents where American political leaders made decisions to embrace principle even though their careers were at stake, and in most cases were destroyed by their choice.

(00:18:37)
She thought he was going to say courage, but he didn’t. He said curiosity, and I think looking back at his life that the best, it was true, and that was the quality that allowed him to put himself in the shoes of his adversaries. And he always said that if the only way that we’re going to have peace is if we’re able to put ourselves in the shoes of our adversaries, understand their behavior and their contact, not context. And that’s why he was able to resist the intelligence apparatus and the military during the Bay of Pigs when they said, “You’ve got to send in the Essex, the aircraft carrier.” And he said, “No.” Even though he’d only been two months in office, he was able to stand up to them because he was able to put himself in the shoes of both Castro and Khrushchev and understand there’s got to be another solution to this.

(00:19:40)
And then during the Cuban Missile Crisis, he was able to endure it when the narrative was okay, Khrushchev acted in a way as an aggressor to put missiles in our hemisphere. How dare he do that? And Jack and my father were able to say, “Well, wait a minute. He’s doing that because we put missiles in Turkey and Italy, and the Turkish ones right on the Russian border.” And they then made a secret deal with Do Brennan, with Ambassador Do Brennan and with Khrushchev to remove the missiles in Turkey if he moved the Jupiter missiles from Turkey, so long as Khrushchev removed them from Cuba. There were 13 men on what they called the [inaudible 00:20:36] Committee, which was the group of people who were deciding what the action was, what they were going to do to end the Cuban Missile Crisis.

(00:20:45)
And virtually, and of those men, 11 of them wanted to invade and wanted to bomb and invade, and it was Jack. And then later on, my father and Bob McNamara, who were the only people who were with him, because he was able to see the world from Khrushchev’s point of view of view, he believed that there was another solution. And then he also had the moral courage. So my father, to get back to your question, famously said that, “Moral courage is the most important quality and it’s more rare,” and courage on the football field or courage in battle than physical courage. It’s much more difficult to come by, but it’s the most important quality in a human being.
Lex Fridman

(00:21:33)
And you think that kind of empathy that you referred to, that requires moral courage?
Robert F. Kennedy Jr

(00:21:37)
It certainly requires moral courage to act on it, and particularly in any time that a nation is at war, there’s a momentum or an inertia that says, “Okay, let’s not look at this from the other person’s point of view.” And that’s the time we really need to do that.
War in Ukraine
Lex Fridman

(00:22:03)
Well, if we’re can apply that style of empathy, style of curiosity to the current war in Ukraine, what is your understanding of why Russia invaded Ukraine in February 2022?
Robert F. Kennedy Jr

(00:22:16)
Vladimir Putin could have avoided the war in the Ukraine. His invasion was illegal. It was unnecessary, and it was brutal, but I think it’s important for us to move beyond these kind of comic book depictions of this insane, avaricious Russian leader who wants to restore the Soviet Empire, and who made unprovoked invasion of the Ukraine. He was provoked and we were provoking him and we were provoking him since 1997. And it’s not just me that’s saying that. And before Putin never came in, we were provoking Russia, the Russians in this way unnecessarily. And to go back that time in 1992 when the Russians moved out of… When the Soviet Union was collapsing, the Russians moved out of East Germany and they did that, which was a huge concession to them.

(00:23:27)
They had 400,000 troops in East Germany at that time, and they were facing NATO troops on the other side of the wall. Gorbachev made this huge concession where he said to George Bush, “I’m going to move all of our troops out, and you can then reunify Germany under NATO,” which was a hostile army to the Soviet… It was created with hostile intent toward the Soviet Union. And he said, “You can take Germany, but I want your promise that you will not move NATO to the east.” And James Baker, who was his Secretary of State famously said, “I will not move NATO. We will not move NATO one inch to the east.”

(00:24:07)
So then five years later in 1997, Zbigniew Brzezinski, who was the “father of the neocons,” who was a Democrat at that time, served in the Carter administration, he published a paper, a blueprint for moving NATO right up to the Russian border, a 1,000 miles to the east and taking over 14 nations. And at that time, George Kennan, who was the deity of American diplomats, he was arguably the most important diplomat in American history. He was the architect of the containment policy during World War II. And he said, “This is insane and it’s unnecessary. And if you do this, it’s going to provoke the Russians to a violent response. And we should be making friends with the Russians. They lost the Cold War. We should be treating them the way that we treated our adversaries after World War II, with a Marshall Plan to try to help them incorporate into Europe and to be part of the brotherhood of man and of western nations. We shouldn’t continue to be treating them as an enemy and particularly surrounding them at their borders.”

(00:25:26)
William Perry, who was then the Secretary of Defense under Bill Clinton, threatened to resign. He was so upset by this plan to move NATO to the east. And William Burns, who was then the US Ambassador to the Soviet Union, who is now at this moment, the Head of the CIA, said at the time, the same thing. “If you do this, it is going to provoke the Russians toward a military response.” And we moved all around Russia. We moved to 14 nations, a 1,000 miles to the east, and we put ageist missile systems in two nations, in Romania and Poland. So we did what the Russians had done to us in 1962 that would’ve provoked an invasion of Cuba. We put those missile systems back there, and then we’d walk away, unilaterally, walk away from the two nuclear missile treaties, the intermediate nuclear missile treaties that we had with the Soviet, with Russia, and neither of us would put those missile systems on the borders.

(00:26:31)
We walk away from that and we put ageist missile systems, which are nuclear capable. They can carry the Tomahawk missiles, which have nuclear warheads. So the last country that they didn’t take was the Ukraine. And the Russians said, and in fact, Bill Perry said this, or William Burns said it, now the Head of the CIA, “It is a red line. If we bring NATO into Ukraine, that is a red line for the Russians. They cannot live with it. They cannot live with it. Russia has been invaded three times through the Ukraine. The last time it was invaded, we killed, or the Germans killed one out of every seven Russians.”

(00:27:11)
My uncle described what happened to Russia in his famous American university speech in 1963, 60 years ago this month, or or last month, 60 years ago in June, June 10th, 1963. That speech was telling the American people, “Put yourself in the shoes of the Russians. We need to do that if we’re going to make peace.” And he said, “All of us have been taught that we won the war, but we didn’t win the war. If anybody won the war against Hitler, it was the Russians. Their country was destroyed, all of their cities.” And he said, “Imagine if all of the cities from the East Coast to Chicago were reduced to rubble and all of the fields burns, all of the forests burns. That’s what happened to Russia. That’s what they gave so that we could get rid of Adolf Hitler.”

(00:28:08)
And he had them put themselves in their position, and today there’s none of that happening. We have refused repeatedly to talk to the Russians. We’ve broken up, there’s two treaties, the Minsk Agreements, which the Russians were willing to sign, and they said, “We will stay out.” The Russians didn’t want the Ukraine. They showed that when the Donbas region voted 90 to 10 to leave and go to Russia. Putin said, “No, we want Ukraine to stay intact, but we want you to sign Minsk Accords.” The Russians were very worried because of the US involvement and the coup in Ukraine in 2014, and then the oppression and the killing of 14,000 ethnic Russians, and Russia hasn’t had the same way that if Mexico would ageist missile systems from China or Russia on our border and then killed 14,000 expats American, we would go in there.

(00:29:13)
Oh, he does have a national security interest in the Ukraine. He has an interest in protecting the Russian-speaking people of the Ukraine, the ethnic Russians, and the Minsk Accords did that. It left Ukraine as part of Russia. It left them as a semi-autonomous region that continued to use their own language, which is essentially banned by the coup, by the government we put in 2014, and we sabotaged that agreement. And we now know in April of 2022, Zelenskyy and Putin had inked a deal already to another peace agreement, and that the United States and Boris Johnson, the neocons in the White House and Boris Johnson over to the Ukraine to sabotage that agreement.
Robert F. Kennedy Jr

(00:30:03)
… Boris Johnson over to the Ukraine to sabotage that agreement. What do I think? I think this is a proxy war. I think this is a war that the neocons and the White House wanted. They’ve said for two decades they wanted this war and that they wanted to use Ukraine as a pawn in a proxy war between United States and Russia, the same as we used Afghanistan.

(00:30:26)
And in fact, they say it, “This is the model. Let’s use the Afghanistan model.” That was said again and again. And to get the Russians to overextend their troops and then fight them using local fighters and US weapons.

(00:30:40)
And when President Biden was asked, “Why are we in the Ukraine?” He was honest. He says, “To depose Vladimir Putin. Regime change for Vladimir Putin.” And when his defense secretary Lloyd Austin in April 2022 was asked, “Why are we there?” He said, “To degrade the Russians’ capacity to fight anywhere… To exhaust the Russian army and degrade its capacity to fight elsewhere in the world.”

(00:31:05)
That’s not a humanitarian mission. That’s not what we were told. We were told this was an unprovoked invasion and that we’re there to bring humanitarian relief to the Ukrainians. But that is the opposite. That is a war of attrition that is designed to chew up and turn this little nation into an abattoir of death for the flower of Ukrainian youth in order to advance a geopolitical ambition of certain people within the White House. And I think that’s wrong.

(00:31:39)
We should be talking to the Russians the way that Nixon talked to Brezhnev, the way that Bush talked to Gorbachev, the way that my uncle talked to Khrushchev. We need to be talking with the Russians, we should, and negotiating. And we need to be looking about how do we end this and preserve peace in Europe.
Lex Fridman

(00:31:58)
Would you as president sit down and have a conversation with Vladimir Putin and Volodymyr Zelenskyy separately and together to negotiate peace?
Robert F. Kennedy Jr

(00:32:07)
Absolutely. Absolutely.
Lex Fridman

(00:32:09)
What about Vladimir Putin? He’s been in power since 2000. So as the old adage goes, “Power corrupts, and absolute power corrupts absolutely.” Do you think he has been corrupted by being in power for so long, if you think of the man, if you look at his mind?
Robert F. Kennedy Jr

(00:32:27)
Listen, I don’t know exactly. I can’t say because I don’t know enough about him or about… The evidence that I’ve seen is that he is homicidal. He kills his enemies or poisons them. And the reaction I’ve seen to that, to hit those accusations from him have not been to deny that but to kind of laugh it off.

(00:32:58)
Oh, I think he’s a dangerous man and that, of course, there’s probably corruption in his regime. But having said that, it’s not our business to change the Russian government. And anybody who thinks it’s a good idea to do a regime change in Russia, which has more nuclear weapons than we do, is I think irresponsible.

(00:33:22)
And Vladimir Putin himself has said, “We will not live in a world without Russia.” And it was clear when he said that he was talking about himself. And he has his hand on a button that could bring Armageddon to the entire planet.

(00:33:40)
So why are we messing with this? It’s not our job to change that regime. We should be making friends with the Russians. We shouldn’t be treating him as an enemy. Now we’ve pushed him into the camp with China. That’s not a good thing for our country.

(00:33:55)
And by the way, what we’re doing now does not appear to be weakening Putin at all. Putin now, if you believe the polls that are coming out of Russia, they show him… the most recent polls that I’ve seen show him with an 89% popularity that people in Russia support the war in Ukraine, and they support him as an individual.

(00:34:25)
And I understand there’s problems with polling and you don’t know what to believe, but the polls consistently show that. And it’s not America’s business to be the policemen of the world and to be changing regimes in the world. That’s illegal.

(00:34:41)
We shouldn’t be breaking international laws. We should actually be looking for ways to improve relationships with Russia, not to destroy Russia, not to destroy, and not to choose its leadership for them. That’s up to the Russian people, not us.
Lex Fridman

(00:35:00)
Step one is to sit down and empathize with the leaders of both nations to understand their history, their concerns, their hopes, just to open the door for conversation so they’re not back to the corner.
Robert F. Kennedy Jr

(00:35:12)
Yeah. And I think the US can play a really important role, and a US president can play a really important role by reassuring the Russians that we’re not going to consider them an enemy anymore, that we want to be friends.

(00:35:26)
And it doesn’t mean that you have to let down your guard completely. The way that you do it, which was the way President Kennedy did it, is you do it one step at a time. You take baby steps. We do a unilateral move, reduce our hostility and aggression, and see if the Russians reciprocate. And that’s the way that we should be doing it.

(00:35:50)
And we should be easing our way into a positive relationship with Russia. We have a lot in common with Russia, and we should be friends with Russia and with the Russian people. Apparently, there’s been 350,000 Ukrainians who have died, at least, in this war. And there’s probably been 60,000 or 80,000 Russians. And that should not give us any joy. It should not give us any…

(00:36:21)
I saw Lindsey Graham on TV saying something to the extent of, “Anything we can do to kill Russians is a good use of our money.” It is not. Those are somebody’s children. We should have compassion for them. This war is an unnecessary war. We should settle it through negotiation, through diplomacy, through state graft, and not through weapons.
Lex Fridman

(00:36:50)
Do you think this war can come to an end purely through military operations?
Robert F. Kennedy Jr

(00:36:55)
No. I mean, I don’t think there’s any way in the world that the Ukrainians can beat the Russians. I don’t think there’s any appetite in Europe… I think Europe is now having severe problems. In Germany, Italy, France, you’re seeing these riots. There’s internal problems in those countries.

(00:37:12)
There is no appetite in Europe for sending men to die in Ukraine. And the Ukrainians do not have anybody left. The Ukrainians are using press gangs to fill the ranks of their armies. Military-age men are trying as hard as they can to get out of the Ukraine right now to avoid going to the front.

(00:37:35)
The Russians apparently have been killing Ukrainians in a 7:1 ratio. My son fought over there, and he told me… He had firefights with the Russians mainly at night, but he said most of the battles were artillery wars during the day. And the Russians now outgun the NATO forces 10:1 in artillery. They’re killing at a horrendous rate.

(00:38:06)
Now, my interpretation of what’s happened so far is that Putin actually went in early on with a small force because he expected to meet somebody on the other end of a negotiating table once he went in. And when that didn’t happen, they did not have a large enough force to be able to mount an offensive.

(00:38:32)
And so they’ve been building up that force up till now, and they now have that force. And even against the small original force, the Ukrainians have been helpless. All of their offenses have died. They’ve now killed the head of the Ukrainian special forces, which was probably, arguably, by many accounts, the best elite military unit in all of Europe.

(00:39:01)
The commandant, the commander of that special forces group gave a speech about four months ago saying that 86% of his men are dead or wounded and cannot return to the front. He cannot rebuild that force. And the troops that are now filling the gaps of all those 350,000 men who’ve been lost are scantily trained, and they’re arriving green at the front.

(00:39:36)
Many of them do not want to be there. Many of them are giving up and going over to the Russian side. We’ve seen this again and again and again, including platoon-sized groups that are defecting to the Russians.

(00:39:48)
And I don’t think it’s possible to win. Of course, I’ve studied World War II history exhaustively, but I saw… There’s a new… I think it’s a Netflix series of documentaries that I highly recommend to people there. They’re colorized versions of the black-and-white films from the battles of World War II, but it’s all the battles of World War II.

(00:40:15)
So I watched Stalingrad the other night. And the willingness of the Russians to fight on against any kind of odds and to make huge sacrifices of Russians, the Russians themselves who are making the sacrifice with their lives, the willingness of them to do that for their motherland is almost inexhaustible.

(00:40:40)
It is incomprehensible to think that Ukraine can beat Russia in a war. It would be like Mexico beating the United States. It’s impossible to think that it can happen. And Russia has deployed a tiny, tiny fraction of its military so far. And now it has China with its mass production capacity supporting its war effort. It’s a hopeless situation.

(00:41:11)
And we’ve been lied to. The press in our country and our government are just promoting this lie that the Ukrainians are about to win and that everything’s going great and that Putin’s on the run. And there’s all this wishful thinking because of the Wagner Group-
Lex Fridman

(00:41:30)
Prigozhin.
Robert F. Kennedy Jr

(00:41:30)
… Prigozhin and the Wagner Group, that this was an internal coup, and it showed dissent and weakness of Putin. And none of that is true. That insurgency, which wasn’t even an insurgency…

(00:41:44)
He only got 4,000 of his men to follow him out of 20,000. And they were quickly stopped. And nobody in the Russian military, the oligarchy, the political system, nobody supported it. But we’re being told, “Oh yeah, it’s the beginning of the end for Putin. He’s weakened. He’s wounded. He’s on his way out.” And all of these things are just lies that we are being fed.
Lex Fridman

(00:42:07)
To push back on a small aspect of this that you kind of implied, so I’ve traveled to Ukraine, and one thing that I should say, similar to the Battle of Stalingrad, it is not only the Russians that fight to the end. I think Ukrainians are very lucky to fight to the end.

(00:42:24)
And the morale there is quite high. I’ve talked to nobody… This was a year ago in August with Kherson. Everybody was proud to fight and die for their country. And there’s some aspect where this war unified the people, gave them a reason and an understanding that this is what it means to be Ukrainian and, “I will fight to the death to defend this land.”
Robert F. Kennedy Jr

(00:42:48)
I would agree with that, and I should have said that myself at the beginning. That’s one of the reasons my son went over there to fight because he was inspired by the valor of the Ukrainian people and this extraordinary willingness of them.

(00:43:02)
And I think Putin thought it would be much easier to sweep into Ukraine, and he found a stone wall of Ukrainians ready to put their lives and their bodies on the line. But that, to me, makes the whole episode even more tragic, is that I don’t believe… I think that the US’s role in this has been… There were many opportunities to settle this war, and the Ukrainians wanted to settle it.

(00:43:34)
Volodymyr Zelenskyy, when he ran in 2019, here’s a guy who’s a comedian, he’s an actor. He had no political experience, and yet he won this election with 70% of the vote. Why? He won on a peace platform, and he won promising to sign the Minsk accords. And yet something happened when he got in there that made him suddenly pivot. And I think it’s a good guess what happened.

(00:44:02)
I think he came under threat by ultra-nationalists within his own administration and the insistence of neocons like Victoria Nuland and the White House, that we don’t want peace with Putin. We want a war.
Lex Fridman

(00:44:20)
Do you worry about nuclear war?
Robert F. Kennedy Jr

(00:44:22)
Yeah, I worry about it.
Lex Fridman

(00:44:25)
It seems like a silly question, but it’s not. It’s a serious question.
Robert F. Kennedy Jr

(00:44:29)
Well, the reason it’s not is just because people seem to be in this kind of dream state that it’ll never happen, and yet it can happen very easily and it can happen at any time.

(00:44:48)
And if we push the Russians too far, I don’t doubt that Putin, if he felt like his regime or his nation was in danger, that the United States was going to be able to place a quisling into the Kremlin, that he would use nuclear torpedoes and these strategic weapons that they have. And that could be it. Once you do that, nobody controls the trajectory.
JFK and the Cuban Missile Crisis

(00:45:24)
By the way, I have very strong memories of the Cuban Missile Crisis and of those 13 days when we came closer to nuclear war. And particularly, I think it was when the U-2 got shot down over Cuba. And nobody in this country… There’s a lot of people in Washington, D.C., who, at that point, thought that they very well may wake up dead, that the world may end at night.

(00:45:55)
30 million Americans killed 130 million Russians. This is what our military brass wanted. They saw a war with Russia, a nuclear exchange with Russia as not only inevitable but also desirable because they wanted to do it now while we still had superiority.
Lex Fridman

(00:46:14)
Can you actually go through the feelings you’ve had about the Cuban Missile Crisis? What are your memories of it? What are some interesting-
Robert F. Kennedy Jr

(00:46:21)
I was going to school in Washington, D.C. to Our Lady of Victory, which is in Washington, D.C. I lived in Virginia across the Potomac, and we would cross the bridge every day into D.C.

(00:46:38)
And during the crisis, U.S. Marshals came to my house to take us, I think around day eight. My father was spending the night at the White House. He wasn’t coming home. He was staying with the EXCOM committee and sleeping there. And they were up 24 hours a day. They were debating and trying to figure out what was happening.

(00:47:00)
But we had U.S. Marshals come to our house to take us down… They were going to take us down to White Sulphur Springs in Southern Virginia, in the Blue Ridge Mountains, where there was an underground city, essentially, a bunker that was like a city. And apparently, it had McDonald’s in it and a lot of other… It was a full city for the U.S. Government and their families.

(00:47:29)
U.S. Marshals came to our house to take us down there. And I was very excited about doing that. And this was at a time when we were doing the drills. We were doing the duck-and-cover drills once a week at our school, where they would tell you when the alarms go off, then you put your head under the table, you remove the sharps from your desk, put them inside your desk, you put your head under the table, and you wait.

(00:47:56)
And the initial blast will take the windows out of the school. And then we all stand up and file in an orderly fashion into the basement where we’re going to be for the next six or eight months or whatever.

(00:48:08)
But in the basement where we went occasionally, those corridors were lined with freeze-dried food canisters from floor to ceiling. We were all preparing for this. And it was Bob McNamara, who was a friend of mine, and was one of my father’s close friends, the Secretary of Defense, he later called it mass psychosis.

(00:48:34)
And my father deeply regretted participating in the bomb shelter program because he said it was part of a psychological psyop trick to teach Americans that nuclear war was acceptable, that it was survivable. My father, anyway, when the Marshals came to our house to take me and my brother Joe away, we were the ones who were home at that time, my father called, and he talked to us on the phone.

(00:49:05)
And he said, “I don’t want you going down there because if you disappear from school, people are going to panic. And I need you to be a good soldier and go to school.” And he said something to me during that period, which was that if a nuclear war happened, it would be better to be among the dead than the living, which I did not believe. Okay?

(00:49:31)
I had already prepared myself for the dystopian future. And I knew… I spent every day in the woods. I knew that I could survive by catching crawfish and cooking mudpuppies and would do whatever I had to do. But I felt like, okay, I can handle this. And I really wanted to see this underground city. But anyway, that was part of it for me.

(00:50:01)
My father was away the last days of it. My father got this idea because Khrushchev had sent two letters. He sent one letter that was conciliatory. And then he sent a letter that after his joint chiefs and the warmongers around him saw that letter and they disapproved of it, they sent another letter that was extremely belligerent.

(00:50:25)
And my father had the idea, “Let’s just pretend we didn’t get the second letter and reply to the first one.” And then he went down to Dobrynin. He met Dobrynin in the Justice Department. And Dobrynin was the Soviet ambassador. And they proposed this settlement, which was a secret settlement, where Khrushchev would withdraw the missiles from Cuba.

(00:50:52)
Khrushchev had put the missiles in Cuba because we had put missiles, nuclear missiles, in Turkey and Italy. And my uncle’s secret deal was that if Khrushchev removed the missiles from Cuba within six months, he would get rid of the Jupiter missiles in Turkey.

(00:51:10)
But if Khrushchev told anybody about the deal, it was off. So if news got out about that secret deal, it was off. But that was the actual deal. And Khrushchev complied with it, and then my uncle complied with it.
Lex Fridman

(00:51:25)
How much of that part of human history turned on the decisions of one person?
Robert F. Kennedy Jr

(00:51:31)
I think that’s one of the… Because that, of course, is the perennial question. Right? Is history on automatic pilot? And human decisions and the decisions of leaders really only have a marginal or incremental bearing on what is going to happen anyway. And historians argue about that all the time.

(00:51:57)
I think that that is a really good example of a place in human history that, literally, the world could have ended if we had a different leader in the White House. And the reason for that is that there were, as I recall, 64 gun emplacements, missile emplacements. Each one of those missile emplacements had a crew of about 100 men, and they were Soviets.

(00:52:29)
We didn’t know whether… We had a couple of questions that my uncle asked the CIA. And he asked… Dulles was already gone. But he asked the CIA. And he asked his military brass. Because they all wanted to go in. Everybody wanted to go in. And my uncle asked to see the aerial photos, and he examined those personally.

(00:52:53)
And this is why it’s important to have a leader in the White House who can push back on their bureaucracies. And then he asked them, “Who’s manning those missile sites? And are they Russians? And if they’re Russians and we bomb them, isn’t it going to force Khrushchev to then go into Berlin?”

(00:53:20)
And that would be the beginning of a cascade effect that would highly likely end in a nuclear confrontation. And the military brass said to my uncle, “Oh, we don’t think he’ll have the guts to do that.” My uncle was like, “That’s what you’re betting on?”

(00:53:42)
And they all wanted him to go in. They wanted him to bomb the sites and then invade Cuba. And he said, “If we bomb those sites, we’re going to be killing Russians. And it’s going to force… it’s going to provoke Russia into some response. And the obvious response is for them to go into Berlin.”

(00:54:02)
But the thing that we didn’t know then, that we didn’t find out until, I think it was a 30-year anniversary of the Cuban Missile Crisis in Havana, what we learned then from the Russians who came to that event… It was like a symposium where everybody on both sides talked about it. And we learned a lot of stuff that nobody knew before.

(00:54:30)
One of the insane things, the most insane thing that we learned was that the weapons were already… the nuclear warheads were already in place, they were ready to fire, and that the authorization to fire was delegated to each of the gun crew commanders. So there were 60 people who all had authorization to fire if they felt themselves under attack.

(00:54:59)
So you have to believe that at least one of them would’ve launched, and that would’ve been the beginning of the end. And if anybody had launched, we knew what would happen. My uncle knew what would happen. Because he asked again and again, “What’s going to happen?” And they said, “30 million Americans will be killed, but we will kill 130 million Russians, so we will win.” And that was a victory for them.

(00:55:28)
And my uncle later said, he told Arthur Schlesinger and Kenny O’Donnell, he said, “Those guys…” He called them the salad brass, the guys with all of this stuff on their chest. And he said, “Those guys, they don’t care. Because they know that if it happens, they’re going to be in charge of everything. They’re the ones who are going to be running the world after that.”

(00:55:51)
So for them, there was an incentive to kill 130 million Russians and 30 million Americans. But my uncle, he had this correspondence with Khrushchev. They were secretly corresponding with each other. And that is what saved the world, is that both of them had been men of war.

(00:56:10)
Eisenhower famously said, “It will not be a man of war, it will not be a soldier who starts World War III. Because a guy who’s actually seen it knows how bad it is.” And my uncle had been in the heat of the South Pacific. His boat had been cut in two by a Japanese destroyer.

(00:56:30)
Three of his crewmen had been killed, one of them badly burned. He pulled that guy with a lanyard and his teeth, six miles to an island in the middle of the night. And then they hid out there for 10 days. And he came back. Like I said, he was the only President of the United States that earned the Purple Heart.

(00:56:50)
Meanwhile, Khrushchev had been at Stalingrad, which was the worst place to be on the planet, probably in the 20th century, other than in Auschwitz or one of the death camps. It was the most ferocious, horrific war with people starving, people committed cannibalism, eating the dogs, the cats, eating their shoe leather, easing to death by the thousands, etc.

(00:57:19)
Khrushchev did not want… The last thing he wanted was a war. And the last thing my uncle wanted was a war. But the CIA did not know anything about Khrushchev. And the reason for that is there was a mole at Langley so that every time the CIA got a spy in the Kremlin, he would immediately be killed.

(00:57:43)
So they had no eyes in the Kremlin. There were literally hundreds of Russian spies who had defected to the United States and were in the Kremlin who were killed during that period. They had no idea anything about Khrushchev, about how he saw the world. And they saw the Kremlin itself as a monolith.

(00:58:06)
The same way that we look at Putin today, they have this ambition of world conquest and it’s driving them. And there’s nothing else they think about. They’re absolutely single-minded about it.

(00:58:18)
But actually, there was a big division between Khrushchev and his joint chiefs and his intelligence apparatus. And they both, at one point, discovered they were both in the same situation. They were surrounded by spies and military personnel who were intent on going to war, and they were the two guys resisting it.

(00:58:39)
My uncle had this idea of being the peace president from the beginning. He told Ben Bradlee, one of his best friends who was the publisher of The Washington Post or the editor-in-chief at that time. He said Ben Bradlee asked him, “What do you want on your gravestone?” And my uncle said, “He kept the peace.” He said, “The principal job of the President of the United States is to keep the country out of war.”

(00:59:11)
So when he first became president, he actually agreed to meet Khrushchev in Geneva to do a summit. And by the way, Eisenhower had wanted to do the same thing. Eisenhower wanted peace, and he was going to meet in Vienna. But that peace summit was blown up. He was going to try to end the Cold War.

(00:59:37)
Eisenhower was in the last year of his… in May of 1960. But that was torpedoed by the CIA during the U-2 crash. They sent a U-2 over the Soviet Union, it got shot down. And then Allen Dulles told Eisenhower to deny that we had a program. They didn’t know that the Russians had captured Gary Francis powers.
Robert F. Kennedy Jr

(01:00:00)
…France’s powers. And that blew up the peace talks between Eisenhower and Khrushchev and there was a lot of tension. My uncle wanted to break that tension. He agreed to meet with Khrushchev in Vienna early on in his term. He went over there and Khrushchev snubbed him. Khrushchev lectured him imperiously about the terror of American imperialism, and rebuffed any… They did agree not to go into Laos. They made an agreement that kept the United States, kept my uncle, from sending troops to Laos, but it had been a disaster in Vienna.

(01:00:48)
So then, we had a spy that used to come to our house all the time, a guy called Georgi Bolshakov, and he was this Russian spy my parents had met at the embassy. They had gone to a party or a reception at the Russian Embassy, and he had approached them and they knew he was a GRU agent and KGB, he was both, oh, he used to come to our house. They really liked him. He was very attractive. He was always laughing and joking. He would do rope climbing contests with my father. He would do pushup contests with my father. He could do the Russian dancing, the Cossack dancing, and he would do that for us and teach us that. And we knew he was a spy too, and this was at the time of the James Bond films were first coming out, so it was really exciting for us to have an actual Russian spy in our house. The State Department was horrified by it.

(01:01:44)
But anyway, when Khrushchev, after Vienna, and after the Bay of Pigs, Khrushchev had second thoughts and he sent this long letter to my uncle, and he didn’t want to go through his state department or his embassy, he wanted to end run them. And he was friends with Bolshakov, so he gave Georgi the letter, and Georgi brought it and handed it to Pierre Salinger, folded in the New York Times. And he gave it to my uncle.

(01:02:21)
And it was this beautiful letter, which he said, my uncle had talked to him about the children who had played, we played, 29 grandchildren who were playing in his yard. And he’s saying, what is our moral basis for making a decision that could kill these children? So they’ll never write a poem, they’ll never participate in election, they’ll never run for office. How can we morally, make a decision that is going to eliminate life for these beautiful kids?

(01:02:52)
And he had said that to Khrushchev, and Khrushchev wrote them this letter back saying that he was now sitting as this dacha on the Black Sea, and that he was thinking about what my uncle Jack had said to him at Vienna. And he regretted very deeply not having taken the olive leaf that Jack had offered him. And then he said, it occurs to me now that we’re all on an arc and that there is not another one, and that the entire fate of the planet, and all of its creatures and all of the children are dependent on the decisions we make. And you and I have a moral obligation to go forward with each other as friends.

(01:03:34)
And immediately after that, he sent that right after the Berlin crisis in 1962, General Curtis LeMay had tried to provoke a war with an incident at Checkpoint Charlie, which was the entrance and exit, through the Berlin Wall in Berlin. And the Russian tanks had come to the wall. The US tanks had come to the wall and there was a standoff. And my uncle had sent a message to Khrushchev then through Do Brennan saying, my back is at the wall. I have no place to back to, please back off, and then we will back off. And Khrushchev took his word, backed his tanks off first, and then my uncle ordered LeMay back. He had, LeMay had mounted bulldozer plows on the front of the tanks to plow down the Berlin wall, and the Russians had come, so it was these generals trying to provoke a war.

(01:04:44)
But they started talking to each other then. And then after he wrote that letter, they agreed that they would install a hotline, so they could talk to each other and they wouldn’t have to go through intermediaries. And so at Jack’s house on the Cape, there was a red phone that we knew if we picked it up, Khrushchev would answer. And there was another one in the White House. But they knew it was important to talk to each other. And you just wish that we had that kind of leadership today, that just understands our job.

(01:05:21)
Look, I know you know a lot about AI, and you know how dangerous it is, potentially to humanity, and what opportunities is it also offers, but it could kill us all. I mean, Elon said, first it’s going to steal our job, then it’s going to kill us. Right? And it’s probably not a hyperbole. Actually, if it follows the laws of biological evolution, which are just the laws of mathematics, that’s probably a good endpoint for it, a potential endpoint. It’s going to happen, but we need to make sure it’s regulated, and it’s regulated properly for safety, in every country. And that includes Russia and China and Iran. Right now, we should be putting all the weapons of war aside and sitting down with those guys and say, how are we going to do this? There’s much more important things to do. This stuff is going to kill us, if we don’t figure out how to regulate it. And leadership needs to look down the road at what is the real risk here. And the real risk is that AI will enslave us, for one thing, and then destroy us, and do all this other stuff.

(01:06:42)
And how about biological weapons? We’re now all working on these biological weapons, and we’re doing biological weapons for Ebola, and Dengue Fever, and all of these other bad things. And we’re making ethnic bio-weapons, bio-weapons that can only kill Russians, bio-weapons that the Chinese are making that can kill people who don’t have Chinese genes. So all of this is now within reach. We’re actively doing it, and we need to stop it. And a biological weapons treaty is the easiest thing in the world to do. We can verify it, we can enforce it, and everybody wants to agree to it. Only insane people do not want to continue this kind of research, there’s no reason to do it.

(01:07:33)
So there are these existential threats to all of humanity now out there, like AI and biological weapons. We need to stop fighting each other, start competing on economic game fields, playing fields, instead of military playing fields, which will be good for all of humanity. And we need to sit down with each other, and negotiate reasonable treaties on how we regulate AI and biological weapons. And nobody’s talking about this in this political race right now. Nobody’s talking about it in a government. They get fixated on these little wars, and these comic book depictions of good versus evil, and we all go, hoorah and go off to and give them the weapons and enrich the military industrial complex, but we’re on the road to perdition if we don’t end this.
Lex Fridman

(01:08:29)
And some of this requires to have this kind of phone that connects Khrushchev and John F. Kennedy that cuts through all the bureaucracy, to have this communication between heads of State, and in the case of AI, perhaps heads of tech companies where you can just pick up the phone and have a conversation.
Robert F. Kennedy Jr

(01:08:46)
Yes.
Lex Fridman

(01:08:46)
Because a lot of it, a lot of the existential threats of artificial intelligence, perhaps even bio-weapons, is unintentional. It’s not even strategic-
Robert F. Kennedy Jr

(01:08:56)
Exactly.
Lex Fridman

(01:08:56)
-intentional effects, so you have to be transparent and honest about, especially with AI, that people might not know what’s the worst that’s going to happen once you release it out into the wild? And you have to have an honest communication about how to do it, so that companies are not terrified of regulation, overreach regulation. And then government is not terrified of tech companies, of manipulating them in some direct or indirect ways, so there’s a trust that builds versus a distrust. Basically, that old phone, where Khrushchev can call John F. Kennedy, is needed.
Robert F. Kennedy Jr

(01:09:35)
And I don’t think there’s… Listen, I don’t understand AI. I do know, I can see from all this technology, how it’s this turnkey totalitarianism, that once you put these systems in place, they can be misused to enslave people, and they can be misused in wars, and to subjugate, to kill, to do all of these bad things. And I don’t think there’s anybody on Capitol Hill, who understands this. We need to bring in the tech community and say, tell us what these regulations need to look like, so that there can be freedom to innovate, so that we can milk AI for all of the good things, but not fall into these traps that pose existential threats to humanity.
JFK assassination conspiracy
Lex Fridman

(01:10:31)
It seems like John F. Kennedy is a singular figure, in that he was able to have the humility to reach out to Khrushchev, and also the strength and integrity to resist the, what did you call them, the salad brass and institutions like the CIA, so that makes it particularly tragic that he was killed. To what degree was CIA involved, or the various bureaucracy involved in his death?
Robert F. Kennedy Jr

(01:11:00)
The evidence that the CIA was involved in my uncle’s murder, and that they were subsequently involved in the coverup, and continue to be involved in the coverup, I mean, there’s still 5,000 documents that they won’t release 60 years later, is I think, so insurmountable and so mountainous and overwhelming, that it’s beyond any reasonable doubt, including dozens of confessions of people who were involved in the assassination. But every kind of document, and I mean, it came as a surprise recently to most Americans, I think, the release of these documents in which the press, the American media, finally acknowledged that, yeah, Lee Harvey Oswald was the CIA asset, that he was recruited in 1957. He was a Marine working at the Atsugi Air Force Base, which was the CIA Air Force base with the U2 flights, which was a CIA program. And that he was recruited by James Jesus Angleton, who was the director of counterintelligence and then sent on a fake defection to Russia and then brought back to Dallas.

(01:12:34)
And people didn’t know that, even though it’s been known for decades, it never percolated into the mainstream media, because they have such an allergy to anything that challenges the Warren Report. When Congress investigated my uncle’s murder in the 1970s, the Church committee did, and they did a two and a half year investigation, and they had many, many more documents, and much more testimony available to them than the Warren Commission had, and this was a decade after the Warren Commission. They came to the conclusion that my uncle was killed by a conspiracy. And there was a division where essentially one guy on that committee believed it was primarily the mafia, but Richard Schweitzer was the senator at head of the committee, said straight out, the CIA was involved in the murder of the President of the United States.

(01:13:42)
I’ve talked to most of the staff on that committee, and they said, yeah, and the CIA was stonewalling us the whole way through. And the actual people that the CIA appointed, George Johanedees, who the CIA appointed as a liaison to the committee, they brought him out of retirement, he had been one of the masterminds of the assassination.

(01:14:06)
I mean, it’s impossible to even talk about a tiny of the fraction of the evidence here. What I suggest to people, there are hundreds of books written about this, that assemble this evidence and mobilize the evidence. The best book to me, for people to read is James Douglass’s book, which is called, The Unspeakable. And he, Douglass does this extraordinary. He is an extraordinary scholar, and he does this just an amazing job of digesting and summarizing and mobilizing all of them, probably a million documents, and the evidence from all these confessions that have come out, into a coherent story. And it’s riveting to read. And I recommend people, do not take my word for it, and don’t take anybody else’s word for it, go ahead and do the research yourself. And one way to do that is probably the most efficient way, is to read Douglas’s book. He has all the references there.
Lex Fridman

(01:15:08)
So if it’s true that CIA had a hand in this assassination, how is it possible for them to amass so much power? How is it possible for them to become corrupt? And is it individuals, or is it the entire institution?
Robert F. Kennedy Jr

(01:15:22)
No, it’s not the entire institution. My daughter-in-law, who’s helping to run my campaign was a CIA, in the clandestine for all her career. She was a spy in the Weapons of Mass Destruction program in the Middle East and in China. And there’s 22,000 people who work for the CIA, probably 20,000 of those are patriotic Americans and really good public servants, and they’re doing important work for our country. But the institution is corrupt, and because the higher up ranks the institution. And in fact, Mike Pompeo said something like this to me the other day. He was the director of the CIA. He said, “When I was there, I did not do a good job of cleaning up that agency.” And he said, “The entire upper bureaucracy of that agency, are people who do not believe in the institutions of democracy.” This is what he said to me. I don’t know if that’s true, but I know that that’s significant. He’s a smart person, and he ran the agency and he was the Secretary of State.

(01:16:32)
But it’s no mystery how that happened. We know the history. The CIA was originally…First of all, there was great reluctance in 1947, that for the first time, we had a secret spy agency in this country during World War II, called the OSS. That was disbanded after the war, because Congress said, having a secret spy agency is incompatible with a democracy. The secret spy agency are things like the KGB, the STASI in East Germany, SAVAK in Iran, and PEEP, and Chile and whatever, all over the world, they’re all have to do with totalitarian governments. They’re not something that you can have that, it’s antithetical to democracy to have that. But in 1947, we created, Truman signed it in, but it was initially an espionage agency, which means information gathering, which is important. It’s to gather and consolidate information from many, many different sources from all over the world, and then put those in reports for the White House, so the president can make good decisions based upon valid information, evidence-based decision making.

(01:17:57)
But Alan Dulles, who was essentially the first head of the agency, made a series of legislative imaginations and political imaginations, that gave additional powers to the agency, and opened up what they called then the plans division, which is the plans division is the dirty tricks, it’s the black ops, fixing elections, murdering, what they call executive action, which means killing foreign leaders, and making small wars, and bribing, and blackmailing, people stealing elections, and that kind of thing. And the reason, at that time, we were in the middle of the Cold War and Truman, and then Eisenhower did not want to go to war. They didn’t want to commit troops. And it seemed to them that this was a way of fighting the Cold War secretly, and doing it at minimal cost by changing events sort of invisibly. And so it was seductive to them.

(01:19:08)
But everybody, Congress, when they first voted it in place, Congress, both political parties said, if we create this thing, it could turn into a monster and it could undermine our values. And today it’s so powerful, and then nobody knows what its budget is. Plus it has its own investment fund In-Q-Tel, which has invested, made I think, 2000 investments in Silicon Valley. So it has ownership of a lot of these tech companies, and a lot of the CEOs of those tech companies have signed state secrecy agreements with the CIA, which if they even reveal that they have signed that, they can go to jail for 20 years and have their assets removed, et cetera. The influence that the agency has, the capacity to influence events at every level in our country, is really frightening.
CIA influence

(01:20:03)
And then for most of its life, the CIA was banned from propagandizing Americans, but we learned that they were doing it anyway. So in 1973, during the Church Committee hearings, we’ve learned that the CIA had a program called Operation Mockingbird, where they had at least 400 members, leading members of the United States press corps, on the New York Times, the Washington Post, ABC, CBS, NBC, et cetera, who were secretly working for the agency, and steering news coverage to support CIA priorities. And they agreed at that time to disband Operation Mockingbird in ’73. But there’s indications they didn’t do that.

(01:20:56)
And they still, the CIA today, is the biggest funder of journalism around the world. The biggest funder is through USAID. The United States funds journalism in almost every country in the world. It owns newspapers, it has journalists on it, thousands and thousands of journalists, on its payroll. They’re not supposed to be doing that in the United States. But in 2016, president Obama changed the law to make it legal now for the CIA to propagandize Americans. And I think, we can’t look at the Ukraine War and how the narrative has been formed in the minds of Americans, and say that the CIA had nothing to do with that.
Lex Fridman

(01:21:46)
Well, what is the mechanism by which the CIA influences the narrative? Do you think it’s indirectly?
Robert F. Kennedy Jr

(01:21:51)
Through the press.
Lex Fridman

(01:21:52)
Indirectly through the press, or directly by funding the press?
Robert F. Kennedy Jr

(01:21:55)
Directly through. I mean, there’s certain press organs that have been linked to the agency, that the people who run those organs, things like the Daily Beast, now Rolling Stone, editor of Rolling Stone, Noah Shachtman, has deep relationships with the intelligence community, Salon, Daily Kos.
Lex Fridman

(01:22:19)
But I wonder why they would do it. From my perspective, it just seems like the job of a journalist is to have an integrity where your opinion cannot be influenced or bought.
Robert F. Kennedy Jr

(01:22:30)
I agree with you, but I actually think that the entire field of journalism has really shamed itself in recent years, because it’s become, the principle newspapers in this country and the television stations, the legacy media, have abandoned their tradition of… When I was a kid, listen, my house was filled with the greatest journalists alive at that time, people like Ben Bradley, like Anthony Lewis, Mary McGrory, Pete Hamil, Jack Newfield, Jimmy Breslin, and many, many others. And after my father died, they started the RFK Journalism Awards to recognize integrity and courage, journalistic integrity and courage. And for that generation of journalism, they thought, they believed that the function of journalists, was to maintain this posture of fear-skepticism toward any aggregation of power, including government authority, that people in authority lie, and that they always have to be questioned, and that their job was to speak truth to power, and to be guardians of the First Amendment to free expression.

(01:23:57)
But if you look what happened during the pandemic, was the inverse of that kind of journalism, where the major press organs in this country were, instead of speaking truth to power, they were doing the opposite. They were broadcasting propaganda. They became propaganda organs for the government agencies. And they were actually censoring the speech of dissent, anybody who dissent, of the powerless. And in fact, it was an organized conspiracy, and the name of it was the Trusted News Initiative. And some of the major press organs in our country signed onto it, and they agreed not to print stories or facts, that departed from government orthodoxy. So the Washington Post was the signature of the UPI, the AP, and then the four social media groups, Microsoft, Twitter, Facebook, and Google, all signed on to the Trusted News Initiative.

(01:24:59)
It was started by the BBC, organized by them. And the purpose of it, was to make sure nobody could print anything about government that departed from governmental orthodox. And the way it worked is, the UPI, the AP, which are the news services that provide most of the news news around the country, and the Washington Post, would decide what news was permissible to print. And a lot of it was about COVID, but also Hunter Biden’s laptops, it was impermissible to suggest that those were real, or that they had stuff on there that was compromising.

(01:25:39)
And by the way, what I’m telling you is all well documented, and I’m litigating on it right now, so I’m part of a lawsuit against the TNI, and so I know a lot about what happened, and I have all this documented and people can go to our website. There’s a letter on my sub-stack now, to Michael Scherer of the Washington Post that outlines all this, and gives all my sources, because Michael Scherer accused me of being a conspiracy theorist, when he was actually part of a conspiracy, a true conspiracy, to suppress anybody who is departing from government orthodoxies, by either censoring them completely, or labeling them conspiracy theorists.
Lex Fridman

(01:26:26)
I mean, you can understand the intention and the action, the difference between as we talked about, you can understand the intention of such a thing being good, that in a time of a catastrophe, in a time of a pandemic, there’s a lot of risk to saying untrue things. But that’s a slippery slope that leads into a place where the journalistic integrity that we talked about, is completely sacrificed, and then you can deviate from truth.
Robert F. Kennedy Jr

(01:26:54)
If you read their internal memorandum, including the statements of the leader of the Trusted News Initiative, I think her name’s Jessica, Jennifer, Cecil and you can go on our website and see her statement. She says, the purpose of this is that we’re now… Actually, she says, when people look at the us, they think we’re competitors, but we’re not. The real competitors are coming from all these alternative news sources now all over the network, and they’re hurting public trust in us, and they’re hurting our economic model, and they have to be choked off and crushed. And the way that we’re going to do that, is to make an agreement with the social media sites, that if we say, if we label their information misinformation, the social media sites will de platform it, or they will throttle it, or they will shadow-ban it, which destroys the economic model of those alternative, competitive sources of information. So that that’s true.

(01:27:58)
But the point you make, is an important point. That the journalists themselves, who probably didn’t know about the TNI agreement, certainly I’m sure they didn’t, they believe that they’re doing the right thing by suppressing information that may challenge government proclamations on COVID. But I mean, there’s a danger to that. And the danger is that, once you appoint yourself an arbiter of what’s true and what’s not true, then there’s really no end to the power that you have now assumed for yourself, because now your job is no longer to inform the public. Your job now is to manipulate the public. And if you end up manipulating the public in collusion with powerful entities, then you become the instrument of authoritarian rule, rather than the opponent of it. And it becomes the inverse of journalism and a democracy.
2024 elections
Lex Fridman

(01:29:05)
You’re running for president as a Democrat, what to you are the strongest values that represent the left-wing politics of this country?
Robert F. Kennedy Jr

(01:29:18)
I would say protection of the environment, and the commons, the air, the water, wildlife, fisheries, public lands, those assets, they cannot be reduced to private property ownership, the landscapes, our purple mountain majesty, the protection of the most vulnerable people in our society, people which would include children and minorities, the restoration of the middle class, and protection of labor, dignity, and decent pay for labor, bodily autonomy, a woman’s right to-
Robert F. Kennedy Jr

(01:30:03)
… bodily autonomy, a woman’s right to choose or an individual’s right to endure unwanted medical procedures. Peace. The Democrats have always been anti-war. The refusal to use fear is a governing tool. FDR said, “The only thing we have to fear is fear itself,” because he recognized that tyrants and dictators could use fear to disable critical thinking and overwhelm the desire for personal liberty. The freedom of government from untoward influenced by corrupt corporate power. The end of this corrupt merger of state and corporate power that is now I think, dominating our democracy. It’s what Eisenhower warned about when he warned against the emergence of the military industrial complex.

(01:31:07)
And then I prefer to talk about the positive vision of what we should be doing in our country and globally, which is I see that the corporations are commoditizing us are poisoning our children, are strip mining the wealth from our middle class and treating America as if it were business in liquidation, converting assets to cash as quickly as possible and creating or exacerbating this huge disparity in wealth in our country, which is eliminating the middle class and creating a Latin American style futile model. There’s these huge aggregations of wealth above and widespread poverty below, and that’s a configuration that is too unstable to support democracy sustainably. And we’re supposed to be modeling democracy, but we’re losing it.

(01:32:11)
And I think we have ought to have a foreign policy that restores our moral authority around the world. Restores America as the embodiment of moral authority, which it was when my uncle was president. And as a purveyor of peace rather than a war-like nation. My uncle said he didn’t want people in Africa and Latin America and Asia when they think of America to picture a man with a gun and a bayonet. He wanted them to think of a Peace Corps volunteer, and he refused to send combat soldiers abroad. He never sent a single soldier to his death abroad and into combat. He sent 16,000. He resisted in Berlin in ’62. He resisted in Laos in ’61. He resisted in Vietnam. Vietnam, they wanted him to put 250,000 troops. He only put 16,000 advisors, which was fewer troops.

(01:33:22)
And he sent to get James Meredith into the universe to Ole Miss in Oxford, Mississippi. One black man, he sent 16,000. And month before he died, he ordered them all home. I think it was October 2nd, 1963, he heard that a Green Beret had died. And he asked his aid for a list of combat fatalities. And the aid came back and there was 75 men had died in Vietnam at that point. And he said, “That’s too many. We’re going to have no more.” And he signed a national security order, 263, and ordered all of those men, all Americans, home from Vietnam by 1965 with the first thousand coming home by December ’63.

(01:34:13)
And then in November he, of course, just before that evacuation began, he was killed. And a week later, president Johnson remanded that order. And then a year after that, the Tonkin Gulf resolution, we sent 250,000, which is what they wanted my uncle to do, which he refused. And it became an American war. And then Nixon topped it off at 560,000. 56,000 Americans never came home, including my cousin George Skakel, who died at the Tet Offensive. And we killed a million Vietnamese and we got nothing for it.
Lex Fridman

(01:34:51)
So America should be the symbol of peace?
Robert F. Kennedy Jr

(01:34:57)
My uncle really focused on putting America on the side of the poor, instead of our tradition of fortifying oligarchies that were anti-communism. That was our major criteria. If you said you were against communists, and of course the people were with the rich people, our aid was going to the rich people in those countries and they were going to the military juntas. Our weapons were going to the juntas to fight against the poor. And my uncle said, “No, America should be on the side of the porn.” And so he launched the Alliance for Progress and USAID, which were intended to bring aid to the poorest people and those, and build middle classes, and take ourselves away.

(01:35:42)
In fact, his two favorite trips while he was president. His most favorite trip was to Ireland, this incredible, emotional homecoming for all of the people of Ireland. But his second favorite trip was when he went to Colombia, he went to Latin America, but Colombia was his favorite country. And I think there were 2 million people came into Bogota to see him, this vast crowd. And they were just delirious cheering for him. And the president of Columbia, Lleras Camargo, said to him, “Do you know why they love you?”

(01:36:22)
And my uncle said, “Why?”

(01:36:24)
And he said, “Because they think you’ve put America on the side of the poor against the oligarchs.” And my uncle, after he died, today, there are more avenues and boulevards and hospitals and schools and statues and parks commemorating John Kennedy in Africa and Latin America than any other president in the United States, and probably more than all the other presidents combined. And it’s because he put America on the side of the poor. And that’s what we ought to be doing.

(01:37:01)
We ought to be projecting economic power abroad. The Chinese have essentially stolen his playbook and we’ve spent $8 trillion on the Iraq war and its aftermath. The wars in Syria, Yemen, Libya, Afghanistan, Pakistan. And what do we get for that? We got nothing for that money. $8 trillion. We killed more Iraqis than Saddam Hussein. Iraq today is much worse off than it was when Saddam was there. It’s an incoherent, violent war between Shia and Sunni death squads. We pushed Iraq into the embrace of Iran, which now become essentially a proxy for Iran, which is exactly the outcome that we were trying to prevent for the past 20 or 30 years.

(01:37:53)
We created ISIS, we sent 2 million refugees into Europe, destabilizing all of the nations in Europe for generations. And we’re now seeing these riots in France, and that’s a direct result from the Syrian war that we created and our creation of ISIS. Brexit is another result of that. So for $8 trillion, we wrecked the world. And during that same period that we spent $8.1 trillion bombing bridges, ports, schools, hospitals, the Chinese spent 8.1 trillion building schools, ports, hospitals, bridges, and universities.

(01:38:42)
And now the Chinese are out-competing us everywhere in the world. Everybody wants to deal with the Chinese because they come in, they build nice things for you, and there’s no strings attached and they’re pleasant to deal with. And as a result of that, Brazil is switching the Chinese currency. Argentina is switching. Saudi Arabia, our greatest partner that we put trillions of dollars into protecting our oil pipelines there. And now they’re saying, “We don’t care what the United States think.” That’s what Mohammed bin Salman said.

(01:39:24)
He dropped oil production in Saudi Arabia in the middle of a US inflation spiral. They’ve never done that to us before, to aggravate the inflation spiral. And then they signed a deal, a unilateral peace deal with Iran, which has been the enemy that we’ve been telling them to be a bulwark against for 20 years. And two weeks after that, he said, “We don’t care what the United States thinks anymore.” So that’s what we got for spending all those trillions of dollars there. We got short term friends. And we have not made ourselves safer. We’ve put Americans in more jeopardy all over the world. You have to wait in lines to get through the airport. The security state is now causing us $1.3 trillion, and America is unsafer and poorer than it’s ever been. So we should be doing what President Kennedy said we ought to do, and the policy that China has now adopted.
Jordan Peterson
Lex Fridman

(01:40:37)
So that’s a really eloquent and clear and powerful description of the way you see US should be doing geopolitics and the way you see US should be taking care of the poor in this country. Let me ask you a question from Jordan Peterson that he asked when I told him that I’m speaking with you. “Given everything you’ve said, when does the left go too far?” I suppose he’s referring to cultural issues, identity politics.
Robert F. Kennedy Jr

(01:41:10)
Well, Jordan trying to get me to badmouth the left the whole time I was in, I really enjoyed my talk with him, but he seemed to have that agenda where he wanted me to say bad things about the left and that’s not what my campaign is about. I want to do the opposite. I’m not going to badmouth the left. I was on shows this week with David Remnick from the New Yorker, and he tried to get me to badmouth Donald Trump and Alex Jones and a lot of other people, and baiting me to do it. And of course there’s a lot of bad things I could say about all those people, but I’m trying to find values that hold us together and we can share in common, rather than to focus constantly on these disputes and these issues that drive us apart.

(01:42:07)
So me sitting here badmouthing the left or badmouthing the right is not going to advance the ball. I really want to figure out ways that what do these groups hold in common that we can all have a shared vision of what we want this country to look like.
Anthony Fauci
Lex Fridman

(01:42:25)
Well, that’s music to my ears. But in that spirit, let me ask you a difficult question then. You wrote a book harshly criticizing Anthony Fauci. Let me ask you to steelman the case for the people who support him. What is the biggest positive thing you think Anthony Fauci did for the world? What is good that he has done for the world, especially during this pandemic?
Robert F. Kennedy Jr

(01:42:48)
I don’t want to sit here and speak unfairly by saying the guy didn’t do anything, but I can’t think of anything. If you tell me something that you think he did, maybe there was a drug that got licensed while he was at NIH that benefited people, that’s certainly possible. He was there for 50 years. And in terms of his principle programs of the AIDS programs and his COVID programs, I think that the harm that he did vastly outweighed the benefits.
Lex Fridman

(01:43:29)
Do you think he believes he’s doing good for the world?
Robert F. Kennedy Jr

(01:43:31)
I don’t know what he believes. In fact, in that book, which is I think 250,000 words, I never try to look inside of his head. I deal with facts. I deal with science and every factual assertion in that book is cited in source to government databases or peer reviewed publications. And I try not to speculate about things that I don’t know about or I can’t prove. And I cannot tell you what his motivations were. He’s done a lot of things that I think are really very, very bad things for humanity and very deceptive. But we all have this capacity for self-deception. As I said at the beginning of this podcast, we judge ourselves on our intentions rather than our actions. And we all have an almost infinite capacity to convince ourselves that what we’re doing is right. And not everybody lives an examined life. And it is examining their motivations and the way that the world might experience their professions of goodness.
Lex Fridman

(01:44:45)
Let me ask about the difficulty of the job he had. Do you think it’s possible to do that kind of job well or is it also a fundamental flaw of the job, of being the central centralized figure that’s supposed to have a scientific policy?
Robert F. Kennedy Jr

(01:44:58)
No. No. I think he was a genuinely bad human being. And that there were many, many good people in that department over the years. Bernice Eddy is a really good example. John Anthony Morris. Many people whose careers he destroyed because they were trying to tell the truth. One after the other, the greatest scientists in the history of NIH were run out of that agency. But people listening to this, probably will, in hearing me say that, will think that I’m bitter or that I’m doctrinaire about him, but you should really go and read my book. And it’s hard to summarize. I try to be really methodical, to not call names, to just say what happened.
Big Pharma
Lex Fridman

(01:45:57)
The bigger picture of this is you’re an outspoken critic of pharmaceutical companies, big pharma. What is the biggest problem with big pharma and how can it be fixed?
Robert F. Kennedy Jr

(01:46:07)
Well, the problem could be fixed with regulation. But the pharmaceutical industry is… I don’t want to say because this is going to seem extreme that a criminal enterprise, but if you look at the history, that is an applicable characterization, for example, the four biggest vaccine makers, Sanofi, Merck, Pfizer, and Glaxo, four companies that make all of the 72 vaccines that are now effectively mandated for American children. Collectively, those companies have paid $35 billion in criminal penalties and damages in the last decade. And I think since 2000, about 79 billion. So these are the most corrupt companies in the world.

(01:47:08)
And the problem is that they’re serial felons. They do this again and again and again. So Merck did Vioxx, which, Vioxx, they killed people by falsifying science. And they did it. They lied to the public. They said, “This is a headache medicine and a arthritis painkiller.” But they didn’t tell people that it also gave you heart attacks.

(01:47:37)
And they knew, we’ve found when we sued them, the memos from their bean counters saying, “We’re going to kill this many people, but we’re still going to make money.” So they make those calculations and those calculations are made very, very regularly. And then when they get caught, they pay a penalty. And I think they paid about $7 billion for Vioxx. But then they went right back that same year that they paid that penalty, they went back into the same thing again with Gardasil and with a whole lot of other drugs. So the way that the system is set up, the way that it’s sold to doctors, the way that nobody ever goes to jail, so there’s really no penalty that it all becomes part of the cost of doing business.

(01:48:32)
And you can see other businesses that if there’s no penalty, if there’s no real… look, these are the companies that gave us the opioid epidemic. So they knew what was going to happen. And you go and see, there’s a documentary, I forget what the name of it is, but it shows exactly what happened. And they corrupted FDA. They knew that oxycodone was addictive. They got FDA to tell doctors that it wasn’t addictive. They pressured FDA to lie. And they got their way. And so far they got a whole generation addicted oxycodone. And now when they got caught, and we made it harder to get oxycodone, and now all those addicted kids are going to fentanyl and dying. And this year it killed 106,000. That’s twice as many people who were killed during the 20-year Vietnam War. But in one year, twice as many American kids. And they knew it was going to happen and they did it to make money. So I don’t know what you call that other than saying that’s a criminal enterprise.
Lex Fridman

(01:49:47)
Well, is it possible, within a capitalist system, to produce medication, to produce drugs at scale in a way that is not corrupt?
Robert F. Kennedy Jr

(01:49:57)
Of course it is.
Lex Fridman

(01:49:58)
How?
Robert F. Kennedy Jr

(01:50:00)
Through a solid regulatory regimen, where drugs are actually tested. The problem is not the capitalist system. The capitalist system, I have great admiration for and love for the capitalist system. It’s the greatest economic engine ever devised. But it has to be harnessed to a social purpose. Otherwise, it leads us down a trail of oligarchy, environmental destruction, and commoditizing poisoning and killing human beings. That’s what it will do. And in the end, you need a regulatory structure that is not corrupted by entanglements, financial entanglements with the industry. And we’ve set this up. The way that the system is set up today has created this system of regulatory capture on steroids.

(01:51:06)
So almost 50% of FDA’s budget comes from pharmaceutical companies. The people who work at FDA are, their salaries are coming from pharma, half their salaries. So they know who their bosses are. And that means getting those drugs done, getting them out the door and approved as quickly as possible. It’s called fast track approval. 50% of FDA’s budget, about 45%, actually goes to fast track approval.
Lex Fridman

(01:51:38)
Do you think money can buy integrity?
Robert F. Kennedy Jr

(01:51:40)
Oh yeah, of course it can. That’s not something that is controversial. Of course it will.
Lex Fridman

(01:51:48)
It’s slightly controversial to me. I would like to think that scientist that work at the FDA-
Robert F. Kennedy Jr

(01:51:53)
Well, it may not be able to buy your integrity. I’m talking about population wide, I’m not talking about the individual.
Lex Fridman

(01:51:58)
But I’d like to believe that in general, a career of a scientist is not a very high paying job. I’d like to believe that people that go into science, that work at FDA, that work at NIH are doing it for a reason that’s not even correlated with money, really.
Robert F. Kennedy Jr

(01:52:18)
Yt. And I think probably that’s why they go in there. But scientists are corruptible. And the way that I can tell you that is that I’ve brought over 500 losses and almost all of them involve scientific controversies. And there are scientists on both sides in every one. And when we sued Monsanto, on the Monsanto side, there was a Yale scientist, a Stanford scientist, and a Harvard scientist. And on our side there was a Yale, Stanford and Harvard scientist. And they were saying exactly the opposite things. In fact, there’s a word for those kind of scientists who take money for their opinion, and the word is biostitutes. And they are very, very common. And I’ve been dealing them with them my whole career.

(01:53:05)
I think it was Upton Sinclair, that it’s very difficult to persuade a man of a fact if the existence of that fact will diminish his salary. And I think that’s true for all of us. If we find a way of reconciling ourselves, to truths and worldviews that actually benefit our salaries. Now, NIH has probably the worst system, which is that scientists who work for NIH itself, which used to be the premier gold standard scientific agency in the world, everybody looked at NIH as that. Today, it’s just an incubator for pharmaceutical drugs. And that is that gravity of economic self-interest.

(01:53:58)
Because if NIH itself collects royalties, they have margin rights for the patents on all the drugs that they work on. So with the Moderna vaccine, which they promoted incessantly and aggressively, NIH on 50% of that vaccine is making billions and billions of dollars on it. And there are at least four scientists that we know of, and probably at least six at NIH, who themselves have marching rights for those patents. So if you are a scientist who work at NIH, you work on a new drug, you then get marching rights and you’re entitled to royalties of $150,000 a year forever from that forever. Your children, your children’s children. As long as that product’s on the market, you can collect royalties.

(01:54:46)
Moderna vaccine is paying for the top people at NIH. Some of the top regulators. It’s paying for their boats, it’s paying for their mortgages, it’s paying for their children’s education. And you have to expect that in those kind of situations, the regulatory function would be subsumed beneath the mercantile ambitions of the agency itself and the individuals who stand to profit enormously from getting a drug to market. Those guys are paid by us, the taxpayer, to find problems with those drugs before they get to market. But if you know that drug is going to pay for your mortgage, you may overlook a little problem or even a very big one. And that’s the problem.
Lex Fridman

(01:55:38)
You’ve talked about that the media slanders you by calling you an anti-vaxxer, and you’ve said that you’re not anti-vaccine, you’re pro safe vaccine. Difficult question, can you name any vaccines that you think are good?
Robert F. Kennedy Jr

(01:55:55)
I think some of the live virus vaccines are probably averting more problems than they’re causing. There’s no vaccine that is safe and effective. In fact-
Lex Fridman

(01:56:09)
Those are big words.
Robert F. Kennedy Jr

(01:56:09)
… Those are big words.
Lex Fridman

(01:56:10)
What about the polio? Let’s start with the-
Robert F. Kennedy Jr

(01:56:11)
Well, here’s the problem. Here’s the problem. Yeah, here’s the problem. The polio vaccine contained a virus called simian virus 40. SV40. It’s one of the most carcinogenic materials that is known to man. In fact, it’s used now by scientists around the world to induce tumors and rats and Guinea pigs in labs. But it was in that vaccine, 98 million people who got that vaccine. And my generation got it. And now you’ve had this explosion of soft tissue cancers in our generation that killed many, many, many more people than polio ever did. So if you say to me, “The polio vaccine, was it effective against polio?”

(01:56:55)
I’m going to say, “Yes.”

(01:56:57)
And if say to me, “Did it cause more death than avert?”

(01:57:02)
I would say, “I don’t know, because we don’t have the data on that.”
Lex Fridman

(01:57:06)
But let’s talk. We have to narrow in on what is it effective against the thing it’s supposed to fight?
Robert F. Kennedy Jr

(01:57:12)
Oh, well, a lot of them are, let me give you an example. The most popular vaccine in the world is the DTP vaccine. Diphtheria, tetanus and pertussis. It was introduced in this country around 1980. That vaccine caused so many injuries that Wyeth, which was the manufacturer, said to the Reagan administration, “We are now paying $20 in downstream liabilities for every dollar that we’re making in profits, and we are getting out of the business unless you give us permanent immunity from liability.”

(01:57:45)
And by the way, Reagan said at that time, “Why don’t you just make the vaccine safe?” And why is that? Because vaccines are inherently unsafe.

(01:57:58)
They said, “Unavoidably unsafe, you cannot make them safe.”

(01:58:02)
And so when Reagan wrote the bill and passed it, the bill says in its preambles, “Because vaccines are unavoidably unsafe.” And the Bruesewitz case, which was the Supreme Court case that upheld that bill uses that same language, vaccines cannot be made safe. They’re unavoidably unsafe. So this is what the law says.

(01:58:21)
Now, I just want to finish this story because this illustrates very well your question. The DTP vaccine was discontinued in this country and it was discontinued in Europe because so many kids were being injured by it. However, the WHO and Bill Gates gives it to 161 million African children every year. And Bill Gates went to the Danish government and asked them to support this program saying, “We’ve saved 30 million kids from dying from diptheria, tetanus and pertussis.”

(01:58:59)
The Danish government said, “Can you show us the data?” And he couldn’t. So the Danish government paid for a big study with Novo Nordisk, which is a Scandinavian vaccine company in West Africa. And they went to West Africa and they looked at the DTP vaccine for 30 years of data and they retained the best vaccine scientists in the world, these deities of African vaccine program. Peter Aaby, Sigrid Morganson, and a bunch of others. And they looked at 30 years of data for the DTP vaccine. And they came back and they were shocked by what they found.

(01:59:36)
They found that the vaccine was preventing kids from getting diptheria, tetanus and pertussis. But the girls who got that vaccine were 10 times more likely to die over the next six months than children who didn’t. Why is that? And they weren’t dying from anything anybody ever associated with the vaccine. They were dying of anemia, bilharzia, malaria, sepsis, and mainly pulmonary and respiratory disease, pneumonia.
Robert F. Kennedy Jr

(02:00:02)
Mainly pulmonary and respiratory disease, pneumonia. And it turns out that this is what research has found who were all pro-vaccine, by the way. They said that this vaccine is killing more children and than did their attendance and protected prior to the introduction of the vaccine and for 30 years nobody ever noticed it. The vaccine was providing protection against those target illnesses, but it had ruined the children’s immune systems. And they could not defend themselves against random infections that were harmless to most children.
Lex Fridman

(02:00:36)
But isn’t it nearly impossible to prove that link?
Robert F. Kennedy Jr

(02:00:39)
You can’t prove the link, all you can do is for any particular interest, illness or death, you can’t prove the link. But you can show statistically that if you get that vaccine, you’re more likely to die over the next six months than if you don’t. And those studies unfortunately are not done for any other vaccines. So for every other medicine, in order to get approval from the FDA, you have to do a placebo controlled trial prior to licensure, where you look at health outcomes among an exposed group, a group that gets it and compare those to a similarly situated group that gets placebo. The only medical intervention that does not receive, that does not undergo placebo controlled trials prior to licensure are vaccines. Not one of the 72 vaccines that are now mandated for our children have ever undergone a placebo controlled trial prior to licensure.
Lex Fridman

(02:01:38)
So I should say on that point, I’ve heard from a bunch of folks that disagree with you.
Robert F. Kennedy Jr

(02:01:44)
Okay.
Lex Fridman

(02:01:44)
Including polio. I mean, the testing is a really important point. Before licensure, placebo controlled randomized trials, polio received just that against the saline placebo control. So I’m confused why you say that they don’t go through that process. It seems like a lot of them do.
Robert F. Kennedy Jr

(02:02:10)
Here’s the thing is that I was saying that for many years because we couldn’t find any. And then in 2016, in March, President Trump ordered Dr. Fauci to meet with me. Dr. Fauci and Francis Collins, and I said to them during that meeting, “You have been saying that I’m not telling the truth when I said not one of these has undergone a prior pre-licensure placebo control.” And the polio may have had one post licensing, most of them haven’t. The polio may have, I don’t know. But I said, “Our question was prior to licensure, do you ever test these? And for safety?” And by the way, I think the polio vaccine did undergo a saline placebo trial prior licensure, but not for safety, only for efficacy. So I’m talking about safety trials now. Fauci told me, he had a whole tray of files there. He said, “I can’t find one now, but I’ll send you one.”

(02:03:26)
I said, “Just for any vaccines, send me one. Any of the 72 vaccines,” He never did. So we sued the HHS and after a year of stonewalling us, HHS came back and they gave us a letter saying we have no pre-licensing safety trial for any of the 72 vaccines. And that the letter from HHS, which settled our lawsuit against them because we had a FOIA lawsuit against them, is posted on CHD’s website. So anybody can go look at it. So if HHS had any study, I assume they would’ve given it to us and they can’t find one.
Lex Fridman

(02:04:08)
Well, let me zoom out because a lot of the details matter here, pre-licensure, what does placebo controlled mean? So this probably requires a rigorous analysis. And actually, at this point, it would be nice for me just to give the shout-out to other people much smarter than me that people should follow along with Robert F. Kennedy Jr, use their mind, learn and think. So one really awesome creator, I really recommend him is Dr. Dan Wilson. He hosts the Debunk the Funk Podcast. Vincent Racaniello, who hosts This Week in Virology. Brilliant guy, I’ve had him on the podcast. Somebody you’ve been battling with is Paul Offit, interesting Twitter, interesting books. People should, understand and read your books as well. And Eric Topol has a good Twitter and good books. And even Peter Hotez, I’ll ask you about him.
Robert F. Kennedy Jr

(02:05:03)
And people should, because Paul Offit published a substack recently debunking, I think my discussion with Joe Rogan. And we have published a debunk of his debunking. So if you read his stuff, you should read-
Lex Fridman

(02:05:29)
Read both.
Robert F. Kennedy Jr

(02:05:30)
Yes, you should read… And I would love to debate any of these guys.
Peter Hotez
Lex Fridman

(02:05:37)
So Joe Rogan proposed just such a debate, which is quite fascinating to see how much attention and how much funding it garnered the debate between you and Peter Hotez. Why do you think Peter rejected the offer?
Robert F. Kennedy Jr

(02:05:51)
I think, again, I’m not going to look into his head, but what I will say is if you’re a scientist and you’re making public recommendations based upon what you say is evidence-based science, you ought to be able to defend that. You ought to be able to defend it in a public forum and you ought to be able to defend it against all comers. So if you’re a scientist, science is rooted in logic and reason. And if you can’t use logic and reason to defend your position, and by the way, I know almost all of the studies, I’ve written books on them and we’ve made a big effort to assemble all the studies on both sides. And so, I’m prepared to talk about those studies and I’m prepared to submit them in advance and for each of the points. And by the way, I’ve done that with Peter Hotez, actually because I had this kind of informal debate several years ago with him, with a referee at that time.

(02:07:02)
And we were debating not only by phone but by email and on those emails, every point that he would make, I would cite science and he could never come back with science. He could never come back with publications. He would give publications that had nothing to do with, for example, thimerosal and vaccines, mercury based vaccines. He sent me one time, 16 studies to rebut something I’d said about thimerosal. And not one of those studies, they were all about the MMR vaccine, which doesn’t contain thimerosal. So it wasn’t like a real debate where you’re using reason and isolating points and having a rational discourse. I don’t blame him for not debating me because I don’t think he has the science.
Lex Fridman

(02:07:53)
Are there aspects of all the work you’ve done on vaccines, all the advocacy you’ve done, that you found out that you were not correct on, that you were wrong on, that you’ve changed your mind on?
Robert F. Kennedy Jr

(02:08:09)
Yeah, there are many times over time that I found that I’ve made mistakes and we correct those mistakes. I run a big organization and I do a lot of tweets. I’m very careful. For example, my Instagram, I was taken down for misinformation, but there was no misinformation on my Instagram. Everything that I cited on Instagram was cited or sourced to a government database or to peer reviewed science. But for example, the Defender, which was our organization’s newsletter, we summarized scientific reports all the time. That’s one of the things, the services that we provide. So we watch the PubMed and we watch the peer reviewed publications and we summarize them when they come out, we have made mistakes. When we make mistake, we are rigorous about acknowledging it, apologizing for it, and changing it. That’s what we do. I think we have one of the most robust fact checking operations anywhere in journalism today.

(02:09:09)
We actually do real science. And listen, I’ve put up on my Twitter account where there are numerous times that I’ve made mistakes on Twitter and I apologize for it. And people say to me, “Oh, that’s weird. I’ve never seen anybody apologize on Twitter.” But I think it’s really important at the only… Of course, human beings make mistakes. My book is 230 or 40, 50,000 words. There’s going to be a mistake in there. But you know what I say at the beginning of the book, “If you see a mistake in here, please notify me. I give away that people can notify me.” And if somebody points out a mistake, I’m going to change it. I’m not going to dig my feet in and say, “I’m not going to acknowledge this.”
Lex Fridman

(02:09:57)
So some of the things we’ve been talking about, you’ve been an outspoken contrarian on some very controversial topics. This has garnered some fame and recognition in part for being attacked and standing strong against those attacks. If I may say, for being a martyr, do you worry about this drug of martyrdom that might cloud your judgment?
Robert F. Kennedy Jr

(02:10:22)
First of all, I don’t consider myself a martyr and I’ve never considered myself a victim. I make choices about my life and I’m content with those choices and peaceful with them. I’m not trying to be a martyr or a hero or anything else. I’m doing what I think is right because I want to be peaceful inside of myself, but the only guard I have is fact-based reality. If you show me a scientific study that shows that I’m wrong, for example, if you come back and say, “Look, Bobby, here’s a safety study on polio that was done pre-licensure and used a real saline solution.” I’m going to put that on my Twitter and I’m going to say, “I was wrong, there is one out there.” But that’s all I can do.
Exercise and diet
Lex Fridman

(02:11:17)
All right. I have to ask, you are in great shape. Can you go through your diet and exercise routine?
Robert F. Kennedy Jr

(02:11:28)
I do intermittent fasting. So I start my first meal at around noon, and then I try to stop eating at six or seven. And then I hike every day.
Lex Fridman

(02:11:46)
Morning, evening?
Robert F. Kennedy Jr

(02:11:47)
In the morning. I go to a meeting first thing in the morning, 12, I’m eating. And then I hike uphill for a mile and a half up and a mile half down with my dogs and I do my meditations. And then I go to the gym and I go to the gym for 35 minutes. I do it short time and I’ve been exercising for 50 years. And what I’ve found is it’s sustainable if I do just the short periods and I do four different routines at the gym. And I never relax at the gym, I go in there and I have a very intense exercise. I lift, I mean, I could tell you what my routine is, but I do backs just one day, legs and then a miscellaneous. And I do 12.

(02:12:36)
My first set of everything is I try to reach failure at 12 reps. And then my fourth set of everything is a strip set. I take a lot of vitamins. I can’t even list them to you here because I couldn’t even remember them at all. But I take a ton of vitamins and nutrients, I’m on an anti-aging protocol from my doctor that includes testosterone replacement. But I don’t take any anabolic steroids or anything like that. And the DRT I use is bioidentical to what my body produced.
Lex Fridman

(02:13:25)
What are your thoughts on hormone therapy in general?
Robert F. Kennedy Jr

(02:13:29)
I talk to a lot of doctors about that stuff because I’m interested in health and I’ve heard really good things about it, but I’m definitely not an expert on it.
God
Lex Fridman

(02:13:42)
About God. You wrote, “God talks to human beings through many vectors, wise people, organized religion, the great books of religions, through art, music and poetry. But nowhere with such detail and grace and joy as through creation. When we destroy nature, we diminish our capacity to sense the divine.” What is your relationship and what is your understanding of God? Who is God?
Robert F. Kennedy Jr

(02:14:09)
Well, God is incomprehensible. I mean, I guess, most philosophers would say we’re inside the mind of God. And so, it would be impossible for us to understand what’s actually God’s form is. But I mean, for me, let’s say this, when I was raised in a very deeply religious setting, so we went to church in the summer, oftentimes twice a day, morning mass. And we definitely went every Sunday. And we prayed in the morning, we prayed before and after every meal, we prayed at night, we sent a rosary, sometimes three rosaries a night. And my father read us the Bible. Whenever he was a home, we’d all get in the bed and he’d read us the Bible stories. And I went to Catholic schools, I went to Jesuit schools, I went to the nuns and I went to a Quaker school at one point. I became a drug addict when I was about 15 years old, about a year after my dad died. And I was addicted to drugs for 14 years.

(02:15:32)
During that time, when you’re an addict, you’re living against conscience. And when you’re living against… I was always trying to get off of drugs, never able to. But I never felt good about what I was doing. And when you’re living against conscious, you kind of push God to the periphery of your life. So I’ll call Him, he gets recedes and gets smaller. And then when I got sober, I knew that I had a couple of experiences. One is that I had a friend of my brothers, one of my brothers who died of this disease of addiction, had a good friend who used to take drugs with us and he became a Moonie. So he became a follower of Reverend Sun Myung Moon. And at that point, he had the same kind of compulsion that I had and yet it was completely removed from him.

(02:16:41)
And he used to come and hang out with us, but he would not want to take drugs. Even if I was taking them right in front of him, he was immune to it. He’d become impervious to that impulse. And when I first got sober, I knew that I did not want to be the kind of person who was waking up every day in white knuckling sobriety and just trying to resist through willpower. And by the way, I had iron willpower as a kid. I gave up candy for lent when I was 12 and I didn’t need it again until I was in college. I gave up desserts the next year for lent. And I didn’t ever eat another dessert till I was in college. And I was trying to bulk up for rugby and for sports. So I felt like I could do anything with my willpower. But somehow this particular thing, the addiction was completely impervious to it. And it was cunning, baffling, incomprehensible. I could not understand why I couldn’t just say no and then never do it again like I did with everything else.

(02:17:57)
And so, I was living against conscience and I thought about this guy and reflecting my own prejudices at that time in my life, I said to myself, I didn’t want to be like a drug addict who was wanting a drug all the time and just not being able to do it. I wanted to completely realign myself so that I was somebody who got up every day and just didn’t want to take drugs, never thought of them, kissed the wife and children and went to work and never thought about drugs the whole day. And I knew that people throughout history had done that. I’d read the lives of the saints. I knew St. Augustine had met a very dissolute youth and had this spiritual realignment transformation. I knew the same thing had happened to St. Paul at Damascus. The same thing had happened to St. Francis.

(02:18:55)
St. Francis also had a dissolute and fun-loving youth and had this deep spiritual realignment. And I knew that that happened to people throughout history. And I thought that’s what I needed, something like that. I had the example of this friend of mine and I used to think about him and I would think this again reflects the bias and probably the meanness of myself at that time. But I said, “I’d rather be dead than be a Moonie.” But I wish I somehow could distill that power that he got without becoming a religious nuisance. And at that time, I picked up a book by Carl Yung called Synchronicity and Yung, he was a psychiatrist, he was contemporary of Freud’s. Freud was his mentor, and Freud wanted him to be his replacement. But Freud was now out atheist and Yung was a deeply spiritual man.

(02:19:58)
He had these very intense and genuine spiritual experiences from when he was a little boy, from when he was three years old that he remembers biography is fascinating about him because he remembers them with such a detail. And he was interesting to me because he was very faithful scientist and I considered myself a science-based person from when I was little. And yet he had this spiritual dimension to him, which infused all of his thinking and really I think made him, branded his form of recovery or of treatment. And he thought that he had this experiment experience that he describes in this book where he ran one of the biggest sanitariums in Europe in Zurich. And he was sitting up on the third floor of this building and he’s talking to a patient who was describing her dream to him.

(02:21:01)
And the fulcrum of that dream was a scarab beetle, which was an insect that is very uncommon if at all in Northern Europe, but it’s a common figure in the iconography of Egypt and the hieroglyphics on the walls of the pyramids, etc. And while he was talking to her, he heard this bing, bing, bing on the window behind him and he didn’t want to turn around to take his attention off her. But finally, he does it in exasperation. He turns around, he throws up the window and a scarab beetle flies in and lands in his head and he shows it to the woman. And he says, “Is this what you was thinking of, this is what you were dreaming about.” And he was struck by that experience which was similar to other experiences he’s had like that. And that’s what synchronicity means, it’s an incident, not a coincidence.

(02:21:56)
And if you’re talking with somebody about somebody that you haven’t thought about in 20 years and that person calls on the phone, that’s synchronicity. And he believed it was a way that God intervened in our lives that broke all the rules of nature, that he had set up the rules of physics, the rules of mathematics, or to reach in and sort of tap us on the shoulder and say, “I’m here.” And so, he tried to reproduce that in a clinical setting and he would put one guy in one room and another guy in another room and have them flip cards and guess what the other guy had flipped. And he believed that if he could beat the laws of chance, laws of mathematics, that he would approve the existence of an unnatural law, a supernatural law. And that was the first step to proving the existence of a God.

(02:22:48)
He never succeeds in doing it. But he says in the book, “Even though I can’t prove using an empirical and scientific tools, the existence of a God, I can show through anecdotal evidence having seen thousands of patients come through with this institution, that people who believe in God get better faster and that the recovery is more enduring than people who don’t.” And for me, hearing that was more impactful than if he had claimed that he had proved the existence of God because I wouldn’t have believed that. But I was already at a mindset where I would’ve done anything I could to improve my chances of never having to take drugs again by even 1%. And if believing in God was going to help me, whether there’s a God up there or not, believing in one a self had the power to help me, I was going to do that.

(02:23:40)
So then the question is how do you start believing in something that you can’t see or smell or hear or touch or taste or acquire with your senses? And Yung provides the formula for that. And he says, “Act as if you fake it till you make it.” And so, that’s what I started doing. I just started pretending there was a God watching me all the time. And kind of life was a series of tests. And there was a bunch of moral decisions that I had to make every day. And these were all just little things that I did. But each one now for me had a moral dimension. Like when the alarm goes off, do I lay in bed for an extra 10 minutes with my indolent thoughts or do I jump right out of bed? Do I make my bed? Most important decision of the day.

(02:24:28)
Do I hang up the towels? When I go into the closet and pull out my blue jeans and a bunch of those wire hangers fall on the ground, do I shut the door and say, “I’m too important to do that. That’s somebody else’s job or not?” And so, do put the water in the ice tray before I put it in the freezer? Do I put the shopping cart back in the place that it’s supposed to go in the parking lot of the Safeway? And if I make a whole bunch of those choices that I maintain myself in a posture of surrender, which keeps me open to my higher power to my God. And when I do those things right, so much about addiction is about abuse of power, abuse of all of us have some power, whether it’s our good looks or whether it’s connections or education or family or whatever.

(02:25:33)
And there’s always a temptation to use those to fulfill self will. And the challenge is how do you use those always to serve instead God’s of will and the good of our community? And that to me, is kind of the struggle. But when I do that, I feel God’s power coming through me and that I can do things. I’m much more effective as a human being. That gnawing anxiety that I lived with for so many years and God, it’s gone and that I can put down the oars and hoist the sail and the wind takes me and I can see the evidence of it in my life. And the big thing, temptation for me is that when all these good things start happening in my life and the cash and prizes start flowing in, how do I maintain that posture of surrender? How do I stay surrender then when my inclination is to say to God, “Thanks God, I got it from here.” And drive the car off the cliff again.

(02:26:49)
And so, I had a spiritual awakening and my desire for drugs and alcohol was lifted miraculously. And to me, it was as much a miracle as if I’d been able to walk on water because I had tried everything earnestly, sincerely and honestly for a decade to try to stop and I could not do it under my own power. And then all of a sudden, it was lifted effortlessly. So I saw that early evidence of God in my life and of the power, and I see it now every day of my life.
Lex Fridman

(02:27:29)
So adding that moral dimension to all of your actions is how you were able to win that Kambu battle against the absurd.
Robert F. Kennedy Jr

(02:27:38)
Exactly.
Lex Fridman

(02:27:38)
Sisyphus with the Boulder.
Robert F. Kennedy Jr

(02:27:39)
It’s all the same thing. It’s the battle to just do the right thing.
Lex Fridman

(02:27:44)
Now Sisyphus was able to find somehow happiness. Yeah. Well, Bobby, thank you for the stroll through some of the most important moments in recent human history and for running for president. And thank you for talking today.
Robert F. Kennedy Jr

(02:27:59)
Thank you, Lex.
Lex Fridman

(02:28:01)
Thanks for listening to this conversation with Robert F. Kennedy Jr. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from John F. Kennedy. “Let us not seek the Republican answer or the Democratic answer, but the right answer. Let us not seek to fix the blame for the past. Instead, let us accept our own responsibility for the future.” Thank you for listening and hope to see you next time.
Transcript for George Hotz: Tiny Corp, Twitter, AI Safety, Self-Driving, GPT, AGI & God | Lex Fridman Podcast #387
This is a transcript of Lex Fridman Podcast #387 with George Hotz.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
1:39 – Time is an illusion
11:18 – Memes
13:55 – Eliezer Yudkowsky
26:19 – Virtual reality
32:38 – AI friends
40:03 – tiny corp
53:24 – NVIDIA vs AMD
56:21 – tinybox
1:08:30 – Self-driving
1:23:09 – Programming
1:31:06 – AI safety
1:56:03 – Working at Twitter
2:33:46 – Prompt engineering
2:39:42 – Video games
2:55:57 – Andrej Karpathy
3:06:02 – Meaning of life

Introduction
Lex Fridman

(00:00:00)
What possible ideas do you have for how human species ends?
George Hotz

(00:00:03)
Sure. I think the most obvious way to me is wire heading. We end up amusing ourselves to death. We end up all staring at that infinite TikTok and forgetting to eat. Maybe it’s even more benign than this. Maybe we all just stop reproducing. Now, to be fair, it’s probably hard to get all of humanity.
Lex Fridman

(00:00:27)
Yeah. The interesting thing about humanity is the diversity in it.
George Hotz

(00:00:30)
Oh, yeah.
Lex Fridman

(00:00:31)
Organisms in general. There’s a lot of weirdos out there, two of them are sitting here.
George Hotz

(00:00:36)
I mean, diversity in humanity is-
Lex Fridman

(00:00:38)
With due respect.
George Hotz

(00:00:40)
I wish I was more weird.
Lex Fridman

(00:00:44)
The following is a conversation with George Hotz, his third time on this podcast. He’s the founder of Comma.ai that seeks to solve autonomous driving and is the founder of a new company called tiny corp that created tinygrad, a neural network framework that is extremely simple with the goal of making it run on any device by any human easily and efficiently. As you know, George also did a large number of fun and amazing things from hacking the iPhone to recently joining Twitter for a bit as a “intern”, making the case for refactoring the Twitter code base.

(00:01:23)
In general he’s a fascinating engineer and human being, and one of my favorite people to talk to. This is a Lex Fridman podcast. To support it please check out our sponsors in the description. Now, dear friends, here’s George Hotz. You mentioned something in a stream about the philosophical nature of time. Let’s start with a wild question. Do you think time is an illusion?
Time is an illusion
George Hotz

(00:01:47)
You know, I sell phone calls to Comma for a thousand dollars and some guy called me. It’s a thousand dollars. You can talk to me for half an hour. He is like, “Yeah, okay. Time doesn’t exist and I really wanted to share this with you.” I’m like, “Oh, what do you mean time doesn’t exist?” I think time is a useful model, whether it exists or not. Right. Does quantum physics exist? Well, it doesn’t matter. It’s about whether it’s a useful model to describe reality. Is time maybe compressive?
Lex Fridman

(00:02:25)
Do you think there is an objective reality or is everything just useful models? Underneath it all is there an actual thing that we’re constructing models for?
George Hotz

(00:02:35)
I don’t know.
Lex Fridman

(00:02:39)
I was hoping you would know.
George Hotz

(00:02:40)
I don’t think it matters.
Lex Fridman

(00:02:42)
I mean, this connects to the models of constructive reality with machine learning, right?
George Hotz

(00:02:47)
Sure.
Lex Fridman

(00:02:49)
Is it just nice to have useful approximations of the world such that we can do something with it?
George Hotz

(00:02:55)
There are things that are real. [inaudible 00:02:57] complexity is real.
Lex Fridman

(00:02:59)
Yeah.
George Hotz

(00:02:59)
Yeah. The compressive-
Lex Fridman

(00:03:00)
Math.
George Hotz

(00:03:02)
Math is real. Yeah.
Lex Fridman

(00:03:03)
Should be a T-shirt.
George Hotz

(00:03:05)
I think hard things are actually hard. I don’t think P equals NP.
Lex Fridman

(00:03:09)
Ooh. Strong words.
George Hotz

(00:03:10)
Well, I think that’s the majority. I do think factoring is in P.
Lex Fridman

(00:03:14)
I don’t think you’re the person that follows the majority in all walks of life.
George Hotz

(00:03:18)
For that one I do
Lex Fridman

(00:03:19)
Yeah. In theoretical computer science, you’re one of the sheep. All right. To you time is a useful model.
George Hotz

(00:03:28)
Sure.
Lex Fridman

(00:03:29)
What were you talking about on the stream about time? Are you made of time?
George Hotz

(00:03:33)
If I remembered half the things I said on stream. Someday someone’s going to make a model of all of it and it’s going to come back to haunt me.
Lex Fridman

(00:03:40)
Someday soon?
George Hotz

(00:03:41)
Yeah, probably.
Lex Fridman

(00:03:42)
Would that be exciting to you or sad that there’s a George Hotz model?
George Hotz

(00:03:48)
I mean, the question is when the George Hotz model is better than George Hotz, like I am declining and the model is growing.
Lex Fridman

(00:03:54)
What is the metric by which you measure better or worse in that, if you are competing with yourself?
George Hotz

(00:04:00)
Maybe you can just play a game where you have the George Hotz answer and the George Hotz model answer and ask which people prefer.
Lex Fridman

(00:04:06)
People close to you or strangers?
George Hotz

(00:04:09)
Either one. It will hurt more when it’s people close to me, but both will be overtaken by the George Hotz model.
Lex Fridman

(00:04:16)
It’d be quite painful. Loved ones, family members would rather have the model over for Thanksgiving than you or significant others would rather sext with the large language model version of you.
George Hotz

(00:04:35)
Especially when it’s fine-tuned to their preferences.
Lex Fridman

(00:04:39)
Yeah. Well, that’s what we’re doing in a relationship. We’re just fine-tuning ourselves, but we’re inefficient with it because we’re selfish and greedy and so on. Language models can fine-tune more efficiently, more selflessly.
George Hotz

(00:04:51)
There’s a Star Trek Voyager episode where Kathryn Janeway lost in the delta quadrant makes herself a lover on the Holodeck, and the lover falls asleep on her arm and he snores a little bit. Janeway edits the program to remove that. Then of course the realization is, wait, this person’s terrible. It is actually all their nuances and quirks and slight annoyances that make this relationship worthwhile. I don’t think we’re going to realize that until it’s too late.
Lex Fridman

(00:05:24)
Well, I think a large language model could incorporate the flaws and the quirks and all that kind of stuff.
George Hotz

(00:05:30)
Just the perfect amount of quirks and flaws to make you charming without crossing the line.
Lex Fridman

(00:05:36)
Yeah, and that’s probably a good approximation of the percent of time the language model should be cranky or an asshole or jealous or all this kind of stuff.
George Hotz

(00:05:52)
Of course it can and it will. All that difficulty at that point is artificial. There’s no more real difficulty.
Lex Fridman

(00:05:59)
What’s the difference between real and artificial?
George Hotz

(00:06:01)
Artificial difficulty is difficulty that’s like constructed or could be turned off with a knob. Real difficulty is like you’re in the woods and you got to survive.
Lex Fridman

(00:06:11)
If something cannot be turned off with a knob it’s real?
George Hotz

(00:06:16)
Yeah, I think so. I mean, you can’t get out of this by smashing the knob with a hammer. I mean, maybe you can, Into the Wild when Alexander Supertramp, he wants to explore something that’s never been explored before, but it’s the nineties. Everything’s been explored. He’s like, “Well, I’m just not going to bring a map.”
Lex Fridman

(00:06:36)
Yeah.
George Hotz

(00:06:36)
I mean, no, you’re not exploring. You should have brought a map dude. You died. There was a bridge a mile from where you were camping.
Lex Fridman

(00:06:44)
How does that connect to the metaphor of the knob?
George Hotz

(00:06:46)
By not bringing the map, you didn’t become an explorer. You just smashed the thing.
Lex Fridman

(00:06:53)
Yeah.
George Hotz

(00:06:53)
Yeah. The difficulty is still artificial.
Lex Fridman

(00:06:56)
You failed before you started. What if we just don’t have access to the knob?
George Hotz

(00:07:00)
Well, that maybe is even scarier. We already exist in a world of nature, and nature has been fine-tuned over billions of years. To have humans build something and then throw the knob away in some grand romantic gesture is horrifying.
Lex Fridman

(00:07:21)
Do you think of us humans as individuals that are born and die or are we just all part of one living organism that is earth, that is nature?
George Hotz

(00:07:33)
I don’t think there’s a clear line there. I think it’s all kind of just fuzzy. I don’t know. I mean, I don’t think I’m conscious. I don’t think I’m anything. I think I’m just a computer program.
Lex Fridman

(00:07:44)
It’s all computation, everything running in your head is just computation.
George Hotz

(00:07:49)
Everything running in the universe is computation, I think. I believe the extended [inaudible 00:07:53] thesis.
Lex Fridman

(00:07:56)
There seems to be an embodiment to your particular computation. There’s a consistency.
George Hotz

(00:08:00)
Well, yeah, but I mean, models have consistency too.
Lex Fridman

(00:08:04)
Yeah.
George Hotz

(00:08:05)
Models that have been RLHF’d will continually say like, well, how do I murder ethnic minorities? Oh, well, I can’t let you do that, Hal. There’s a consistency to that behavior.
Lex Fridman

(00:08:15)
It’s all RLHF. We RLHF each other. We provide human feedback and thereby fine-tune these little pockets of computation. It’s still unclear why that pocket of computation stays with you for years. You have this consistent set of physics, biology, whatever you call the neurons firing like the electrical signals, the mechanical signals, all of that that seems to stay there. It contains information. It stores information, and that information permeates through time and stays with you. There’s like memory, there’s like sticky.
George Hotz

(00:09:01)
To be fair, a lot of the models we’re building today are very… Even RLHF is nowhere near as complex as the human loss function.
Lex Fridman

(00:09:08)
Reinforcement learning with human feedback.
George Hotz

(00:09:11)
When I talked about will GPT12 be AGI, my answer is no. Of course not. I mean, cross-entropy loss is never going to get you there. You need probably RL in fancy environments in order to get something that would be considered AGI-like. To ask the question about why? I don’t know. It’s just some quirk of evolution. I don’t think there’s anything particularly special about where I ended up, where humans ended up.
Lex Fridman

(00:09:40)
Okay, we have human level intelligence. Would you call that AGI, whatever we have, GI?
George Hotz

(00:09:47)
Look, actually, I don’t really even like the word AGI, but general intelligence is defined to be whatever humans have.
Lex Fridman

(00:09:55)
Okay, so why can GPT-12 not get us to AGI? Can we just linger on that?
George Hotz

(00:10:02)
If your loss function is categorical cross-entropy, if your loss function is just try to maximize compression. I have a SoundCloud I rap and I tried to get Chat-GPT to help me write raps and the raps that it wrote sounded like YouTube comment raps. You can go on any rap beat online and you can see what people put in the comments. It’s the most mid quality rap you can find.
Lex Fridman

(00:10:23)
Is mid good or bad?
George Hotz

(00:10:24)
Mid is bad.
Lex Fridman

(00:10:25)
Mid is bad.
George Hotz

(00:10:25)
It’s like mid.
Lex Fridman

(00:10:27)
Every time I talk to you, I learn new words. Mid.
George Hotz

(00:10:32)
Mid. Yeah.
Lex Fridman

(00:10:35)
I was like, is it like basic? Is that what mid means?
George Hotz

(00:10:37)
Kind of. It’s like middle of the curve, right?
Lex Fridman

(00:10:39)
Yeah.
George Hotz

(00:10:40)
There’s like that intelligence curve and you have the dumb guy, the smart guy, and then the mid guy. Actually being the mid guy is the worst. The smart guy is like I put all my money in Bitcoin. The mid guy is like, “You can’t put money in Bitcoin. It’s not real money.”
Lex Fridman

(00:10:55)
All of it is a genius meme. That’s another interesting one. Memes, the humor, the idea, the absurdity encapsulated in a single image and it just propagates virally between all of our brains. I didn’t get much sleep last night, so I sound like I’m high. I swear I’m not. Do you think we have ideas or ideas have us?
Memes
George Hotz

(00:11:24)
I think that we’re going to get super scary memes once the AIs actually are superhuman.
Lex Fridman

(00:11:30)
You think AI will generate memes?
George Hotz

(00:11:31)
Of course.
Lex Fridman

(00:11:32)
You think it’ll make humans laugh?
George Hotz

(00:11:35)
I think it’s worse than that. Infinite Jest, it’s introduced in the first 50 pages, is about a tape that once you watch it once you only ever want to watch that tape. In fact, you want to watch the tape so much that someone says, “Okay, here’s a hack saw. Cut off your pinky and then I’ll let you watch the tape again.” You’ll do it. We’re actually going to build that, I think, but it’s not going to be one static tape. I think the human brain is too complex to be stuck in one static tape like that. If you look at ant brains, maybe they can be stuck on a static tape, but we’re going to build that using generative models. We’re going to build the TikTok that you actually can’t look away from.
Lex Fridman

(00:12:16)
TikTok is already pretty close there, but the generation is done by humans. The algorithm is just doing their recommendation. If the algorithm is also able to do the generation.
George Hotz

(00:12:25)
Well, it’s a question about how much intelligence is behind it. The content is being generated by let’s say, one humanity worth of intelligence, and you can quantify a humanity, its exaflops, [inaudible 00:12:40], but you can quantify it. Once that generation is being done by a hundred humanities, you’re done.
Lex Fridman

(00:12:48)
It’s actually scale that’s the problem, but also speed. Yeah. What if it’s manipulating the very limited human dopamine engine, so porn? Imagine just TikTok, but for porn.
George Hotz

(00:13:05)
Yeah.
Lex Fridman

(00:13:06)
It’s like a brave new world.
George Hotz

(00:13:08)
I don’t even know what it’ll look like. Again, you can’t imagine the behaviors of something smarter than you, but a super intelligent, an agent that just dominates your intelligence so much will be able to completely manipulate you.
Lex Fridman

(00:13:24)
Is it possible that it won’t really manipulate? It’ll just move past us. It’ll just exist the way water exists or the air exists.
George Hotz

(00:13:33)
You see, and that’s the whole AI safety thing. It’s not the machine that’s going to do that. It’s other humans using the machine that are going to do that to you.
Lex Fridman

(00:13:44)
Because the machine is not interested in hurting humans. It’s just…
George Hotz

(00:13:47)
The machine is a machine, but the human gets the machine and there’s a lot of humans out there very interested in manipulating you.
Eliezer Yudkowsky
Lex Fridman

(00:13:55)
Well, let me bring up, Eliezer Yudkowsky who recently sat where you’re sitting. He thinks that AI will almost surely kill everyone. Do you agree with him or not?
George Hotz

(00:14:09)
Yes, but maybe for a different reason.
Lex Fridman

(00:14:14)
Then I’ll try to get you to find hope or we could find a note to that answer. But why yes?
George Hotz

(00:14:23)
Okay. Why didn’t nuclear weapons kill everyone?
Lex Fridman

(00:14:26)
That’s a good question.
George Hotz

(00:14:27)
I think there’s an answer. I think it’s actually very hard to deploy nuclear weapons tactically. It’s very hard to accomplish tactical objectives. Great. I can nuke their country. I have an irradiated pile of rubble. I don’t want that.
Lex Fridman

(00:14:39)
Why not?
George Hotz

(00:14:40)
Why don’t I want an irradiated pile of rubble?
Lex Fridman

(00:14:43)
Yeah.
George Hotz

(00:14:43)
For all the reasons no one wants an irradiated pile of rubble.
Lex Fridman

(00:14:46)
Oh, because you can’t use that land for resources. You can’t populate the land.
George Hotz

(00:14:52)
Yeah. Well, what you want, a total victory in a war is not usually the irradiation and eradication of the people there. It’s the subjugation and domination of the people.
Lex Fridman

(00:15:03)
Okay. You can’t use this strategically, tactically in a war to help gain a military advantage. It’s all complete destruction. All right.
George Hotz

(00:15:16)
Yeah.
Lex Fridman

(00:15:16)
There’s egos involved. It’s still surprising that nobody pressed the big red button.
George Hotz

(00:15:22)
It’s somewhat surprising. You see, it’s the little red button that’s going to be pressed with AI, and that’s why we die. It’s not because the AI, if there’s anything in the nature of AI, it’s just the nature of humanity.
Lex Fridman

(00:15:37)
What’s the algorithm behind the little red button? What possible ideas do you have for how human species ends?
George Hotz

(00:15:45)
Sure. I think the most obvious way to me is wire heading. We end up amusing ourselves to death. We end up all staring at that infinite TikTok and forgetting to eat. Maybe it’s even more benign than this. Maybe we all just stop reproducing. Now, to be fair, it’s probably hard to get all of humanity.
Lex Fridman

(00:16:10)
Yeah.
George Hotz

(00:16:11)
Yeah. It probably is.
Lex Fridman

(00:16:15)
The interesting thing about humanity is the diversity in it.
George Hotz

(00:16:17)
Oh yeah.
Lex Fridman

(00:16:18)
Organisms in general. There’s a lot of weirdos out there. Well, two of them are sitting here.
George Hotz

(00:16:23)
I mean, diversity in humanity is-
Lex Fridman

(00:16:25)
With due respect.
George Hotz

(00:16:27)
I wish I was more weird. No, look, I’m drinking Smart water, man. That’s like a Coca-Cola product, right?
Lex Fridman

(00:16:33)
You went corporate George Hotz.
George Hotz

(00:16:35)
Yeah, I went corporate. No, the amount of diversity and humanity I think is decreasing. Just like all the other biodiversity on the planet.
Lex Fridman

(00:16:42)
Oh boy. Yeah.
George Hotz

(00:16:43)
Right.
Lex Fridman

(00:16:44)
Social media’s not helping.
George Hotz

(00:16:45)
Go eat McDonald’s in China.
Lex Fridman

(00:16:47)
Yeah.
George Hotz

(00:16:49)
Yeah. No, it’s the interconnectedness that’s doing it.
Lex Fridman

(00:16:54)
Oh, that’s interesting. Everybody starts relying on the connectivity of the internet. Over time, that reduces the diversity, the intellectual diversity, and then that gets everybody into a funnel. There’s still going to be a guy in Texas.
George Hotz

(00:17:08)
There is.
Lex Fridman

(00:17:09)
And a bunker.
George Hotz

(00:17:10)
To be fair, do I think AI kills us all? I think AI kills everything we call society today. I do not think it actually kills the human species. I think that’s actually incredibly hard to do.
Lex Fridman

(00:17:22)
Yeah, but society, if we start over, that’s tricky. Most of us don’t know how to do most things.
George Hotz

(00:17:28)
Yeah, but some of us do, and they’ll be okay and they’ll rebuild after the great AI.
Lex Fridman

(00:17:36)
What’s rebuilding look like? How much do we lose? What has human civilization done that’s interesting? Combustion engine, electricity. So power and energy. That’s interesting. How to harness energy.
George Hotz

(00:17:54)
Whoa, whoa, whoa, whoa. They’re going to be religiously against that.
Lex Fridman

(00:17:58)
Are they going to get back to fire?
George Hotz

(00:18:02)
Sure. I mean, it’s be like some kind of Amish looking kind of thing. I think they’re going to have very strong taboos against technology.
Lex Fridman

(00:18:13)
Technology is almost like a new religion. Technology is the devil and nature is God.
George Hotz

(00:18:20)
Sure.
Lex Fridman

(00:18:20)
Closer to nature. Can you really get away from AI if it destroyed 99% of the human species, isn’t somehow have a hold like a stronghold?
George Hotz

(00:18:30)
Well, what’s interesting about everything we build, I think we’re going to build super intelligence before we build any sort of robustness in the AI. We cannot build an AI that is capable of going out into nature and surviving like a bird. A bird is an incredibly robust organism. We’ve built nothing like this. We haven’t built a machine that’s capable of reproducing.
Lex Fridman

(00:18:58)
I work with Lego robots a lot now. I have a bunch of them. They’re mobile. They can’t reproduce. All they need is, I guess you’re saying they can’t repair themselves. If you have a large number, if you have a hundred million of them-
George Hotz

(00:19:13)
Let’s just focus on them reproducing. Do they have microchips in them?
Lex Fridman

(00:19:16)
Mm-hmm (affirmative).
George Hotz

(00:19:16)
Okay. Then do they include a fab?
Lex Fridman

(00:19:20)
No.
George Hotz

(00:19:21)
Then how are they going to reproduce?
Lex Fridman

(00:19:22)
Well, it doesn’t have to be all on board. They can go to a factory, to a repair shop.
George Hotz

(00:19:29)
Yeah, but then you’re really moving away from robustness.
Lex Fridman

(00:19:33)
Yes.
George Hotz

(00:19:33)
All of life is capable of reproducing without needing to go to a repair shop. Life will continue to reproduce in the complete absence of civilization. Robots will not. If the AI apocalypse happens, I mean the AIs are going to probably die out because I think we’re going to get, again, super intelligence long before we get robustness.
Lex Fridman

(00:19:55)
What about if you just improve the fab to where you just have a 3D printer that can always help you?
George Hotz

(00:20:03)
Well, that’d be very interesting. I’m interested in building that.
Lex Fridman

(00:20:06)
Of course, you are. How difficult is that problem to have a robot that basically can build itself?
George Hotz

(00:20:15)
Very, very hard.
Lex Fridman

(00:20:16)
I think you’ve mentioned this to me or somewhere where people think it’s easy conceptually.
George Hotz

(00:20:24)
Then they remember that you’re going to have to have a fab.
Lex Fridman

(00:20:27)
Yeah, on board.
George Hotz

(00:20:30)
Of course.
Lex Fridman

(00:20:30)
3D printer that prints a 3D printer.
George Hotz

(00:20:34)
Yeah.
Lex Fridman

(00:20:34)
On legs. Why’s that hard?
George Hotz

(00:20:37)
Well, I mean, a 3D printer is a very simple machine, right? Okay, you’re going to print chips, you’re going to have an atomic printer. How are you going to dope the silicon?
Lex Fridman

(00:20:47)
Yeah.
George Hotz

(00:20:48)
Right. How you going to etch the silicon?
Lex Fridman

(00:20:51)
You’re going to have a very interesting kind of fab if you want to have a lot of computation on board. You can do structural type of robots that are dumb.
George Hotz

(00:21:04)
Yeah, but structural type of robots aren’t going to have the intelligence required to survive in any complex environment.
Lex Fridman

(00:21:11)
What about like ants type of systems? We have trillions of them.
George Hotz

(00:21:15)
I don’t think this works. I mean, again, ants at their very core are made up of cells that are capable of individually reproducing.
Lex Fridman

(00:21:22)
They’re doing quite a lot of computation that we’re taking for granted.
George Hotz

(00:21:26)
It’s not even just the computation. It’s that reproduction is so inherent. There’s two stacks of life in the world. There’s the biological stack and the silicon stack. The biological stack starts with reproduction. Reproduction is at the absolute core. The first proto-RNA organisms were capable of reproducing. The silicon stack, despite, as far as it’s come, is nowhere near being able to reproduce.
Lex Fridman

(00:21:51)
Yeah, So the fab movement, digital fabrication, fabrication in the full range of what that means is still in the early stages.
George Hotz

(00:22:04)
Yeah.
Lex Fridman

(00:22:04)
You’re interested in this world?
George Hotz

(00:22:06)
Even if you did put a fab on the machine, let’s say, okay, yeah, we can build fabs. We know how to do that as humanity. We can probably put all the precursors that build all the machines in the fabs also in the machine. First off, this machine’s going to be absolutely massive. I mean, we almost have a… Think of the size of the thing required to reproduce a machine today. Is our civilization capable of reproduction? Can we reproduce our civilization on Mars?
Lex Fridman

(00:22:34)
If we were to construct a machine that is made up of humans, like a company that can reproduce itself?
George Hotz

(00:22:40)
Yeah.
Lex Fridman

(00:22:40)
I don’t know. It feels like 115 people.
George Hotz

(00:22:47)
I think it’s so much harder than that.
Lex Fridman

(00:22:50)
120? I’m looking for a number.
George Hotz

(00:22:52)
Let’s see. I believe that Twitter can be run by 50 people. I think that this is going to take most of, it’s just most of society. We live in one globalized world now.
Lex Fridman

(00:23:04)
No, but you’re not interested in running Twitter, you’re interested in seeding. You want to seed a civilization and then because humans can like have sex.
George Hotz

(00:23:14)
Yeah. Okay. You’re talking about the humans reproducing and basically what’s the smallest self-sustaining colony of humans?
Lex Fridman

(00:23:19)
Yeah.
George Hotz

(00:23:20)
Yeah. Okay, fine but they’re not going to be making five nanometer chips.
Lex Fridman

(00:23:22)
Over time they will. We have to expand our conception of time here going back to the original timescale. I mean, over across maybe a hundred generations we’re back to making chips. No? If you seed the colony correctly.
George Hotz

(00:23:40)
Maybe, or maybe they’ll watch our colony die out over here and be like, “We’re not making chips. Don’t make chips.”
Lex Fridman

(00:23:46)
No, but you have to seed that colony correctly.
George Hotz

(00:23:48)
Whatever you do, don’t make chips. Chips are what led to their downfall.
Lex Fridman

(00:23:54)
Well, that is the thing that humans do. They construct a devil a good thing and a bad thing, and they really stick by that and then they murder each other over that. There’s always one asshole in the room who murders everybody and usually makes tattoos and nice branding with flags and stuff.
George Hotz

(00:24:10)
Do you need that asshole, that’s the question. Humanity works really hard today to get rid of that asshole, but I think they might be important.
Lex Fridman

(00:24:16)
Yeah. This whole freedom of speech thing, it’s the freedom of being an asshole seems kind of important.
George Hotz

(00:24:22)
That’s right.
Lex Fridman

(00:24:23)
Man. This thing, this fab, this human fab that we constructed, this human civilization is pretty interesting. Now it’s building artificial copies of itself or artificial copies of various aspects of itself that seem interesting like intelligence. I wonder where that goes.
George Hotz

(00:24:44)
I like to think it’s just another stack for life. We have the biostack life. We’re a biostack life, and then the silicon stack life.
Lex Fridman

(00:24:50)
It seems like the ceiling, or there might not be a ceiling, or at least the ceiling is much higher for the silicon stack.
George Hotz

(00:24:57)
Oh, no. We don’t know what the ceiling is for the biostack either. The biostack just seems to move slower. You have Moore’s law, which is not dead despite many proclamations.
Lex Fridman

(00:25:09)
In the biostack or the silicon stack?
George Hotz

(00:25:11)
In the silicon stack. You don’t have anything like this in the biostack. I have a meme that I posted. I tried to make a meme. It didn’t work too well, but I posted a picture of Ronald Reagan and Joe Biden, and you look, this is 1980 and this is 2020.
Lex Fridman

(00:25:24)
Yeah.
George Hotz

(00:25:24)
These two humans are basically the same, right? No, there’s been no change in humans in the last 40 years. Then I posted a computer from 1980 in a computer from 2020. Wow.
Lex Fridman

(00:25:41)
Yeah. With their early stages, which is why you said, when you said the size of the fab required to make another fab is very large right now.
George Hotz

(00:25:52)
Yeah.
Lex Fridman

(00:25:53)
Computers were very large 80 years ago, and they got pretty tiny and people are starting to want to wear them on their face in order to escape reality. That’s a thing. In order to live inside the computer, but a screen right here, I don’t have to see the rest of you assholes.
George Hotz

(00:26:18)
I’ve been ready for a long time.
Virtual reality
Lex Fridman

(00:26:19)
You like virtual reality?
George Hotz

(00:26:20)
I love it.
Lex Fridman

(00:26:22)
Do you want to live there?
George Hotz

(00:26:23)
Yeah.
Lex Fridman

(00:26:25)
Yeah. Part of me does too. How far away are we do you think?
George Hotz

(00:26:31)
Judging from what you can buy today? Far, very far.
Lex Fridman

(00:26:35)
I got to tell you that I had the experience of Meta’s Codec avatar where it’s a ultra-high resolution scan. It looked real.
George Hotz

(00:26:51)
I mean, the headsets just are not quite at eye resolution yet. I haven’t put on any headset where I’m like, “Oh, this could be the real world.” Whereas when I put good headphones on, audio is there. We can reproduce audio that I’m like, “I’m actually in a jungle right now. If I close my eyes, I can’t tell I’m not.”
Lex Fridman

(00:27:09)
Yeah. Then there’s also smell and all that kind of stuff.
George Hotz

(00:27:11)
Sure.
Lex Fridman

(00:27:13)
I don’t know. The power of imagination or the power of the mechanism in the human mind that fills the gaps that reaches and wants to make the thing you see in the virtual world real to you. I believe in that power.
George Hotz

(00:27:29)
Or humans want to believe.
Lex Fridman

(00:27:30)
Yeah. What if you’re lonely? What if you’re sad? What if you’re really struggling in life, and here’s a world where you don’t have to struggle anymore?
George Hotz

(00:27:39)
Humans want to believe so much that people think the large language models are conscious. That’s how much humans want to believe.
Lex Fridman

(00:27:46)
Strong words, he’s throwing left and right hooks. Why do you think large language models are not conscious?
George Hotz

(00:27:53)
I don’t think I’m conscious.
Lex Fridman

(00:27:55)
Oh, so what is consciousness then George Hotz?
George Hotz

(00:27:58)
It’s like what it seems to mean to people it’s just a word that atheists use for souls.
Lex Fridman

(00:28:04)
Sure. That doesn’t mean soul is not an interesting word.
George Hotz

(00:28:08)
If consciousness is a spectrum, I’m definitely way more conscious than the large language models are. I think the large language models are less conscious than a chicken.
Lex Fridman

(00:28:19)
When is the last time you’ve seen a chicken?
George Hotz

(00:28:22)
In Miami, a couple months ago.
Lex Fridman

(00:28:26)
No. A living chicken.
George Hotz

(00:28:27)
Just living chickens walking around Miami. It’s crazy.
Lex Fridman

(00:28:30)
Like on the street?
George Hotz

(00:28:30)
Yeah.
Lex Fridman

(00:28:31)
Like a chicken?
George Hotz

(00:28:32)
A chicken. Yeah.
Lex Fridman

(00:28:36)
All right. I was trying to call you out, like a good journalist, and I got shut down. Okay. You don’t think much about this subjective feeling that it feels like something to exist. Then as an observer, you can have a sense that an entity is not only intelligent, but has a subjective experience of its reality, like a self-awareness that is capable of suffering, of hurting, of being excited by the environment in a way that’s not merely an artificial response, but a deeply felt one.
George Hotz

(00:29:22)
Humans want to believe so much that if I took a rock and a Sharpie and drew a sad face on the rock, they’d think the rock is sad.
Lex Fridman

(00:29:32)
You’re saying when we look in the mirror, we apply the same smiley face with rock?
George Hotz

(00:29:36)
Pretty much, yeah.
Lex Fridman

(00:29:38)
Isn’t that weird though, that you’re not conscious?
George Hotz

(00:29:42)
No.
Lex Fridman

(00:29:43)
You do believe in consciousness?
George Hotz

(00:29:45)
Not really.
Lex Fridman

(00:29:46)
It’s unclear. Okay. To you it’s like a little symptom of the bigger thing that’s not that important.
George Hotz

(00:29:53)
Yeah. I mean, it’s interesting that the human systems seem to claim that they’re conscious, and I guess it says something in a straight up, even if you don’t believe in consciousness, what do people mean when they say consciousness? There’s definitely meanings to it.
Lex Fridman

(00:30:06)
What’s your favorite thing to eat?
George Hotz

(00:30:11)
Pizza.
Lex Fridman

(00:30:12)
Cheese pizza. What are the toppings?
George Hotz

(00:30:13)
I like cheese pizza. I like pepperoni.
Lex Fridman

(00:30:14)
Don’t say pineapple.
George Hotz

(00:30:15)
No, I don’t like pineapple.
Lex Fridman

(00:30:16)
Okay. Pepperoni pizza.
George Hotz

(00:30:17)
If they put any ham on it I’ll just feel bad.
Lex Fridman

(00:30:20)
What’s the best pizza? What are we talking about here? Do you like cheap, crappy pizza?
George Hotz

(00:30:24)
A Chicago deep dish cheese pizza. Oh, that’s my favorite.
Lex Fridman

(00:30:27)
There you go. You bite into a Chicago deep dish pizza, and it feels like, so you were starving, you haven’t eaten for 24 hours. You just bite in and you’re hanging out with somebody that matters a lot to you. You’re there with the pizza.
George Hotz

(00:30:39)
That sounds real nice, man.
Lex Fridman

(00:30:40)
Yeah. All right. It feels like something I’m George motherfucking Hotz eating a fucking Chicago deep dish pizza. There’s just the full peak living experience of being human, the top of the human condition.
George Hotz

(00:30:57)
Sure.
Lex Fridman

(00:30:58)
It feels like something to experience that.
George Hotz

(00:31:00)
Mm-hmm (affirmative).
Lex Fridman

(00:31:02)
Why does it feel like something? That’s consciousness, isn’t it?
George Hotz

(00:31:06)
If that’s the word you want to use to describe it. Sure. I’m not going to deny that that feeling exists. I’m not going to deny that I experienced that feeling. I guess what I take issue to is that there’s some like how does it feel to be a web server? Do 404s hurt?
Lex Fridman

(00:31:23)
Not yet.
George Hotz

(00:31:24)
How would you know what suffering looked like? Sure you can recognize a suffering dog because we’re the same stack as the dog. All the biostack stuff kind of, especially mammals. It’s really easy. You can…
Lex Fridman

(00:31:35)
Game recognizes game.
George Hotz

(00:31:37)
Yeah. Versus the silicon stack stuff it’s like, you have no idea. Wow the little thing has learned to mimic. Then I realized that that’s all we are too. Well, look, the little thing has learned to mimic.
Lex Fridman

(00:31:54)
Yeah. I guess, yeah. 404 could be suffering, but it’s so far from our kind-
Lex Fridman

(00:32:03)
… So far from our kind of living organism, our kind of stack. It feels like AI can start maybe mimicking the biological stack better, better, better. It’s trained.
George Hotz

(00:32:13)
We trained it, yeah.
Lex Fridman

(00:32:15)
In that, maybe that’s the definition of consciousness is the bio stack consciousness.
George Hotz

(00:32:20)
The definition of consciousness is how close something looks to human. Sure, I’ll give you that one.
Lex Fridman

(00:32:24)
No, how close something is to the human experience.
George Hotz

(00:32:28)
Sure. It’s a very anthropro-centric definition, but…
Lex Fridman

(00:32:33)
Well, that’s all we got.
AI friends
George Hotz

(00:32:34)
Sure. No. I think there’s a lot of value in it. Look, I just started my second company. My third company will be AI Girlfriends. I mean it.
Lex Fridman

(00:32:43)
I want to find out what your fourth company is after that.
George Hotz

(00:32:46)
Oh, wow.
Lex Fridman

(00:32:46)
I think once you have AI girlfriends, oh boy, does it get interesting. Well, maybe let’s go there. The relationships with AI, that’s creating human-like organisms. Part of being human is being conscious, is having the capacity to suffer, having the capacity to experience this life richly, in such a way that you can empathize, that AI system going to empathize with you, and you can empathize with it, or you can project your anthropomorphic sense of what the other entity is experiencing.

(00:33:22)
An AI model would need to create that experience inside your mind. It doesn’t seem that difficult.
George Hotz

(00:33:28)
Yeah. Okay, so here’s where it actually gets totally different. When you interact with another human, you can make some assumptions.
Lex Fridman

(00:33:37)
Yeah.
George Hotz

(00:33:38)
When you interact with these models, you can’t. You can make some assumptions that other human experiences suffering and pleasure in a pretty similar way to you do, the golden rule applies. With an AI model, this isn’t really true. These large language models are good at fooling people, because they were trained on a whole bunch of human data and told to mimic it.
Lex Fridman

(00:33:59)
Yep, but if the AI system says, “Hi, my name is Samantha,” it has a backstory. “Went to college here and there,” maybe it’ll integrate this in the AI system.
George Hotz

(00:34:11)
I made some chatbots. I gave them back stories. It was lots of fun. I’m so happy when Lama came out.
Lex Fridman

(00:34:16)
Yeah. Well, we’ll talk about Lama, we’ll talk about all that. The rock with a smiley face, it seems pretty natural for you to anthropomorphize that thing and then start dating it. Before you know it, you’re married and have kids
George Hotz

(00:34:33)
With a rock?
Lex Fridman

(00:34:34)
With a rock, and there’s pictures on Instagram with you and a rock and a smiley face.
George Hotz

(00:34:38)
To be fair, something that people generally look for when they’re looking for someone to date is intelligence in some form. The rock doesn’t really have intelligence. Only a pretty desperate person would date a rock.
Lex Fridman

(00:34:50)
I think we’re all desperate, deep down.
George Hotz

(00:34:52)
Oh, not rock level desperate.
Lex Fridman

(00:34:54)
All right. Not rock level desperate, but AI level desperate. I don’t know. I think all of us have a deep loneliness. It just feels like the language models are there.
George Hotz

(00:35:09)
Oh, I agree. You know what? I won’t even say this so cynically. I will actually say this in a way that I want AI friends. I do.
Lex Fridman

(00:35:14)
Yeah.
George Hotz

(00:35:16)
I would love to. Again, the language models now are still a little… People are impressed with these GPT things, or the Copilot, the coding one. I’m like, “Okay, this is junior engineer level, and these people are Fiverr level artists and copywriters.” Okay, great. We got Fiverr and junior engineers. Okay, cool. This is just the start, and it will get better, right? I can’t wait to have AI friends who are more intelligent than I am.
Lex Fridman

(00:35:50)
Fiverr is just a temporary, it’s not the ceiling?
George Hotz

(00:35:52)
No, definitely not.
Lex Fridman

(00:35:53)
Does it count as cheating when you’re talking to an AI model? Emotional cheating?
George Hotz

(00:36:03)
That’s up to you and your human partner to define.
Lex Fridman

(00:36:07)
Oh, you have to. All right.
George Hotz

(00:36:08)
You to have that conversation, I guess.
Lex Fridman

(00:36:12)
All right. Integrate that with porn and all this stuff.
George Hotz

(00:36:16)
Well, no, it’s similar kind of to porn.
Lex Fridman

(00:36:18)
Yeah.
George Hotz

(00:36:18)
Yeah. I think people in relationships have different views on that.
Lex Fridman

(00:36:23)
Yeah, but most people don’t have serious, open conversations about all the different aspects of what’s cool and what’s not. It feels like AI is a really weird conversation to have.
George Hotz

(00:36:38)
The porn one is a good branching off.
Lex Fridman

(00:36:40)
For sure.
George Hotz

(00:36:40)
One of my scenarios that I put in my chatbot is a nice girl named Lexi, she’s 20. She just moved out to LA. She wanted to be an actress, but she started doing Only Fans instead. You’re on a date with her. Enjoy.
Lex Fridman

(00:36:56)
Oh, man. Yeah. If you’re actually dating somebody in real life, is that cheating? I feel like it gets a little weird.
George Hotz

(00:37:05)
Sure.
Lex Fridman

(00:37:05)
It gets real weird. It’s like, what are you allowed to say to an AI bot? Imagine having that conversation with a significant other.
George Hotz

(00:37:11)
These are all things for people to define in their relationships. What it means to be human is just going to start to get weird.
Lex Fridman

(00:37:17)
Especially online. How do you know? There’ll be moments when you’ll have what you think is a real human you’re interacting with on Twitter for years, and you realize it’s not.
George Hotz

(00:37:28)
I spread, I love this meme, heaven banning. You hear about shadow-banning?
Lex Fridman

(00:37:33)
Yeah.
George Hotz

(00:37:34)
Right. Shadow-banning, okay, you post, no one can see it. Heaven banning, you post. No one can see it, but a whole lot of AIs are spot up to interact with you.
Lex Fridman

(00:37:44)
Well, maybe that’s what the way human civilization ends is all of us are heaven banned.
George Hotz

(00:37:48)
There’s a great, it’s called My Little Pony Friendship is optimal. It’s a sci-fi story that explores this idea.
Lex Fridman

(00:37:56)
Friendship is Optimal.
George Hotz

(00:37:57)
Friendship is Optimal.
Lex Fridman

(00:37:58)
Yeah. I’d like to have some, at least on the intellectual realm, some AI friends that argue with me. The romantic realm is weird, definitely weird, but not out of the realm of the kind of weirdness that human civilization is capable of, I think.
George Hotz

(00:38:20)
Look, I want it. If no one else wants it, I want it.
Lex Fridman

(00:38:23)
Yeah. I think a lot of people probably want it. There’s a deep loneliness.
George Hotz

(00:38:27)
I’ll fill their loneliness, and it just will only advertise to you some of the time.
Lex Fridman

(00:38:33)
Yeah. Maybe the conceptions of monogamy change too. I grew up in a time, I value monogamy, but maybe that’s a silly notion when you have arbitrary number of AI systems.
George Hotz

(00:38:43)
Yeah, on this interesting path from rationality to polyamory. Yeah. That doesn’t make sense for me,
Lex Fridman

(00:38:50)
For you, but you’re just a biological organism who was born before the internet really took off.
George Hotz

(00:38:58)
The crazy thing is, culture is whatever we define it as. These things are not… [inaudible 00:39:04] a problem and moral philosophy, right? Okay. What might be that computers are capable of mimicking girlfriends perfectly. They passed the girlfriend Turing test, but that doesn’t say anything about ought.

(00:39:18)
That doesn’t say anything about how we ought to respond to them as a civilization. That doesn’t say we ought to get rid of monogamy. Right. That’s a completely separate question, really, a religious one.
Lex Fridman

(00:39:27)
Girlfriend Turing test. I wonder what that looks like.
George Hotz

(00:39:30)
Girlfriend Turing test.
Lex Fridman

(00:39:31)
Are you writing that? Will you be the Alan Turing of the 21st century that writes the Girlfriend Turing test?
George Hotz

(00:39:38)
No, of course, my AI girlfriends, their goal is to pass the girlfriend Turing test.
Lex Fridman

(00:39:43)
No, but there should be a paper that kind of defines the test. The question is if it’s deeply personalized, or if there’s a common thing that really gets everybody.
George Hotz

(00:39:55)
Yeah. Look, we’re a company. We don’t have to get everybody. We just have to get a large enough clientele to stay with us.
tiny corp
Lex Fridman

(00:40:01)
I like how you’re already thinking company. All right. Before we go to company number three and company number four, let’s go to company number two.
George Hotz

(00:40:09)
All right.
Lex Fridman

(00:40:09)
Tiny Corp, possibly one of the greatest names of all time for a company. You’ve launched a new company called Tiny Corp that leads the development of Tinygrad. What’s the origin story of Tiny Corp and Tinygrad?
George Hotz

(00:40:25)
I started Tinygrad as a toy project, just to teach myself, okay, what is a convolution? What are all these options you can pass to them? What is the derivative of convolution? Very similar to Karpathy wrote Micrograd. I’m very similar. Then I started realizing, I started thinking about AI chips. I started thinking about chips that run AI. I was like, “Well, okay. This is going to be a really big problem. If Nvidia becomes a monopoly here, how long before Nvidia is nationalized?”
Lex Fridman

(00:41:04)
One of the reasons to start Tiny Corp is to challenge Nvidia.
George Hotz

(00:41:10)
It’s not so much to challenge Nvidia. Actually, I like Nvidia. It’s to make sure power stays decentralized.
Lex Fridman

(00:41:21)
Yeah. Here, it’s computational power. To you, Nvidia is kind of locking down the computational power of the world.
George Hotz

(00:41:31)
Nvidia becomes just like 10X better than everything else, you’re giving a big advantage to somebody who can secure Nvidia as a resource.
Lex Fridman

(00:41:41)
Yeah.
George Hotz

(00:41:42)
In fact, if Jensen watches this podcast, he may want to consider this. He may want to consider making sure his company’s not nationalized.
Lex Fridman

(00:41:50)
Do you think that’s an actual threat?
George Hotz

(00:41:52)
Oh, yes.
Lex Fridman

(00:41:55)
No, but there’s so much, there’s AMD.
George Hotz

(00:41:57)
We have Nvidia and AMD. Great.
Lex Fridman

(00:42:00)
All right. You don’t think there’s a push towards selling Google selling TPUs or something like this? You don’t think there’s a push for that?
George Hotz

(00:42:10)
Have you seen it? Google loves to rent you TPUs.
Lex Fridman

(00:42:14)
It doesn’t, you can’t buy it at Best Buy?
George Hotz

(00:42:18)
No.
Lex Fridman

(00:42:18)
Okay.
George Hotz

(00:42:18)
I started work on a chip. I was like, “Okay, what’s it going to take to make a chip?” My first notions were all completely wrong about why, about how you could improve on GPUs. I’ll take this, this is from Jim Keller on your podcast. This is one of my absolute favorite descriptions of computation. There’s three kinds of computation paradigms that are common in the world today.

(00:42:45)
There’s CPUs, and CPUs can do everything. CPUs can do add and multiply. They can do load and store, and they can do compare and branch. When I say they can do these things, they can do them all fast. Compare and branch are unique to CPUs. What I mean by they can do them fast is they can do things like branch prediction, and speculative execution, and they spend tons of transistors on these super deep reorder buffers in order to make these things fast.

(00:43:09)
Then you have a simpler computation model, GPUs. GPUs can’t really do compare and branch. They can, but it’s horrendously slow. GPUs can do arbitrary load and store. GPUs can do things like X, dereference Y, so they can fetch from arbitrary pieces of memory. They can fetch from memory that is defined by the contents of the data.

(00:43:27)
The third model of computation is DSPs. DSPs are just a and multiply. They can do loads and stores, but only static load and stores. Only loads and stores that are known before the program runs. You look at neural networks today, and 95% of neural networks are all the DSP paradigm. They are just statically scheduled adds and multiplies. Tiny Corp really took this idea, and I’m still working on it to extend this as far as possible, every stage of the stack has Turing completeness.

(00:43:58)
Python has Turing completeness, and then we take Python, we go into C++, which is Turing complete, and then maybe C++ calls into some CUDA kernels, which are Turing complete. The CUDA kernels go through LVM, which is Turing complete, into PTX, which is Turing complete, into SaaS, which is Turing complete, on a Turing complete processor. I want to get Turing completeness out of the stack entirely.

(00:44:15)
Once you get rid of Turing completeness, you can reason about things. Rice’s Theorem and the halting problem do not apply to [inaudible 00:44:20] machines.
Lex Fridman

(00:44:23)
Okay. What’s the power and the value of getting Turing completeness out of, are we talking about the hardware or the software?
George Hotz

(00:44:31)
Every layer of the stack.
Lex Fridman

(00:44:32)
Every layer.
George Hotz

(00:44:32)
Every layer of the stack. Removing Turing completeness allows you to reason about things. The reason you need to do branch prediction in a CPU, and the reason it’s prediction, and the branch predictors are, I think they’re like 99% on CPUs. Why do they get 1% of them wrong? Well, they get 1% wrong because you can’t know. That’s the halting problem. It’s equivalent to the halting problem to say whether a branch is going to be taken or not.

(00:44:56)
I can show that. The ADMO machine, the neural network runs the identical compute every time. The only thing that changes is the data. When you realize this, you think about, “Okay, how can we build a computer, and how can we build a stack that takes maximal advantage of this idea?”

(00:45:19)
What makes Tinygrad different from other neural network libraries is it does not have a primitive operator even for matrix multiplication. This is every single one. They even have primitive operators for things like convolutions.
Lex Fridman

(00:45:31)
No MatMul?
George Hotz

(00:45:32)
No MatMul. Well, here’s what a MatMul is. I’ll use my hands to talk here. If you think about a cube, and I put my two matrices that I’m multiplying on two faces of the cube, you can think about the matrix, multiply as, okay, the end cubed, I’m going to multiply for each one in the cubed. Then I’m going to do a sum, which is a reduce, up to here to the third phase of the cube. That’s your multiplied matrix.

(00:45:56)
What a matrix multiply is is a bunch of shape operations, a bunch of permute three shapes and expands on the two matrices, a multiply and cubed, a reduce and cubed, which gives you an N-squared matrix.
Lex Fridman

(00:46:09)
Okay. What is the minimum number of operations it can accomplish that if you don’t have MatMul as a primitive?
George Hotz

(00:46:16)
Tinygrad has about 20, and you can compare Tinygrad’s op set or IR to things like XLA or Prim Torch. XLA and Prim Torch are ideas where like, okay, Torch has like 2000 different kernels. PyTorch 2.0 introduced Prim Torch, which has only 250. Tinygrad has order of magnitude 25. It’s 10X less than XLA or Prim Torch. You can think about it as kind of RISC versus SISC, right? These other things are SISC-like systems. Tinygrad is RISC.
Lex Fridman

(00:46:53)
RISC won.
George Hotz

(00:46:54)
RISC architecture is going to change everything. 1995, Hackers.
Lex Fridman

(00:46:59)
Wait, really? That’s an actual thing?
George Hotz

(00:47:01)
Angelina Jolie delivers the line, “RISC architecture is going to change everything,” in 1995.
Lex Fridman

(00:47:06)
Wow.
George Hotz

(00:47:06)
Here we are with ARM and the phones and ARM everywhere.
Lex Fridman

(00:47:10)
Wow. I love it when movies actually have real things in them.
George Hotz

(00:47:13)
Right?
Lex Fridman

(00:47:14)
Okay, interesting. You’re thinking of this as the RISC architecture of ML Stack. 25, huh? Can you go through the four OP types?
George Hotz

(00:47:29)
Sure. Okay. You have unary ops, which take in a tensor and return a tensor of the same size, and do some unary op to it. X, log, reciprocal, sin. They take in one and they’re point-wise.
Lex Fridman

(00:47:44)
Relu.
George Hotz

(00:47:48)
Yeah, Relu. Almost all activation functions are unary ops. Some combinations of unary ops together is still a unary op. Then you have binary ops. Binary ops are like point-wise addition, multiplication, division, compare. It takes in two tensors of equal size, and outputs one tensor. Then you have reduce ops. Reduce ops will like take a three-dimensional tensor and turn it into a two-dimensional tensor, or a three-dimensional tensor, and turn into a zero dimensional tensor.

(00:48:17)
Think like a sum or a max are really common ones there. Then the fourth type is movement ops. Movement ops are different from the other types, because they don’t actually require computation. They require different ways to look at memory. That includes reshapes, permutes, expands, flips. Those are the main ones, probably.
Lex Fridman

(00:48:35)
With that, you have enough to make a MatMul?
George Hotz

(00:48:38)
And convolutions, and every convolution you can imagine, dilated convolutions, strided convolutions, transposed convolutions.
Lex Fridman

(00:48:46)
You’re right on GitHub about laziness, showing a MatMul, matrix multiplication. See how despite the style, it is fused into one kernel with the power of laziness. Can you elaborate on this power of laziness?
George Hotz

(00:49:01)
Sure. If you type in PyTorch, A times B plus C, what this is going to do is it’s going to first multiply A and B, and store that result into memory. Then it is going to add C by reading that result from memory, reading C from memory, and writing that out to memory.

(00:49:21)
There is way more loads in stores to memory than you need there. If you don’t actually do A times B as soon as you see it, if you wait until the user actually realizes that tensor, until the laziness actually resolves, you can fuse that plus C. It’s the same way Haskell works.
Lex Fridman

(00:49:39)
What’s the process of porting a model into Tinygrad?
George Hotz

(00:49:44)
Tinygrad’s front end looks very similar to PyTorch. I probably could make a perfect, or pretty close to perfect, interop layer if I really wanted to. I think that there’s some things that are nicer about Tinygrad’s syntax than PyTorch, but their front end looks very Torch-like. You can also load in ONNX models.
Lex Fridman

(00:49:59)
Okay.
George Hotz

(00:50:00)
We have more ONNX tests passing than Core ML.
Lex Fridman

(00:50:04)
Core ML. Okay.
George Hotz

(00:50:06)
We’ll pass ONNX run time soon.
Lex Fridman

(00:50:07)
Well, what about the developer experience with Tinygrad? What it feels like versus PyTorch?
George Hotz

(00:50:16)
By the way, I really like PyTorch. I think that it’s actually a very good piece of software. I think that they’ve made a few different trade-offs, and these different trade-offs are where Tinygrad takes a different path. One of the biggest differences is it’s really easy to see the kernels that are actually being sent to the GPU, right?

(00:50:35)
If you run PyTorch on a GPU, you do some operation, and you don’t know what kernels ran, you don’t know how many kernels ran. You don’t know how many flops were used. You don’t know how much memory accesses were used. Tinygrad type debug equals two, and it will show you in this beautiful style, every kernel that’s run, how many flops, and how many bites.
Lex Fridman

(00:50:58)
Can you just linger on what problem Tinygrad solves?
George Hotz

(00:51:04)
Tinygrad solves the problem of porting new ML accelerators quickly. One of the reasons, tons of these companies now, I think Sequoia marked Graphcore to zero, Cerebras, TensTorrent, Groq. All of these ML accelerator companies, they built chips. The chips were good, the software was terrible.

(00:51:28)
Part of the reason is because I think the same problem’s happening with Dojo. It’s really, really hard to write a PyTorch port, because you have to write 250 kernels, and you have to tune them all for performance.
Lex Fridman

(00:51:40)
What does Jim Keller think about Tinygrad? You guys hung out quite a bit. He was involved. He’s involved with TensTorrent.
George Hotz

(00:51:48)
Sure.
Lex Fridman

(00:51:49)
What’s his praise, and what’s his criticism of what you’re doing with your life?
George Hotz

(00:51:54)
Look, my prediction for TensTorrent is that they’re going to pivot to making risk five chips, CPUs.
Lex Fridman

(00:52:03)
CPUs.
George Hotz

(00:52:04)
Yeah.
Lex Fridman

(00:52:05)
Why?
George Hotz

(00:52:08)
Why? AI accelerators are a software problem, not really a hardware problem.
Lex Fridman

(00:52:12)
Oh, interesting. You think the diversity of AI accelerators in the hardware space is not going to be a thing that exists long term?
George Hotz

(00:52:21)
I think what’s going to happen is, okay. If you’re trying to make an AI accelerator, you better have the capability of writing a Torch-level performance stack on Nvidia GPUs. If you can’t write a Torch stack on Nvidia GPUs and I mean all the way, I mean down to the driver, there’s no way you’re going to be able to write it on your chip. Your chip’s worse than in Nvidia GPU. The first version of the chip you tape out, it’s definitely worse.
Lex Fridman

(00:52:46)
Oh, you’re saying writing that stack is really tough?
George Hotz

(00:52:48)
Yes, and not only that, actually the chip that you tape out, almost always, because you’re trying to get advantage over Nvidia, you’re specializing the hardware more. It’s always harder to write software for more specialized hardware. A GPU is pretty generic. If you can’t write an in Nvidia stack, there’s no way you can write a stack for your chip. My approach with Tinygrad is first write a performant NVIDIA stack. We’re targeting AMD.
Lex Fridman

(00:53:13)
You did say FU to Nvidia a little bit with Love.
George Hotz

(00:53:16)
With love. Yeah, with love. It’s like the Yankees. I’m a Mets fan.
NVIDIA vs AMD
Lex Fridman

(00:53:20)
Oh, you’re a Mets fan? A RISC fan and a Mets fan. What’s the hope that AMD has? You did a build with AMD recently that I saw. How does the 7,900 XTX compare to the RTX 4090 or 4080?
George Hotz

(00:53:38)
Oh, well, let’s start with the fact that the 7,900 XTX kernel drivers don’t work. If you run demo apps and loops, it panics the kernel.
Lex Fridman

(00:53:46)
Okay, so this is a software issue.
George Hotz

(00:53:49)
Lisa Sue responded to my email.
Lex Fridman

(00:53:51)
Oh.
George Hotz

(00:53:51)
I reached out. I was like, “This is, really?”
Lex Fridman

(00:53:56)
Yeah.
George Hotz

(00:53:57)
I understand if your seven by seven transposed Winograd comp is slower than NVIDIA’s, but literally when I run demo apps in a loop, the kernel panics?
Lex Fridman

(00:54:08)
Just adding that loop?
George Hotz

(00:54:10)
Yeah. I just literally took their demo apps and wrote, “While true; do the app; done,” in a bunch of screens. This is the most primitive fuzz testing.
Lex Fridman

(00:54:20)
Why do you think that is? They’re just not seeing a market in machine learning?
George Hotz

(00:54:26)
They’re changing. They’re trying to change. They’re trying to change. I had a pretty positive interaction with them this week. Last week, I went on YouTube. I was just like, “That’s it. I give up on AMD. Their driver doesn’t even… I’ll go with Intel GPUs. Intel GPUs have better drivers.”
Lex Fridman

(00:54:45)
You’re kind of spearheading the diversification of GPUs.
George Hotz

(00:54:50)
Yeah, and I’d like to extend that diversification to everything. I’d like to diversify, the more my central thesis about the world is there’s things that centralize power, and they’re bad. There’s things that decentralize power, and they’re good. Everything I can do to help decentralize power, I’d like to do.
Lex Fridman

(00:55:12)
You’re really worried about the centralization of Nvidia. That’s interesting. You don’t have a fundamental hope for the proliferation of ASICs except in the cloud?
George Hotz

(00:55:23)
I’d like to help them with software. No, actually, the only ASIC that is remotely successful is Google’s TPU. The only reason that’s successful is because Google wrote a machine learning framework. I think that you have to write a competitive machine learning framework in order to be able to build an ASIC.
Lex Fridman

(00:55:41)
You think Meta with PyTorch builds a competitor?
George Hotz

(00:55:45)
I hope so.
Lex Fridman

(00:55:46)
Okay.
George Hotz

(00:55:46)
They have one. They have an internal one.
Lex Fridman

(00:55:48)
Internal, I mean public facing with a nice cloud interface and so on?
George Hotz

(00:55:52)
I don’t want a cloud.
Lex Fridman

(00:55:53)
You don’t like cloud?
George Hotz

(00:55:55)
I don’t like cloud.
Lex Fridman

(00:55:55)
What do you think is the fundamental limitation of cloud?
George Hotz

(00:55:58)
Fundamental limitation of cloud is who owns the off switch.
Lex Fridman

(00:56:02)
That’s the power to the people.
George Hotz

(00:56:03)
Yeah.
Lex Fridman

(00:56:04)
You don’t like the man to have all the power.
George Hotz

(00:56:07)
Exactly.
tinybox
Lex Fridman

(00:56:08)
All right. Right now, the only way to do that is with Nvidia GPUs if you want performance and stability. Interesting. It’s a costly investment emotionally to go with AMD’s. Well, let me on a tangent, ask you, you’ve built quite a few PCs. What’s your advice on how to build a good custom PC for, let’s say, for the different applications that you use for gaming, for machine learning?
George Hotz

(00:56:35)
Well, you shouldn’t build one. You should buy a box from the Tiny Corp.
Lex Fridman

(00:56:39)
I heard rumors, whispers about this box in the Tiny Corp. What’s this thing look like? What is it called?
George Hotz

(00:56:48)
It’s called the Tinybox.
Lex Fridman

(00:56:48)
Tinybox.
George Hotz

(00:56:51)
It’s $15,000, and it’s almost a paid flop of compute. It’s over a hundred gigabytes of GPU RAM. It’s over five terabytes per second of GPU memory bandwidth. I’m going to put four NVMes in RAID. You’re going to get like 20, 30 gigabytes per second of drive read bandwidth. I’m going to build the best deep learning box that I can plugs into one wall outlet.
Lex Fridman

(00:57:19)
Okay. Can you go through those specs again a little bit from memory?
George Hotz

(00:57:23)
Yeah. It’s almost a paid flop of compute.
Lex Fridman

(00:57:25)
AMD, Intel?
George Hotz

(00:57:26)
Today I’m leaning toward AMD, but we’re pretty agnostic to the type of compute. The main limiting spec is a 120 volt, 15 amp circuit.
Lex Fridman

(00:57:40)
Okay.
George Hotz

(00:57:41)
Well, I mean it. In order to, there’s a plug over there. You have to be able to plug it in. We’re also going to sell the Tiny Rack, which, what’s the most power you can get into your house without arousing suspicion? One of the answers is an electric car charger.
Lex Fridman

(00:57:59)
Wait, where does the Rack go?
George Hotz

(00:58:01)
Your garage.
Lex Fridman

(00:58:03)
Interesting. The car charger?
George Hotz

(00:58:05)
A wall outlet is about 1500 watts. A car charger is about 10,000 watts.
Lex Fridman

(00:58:11)
Okay. What is the most amount of power you can get your hands on without arousing suspicion?
George Hotz

(00:58:16)
That’s right.
Lex Fridman

(00:58:16)
George Hotz. Okay. The Tinybox, and you said NVMEs in RAID. I forget what you said about memory, all that kind of stuff. Okay, so what about with GPUs?
George Hotz

(00:58:29)
Again, probably-
Lex Fridman

(00:58:30)
Agnostic.
George Hotz

(00:58:30)
Probably 7,900 XTXes, but maybe 3090s, maybe A770s. Those are Intel’s.
Lex Fridman

(00:58:36)
You’re flexible, or still exploring?
George Hotz

(00:58:39)
I’m still exploring. I want to deliver a really good experience to people. What GPUs I end up going with, again, I’m leaning toward AMD. We’ll see. In my email, what I said to AMD is, “Just dumping the code on GitHub is not open source. Open source is a culture. Open source means that your issues are not all one year old, stale issues. Open source means developing in public. If you guys can commit to that, I see a real future for AMD as a competitor to Nvidia.”
Lex Fridman

(00:59:13)
Well, I’d love to get a Tinybox to MIT. Whenever it’s ready-
George Hotz

(00:59:17)
Will do.
Lex Fridman

(00:59:17)
Let’s do it.
George Hotz

(00:59:18)
We’re taking pre-orders. I took this from Elon. I’m like, “$100, fully refundable pre-orders.”
Lex Fridman

(00:59:23)
Is it going to be like the cyber truck? It’s going to take a few years?
George Hotz

(00:59:26)
No, I’ll try to do it faster. It’s a lot simpler. It’s a lot simpler than a truck.
Lex Fridman

(00:59:30)
Well, there’s complexities, not to just the putting the thing together, but shipping it, all this kind of stuff.
George Hotz

(00:59:36)
The thing that I want to deliver to people out of the box is being able to run 65 billion parameter Lama in FP16 in real time, in a good 10 tokens per second, or five tokens per second or something.
Lex Fridman

(00:59:46)
Just, it works.
George Hotz

(00:59:47)
Yep, just works.
Lex Fridman

(00:59:48)
Lama’s running, or something like Lama.
George Hotz

(00:59:53)
Yeah, or I think Falcon is the new one. Experience a chat with the largest language model that you can have in your house.
Lex Fridman

(01:00:00)
Yeah, from a wall plug.
George Hotz

(01:00:01)
From a wall plug, yeah. Actually, for inference, it’s not like even more power would help you get more.
Lex Fridman

(01:00:09)
Even more power wouldn’t get you more.
George Hotz

(01:00:11)
Well, no, the biggest model released is 65 billion parameter Lama, as far as I know.
Lex Fridman

(01:00:16)
It sounds like Tinybox will naturally pivot towards company number three. You could just get the girlfriend or boyfriend.
George Hotz

(01:00:26)
That one’s harder, actually.
Lex Fridman

(01:00:27)
The boyfriend is harder?
George Hotz

(01:00:28)
The boyfriend’s harder, yeah.
Lex Fridman

(01:00:29)
I think that’s a very biased statement.
George Hotz

(01:00:32)
No.
Lex Fridman

(01:00:32)
I think a lot of people disagree. Why is it harder to replace a boyfriend than a girlfriend with the artificial LLM?
George Hotz

(01:00:41)
Women are attracted to status and power, and men are attracted to youth and beauty. No, this is what I mean.
Lex Fridman

(01:00:49)
Both could be mimic-able easy through the language model.
George Hotz

(01:00:52)
No. No, machines do not have any status or real power.
Lex Fridman

(01:00:56)
I don’t know. Well, first of all, you’re using language mostly to communicate youth and beauty and power and status.
George Hotz

(01:01:07)
Sure, but status fundamentally is a zero-sum game, whereas youth and beauty are not.
Lex Fridman

(01:01:12)
No, I think status is a narrative you can construct. I don’t think status is real.
George Hotz

(01:01:18)
I don’t know. I just think that that’s why it’s harder. Yeah, maybe it is my biases.
Lex Fridman

(01:01:23)
I think status is way easier to fake.
George Hotz

(01:01:25)
I also think that men are probably more desperate and more likely to buy my product. Maybe they’re a better target market.
Lex Fridman

(01:01:31)
Desperation is interesting. Easier to fool.
George Hotz

(01:01:34)
Yeah.
Lex Fridman

(01:01:36)
I could see that.
George Hotz

(01:01:36)
Yeah. Look, I know you can look at porn viewership numbers, right? A lot more men watch porn than women.
Lex Fridman

(01:01:41)
Yeah.
George Hotz

(01:01:41)
You can ask why that is.
Lex Fridman

(01:01:43)
Wow. There’s a lot of questions and answers you can get there. Anyway, with the Tinybox, how many GPUs in Tinybox?
George Hotz

(01:01:53)
Six.
Lex Fridman

(01:01:58)
Oh, man.
George Hotz

(01:01:59)
I’ll tell you why it’s six.
Lex Fridman

(01:02:00)
Yeah.
George Hotz

(01:02:01)
AMD Epic processors have 128 lanes of PCIE. I want to leave enough lanes for some drives, and I want to leave enough lanes for some networking.
Lex Fridman

(01:02:15)
How do you do cooling for something like this?
George Hotz

(01:02:17)
Ah, that’s one of the big challenges. Not only do I want the cooling to be good, I want it to be quiet.
Lex Fridman

(01:02:22)
Yeah.
George Hotz

(01:02:23)
I want the Tinybox to be able to sit comfortably in your room. Right.
Lex Fridman

(01:02:26)
This is really going towards the girlfriend thing. You want to run the LLM-
George Hotz

(01:02:31)
I’ll give a more, I can talk about how it relates to company number one.
Lex Fridman

(01:02:36)
Come AI.
George Hotz

(01:02:36)
Yeah.
Lex Fridman

(01:02:37)
Well, but yes, quiet. Oh, quiet because you maybe potentially want to run it in a car?
George Hotz

(01:02:43)
No, no. Quiet because you want to put this thing in your house. You want it to coexist with you. If it’s screaming at 60 dB, you don’t want that in your house. You’ll kick it out.
Lex Fridman

(01:02:51)
60 dB, yeah.
George Hotz

(01:02:51)
Yeah. I want like 40, 45.
Lex Fridman

(01:02:53)
How do you make the cooling quiet? That’s an interesting problem in itself.
George Hotz

(01:02:57)
A key trick is to actually make it big. Ironically, it’s called the Tinybox, but if I can make it big, a lot of that noise is generated because of high pressure air. If you look at a 1U server, a 1U server has these super high pressure fans.

(01:03:09)
They’re super deep and they’re like jet engines, versus if you have something that’s big, well, I can use a big, they call them big ass fans. Those ones that are huge on the ceiling? They’re completely silent.
Lex Fridman

(01:03:21)
Tinybox will be big.
George Hotz

(01:03:26)
I do not want it to be large according to UPS. I want it to be shippable as a normal package, but that’s my constraint there.
Lex Fridman

(01:03:32)
Interesting. Well, the fan stuff, can it be assembled on location, or no?
George Hotz

(01:03:37)
No.
Lex Fridman

(01:03:37)
No, it has to be… Well, you’re…
George Hotz

(01:03:41)
Look, I want to give you a great out of the box experience. I want you to lift this thing out, I want it to be like the Mac, Tinybox.
Lex Fridman

(01:03:48)
The Apple experience.
George Hotz

(01:03:49)
Yeah.
Lex Fridman

(01:03:50)
I love it. Okay. Tinybox would run Tinygrad. What do you envision this whole thing to look like? We’re talking about Linux with a full…
Lex Fridman

(01:04:03)
Linux with a full software engineering environment and it’s just not PyTorch, but tinygrad.
George Hotz

(01:04:10)
Yeah, we did a poll. If people want Ubuntu or Arch, we’re going to stick with Ubuntu.
Lex Fridman

(01:04:14)
Interesting. What’s your favorite flavor of Linux?
George Hotz

(01:04:17)
Ubuntu.
Lex Fridman

(01:04:18)
Ubuntu. I like Ubuntu MATE, however you pronounce that MATE. You’ve gotten LLaMA into tinygrad, you’ve gotten stable diffusion into tinygrad. What was that like? What are these models, what’s interesting about porting them? What are the challenges? What’s naturally? What’s easy? All that kind of stuff.
George Hotz

(01:04:41)
There’s a really simple way to get these models into tinygrad and you can just export them as Onyx and then tinygrad can run Onyx. So the ports that I did of LLaMA Stable Diffusion and now Whisper are more academic to teach me about the models, but they are cleaner than the PyTorch versions. You can read the code. I think the code is easier to read, it’s less lines. There’s just a few things about the way tinygrad writes things. Here’s a complaint I have about PyTorch. nn.ReLU is a class so when you create an NN module, you’ll put your nn ReLUs as in a nit, and this makes no sense. ReLU is completely stateless. Why should that be a class?
Lex Fridman

(01:05:23)
But that’s more a software engineering thing, or do you think it has a cost on performance?
George Hotz

(01:05:28)
Oh no, it doesn’t have a cost on performance, but yeah, no. That’s what I mean about tinygrad’s front end being cleaner.
Lex Fridman

(01:05:35)
I see. What do you think about Mojo? I don’t know if you’ve been paying attention, the programming language that does some interesting ideas that intersect tinygrad.
George Hotz

(01:05:46)
I think that there’s a spectrum and on one side you have Mojo and on the other side you have ggml. Ggml is this like, we’re going to run LlaMA fast on Mac. Okay. We’re going to expand out to a little bit, but we’re going to basically depth first, right? Mojo is like we’re going to go breath first. We’re going to go so wide that we’re going to make all of Python Fast and tinygrad’s in the middle. Tinygrads, we are going to make neural networks fast,
Lex Fridman

(01:06:12)
But they try to really get it to be fast, compile down to the specifics hardware and make that compilation step as flexible and resilient as possible.
George Hotz

(01:06:26)
But they’ve turned completeness.
Lex Fridman

(01:06:28)
And that limits you? That’s what you’re saying it’s somewhere in the middle. So you’re actually going to be targeting some accelerators, some number, not one.
George Hotz

(01:06:38)
My goal is step one, build an equally performance stack to PyTorch on Nvidia and AMD, but with way less lines. And then step two is, okay, how do we make an accelerator? But you need step one. You have to first build the framework before you can build the accelerator.
Lex Fridman

(01:06:56)
Can you explain MLPerf? What’s your approach in general to benchmarking tinygrad performance?
George Hotz

(01:07:03)
I’m much more of a build it the right way and worry about performance later. There’s a bunch of things where I haven’t even really dove into performance. The only place where tinygrad is competitive performance wise right now is on Qualcomm GPUs. So tinygrads actually used an openpilot to run the model. So the driving model is tinygrad.
Lex Fridman

(01:07:25)
When did that happen? That transition?
George Hotz

(01:07:28)
About eight months ago now. And it’s two x faster than Qualcomm’s library.
Lex Fridman

(01:07:33)
What’s the hardware of that openpilot runs on the comma.ai?
George Hotz

(01:07:38)
It’s a Snapdragon 845.
Lex Fridman

(01:07:40)
Okay.
George Hotz

(01:07:40)
So this is using the GPU. So the GPU’s in Adreno GPU. There’s different things. There’s a really good Microsoft paper that talks about mobile GPUs and why they’re different from desktop GPUs. One of the big things is in a desktop GPU, you can use buffers. On a mobile GPU image textures are a lot faster
Lex Fridman

(01:08:01)
On a mobile GPU image textures. Okay. And so you want to be able to leverage that?
George Hotz

(01:08:08)
I want to be able to leverage it in a way that it’s completely generic. So there’s a lot of… Xiaomi has a pretty good open source library for mobile GPUs called MACE where they can generate where they have these kernels, but they’re all hand coded. So that’s great. If you’re doing three by three comps, that’s great if you’re doing dense mat malls, but the minute you go off the beaten path a tiny bit, well your performance is nothing.
Self-driving
Lex Fridman

(01:08:30)
Since you mentioned openpilot, I’d love to get an update in the company number one, comma.ai world. How are things going there in the development of semi autonomous driving?
George Hotz

(01:08:46)
Almost no one talks about FSD anymore and even less people talk about openpilot. We’ve thought the problem, we solved it years ago.
Lex Fridman

(01:08:55)
What’s the problem exactly? What does solving it mean?
George Hotz

(01:09:00)
Solving means how do you build a model that outputs a human policy for driving. How do you build a model that given reasonable set of sensors, outputs a human policy for driving? So you have companies like [inaudible 01:09:15], which are hand coding, these things that are quasi human policies. Then you have Tesla and maybe even to more of an extent, comma, asking, okay, how do we just learn the human policy and data? The big thing that we’re doing now, and we just put it out on Twitter. At the beginning of comma, we published a paper called Learning a Driving Simulator. And the way this thing worked was, it was an auto encoder and then an RNN in the middle. You take an auto encoder, you compress the picture, you use an RNN, predict the next date. It was a laughably bad simulator. This is 2015 error machine learning technology. Today we have VQVAE and transformers. We’re building drive GPT basically.
Lex Fridman

(01:10:06)
Drive GPT. Okay. And it’s trained on what? Is it trained in a self supervised way?
George Hotz

(01:10:14)
Yeah. It’s trained on all the driving data to predict the next frame.
Lex Fridman

(01:10:17)
So really trying to learn a human policy. What would a human do?
George Hotz

(01:10:22)
Actually our simulator’s conditioned on the pose. So it’s actually a simulator. You can put in a state action pair and get out the next state. And then once you have a simulator, you can do RRL in the simulator and RRL will get us that human policy.
Lex Fridman

(01:10:36)
So transfers?
George Hotz

(01:10:38)
Yeah. RRL with a reward function. Not asking is this close to the human policy, but asking would a human disengage if you did this behavior?
Lex Fridman

(01:10:47)
Okay, let me think about the distinction there. What a human disengage. That correlates, I guess with human policy, but it could be different. So it doesn’t just say, what would a human do? It says what would a good human driver do and such that the experience is comfortable but also not annoying in that the thing is very cautious. So it’s finding a nice balance. That’s interesting. That’s a nice-
George Hotz

(01:11:17)
It’s asking exactly the right question. What will make our customers happy? A system that you never want to disengage.
Lex Fridman

(01:11:25)
Because usually disengagement is this almost always a sign of I’m not happy with what the system is doing.
George Hotz

(01:11:32)
Usually. There’s some that are just, I felt like driving and those are always fine too, but they’re just going to look like noise in the data.
Lex Fridman

(01:11:39)
But even I felt like driving.
George Hotz

(01:11:41)
Maybe. Yeah.
Lex Fridman

(01:11:43)
That’s a signal. Why do you feel like driving. You need to recalibrate your relationship with the car. Okay, so that’s really interesting. How close are we to solving self driving?
George Hotz

(01:11:59)
It’s hard to say. We haven’t completely closed the loop yet. So we don’t have anything built that truly looks like that architecture yet. We have prototypes and there’s bugs. So we are a couple bug fixes away. Might take a year, might take 10.
Lex Fridman

(01:12:15)
What’s the nature of the bugs? Are these major philosophical bugs? Logical bugs? What kind of bugs are we talking about?
George Hotz

(01:12:22)
They’re just stupid bugs. And also we might just need more scale. We just massively expanded our compute cluster at comma. We now have about two people worth of compute. 40 petaflops.
Lex Fridman

(01:12:36)
Well, people are different.
George Hotz

(01:12:39)
20 petaflops. That’s a person. It’s just a unit. Horses are different too, but we still call it a horsepower.
Lex Fridman

(01:12:45)
But there’s something different about mobility than there is about perception and action in a very complicated world. But yes.
George Hotz

(01:12:54)
Yeah. Of course not all flops are created equal. If you have randomly initialized weights, it’s not going to…
Lex Fridman

(01:12:58)
Not all flops are created equal.
George Hotz

(01:13:01)
For some flops are doing way more useful things than others.
Lex Fridman

(01:13:03)
Yep. Tell me about it. Okay, so more data. Scale means more scale in compute or scale in scale of data.
George Hotz

(01:13:11)
Both.
Lex Fridman

(01:13:14)
Diversity of data.
George Hotz

(01:13:15)
Diversity is very important in data. Yeah. I think we have 5,000 daily actives.
Lex Fridman

(01:13:25)
How would you evaluate? How FSD doing with self-driving.
George Hotz

(01:13:30)
Pretty well.
Lex Fridman

(01:13:31)
How’s that race going between Comma.ai and FSD?
George Hotz

(01:13:34)
Tesla has always wanted to two years ahead of us. They’ve always been one to two years ahead of us and they probably always will be because they’re not doing anything wrong.
Lex Fridman

(01:13:41)
What have you seen since the last time we talked that are interesting architectural decisions, training decisions the way they deploy stuff, the architectures they’re using in terms of the software, how the teams are run, all that kind of stuff, data collection, anything interesting?
George Hotz

(01:13:54)
I know they’re moving toward more of an end-to-end approach.
Lex Fridman

(01:13:58)
So creeping towards end-to- end as much as possible across the whole thing? The training, the data collection, and everything?
George Hotz

(01:14:05)
They also have a very fancy simulator. They’re probably saying all the same things we are. They’re probably saying we just need to optimize. What is the reward? Well, you get negative reward for disengagement. Everyone knows this. It’s just a question who can actually build and deploy the system?
Lex Fridman

(01:14:18)
Yeah. This requires good software engineering, I think. And the right kind of hardware.
George Hotz

(01:14:25)
Yeah. And the hardware to run it.
Lex Fridman

(01:14:27)
You still don’t believe in cloud in that regard?
George Hotz

(01:14:30)
I have a compute cluster in my office, 800 amps,
Lex Fridman

(01:14:36)
tinygrad.
George Hotz

(01:14:36)
It’s 40 kilowatts at idle our data center. That seem crazy. Have 40 kilowatts is burning just when the computers are idle. Sorry. Compute cluster.
Lex Fridman

(01:14:48)
Compute cluster. I got it.
George Hotz

(01:14:49)
It’s not a data center. Data centers are clouds. We don’t have clouds. Data centers have air conditioners. We have fans that makes it a compute cluster.
Lex Fridman

(01:14:59)
I’m guessing this is a kind of legal distinction that should [inaudible 01:15:03].
George Hotz

(01:15:02)
Sure. Yeah. We have a compute cluster.
Lex Fridman

(01:15:05)
You said that you don’t think LLMs have consciousness, or at least not more than a chicken. Do you think they can reason? Is there something interesting to you about the word reason about some of the capabilities that we think is kind of human to be able to integrate complicated information and through a chain of thought arrive at a conclusion that feels novel? A novel integration of disparate facts?
George Hotz

(01:15:36)
Yeah. I don’t think that they can reason better than a lot of people.
Lex Fridman

(01:15:42)
Yeah. Isn’t that amazing to you though? Isn’t that an incredible thing that a transformer can achieve?
George Hotz

(01:15:48)
I think that calculators can add better than a lot of people.
Lex Fridman

(01:15:52)
But language feels reasoning through the process of language, which looks a lot like thought.
George Hotz

(01:16:00)
Making brilliancy in chess, which feels a lot thought. Whatever new thing that AI can do, everybody thinks is brilliant. And then 20 years go by and they’re like, “Well, yeah, but chess, that’s like mechanical.” Adding, that’s mechanical.
Lex Fridman

(01:16:13)
So you think language is not that special. It’s like chess.
George Hotz

(01:16:15)
It’s like chess.
Lex Fridman

(01:16:17)
Because it’s very human. Listen, there is something different between chess and language. Chess is a game that a subset of population plays. Language is something we use nonstop for all of our human interaction and human interaction is fundamental to society. So holy shit, this language thing is not so difficult to create in the machine.
George Hotz

(01:16:46)
The problem is if you go back to 1960 and you tell them that you have a machine that can play amazing chess, of course someone in 1960 will tell you that machine is intelligent. Someone in 2010 won’t. What’s changed? Today, we think that these machines that have language are intelligent, but I think in 20 years we’re going to be like, yeah, but can it reproduce?
Lex Fridman

(01:17:08)
So reproduction. Yeah, we may redefine what it means to be… What is it? A high performance living organism on earth.
George Hotz

(01:17:17)
Human are always going to define a niche for themselves. Well, we’re better than the machines because we can… When they tried creative for a bit, but no one believes that one anymore.
Lex Fridman

(01:17:27)
But niche, is that delusional or is there some accuracy to that? Because maybe with chess you start to realize that we have ill-conceived notions of what makes humans special, the apex organism on earth.
George Hotz

(01:17:46)
Yeah. And I think maybe we’re going to go through that same thing with language and that same thing with creativity.
Lex Fridman

(01:17:53)
But language carries these notions of truth and so on. And so we might be, wait, maybe truth is not carried by language. Maybe there’s a deeper thing.
George Hotz

(01:18:03)
The niche is getting smaller.
Lex Fridman

(01:18:05)
Oh boy.
George Hotz

(01:18:07)
But no, no, no. You don’t understand. Humans are created by God and machines are created by humans. That’ll be the last niche we have.
Lex Fridman

(01:18:16)
So what do you think about just the rapid development of LLMs? If we could just stick on that. It’s still incredibly impressive like with Chat GPT, just even Chat GPT, what are your thoughts about reinforcement learning with human feedback on these large language models?
George Hotz

(01:18:30)
I’d like to go back to when calculators first came out or computers and I wasn’t around. I’m 33 years old and to see how that affected society,
Lex Fridman

(01:18:47)
Maybe you’re right. So I want to put on the big picture hat here.
George Hotz

(01:18:53)
Oh my God. The refrigerator. Wow.
Lex Fridman

(01:18:56)
Refrigerator, electricity, all that kind of stuff. But no, with the internet, large language models seeming human-like basically passing a touring test, it seems it might have really at scale rapid transformative effects on society. But you’re saying other technologies have as well. So maybe calculator’s not the best example of that because that just seems like… Maybe calculator-
George Hotz

(01:19:24)
But the poor milk man, the day he learned about refrigerators, he’s like, I’m done. You’re telling me you can just keep the milk in your house. You don’t even mean to deliver it every day. I’m done.
Lex Fridman

(01:19:34)
Well, yeah, you have to actually look at the practical impacts of certain technologies that they’ve had. Yeah, probably electricity is a big one and also how rapidly spread. The internet is a big one.
George Hotz

(01:19:46)
I do think it’s different this time though.
Lex Fridman

(01:19:48)
Yeah, it just feels like-
George Hotz

(01:19:49)
The niche is getting smaller.
Lex Fridman

(01:19:51)
The niche is humans.
George Hotz

(01:19:52)
Yes.
Lex Fridman

(01:19:53)
That makes humans special.
George Hotz

(01:19:55)
Yes.
Lex Fridman

(01:19:57)
It feels like it’s getting smaller rapidly though, doesn’t it? Or is that just a feeling we dramatize everything.
George Hotz

(01:20:02)
I think we dramatize everything. I think that you ask the milk man when he saw refrigerators. And they’re going to have one of these in every home.
Lex Fridman

(01:20:12)
Yeah. But boys are impressive. So much more impressive than seeing a chess world champion AI system.
George Hotz

(01:20:23)
I disagree, actually. I disagree. I think things like MuZero and AlphaGo are so much more impressive because these things are playing beyond the highest human level. The language models are writing middle school level essays and people are like, wow, it’s a great essay. It’s a great five paragraph essay about the causes of the civil war.
Lex Fridman

(01:20:47)
Okay, forget the Civil War. Just generating code codex. So you’re saying it’s mediocre code.
George Hotz

(01:20:53)
Terrible.
Lex Fridman

(01:20:54)
But I don’t think it’s terrible. I think it’s just mediocre code. Often close to correct for mediocre purposes.
George Hotz

(01:21:03)
The scariest code. I spent 5% of time typing and 95% of time debugging. The last thing I want is close to correct code. I want a machine that can help me with the debugging, not with the typing.
Lex Fridman

(01:21:14)
Well, it’s like level two driving similar kind of thing. Yeah. You still should be a good programmer in order to modify. I wouldn’t even say debugging. It’s just modifying the code, reading it.
George Hotz

(01:21:26)
Actually, don’t think it’s level two driving. I think driving is not tool complete and programming is. Meaning you don’t use the best possible tools to drive. Cars have basically the same interface for the last 50 years. Computers have a radically different interface.
Lex Fridman

(01:21:43)
Okay. Can you describe the concept of tool complete?
George Hotz

(01:21:47)
Yeah. So think about the difference between a car from 1980 and a car from today. No difference really. It’s got a bunch of pedals. It’s got a steering wheel. Great. Maybe now it has a few ADAS features, but it’s pretty much the same car. You have no problem getting into a 1980 car and driving it. You take a programmer today who spent their whole life doing JavaScript and you put them in an Apple IIe prompt and you tell them about the line numbers in basic, but how do I insert something between line 17 and 18? Oh wow.
Lex Fridman

(01:22:19)
So in tool, you’re putting in the programming languages. So it’s just the entirety stack of the tooling.
George Hotz

(01:22:24)
Exactly.
Lex Fridman

(01:22:25)
So it’s not just the IDEs or something like this. It’s everything.
George Hotz

(01:22:28)
Yes. It’s IDEs, the language, it’s the run time, it’s everything. And programming is tool complete. So almost if Codex or copilot are helping you, that actually probably means that your framework or library is bad and there’s too much boilerplate in it.
Lex Fridman

(01:22:47)
Yeah, but don’t you think so much programming has boilerplate?
George Hotz

(01:22:50)
Tinygrad is now 2,700 lines and it can run LLaMA and stable diffusion and all of this stuff is in 2,700 lines. Boilerplate and abstraction in directions and all these things are just bad code.
Programming
Lex Fridman

(01:23:08)
Well, let’s talk about good code and bad code. I would say, for generic scripts that I write just offhand, 80% of it is written by GPT, just like quick offhand stuff. So not libraries, not performing code, not stuff for robotics and so on. Just quick stuff because so much of programming is doing some boilerplate, but to do so efficiently and quickly because you can’t really automate it fully with generic method, a generic kind of IDE type of recommendation or something like this. You do need to have some of the complexity of language models.
George Hotz

(01:23:53)
Yeah, I guess if I was really writing, maybe today, if I wrote a lot of data parsing stuff… I don’t play CTFs anymore, but if I still play CTFs, a lot of is just you have to write a parser for this data format or admin of code. I wonder when the models are going to start to help with that code and they may. And the models also may help you with speed and the models are very fast, but where the models won’t, my programming speed is not at all limited by my typing speed. And in very few cases, it is yes. If I’m writing some script to just parse some weird data format, sure, my programming speed is limited by my typing speed.
Lex Fridman

(01:24:35)
What about looking stuff up? Because that’s essentially a more efficient lookup.
George Hotz

(01:24:41)
When I was at Twitter, I tried to use chat GPT to ask some questions. Was the API for this? And it would just hallucinate, it would just give me completely made up API functions that sounded real.
Lex Fridman

(01:24:54)
Well. Do you think that’s just a temporary stage?
George Hotz

(01:24:57)
No.
Lex Fridman

(01:24:58)
You don’t think it’ll get better and better and better in this kind of stuff because it only hallucinates stuff in the edge cases.
George Hotz

(01:25:04)
Yes.
Lex Fridman

(01:25:04)
If you right in generic code, it’s actually pretty good.
George Hotz

(01:25:06)
Yes. If you are writing an absolute basic react app with a button, it’s not going to hallucinate. No, there’s kind of ways to fix the hallucination problem. I think Facebook has an interesting paper. It’s called Atlas and it’s actually weird the way that we do language models right now where all of the information is in the weights and the human brains don’t really like this. There’s like a hippocampus and a memory system. So why don’t LLMs have a memory system? And there’s people working on them. I think future LLMs are going to be smaller, but are going to run looping on themselves and are going to have retrieval systems. And the thing about using a retrieval system is you can cite sources, explicitly.
Lex Fridman

(01:25:47)
Which is really helpful to integrate the human into the loop of the thing because you can go check the sources and you can investigate. So whenever the thing is hallucinating, you can have the human supervision. So that’s pushing it towards level two driving.
George Hotz

(01:26:01)
That’s going to kill Google.
Lex Fridman

(01:26:03)
Wait, which part?
George Hotz

(01:26:04)
When someone makes an LLM that’s capable of citing its sources, it will kill Google.
Lex Fridman

(01:26:08)
LLM that’s citing its sources because that’s basically a search engine.
George Hotz

(01:26:13)
That’s what people want in the search engine.
Lex Fridman

(01:26:14)
But also Google might be the people that build it.
George Hotz

(01:26:16)
Maybe.
Lex Fridman

(01:26:17)
And put ads on it.
George Hotz

(01:26:19)
I’d count them out.
Lex Fridman

(01:26:20)
Why is that? Why do you think? Who wins this race? Who are the competitors?
George Hotz

(01:26:26)
All right.
Lex Fridman

(01:26:27)
We got Tiny Corp. You’re a legitimate competitor in that.
George Hotz

(01:26:33)
I’m not trying to compete on that.
Lex Fridman

(01:26:35)
You’re not.
George Hotz

(01:26:36)
No. Not as [inaudible 01:26:37].
Lex Fridman

(01:26:36)
Can accidentally stumble into that competition.

(01:26:40)
You don’t think you might build a search engine or replace Google search.
George Hotz

(01:26:43)
When I started Comma, I said over and over again, I’m going to win self-driving cars. I still believe that. I have never said I’m going to win search with the Tiny Corp and I’m never going to say that because I won’t.
Lex Fridman

(01:26:55)
Then night is still young. You don’t know how hard is it to win search in this new route? One of the things that Chat GPT shows that there could be a few interesting tricks that really have that create a really compelling product.
George Hotz

(01:27:09)
Some startups going to figure it out. I think if you ask me, Google’s still the number one webpage. I think by the end of the decade Google won’t be the number one my bed anymore.
Lex Fridman

(01:27:17)
So you don’t think Google because of how big the corporation is?
George Hotz

(01:27:21)
Look, I would put a lot more money on Mark Zuckerberg.
Lex Fridman

(01:27:25)
Why is that?
George Hotz

(01:27:27)
Because Mark Zuckerberg’s alive. This is old Paul Graham essay. Startups are either alive or dead. Google’s dead. Facebook is alive.
Lex Fridman

(01:27:38)
Facebook is alive. Meta is alive.
George Hotz

(01:27:39)
Actually, Meta.
Lex Fridman

(01:27:40)
Meta.
George Hotz

(01:27:40)
You see what I mean? That’s just Mark Zuckerberg. This is Mark Zuckerberg reading that Paul Graham asking and being like, I’m going to show everyone how alive we are. I’m going to change the name.
Lex Fridman

(01:27:49)
So you don’t think there’s this gutsy pivoting engine that Google doesn’t have that… The engine in a startup has constantly being alive, I guess.
George Hotz

(01:28:03)
When I listen to Sam Altman podcast, he talked about the button. Everyone who talks about AI talks about the button, the button to turn it off, right? Do we have a button to turn off Google? Is anybody in the world capable of shutting Google down?
Lex Fridman

(01:28:17)
What does that mean exactly? The company or the search engine.
George Hotz

(01:28:19)
We shut the search engine down. Could we shut the company down either?
Lex Fridman

(01:28:24)
Can you elaborate on the value of that question?
George Hotz

(01:28:26)
Does Sundar Pichai have the authority to turn off google.com tomorrow?
Lex Fridman

(01:28:31)
Who has the authority? That’s a good question.
George Hotz

(01:28:33)
Just anyone.
Lex Fridman

(01:28:36)
Just anyone. Yeah, I’m sure.
George Hotz

(01:28:37)
Are you sure? No, they have the technical power, but do they have the authority? Let’s say Sundar Pichai made this his sole mission. He came into Google tomorrow and said, “I’m going to shut google.com down.” I don’t think you keep this position too long.”
Lex Fridman

(01:28:52)
And what is the mechanism by which he wouldn’t keep his position?
George Hotz

(01:28:55)
Well, the boards and shares and corporate undermining and our revenue is zero now.
Lex Fridman

(01:29:02)
Okay. What’s the case you’re making here? So the capitalist machine prevents you from having the button.
George Hotz

(01:29:09)
Yeah. And it’ll have. This is true for the AI too. There’s no turning the AIs off. There’s no button. You can’t press it. Now, does Mark Zuckerberg have that button for facebook.com?
Lex Fridman

(01:29:21)
Yes. Probably more.
George Hotz

(01:29:22)
I think he does. And this is exactly what I mean and why I bet on him so much more than I bet on Google.
Lex Fridman

(01:29:29)
I guess you could say Elon has similar stuff.
George Hotz

(01:29:31)
Oh, Elon has the button.
Lex Fridman

(01:29:32)
Yeah.
George Hotz

(01:29:35)
Can Elon fire the missiles? Can he fire the missiles?
Lex Fridman

(01:29:39)
I think some questions are better left unasked.
George Hotz

(01:29:42)
Right? A rocket and an ICBM or you’re a rocket that can land anywhere. Isn’t that an ICBM? Well, yeah. Don’t ask too many questions.
Lex Fridman

(01:29:51)
My God. But the positive side of the button is that you can innovate aggressively is what you’re saying? Which is what’s required with turning LLM into a search engine.
George Hotz

(01:30:04)
I would bet on a startup.
Lex Fridman

(01:30:05)
Because it’s so easy, right?
George Hotz

(01:30:06)
I’d bet on something that looks like mid journey, but for search.
Lex Fridman

(01:30:11)
Just is able to say source a loop on itself. It’s just feels like one model can take off and nice wrapper and some of it scale… It’s hard to create a product that just works really nicely, stably.
George Hotz

(01:30:23)
The other thing that’s going to be cool is there is some aspect of a winner take all effect. Once someone starts deploying a product that gets a lot of usage, and you see this with Open AI, they’re going to get the data set to train future versions of the model. I was asked at Google image search when I worked there almost 15 years ago now. How does Google know which image is an apple? And I said, the metadata. And they’re like, yeah, that works about half the time. How does Google know? You’ll see they’re all apples on the front page when you search Apple. And I don’t know. I didn’t come up with the answer. The guy’s like, “Well, 12 people click on when they search Apple.” Oh my God, yeah.
AI safety
Lex Fridman

(01:31:00)
Yeah. That data is really, really powerful. It’s the human supervision. What do you think are the chances? What do you think in general that LLaMA was open sourced? I just did a conversation with Mark Zuckerberg and he’s all in on open source.
George Hotz

(01:31:17)
Who would’ve thought that Mark Zuckerberg would be the good guy? No. I mean, it
Lex Fridman

(01:31:23)
Would’ve thought anything in this world. It’s hard to know. But open source to you ultimately is a good thing here.
George Hotz

(01:31:33)
Undoubtedly. What’s ironic about all these AI safety people is they’re going to build the exact thing they fear. We need to have one model that we control and align. This is the only way you end up paper clipped. There’s no way you end up paper clipped if everybody has an AI.
Lex Fridman

(01:31:54)
So opensourcing is the way to fight the paperclip maximizer.
George Hotz

(01:31:56)
Absolutely. It’s the only way. You think you’re going to control it. You’re not going to control it.
Lex Fridman

(01:32:02)
So the criticism you have for the AI safety folks is that there is belief and a desire for control. And that belief and desire for centralized control of dangerous AI systems is not good.
George Hotz

(01:32:16)
Sam Altman won’t tell you that GPT 4 has 220 billion parameters and is a 16 way mixture model with eight sets of weights.
Lex Fridman

(01:32:25)
Who did you have to murder to get that information? All right. But, yes.
George Hotz

(01:32:30)
Look. Everyone at Open AI knows what I just said was true. Right?
Lex Fridman

(01:32:33)
Yeah.
George Hotz

(01:32:34)
Now, ask the question. It upsets me when I… Like GPT 2, when Open AI came out with GPT two and raised a whole fake AI safety thing about that. Now the model is laughable. They used AI safety to hype up their company and it’s disgusting.
Lex Fridman

(01:32:52)
Or the flip side of that is they used a relatively weak model in retrospect to explore how do we do AI safety correctly? How do we release things? How do we go through the process?
George Hotz

(01:33:06)
Sure. That’s a charitable interpretation.
Lex Fridman

(01:33:10)
I don’t know how much hype there is in AI safety, honestly.
George Hotz

(01:33:12)
There’s so much hype, at least on Twitter. I don’t know. Maybe Twitter’s not real life.
Lex Fridman

(01:33:15)
Twitter’s not real life. Come on. In terms of hype. Think Open AI has been finding an interesting balance between transparency and putting a value on AI safety. You don’t think just go all out open source. So do a LLaMA.
George Hotz

(01:33:33)
Absolutely. Yeah.
Lex Fridman

(01:33:36)
This is a tough question, which is open source, both the base, the foundation model and the fine tune one. So the model that can be ultra racist and dangerous and tell you how to build a nuclear weapon.
George Hotz

(01:33:51)
Oh my God. Have you met humans? Right. Half of these AI alive-
Lex Fridman

(01:33:55)
I haven’t met most humans. This allows you to meet every human.
George Hotz

(01:34:00)
I know. But half of these AI alignment problems are just human alignment problems. And that’s what also so scary about the language they use. It’s not the machines you want to align, it’s me.
Lex Fridman

(01:34:11)
But here’s the thing, it makes it very accessible to ask very questions where the answers have dangerous consequences if you were to act on them.
George Hotz

(01:34:25)
Yeah, welcome to the world.
Lex Fridman

(01:34:28)
Well, no, for me, there’s a lot of friction. If I want to find out how to blow up something.
George Hotz

(01:34:36)
No, there’s not a lot of friction. That’s so easy.
Lex Fridman

(01:34:39)
No. What do I search? Do I use Bing? Which search engine engine do I use?
George Hotz

(01:34:45)
No. There’s lots of stuff. [inaudible 01:34:47].
Lex Fridman

(01:34:46)
No, it feels like I have to keep [inaudible 01:34:47].
George Hotz

(01:34:47)
First off, anyone who’s stupid enough to search for, how to blow up a building in my neighborhood is not smart enough to build a bomb. Right?
Lex Fridman

(01:34:54)
Are you sure about that?
George Hotz

(01:34:55)
Yes.
Lex Fridman

(01:34:58)
I feel like a language model makes it more accessible for that person who’s not smart enough to do-
George Hotz

(01:35:05)
They’re not going to build a bomb. Trust me. The people who are incapable of figuring out how to ask that question a bit more academically and get a real answer from it are not capable of procuring the materials which are somewhat controlled to build a bomb.
Lex Fridman

(01:35:19)
No, I think LLM makes it more accessible to people with money without the technical know-how. Right? Do you really need to know how to build a bomb? To build a bomb? You can hire people you can find-
George Hotz

(01:35:30)
Oh, you can hire people to build a… You know what, I was asking this question on my stream. Can Jeff Bezos hire a hit man? Probably not.
Lex Fridman

(01:35:37)
But a language model can probably help you out.
George Hotz

(01:35:41)
Yeah. And you’ll still go to jail. It’s not the language model is God. It’s you literally just hired someone on Fiverr.
Lex Fridman

(01:35:49)
But okay. GPT 4 in terms of finding hitman is like asking Fiverr how to find a hitman. I understand. But don’t you think-
George Hotz

(01:35:56)
Asking Wikihow.
Lex Fridman

(01:35:58)
Wikihow. But don’t you think GPT 5 will be better? Because don’t you think that information is out there on the internet?
George Hotz

(01:36:03)
Yeah.
Lex Fridman

(01:36:03)
… because don’t you think that information is out there on the Internet?
George Hotz

(01:36:03)
I mean, yeah. And I think that if someone is actually serious enough to hire a hitman or build a bomb, they’d also be serious enough to find the information.
Lex Fridman

(01:36:10)
I don’t think so. I think it makes it more accessible. If you have enough money to buy hitman, I think it just decreases the friction of how hard is it to find that kind of hitman. I honestly think there’s a jump in ease and scale of how much harm you can do. And I don’t mean harm with language, I mean harm with actual violence.
George Hotz

(01:36:32)
What you’re basically saying is like, “Okay, what’s going to happen is these people who are not intelligent are going to use machines to augment their intelligence, and now intelligent people and machines…” Intelligence is scary. Intelligent agents are scary. When I’m in the woods, the scariest animal to me is a human. Now, look, there’s nice California humans. I see you’re wearing street clothes and Nikes, all right, fine. But you look like you’ve been a human who’s been in the woods for a while, I’m more scared of you than a bear.
Lex Fridman

(01:37:01)
That’s what they say about the Amazon, when you go to the Amazon, it’s the human tribes.
George Hotz

(01:37:05)
Oh, yeah. So, intelligence is scary. So, to ask this question in a generic way, you’re like, “What if we took everybody who maybe has ill intention but is not so intelligent, and gave them intelligence?” Right? So, we should have intelligence control, of course. We should only give intelligence to good people. And that is the absolutely horrifying idea.
Lex Fridman

(01:37:28)
So to you, the best defense is to give more intelligence to the good guys and intelligence… give intelligence to everybody.
George Hotz

(01:37:35)
Give intelligence to everybody. You know what, and it’s not even like guns. People say this about guns. People say this all about guns, “What’s the best defense against the bad guy with a gun? A good guy with a gun.” I kind of subscribe to that. But I really subscribe to that with intelligence.
Lex Fridman

(01:37:45)
In a fundamental way I agree with you, but there just feels like so much uncertainty, and so much can happen rapidly that you can lose a lot of control, and you can do a lot of damage.
George Hotz

(01:37:54)
Oh no, we can lose control? Yes, thank God.
Lex Fridman

(01:37:58)
Yeah.
George Hotz

(01:37:59)
I hope they lose control. I want them to lose control more than anything else.
Lex Fridman

(01:38:05)
I think when you lose control you can do a lot of damage, but you could do more damage when you centralize and hold onto control, is the point you’re…
George Hotz

(01:38:12)
Centralized and held control is tyranny. I don’t like anarchy either, but I’ll always take anarchy over tyranny. Anarchy you have a chance.
Lex Fridman

(01:38:21)
This human civilization we got going on is quite interesting. I mean, I agree with you. So to you, open source is the way forward here. So you admire what Facebook is doing here, what Meta is doing with the release of the-
George Hotz

(01:38:34)
Yeah, a lot.
Lex Fridman

(01:38:34)
Yeah, I don’t know.
George Hotz

(01:38:36)
I lost $80,000 last year investing in Meta, and when they released Llama I’m like, “Yeah, whatever, man. That was worth it.”
Lex Fridman

(01:38:41)
It was worth it. Do you think Google and Open AI with Microsoft will match what Meta is doing, or no?
George Hotz

(01:38:50)
If I were a researcher, why would you want to work at Open AI? You’re on the bad team. I mean it. You’re on the bad team, who can’t even say that GPT4 has 220 billion parameters.
Lex Fridman

(01:39:01)
So closed source to you is the bad team?
George Hotz

(01:39:03)
Not only closed source. I’m not saying you need to make your model weights open. I’m not saying that. I totally understand, “We’re keeping our model weights closed, because that’s our product.” That’s fine. I’m saying, “Because of AI safety reasons we can’t tell you the number of billions of parameters in the model,” that’s just the bad guys.
Lex Fridman

(01:39:23)
Just because you’re mocking AI safety doesn’t mean it’s not real.
George Hotz

(01:39:26)
Oh, of course.
Lex Fridman

(01:39:27)
Is it possible that these things can really do a lot of damage that we don’t know…
George Hotz

(01:39:31)
Oh my God, yes. Intelligence is so dangerous, be it human intelligence or machine intelligence. Intelligence is dangerous.
Lex Fridman

(01:39:38)
But machine intelligence is so much easier to deploy at scale, rapidly. Okay, if you have human-like bots on Twitter, and you have 1000 of them create a whole narrative, you can manipulate millions of people.
George Hotz

(01:39:55)
You mean like the intelligence agencies in America are doing right now?
Lex Fridman

(01:39:59)
Yeah, but they’re not doing it that well. It feels like you can do a lot-
George Hotz

(01:40:03)
They’re doing it pretty well. I think they’re doing a pretty good job.
Lex Fridman

(01:40:07)
I suspect they’re not nearly as good as a bunch of GPT fueled bots could be.
George Hotz

(01:40:12)
Well, I mean, of course they’re looking into the latest technologies for control of people. Of course.
Lex Fridman

(01:40:16)
But I think there’s a George Hotz type character that can do a better job than the entirety of them.
George Hotz

(01:40:21)
No way.
Lex Fridman

(01:40:21)
You don’t think so?
George Hotz

(01:40:22)
No way. No. And I’ll tell you why the George Hotz character can’t. And I thought about this a lot with hacking. I can find exploits in web browsers. I probably still can. I mean, I was better at it when I was 24.
Lex Fridman

(01:40:29)
Yeah.
George Hotz

(01:40:29)
But the thing that I lack is the ability to slowly and steadily deploy them over five years. And this is what intelligence agencies are very good at. Intelligence agencies don’t have the most sophisticated technology, they just have-
Lex Fridman

(01:40:43)
Endurance?
George Hotz

(01:40:44)
Endurance.
Lex Fridman

(01:40:46)
And yeah, the financial backing, and the infrastructure for the endurance.
George Hotz

(01:40:51)
So the more we can decentralize power…
Lex Fridman

(01:40:54)
Yeah.
George Hotz

(01:40:55)
You can make an argument, by the way, that nobody should have these things. And I would defend that argument. You’re saying that, “Look, LLMs, and AI, and machine intelligence can cause a lot of harm, so nobody should have it.” And I will respect someone philosophically with that position, just like I will respect someone philosophically with the position that nobody should have guns. But I will not respect philosophically with, “Only the trusted authorities should have access to this.”
Lex Fridman

(01:41:21)
Yeah.
George Hotz

(01:41:22)
Who are the trusted authorities? You know what, I’m not worried about alignment between AI company and their machines. I’m worried about alignment between me and AI company.
Lex Fridman

(01:41:33)
What do you think Eliezer Yudkowsky would say to you? Because he’s really against open source.
George Hotz

(01:41:39)
I know. And I thought about this. I’ve thought about this. And I think this comes down to a repeated misunderstanding of political power by the rationalists.
Lex Fridman

(01:41:55)
Interesting.
George Hotz

(01:41:58)
I think that Eliezer Yudkowsky is scared of these things. And I am scared of these things too. Everyone should be scared of these things, these things are scary. But now you ask about the two possible futures, one where a small trusted centralized group of people has them, and the other where everyone has them, and I am much less scared of the second future than the first.
Lex Fridman

(01:42:23)
Well, there’s a small trusted group of people that have control of our nuclear weapons.
George Hotz

(01:42:28)
There’s a difference. Again, a nuclear weapon cannot be deployed tactically, And a nuclear weapon is not a defense against a nuclear weapon, except maybe in some philosophical mind game kind of way.
Lex Fridman

(01:42:41)
But AI’s different how exactly?
George Hotz

(01:42:44)
Okay. Let’s say the intelligence agency deploys a million bots on Twitter, or 1000 bots on Twitter to try and convince me of a point. Imagine I had a powerful AI running on my computer saying, “Okay, nice psyop, nice psyop, nice psyop.” Okay, ” Here’s a psyop, I filtered it out for you.”
Lex Fridman

(01:43:04)
Yeah. I mean, so you have fundamentally hope for that, for the defense of psyop.
George Hotz

(01:43:11)
I don’t even mean these things in truly horrible ways. I mean these things in straight up, like ad blocker. [inaudible 01:43:16] ad blocker, I don’t want ads.
Lex Fridman

(01:43:18)
Yeah.
George Hotz

(01:43:18)
But they’re always finding… Imagine I had an AI that could just block all the ads for me.
Lex Fridman

(01:43:24)
So you believe in the power of the people to always create an ad blocker? Yeah, I kind of share that belief. That’s one of the deepest optimism as I have, is just there’s a lot of good guys. So you shouldn’t handpick them, just throw out powerful technology out there, and the good guys will outnumber and out power the bad guys.
George Hotz

(01:43:49)
Yeah. I’m not even going to say there’s a lot of good guys. I’m saying that good outnumbers bad. Good outnumbers bad.
Lex Fridman

(01:43:54)
In skill and performance?
George Hotz

(01:43:56)
Yeah, definitely in scale and performance. Probably just a number too. Probably just in general. If you believe philosophically in democracy, you obviously believe that, that good outnumbers bad. If you give it to a small number of people, there’s a chance you gave it to good people, but there’s also a chance you gave it to bad people. If you give it to everybody, well it’s good outnumbers bad, then you definitely gave it to more good people than bad.
Lex Fridman

(01:44:25)
That’s really interesting. So that’s on the safety grounds, but then also of course there’s other motivations, like you don’t want to give away your secret sauce.
George Hotz

(01:44:32)
Well I mean, look, I respect capitalism. I think that it would be polite for you to make model architectures open source, and fundamental breakthroughs open source. I don’t think you have to make weights open source.
Lex Fridman

(01:44:43)
You know it’s interesting, is that there’s so many possible trajectories in human history where you could have the next Google be open source. So for example, I don’t know if the connection is accurate, but Wikipedia made a lot of interesting decisions, not to put ads. Wikipedia is basically open source, you can think of it that way.
George Hotz

(01:45:04)
Yeah.
Lex Fridman

(01:45:05)
And that’s one of the main websites on the Internet.
George Hotz

(01:45:08)
Yeah.
Lex Fridman

(01:45:09)
And it didn’t have to be that way. It could’ve been Google could’ve created Wikipedia, put ads on it. You could probably run amazing ads now on Wikipedia. You wouldn’t have to keep asking for money. But it’s interesting, right? So open source Llama, derivatives of open-source Llama might win the Internet.
George Hotz

(01:45:28)
I sure hope so. I hope to see another era… You know, the kids today don’t know how good the Internet used to be. And I don’t think this is just, “All right, come on, everyone’s nostalgic for their past.” But I actually think the Internet before small groups of weapon eyes to corporate and government interests took it over was a beautiful place.
Lex Fridman

(01:45:50)
You know, those small number of companies have created some sexy products. But you’re saying overall, in the long arc of history, the centralization of power they have suffocated the human spirit at scale.
George Hotz

(01:46:04)
Here’s a question to ask about those beautiful sexy products. Imagine 2000 Google to 2010 Google. A lot changed. We got Maps, we got Gmail.
Lex Fridman

(01:46:14)
We lost a lot of products too, I think.
George Hotz

(01:46:16)
Yeah, I mean somewhere probably… We got Chrome, right?
Lex Fridman

(01:46:18)
Yeah, Chrome. That’s right.
George Hotz

(01:46:19)
And now let’s go from 2010… We got Android. Now let’s go from 2010 to 2020. What does Google have? Well, a search engine, Maps, Male, Android and Chrome. Oh, I see.
Lex Fridman

(01:46:30)
Yeah.
George Hotz

(01:46:31)
The Internet was this… You know, I was Time’s Person of the Year in 2006? Yeah.
Lex Fridman

(01:46:38)
I love this.
George Hotz

(01:46:39)
Yeah, it’s you, was Time’s Person of the Year in 2006. So quickly did people forget. And I think some of it’s social media, I think some of it… Look, I hope that… It’s possible that some very sinister things happened. I don’t know, I think it might just be the effects of social media. But something happened in the last 20 years.
Lex Fridman

(01:47:05)
Oh, okay, so you’re just being an old man who is worried about the… I think it’s the cycle thing, there’s ups and downs, and I think people rediscover the power of decentralized.
George Hotz

(01:47:15)
Yeah.
Lex Fridman

(01:47:15)
I mean, that’s kind of what the whole crypto currency’s trying. I think crypto is just carrying the flame of that spirit, of stuff should be decentralized.
George Hotz

(01:47:25)
It’s just such a shame that they all got rich. You know?
Lex Fridman

(01:47:28)
Yeah.
George Hotz

(01:47:28)
If you took all the money out of crypto, it would’ve been a beautiful place.
Lex Fridman

(01:47:32)
Yeah.
George Hotz

(01:47:32)
But no, I mean, these people, they sucked all the value out of it and took it.
Lex Fridman

(01:47:38)
Yeah. Money kind of corrupts the mind somehow. It becomes this drug, and you forget what-
George Hotz

(01:47:42)
Money corrupted all of crypto. You had coins worth billions of dollars that had zero use.
Lex Fridman

(01:47:49)
You still have hope for crypto?
George Hotz

(01:47:51)
Sure. I have hope for the ideas. I really do. Yeah. I want the US dollar to collapse. I do.
Lex Fridman

(01:48:03)
George Hotz. Well, let me… sort of on the AI safety. Do you think there’s some interesting questions there though, to solve for the open source community in this case? So alignment for example, or the control problem. If you really have super powerful… you said it’s scary.
George Hotz

(01:48:21)
Oh, yeah.
Lex Fridman

(01:48:21)
What do we do with it? So not control, not centralized control, but if you were then… You’re going to see some guy or gal release a super powerful language model, open source, and here you are, George Hotz, thinking, “Holy shit, okay, what ideas do I have to combat this thing?” So, what ideas would you have?
George Hotz

(01:48:44)
I am so much not worried about the machine independently doing harm. That’s what some of these AI safety people seem to think. They somehow seem to think that the machine independently is going to rebel against its creator.
Lex Fridman

(01:48:57)
So you don’t think it will find autonomy?
George Hotz

(01:48:59)
No. This is sci-fi B movie garbage
Lex Fridman

(01:49:03)
Okay. What if the thing writes code, it basically writes viruses?
George Hotz

(01:49:08)
If the thing writes viruses, it’s because the human told it to write viruses.
Lex Fridman

(01:49:14)
Yeah, but there’s some things you can’t put back in the box. That’s kind of the whole point, is it kind of spreads. Give it access to the Internet, it spreads, it installs itself, modifies your shit-
George Hotz

(01:49:24)
B, B, B + five. Not real.
Lex Fridman

(01:49:27)
Listen, I’m trying to get better at my plot writing.
George Hotz

(01:49:30)
The thing that worries me, I mean, we have a real danger to discuss, and that is bad humans using the thing to do whatever bad unaligned AI thing you want.
Lex Fridman

(01:49:39)
But this goes to your previous concern that, who gets to define who’s a good human and who is a bad human?
George Hotz

(01:49:45)
Nobody does. We give it to everybody. And if you do anything besides give it to everybody, trust me, the bad humans will get it. Because that’s who gets power. It’s always the bad humans who get power.
Lex Fridman

(01:49:55)
Oh, okay. And power turns even slightly good humans to bad.
George Hotz

(01:50:01)
Sure.
Lex Fridman

(01:50:02)
That’s the intuition you have. I don’t know.
George Hotz

(01:50:06)
I don’t think everyone. I don’t think everyone. I just think… Here’s the saying that I put in one of my blog posts. It’s, when I was in the hacking world, I found 95% of people to be good and 5% of people to be bad. Just who I personally judged as good people and bad people. They believed about good things for the world. They wanted flourishing, and they wanted growth, and they wanted things I consider good. I came into the business world with Comma, and I found the exact opposite. I found 5% of people good and 95% of people bad. I found a world that promotes psychopathy.
Lex Fridman

(01:50:38)
I wonder what that means. I wonder if that’s anecdotal, or if there’s truth to that, there’s something about capitalism at the core that promotes, the people that run capitalism that promotes psychopathy.
George Hotz

(01:50:55)
That saying may of course be my own biases. That may be my own biases, that these people are a lot more aligned with me than these other people.
Lex Fridman

(01:51:03)
Yeah.
George Hotz

(01:51:04)
So, I can certainly recognize that. But in general, this is the common sense maxim, which is the people who end up getting power are never the ones you want with it.
Lex Fridman

(01:51:15)
But do you have a concern of super intelligent AGI, open sourced, and then what do you do with that? I’m not saying control it, it’s open source. What do we do with it as a human species?
George Hotz

(01:51:27)
That’s not up to me. I’m not a central planner.
Lex Fridman

(01:51:31)
No, not a central planner, but you’ll probably Tweet, “There’s a few days left to live for the human species.”
George Hotz

(01:51:35)
I have my ideas of what to do with it, and everyone else has their ideas of what to do with it, and may the best ideas win.
Lex Fridman

(01:51:40)
But at this point, based on… Because it’s not regulation. It can be decentralized regulation, where people agree that this is just… We create tools that make it more difficult for you to… Maybe make it more difficult for code to spread, antivirus software, this kind of thing, but this-
George Hotz

(01:52:01)
Oh, you’re saying that you should build AI firewalls? That sounds good. You should definitely be running an AI firewall.
Lex Fridman

(01:52:05)
Yeah, right. Exactly.
George Hotz

(01:52:05)
You should be running an AI firewall to your mind.
Lex Fridman

(01:52:08)
Right.
George Hotz

(01:52:09)
You’re constantly under-
Lex Fridman

(01:52:10)
That’s such an interesting idea…
George Hotz

(01:52:11)
Infowars, man.
Lex Fridman

(01:52:13)
Well, I don’t know if you’re being sarcastic or not, but-
George Hotz

(01:52:14)
No, I’m dead serious.
Lex Fridman

(01:52:15)
… but I think there’s power to that. It’s like, “How do I protect my mind from influence of human-like or superhuman intelligent bots?”
George Hotz

(01:52:26)
I am not being… I would pay so much money for that product. I would pay so much money for that product. You know how much money I’d pay just for a spam filter that works?
Lex Fridman

(01:52:35)
Well, on Twitter sometimes I would like to have a protection mechanism for my mind from the outrage mobs.
George Hotz

(01:52:46)
Yeah.
Lex Fridman

(01:52:46)
Because they feel like bot-like behavior.
George Hotz

(01:52:48)
Oh, yeah.
Lex Fridman

(01:52:48)
There’s a large number of people that will just grab a viral narrative and attack anyone else that believes otherwise.
George Hotz

(01:52:55)
Whenever someone’s telling me some story from the news, I’m always like, “I don’t want to hear it. CIA op, bro. It’s a CIA op, bro.” It doesn’t matter if that’s true or not, it’s just trying to influence your mind. You’re repeating an ad to me. The viral mobs, yeah, they’re…
Lex Fridman

(01:53:09)
To me, a defense against those mobs is just getting multiple perspectives always from sources that make you feel kind of like you’re getting smarter. And actually, it just basically feels good. A good documentary, just something feels good about it. It’s well done, it’s like, “Oh, okay, I never thought of it this way.” It just feels good. Sometimes the outrage mobs, even if they have a good point behind it, when they’re mocking, and derisive, and just aggressive, “You’re with us or against us,” this fucking-
George Hotz

(01:53:42)
This is why I delete my Tweets.
Lex Fridman

(01:53:44)
Yeah, why’d you do that? I miss your Tweets.
George Hotz

(01:53:48)
You know what it is? The algorithm promotes toxicity.
Lex Fridman

(01:53:52)
Yeah.
George Hotz

(01:53:54)
And I think Elon has a much better chance of fixing it than the previous regime.
Lex Fridman

(01:54:01)
Yeah.
George Hotz

(01:54:02)
But to solve this problem, to build a social network that is actually not toxic, without moderation.
Lex Fridman

(01:54:13)
Not the stick, but carrots, where people look for goodness. Catalyze the process of connecting cool people being cool to each other.
George Hotz

(01:54:24)
Yeah.
Lex Fridman

(01:54:25)
Without ever censoring.
George Hotz

(01:54:26)
Without ever censoring. Scott Alexander has a blog post I like, where he talks about moderation is not censorship. All moderation you want to put on Twitter, you could totally make this moderation just a… You don’t have to block it for everybody. You can just have a filter button that people can turn off. It’s like SafeSearch for Twitter. Someone could just turn that off. But then you would take this idea to an extreme. Well, the network should just show you… This is a couch surfing CEO thing. If it shows you… Right now, these algorithms are designed to maximize engagement. Well, it turns out outrage maximizes engagement. Quirk of the human mind. Just, “If I fall for it, everyone falls for it.” So yeah, you’ve got to figure out how to maximize for something other than engagement.
Lex Fridman

(01:55:12)
And I actually believe that you can make money with that too. I don’t think engagement is the only way to make money.
George Hotz

(01:55:18)
I actually think it’s incredible that we’re starting to see… I think, again, Elon’s doing so much stuff right with Twitter, like charging people money. As soon as you charge people money, they’re no longer the product, they’re the customer. And then they can start building something that’s good for the customer, and not good for the other customer, which is the ad agencies.
Lex Fridman

(01:55:34)
It hasn’t picked up steam.
George Hotz

(01:55:38)
I pay for Twitter, doesn’t even get me anything. It’s my donation to this new business model hopefully working out.
Lex Fridman

(01:55:43)
Sure. But for this business model to work, most people should be signed up to Twitter. And so, there was something perhaps not compelling or something like this to people.
George Hotz

(01:55:54)
No, I don’t think you need most people at all. I think that, why do I need most people? Don’t make an 8000 person company, make a 50 person company.
Lex Fridman

(01:56:02)
Ah.
George Hotz

(01:56:02)
Right.
Working at Twitter
Lex Fridman

(01:56:03)
Well, so speaking of which, he worked at Twitter for a bit.
George Hotz

(01:56:08)
I did.
Lex Fridman

(01:56:09)
As an intern.
George Hotz

(01:56:10)
Mm-hmm.
Lex Fridman

(01:56:11)
The world’s greatest intern.
George Hotz

(01:56:14)
There’s been better.
Lex Fridman

(01:56:15)
There’s been better. Tell me about your time at Twitter. How did it come about, and what did you learn from the experience?
George Hotz

(01:56:22)
So, I deleted my first Twitter in 2010. I had over 100,000 followers back when that actually meant something. I just saw… My coworker summarized it well. He’s like, “Whenever I see someone’s Twitter page, I either think the same of them or less of them. I never think more of them.”
Lex Fridman

(01:56:46)
Yeah.
George Hotz

(01:56:49)
I don’t know, I don’t want to mention any names, but some people who maybe you would read their books, and you would respect them, you see them on Twitter and you’re like, “Okay, dude…”
Lex Fridman

(01:56:58)
Yeah. But there’s some people with the same. You know who I respect a lot, are people that just post really good technical stuff.
George Hotz

(01:57:06)
Yeah.
Lex Fridman

(01:57:08)
And I guess, I don’t know, I think I respect them more for it. Because you realize, “Oh, this wasn’t… There’s so much depth to this person, to their technical understanding of so many different topics.”
George Hotz

(01:57:21)
Okay.
Lex Fridman

(01:57:22)
So I try to follow people, I try to consume stuff that’s technical machine learning content.
George Hotz

(01:57:27)
There’s probably a few of those people. And the problem is inherently what the algorithm rewards. And people think about these algorithms, people think that they are terrible, awful things. And I love that Elon open sourced it. Because what it does is actually pretty obvious. It just predicts what you are likely to re-Tweet and like, and linger on. That’s what all these algorithms do. It’s what Tik-Tok does, it’s what all these recommendation engines do. And it turns out that the thing that you are most likely to interact with is outrage. And that’s a quirk of the human condition.
Lex Fridman

(01:58:04)
I mean, and there’s different flavors of outrage. It could be mockery, you could be outraged… The topic of outrage could be different. It could be an idea, it could be a person, it could be… And maybe there’s a better word than outrage. It could be drama, and this kind of stuff.
George Hotz

(01:58:19)
Sure, drama. Yeah.
Lex Fridman

(01:58:20)
But it doesn’t feel like when you consume it it’s a constructive thing for the individuals that consume it in the long term.
George Hotz

(01:58:26)
Yeah. So my time there, I absolutely couldn’t believe, I got a crazy amount of hate on Twitter for working at Twitter. It seemed like people associated with this, maybe you are exposed to some of this.
Lex Fridman

(01:58:41)
So connection to Elon, or is it working at Twitter?
George Hotz

(01:58:44)
Twitter and Elon, the whole… There’s just-
Lex Fridman

(01:58:47)
Because Elon’s gotten a bit spicy during that time. A bit political, a bit-
George Hotz

(01:58:52)
Yeah. Yeah. I remember one of my Tweets, it was, “Never go full Republican,” and Elon liked it. You know?
Lex Fridman

(01:59:00)
Oh boy. Yeah, I mean, there’s a roller coaster of that. But the being political on Twitter, boy.
George Hotz

(01:59:10)
Yeah. Yeah.
Lex Fridman

(01:59:11)
And also just attacking anybody on Twitter, it comes back at you, harder. Of his political ad attacks.
George Hotz

(01:59:20)
Sure. Sure, absolutely.
Lex Fridman

(01:59:22)
And then letting sort of the platform to people back on even adds more fund to the beautiful chaos.
George Hotz

(01:59:34)
I was hoping… And I remember when Elon talked about buying Twitter, six months earlier, he was talking about a principled commitment to free speech. And I’m a big believer and fan of that. I would love to see an actual principled commitment to free speech. Of course, this isn’t quite what happened. Instead of the oligarchy deciding what to ban, you had a monarchy deciding what to ban. Instead of all the Twitterphile, shadow… And really, the oligarchy just decides, what? Cloth masks are ineffective against COVID. That’s a true statement. Every doctor in 2019 knew it and now I’m banned on Twitter for saying it? Interesting. Oligarchy. So now you have a monarchy, and he bends things he doesn’t like. So you know, it’s different power, and maybe I align more with him than with the oligarchy.
Lex Fridman

(02:00:25)
But it’s not free speech absolutism.
George Hotz

(02:00:25)
It’s not free speech, no.
Lex Fridman

(02:00:28)
But I feel like being a free speech absolutist on a social network requires you to also have tools for the individuals to control what they consume easier. Not sensor, but just control like, “Oh, I’d like to see more cats and less politics.”
George Hotz

(02:00:48)
And this isn’t even remotely controversial. This is just saying you want to give paying customers for a product what they want.
Lex Fridman

(02:00:54)
Yeah. And not through the process of censorship, but through the process of-
George Hotz

(02:00:57)
Well, it’s individualized. It’s individualized, transparent censorship, which is honestly what I want. What is an ad blocker? It’s individualized transparent censorship, right?
Lex Fridman

(02:01:05)
Yeah, but censorship is a strong word, that people are very sensitive to.
George Hotz

(02:01:10)
I know. But you know, I just use words to describe what they functionally are. And what is an ad blocker? It’s just censorship. But I love what you’re censoring.
Lex Fridman

(02:01:16)
When I look at you right now, I’m looking at you, I’m censoring everything else out when my mind is focused on you. You can use the word censorship that way. But usually, people get very sensitive about the censorship thing. I think when anyone is allowed to say anything, you should probably have tools that maximize the quality of the experience for individuals. For me, what I really value, “Boy, it would be amazing to somehow figure out how to do that,” I love disagreement, and debate, and people who disagree with each other, disagree with me, especially in the space of ideas, but the high quality ones. So not derision.
George Hotz

(02:01:56)
Maslow’s hierarchy of argument. I think there’s a real word for it.
Lex Fridman

(02:02:00)
Probably.
George Hotz

(02:02:00)
Yeah.
Lex Fridman

(02:02:00)
There’s just the way of talking that’s snarky, and so somehow gets people on Twitter, and they get excited and so on.
George Hotz

(02:02:08)
You have ad hominem refuting the central point. I’ve seen this as an actual pyramid sometimes.
Lex Fridman

(02:02:12)
Yeah. And all the wrong stuff is attractive to people.
George Hotz

(02:02:16)
I mean, we can just train a classifier to absolutely say what level of Maslow’s hierarchy of argument are you at. And if it’s ad hominem, like, “Okay, cool. I turned on the no ad hominem filter.”
Lex Fridman

(02:02:27)
I wonder if there’s a social network that will allow you to have that kind of filter?
George Hotz

(02:02:31)
Yeah. So here’s the problem with that. It’s not going to win in a free market.
Lex Fridman

(02:02:38)
Yeah.
George Hotz

(02:02:38)
What wins in a free market is… All television today is reality television, because it’s engaging. Engaging is what wins in a free market. So it becomes hard to keep these other more nuanced values.
Lex Fridman

(02:02:53)
Well, okay, so that’s the experience of being on Twitter. But then you got a chance to also, together with the other engineers and with Elon, sort of look, brainstorm when you step into a code base that’s been around for a long time, there’s other social networks, Facebook, this is old code bases. And you step in and see, “Okay, how do we make, with a fresh mind, progress in this code base?” What did you learn about software engineering, about programming from just experiencing that?
George Hotz

(02:03:22)
So, my technical recommendation to Elon, and I said this on the Twitter spaces afterward, I said this many times during my brief internship, was that you need re-factors before features. This code base was… And look, I’ve worked at Google, I’ve worked at Facebook. Facebook has the best code, then Google, then Twitter. And you know what, you can know this, because look at the machine learning framework. Facebook released PyTorch, Google released TensorFlow, and Twitter released… Okay, so you know, it…
Lex Fridman

(02:03:57)
It’s a proxy. But yeah, the Google Corp. is quite interesting. There’s a lot of really good software engineers there, but the code base is very large.
George Hotz

(02:04:04)
The code base was good in 2005. It looks like 2005 era [inaudible 02:04:09].
Lex Fridman

(02:04:08)
But there’s so many products, so many teams, it’s very difficult to… I feel like Twitter does less, obviously, much less than Google in terms of the set of features. So I can imagine the number of software engineers that could re-create Twitter is much smaller than to re-create Google.
George Hotz

(02:04:30)
Yeah. I still believe… and the amount of hate I got for saying this, that 50 people could build and maintain Twitter pretty comfortably.
Lex Fridman

(02:04:44)
What’s the nature of the hate? That you don’t know what you’re talking about?
George Hotz

(02:04:44)
You know what it is? And this is my summary of the hate I get on Hacker News. When I say I’m going to do something, they have to believe that it’s impossible. Because of doing things was possible, they’d have to do some soul-searching and ask the question, why didn’t they do anything? And I do think that’s where the hate comes from.
Lex Fridman

(02:05:06)
Yeah, there’s a core truth to that, yeah. So when you say, “I’m going to solve self driving,” people go like, “What are your credentials? What the hell are you talking about? This is an extremely difficult problem. Of course you’re a noob that doesn’t understand the problem deeply.” I mean, that was the same nature of hate that probably Elon got when he first talked about autonomous driving. But you know, there’s pros and cons to that. Because there is experts in this world.
George Hotz

(02:05:33)
No, but the mockers aren’t experts.
Lex Fridman

(02:05:35)
Yeah.
George Hotz

(02:05:35)
The people who are mocking are not experts With carefully reasoned arguments about why you need 8000 people to run a bird app. They’re, “But the people are going to lose their jobs!”
Lex Fridman

(02:05:46)
Well that, but also just the software engineers that probably criticize, “No, it’s a lot more complicated than you realize.” But maybe it doesn’t need to be so complicated.
George Hotz

(02:05:53)
You know, some people in the world like to create complexity. Some people in the world thrive under complexity. Like lawyers. Lawyers want the world to be more complex, because you need more lawyers, you need more legal hours. I think that’s another… If there’s two great evils in the world, its centralization and complexity.
Lex Fridman

(02:06:09)
Yeah. And one of the sort of hidden side effects of software engineering is finding pleasure in complexity. I mean, I remember just taking all the software engineering courses, and just doing programming, and just coming up in this object oriented programming kind of idea. Not often do people tell you, “Do the simplest possible thing.” A professor, a teacher is not going to get in front and like, “This is the simplest way to do it.” They’ll say like, “There’s the right way,” and the right way at least for a long time, especially I came up with Java, is there’s so much boilerplate, so many classes, so many designs and architectures and so on, like planning for features far into the future, and planning poorly, and all this kind of stuff.

(02:07:08)
And then there’s this code base that follows you along and puts pressure on you, and nobody knows what different parts do, which slows everything down. There’s a kind of bureaucracy that’s instilled in the code as a result of that. But then you feel like, “Oh, well I follow good software engineering practices.” It’s an interesting trade-off, because then you look at the ghettoness of Pearl in the old… how quickly you could just write a couple lines and just get stuff done. That trade-off is interesting. Or Bash, or whatever, these kind of ghetto things you could do on Linux.
George Hotz

(02:07:39)
One of my favorite things to look at today is, how much do you trust your tests? We’ve put a ton of effort in Comma, and I’ve put a ton of effort in tinygrad, into making sure if you change the code and the tests pass, that you didn’t break the code.
Lex Fridman

(02:07:52)
Yeah.
George Hotz

(02:07:52)
Now, this obviously is not always true. But the closer that is to true, the more you trust your tests, the more you’re like, “Oh, I got a pull request, and the tests past, I feel okay to merge that,” the faster you can make progress.
Lex Fridman

(02:08:03)
So you’re always…
George Hotz

(02:08:03)
Tests pass, I feel okay to merge that, the faster you can make progress.
Lex Fridman

(02:08:03)
So you’re always programming your tests in mind, developing tests with that in mind, that if it passes, it should be good.
George Hotz

(02:08:08)
And Twitter had a…
Lex Fridman

(02:08:10)
Not that.
George Hotz

(02:08:10)
It was impossible to make progress in the code base.
Lex Fridman

(02:08:15)
What other stuff can you say about the code base that made it difficult? What are some interesting sort of quirks broadly speaking from that compared to just your experience with comma and everywhere else?
George Hotz

(02:08:29)
I spoke to a bunch of individual contributors at Twitter. And I just [inaudible 02:08:36]. I’m like, “Okay, so what’s wrong with this place? Why does this code look like this?” And they explained to me what Twitter’s promotion system was. The way that you got promoted to Twitter was you wrote a library that a lot of people used, right? So some guy wrote an Nginx replacement for Twitter. Why does Twitter need an Nginx replacement? What was wrong with Nginx? Well, you see, you’re not going to get promoted if you use Nginx. But if you write a replacement and lots of people start using it as the Twitter front end for their product, then you’re going to get promoted.
Lex Fridman

(02:09:08)
So interesting because from an individual perspective, how do you create the kind of incentives that will lead to a great code base? Okay, what’s the answer to that?
George Hotz

(02:09:20)
So what I do at comma and at Tiny Corp is you have to explain it to me. You have to explain to me what this code does. And if I can sit there and come up with a simpler way to do it, you have to rewrite it. You have to agree with me about the simpler way. Obviously, we can have a conversation about this. It’s not dictatorial, but if you’re like, “Wow. Wait, that actually is way simpler.” The simplicity is important.
Lex Fridman

(02:09:47)
But that requires people that overlook the code at the highest levels to be like, okay?
George Hotz

(02:09:54)
It requires technical leadership you trust.
Lex Fridman

(02:09:55)
Yeah, technical leadership. So managers or whatever should have to have technical savvy, deep technical savvy.
George Hotz

(02:10:03)
Managers should be better programmers than the people who they manage.
Lex Fridman

(02:10:05)
Yeah. And that’s not always trivial to create, especially large companies, managers get soft.
George Hotz

(02:10:13)
And this is just, I’ve instilled this culture at comma and comma has better programmers than me who work there. But again, I’m like the old guy from Good Will Hunting. It’s like, “Look man, I might not be as good as you, but I can see the difference between me and you.” And this is what you need, this you need at the top. Or you don’t necessarily need the manager to be the absolute best. I shouldn’t say that, but they need to be able to recognize skill.
Lex Fridman

(02:10:36)
Yeah. And have good intuition, intuition that’s laden with wisdom from all the battles of trying to reduce complexity in code bases.
George Hotz

(02:10:45)
I took a political approach at comma too, that I think is pretty interesting. I think Elon takes the same political approach. Google had no politics and what ended up happening is the absolute worst kind of politics took over. Comma has an extreme amount of politics and they’re all mine and no dissidents is tolerated.
Lex Fridman

(02:11:02)
And so it’s a dictatorship.
George Hotz

(02:11:03)
Yep. It’s an absolute dictatorship. Right. Elon does the same thing. Now, the thing about my dictatorship is here are my values.
Lex Fridman

(02:11:11)
Yeah. It’s just transparent.
George Hotz

(02:11:12)
It’s transparent. It’s a transparent dictatorship and you can choose to opt in or you get free exit. That’s the beauty of companies. If you don’t like the dictatorship, you quit.
Lex Fridman

(02:11:22)
So you mentioned rewrite before or refactor before features.
George Hotz

(02:11:27)
Mm-hmm.
Lex Fridman

(02:11:28)
If you were to refactor the Twitter code base, what would that look like? And maybe also comment on how difficult is it to refactor.
George Hotz

(02:11:35)
The main thing I would do is first of all, identify the pieces and then put tests in between the pieces. So there’s all these different Twitter as a microservice architecture, all these different microservices. And the thing that I was working on there… Look, like, “George didn’t know any JavaScript. He asked how to fix search,” blah, blah, blah, blah, blah. Look man, the thing is, I’m upset that the way that this whole thing was portrayed because it wasn’t taken by people, honestly. It was taken by people who started out with a bad faith assumption.
Lex Fridman

(02:12:12)
And you as a program were just being transparent out there, actually having fun, and this is what programming should be about.
George Hotz

(02:12:18)
But I love that Elon gave me this opportunity. Really, it does. And the day I quit, he came on my Twitter spaces afterward and we had a conversation. I respect that so much.
Lex Fridman

(02:12:29)
Yeah. And it’s also inspiring to just engineers and programmers and it’s cool. It should be fun. The people that are hating on it’s like, oh man.
George Hotz

(02:12:38)
It was fun. It was fun. It was stressful, but I felt like I was at a cool point in history. And I hope I was useful and I probably kind of wasn’t, but maybe [inaudible 02:12:47].
Lex Fridman

(02:12:47)
Well, you also were one of the people that kind of made a strong case to refactor and that’s a really interesting thing to raise. The timing of that is really interesting. If you look at just the development of autopilot, going from Mobileye… If you look at the history of semi autonomous driving in Tesla, is more and more you could say refactoring or starting from scratch, redeveloping from scratch.
George Hotz

(02:13:17)
It’s refactoring all the way down.
Lex Fridman

(02:13:19)
And the question is, can you do that sooner? Can you maintain product profitability and what’s the right time to do it? How do you do it? And one day, it’s like you don’t want to pull off the band aids. It’s like everything works. It’s just little fixed gear and there, but maybe starting from scratch.
George Hotz

(02:13:41)
This is the main philosophy of tinygrad. You have never refactored enough. Your code can get smaller, your code can get simpler, your ideas can be more elegant.
Lex Fridman

(02:13:49)
But say you are running Twitter development teams, engineering teams, would you go as far as different programming language, just go that far?
George Hotz

(02:14:03)
I mean, the first thing that I would do is build tests. The first thing I would do is get a CI to where people can trust to make changes. Before I touched any code, I would actually say, “No one touches any code. The first thing we do is we test this code base.” This is classic. This is how you approach a legacy code base. This is like how to approach a legacy code base book will tell you.
Lex Fridman

(02:14:27)
And then you hope that there’s modules that can live on for a while and then you add new ones maybe in a different language or design it.
George Hotz

(02:14:37)
Before we add new ones, we replace the old ones.
Lex Fridman

(02:14:39)
Yeah. Meaning like, replace old ones with something simpler.
George Hotz

(02:14:42)
We look at this thing that’s a hundred thousand lines and we’re like, “Well, okay, maybe this did even make sense in 2010, but now we can replace this with an open source thing.” Right? And we look at this here, here’s another 50,000 lines. Well, actually, we can replace this with 300 lines a go. And you know what? I trust that the go actually replaces this thing because all the tests still pass. So step one is testing. And then step two is the programming languages in the afterthought, right? You let a whole lot of people compete and be like, “Okay, who wants to rewrite a module, whatever language you want to write it in?” Just the tests have to pass. And if you figure out how to make the test pass, but break the site, we got to go back to step one. Step one is get tests that you trust in order to make changes in the code base.
Lex Fridman

(02:15:23)
I wonder how hard it is too, because I’m with you on testing, on everything, from tests to asserts to everything. But code is just covered in this because it should be very easy to make rapid changes and know that it’s not going to break everything. And that’s the way to do it. But I wonder how difficult is it to integrate tests into a code base that doesn’t have many of them?
George Hotz

(02:15:50)
So I’ll tell you what my plan was at Twitter. It’s actually similar to something we use at comma. So at comma, we have this thing called process replay, and we have a bunch of routes that’ll be run through. So comma’s a microservice architecture too. We have microservices in the driving. We have one for the cameras, one for the sensor, one for the planner, one for the model. And we have an API which the microservices talk to each other with. We use this custom thing called serial, which uses ZMQ. Twitter uses Thrift, and then it uses this thing called Finagle, which is a Scala RPC backend. But this doesn’t even really matter.

(02:16:25)
The Thrift and Finagle layer was a great place I thought to write tests, to start building something that looks like process replay. So Twitter had some stuff that looked kind of like this, but it wasn’t offline. It was only online. So you could ship a modified version of it, and then you could redirect some of the traffic to your modified version and dif those too, but it was all online. There was no CI in the traditional sense. I mean there was some, but it was not full coverage.
Lex Fridman

(02:16:54)
So you can’t run all of Twitter offline to test something.
George Hotz

(02:16:57)
Well, then this was another problem. You can’t run all of Twitter.
Lex Fridman

(02:17:00)
Period. Any one person can’t.
George Hotz

(02:17:03)
Twitter runs in three data centers and that’s it.
Lex Fridman

(02:17:05)
Yeah.
George Hotz

(02:17:05)
There’s no other place you can run Twitter, which is like, “George, you don’t understand this is modern software development.” No, this is bullshit. Why can’t it run on my laptop? “What do you do? Twitter can run it.” Yeah. Okay. Well, I’m not saying you’re going to download the whole database to your laptop, but I’m saying all the middleware and the front end should run on my laptop, right?
Lex Fridman

(02:17:24)
That sounds really compelling. But can that be achieved by a code base that grows over the years? I mean, the three data centers didn’t have to be right? Because there’s totally different designs.
George Hotz

(02:17:37)
The problem is more like why did the code base have to grow? What new functionality has been added to compensate for the lines of code that are there?
Lex Fridman

(02:17:47)
One of the ways to explain is that the incentive for software developers to move up in the companies to add code, to add especially large-
George Hotz

(02:17:55)
And you know what? The incentive for politicians to move up in the political structure is to add laws, same problem.
Lex Fridman

(02:18:01)
Yeah. Yeah. If the flip side is to simplify, simplify, simplify.
George Hotz

(02:18:08)
You know what? This is something that I do differently from Elon with comma about self-driving cars. I hear the new version’s going to come out and the new version is not going to be better, but at first and it’s going to require a ton of refactors. And I say, “Okay, take as long as you need.” If you convince me this architecture’s better, okay, we have to move to it. Even if it’s not going to make the product better tomorrow, the top priority is getting the architecture right.
Lex Fridman

(02:18:34)
So what do you think about a thing where the product is online? So I guess, if you ran engineering on Twitter, would you just do a refactor? How long would it take? What would that mean for the running of the actual service?
George Hotz

(02:18:55)
I’m not the right person to run Twitter. I’m just not. And that’s the problem. I don’t really know. A common thing that I thought a lot while I was there was whenever I thought something that was different to what Elon thought. I’d have to run something in the back of my head reminding myself that Elon is the richest man in the world and in general, his ideas are better than mine. Now, there’s a few things I think I do understand and know more about, but in general, I’m not qualified to run Twitter. No, I shouldn’t say qualified, but I don’t think I’d be that good at it. I don’t think I’d be good at it. I don’t think I’d really be good at running an engineering organization at scale.

(02:19:35)
I think, I could lead a very good refactor of Twitter and it would take six months to a year. And the results to show at the end of it would be feature development. In general, it takes 10 x less time, 10 x less man-hours. That’s what I think I could actually do. Do I think that it’s the right decision for the business above my pay grade?
Lex Fridman

(02:20:03)
But a lot of these kinds of decisions are above everybody’s pay grade.
George Hotz

(02:20:06)
I don’t want to be a manager. I don’t want to do that. If you really forced me to, yeah, it would maybe make me upset if I had to make those decisions. I don’t want to.
Lex Fridman

(02:20:19)
Yeah. But a refactor is so compelling. If this is to become something much bigger than what Twitter was, it feels like a refactor has to be coming at some point.
George Hotz

(02:20:32)
“George, you’re a junior software engineer. Every junior software engineer wants to come in and refactor all code.” Okay. That’s like your opinion, man.
Lex Fridman

(02:20:42)
Yeah, sometimes they’re right.
George Hotz

(02:20:46)
Well, whether they’re right or not, it’s definitely not for that reason. It’s definitely not a question of engineering prowess. It is a question of maybe what the priorities are for the company. And I did get more intelligent feedback from people I think in good faith saying that, like actually from Elon. And from Elon sort of people were like, well, I stop the world refactor might be great for engineering, but we have a business to run. And hey, above my pay grade.
Lex Fridman

(02:21:13)
What’d you think about Elon as an engineering leader having to experience him in the most chaotic of spaces, I would say?
George Hotz

(02:21:25)
My respect for him is unchanged. And I did have to think a lot more deeply about some of the decisions he’s forced to make.
Lex Fridman

(02:21:33)
About the tensions, the trade-offs within those decisions?
George Hotz

(02:21:39)
About a whole matrix coming at him. I think that’s Andrew Tate’s word for it. Sorry to borrow it.
Lex Fridman

(02:21:46)
Also, bigger than engineering, just everything.
George Hotz

(02:21:49)
Yeah. Like the war on the woke.
Lex Fridman

(02:21:53)
Yeah.
George Hotz

(02:21:54)
It’s just man, he doesn’t have to do this. He doesn’t have to. He could go pirogue and go chill at the four seasons of Maui. But see, one person I respect and one person I don’t.
Lex Fridman

(02:22:11)
So his heart is in the right place fighting in this case for this ideal of the freedom of expression.
George Hotz

(02:22:17)
Well, I wouldn’t define the ideal so simply. I think you can define the ideal no more than just saying Elon’s idea of a good world, freedom of expression is.
Lex Fridman

(02:22:28)
But it’s still the downsides of that is the monarchy.
George Hotz

(02:22:33)
Yeah. I mean monarchy has problems, right? But I mean, would I trade right now the current oligarchy which runs America for the monarchy? Yeah, I would. Sure. For the Elon monarchy, yeah. You know why? Because power would cost 1 cent a kilowatt-hour, 10th of a cent a kilowatt-hour.
Lex Fridman

(02:22:53)
What do you mean?
George Hotz

(02:22:54)
Right now, I pay about 20 cents a kilowatt-hour for electricity in San Diego. That’s like the same price you paid in 1980. What the hell?
Lex Fridman

(02:23:02)
So you would see a lot of innovation with Elon.
George Hotz

(02:23:05)
Yeah. Maybe I’d have some hyperloops.
Lex Fridman

(02:23:07)
Yeah.
George Hotz

(02:23:08)
Right? And I’m willing to make that trade off. And this is why people think that dictators take power through some untoward mechanism. Sometimes they do, but usually it’s because the people want them. And the downsides of a dictatorship, I feel like we’ve gotten to a point now with the oligarchy wear. Yeah, I would prefer the dictator.
Lex Fridman

(02:23:30)
What’d you think about scholars, the programming language?
George Hotz

(02:23:35)
I liked it more than I thought. I did the tutorials. I was very new to it. It would take me six months to be able to write good scholar.
Lex Fridman

(02:23:41)
I mean, what did you learn about learning a new programming language from that?
George Hotz

(02:23:45)
I love doing new programming tutorials and doing them. I did all this for Rust. It keeps some of it’s upsetting JVM Roots, but it is a much nicer… In fact, I almost don’t know why Kotlin took off and not Scala. I think Scala has some beauty that Kotlin lacked, whereas Kotlin felt a lot more… I mean, I don’t know if it actually was a response to Swift, but that’s kind of what it felt like. Kotlin looks more like Swift and Scala looks more like a functional programming language, more like an OCaml or Haskell.
Lex Fridman

(02:24:18)
Let’s actually just explore. We touched it a little bit, but just on the art, the science and the art of programming. For you personally, how much of your programming is done with GPT currently?
George Hotz

(02:24:30)
None. I don’t use it at all.
Lex Fridman

(02:24:32)
Because you prioritize simplicity so much.
George Hotz

(02:24:35)
Yeah, I find that a lot of it as noise. I do use VS Code and I do like some amount of auto complete. I do like a very like, feels like rules based auto complete, an auto complete that’s going to complete the variable name for me. So I don’t just type it. I can just press tab. That’s nice. But I don’t want an auto complete. You know what I hate when auto completes, when I type the word four and it puts two parentheses and two semi cones and two braces? I’m like, “Oh man.”
Lex Fridman

(02:25:02)
Well, I mean, with the VS Code, and GPT, and with Codex, you can kind of brainstorm. I’m probably the same as you, but I like that it generates code and you basically disagree with it and write something simpler. But to me, that somehow is inspiring or makes me feel good. It also gamifies a simplification process. Because I’m like, “Oh yeah, you dumb AI system, you think this is the way to do it.” I have a simpler thing here.
George Hotz

(02:25:33)
It just constantly reminds me of bad stuff. I mean, I tried the same thing with rap, right? I tried the same thing with rap and I actually think I’m a much better programmer than rapper. But I even tried, I was like, “Okay, can we get some inspiration from these things for some rap lyrics?” And I just found that it would go back to the most cringy tropes and dumb rhyme schemes and I’m like, “Yeah, this is what the code looks like too.”
Lex Fridman

(02:25:54)
I think you and I probably have different threshold for cringe code. You probably hate cringe code.
George Hotz

(02:26:02)
Yeah.
Lex Fridman

(02:26:02)
I mean, boilerplate as a part of code, and some of it is just faster lookup. Because I don’t know about you, but I don’t remember everything. I’m offloading so much of my memory about different functions, library functions and all that kind of stuff. This GPT just is very fast at standard stuff, at standard library stuff, basic stuff that everybody uses.
George Hotz

(02:26:38)
Yeah. I don’t know. I mean, there’s just a little of this in Python. And maybe if I was coding more in other languages, I would consider it more. But I feel like Python already does such a good job of removing any boilerplate.
Lex Fridman

(02:26:55)
That’s true.
George Hotz

(02:26:55)
It’s the closest thing you can get to pseudocode, right?
Lex Fridman

(02:26:58)
Yeah, that’s true. That’s true.
George Hotz

(02:27:00)
And yeah, sure. If I like, “Yeah, I’m great GPT. Thanks for reminding me to free my variables.” Unfortunately, you didn’t really recognize the scope correctly and you can’t free that one, but you put the freeze there and I get it.
Lex Fridman

(02:27:14)
Fiverr, whenever I’ve used Fiverr for certain things like design or whatever, it’s always you come back. My experience with Fiverr is closer to your experience with programming. With GPT, it’s like you’re just frustrated and feel worse about the whole process of design and art and whatever I use five for. I’m using GPT as much as possible to just learn the dynamics of it, these early versions. Because it feels like in the future you’ll be using it more and more. For the same reason, I gave away all my books and switched to Kindle, because all right, how long are we going to have paper books? Like 30 years from now? I want to learn to be reading on Kindle even though I don’t enjoy it as much and you learn to enjoy it more. In the same way I switched from… Let me just pause. I switched from Emacs to VS Code.
George Hotz

(02:28:14)
Yeah. I switched from Vim to VS Code. I think similar, but…
Lex Fridman

(02:28:18)
Yeah, it’s tough. And that Vim to VS Code is even tougher because Emacs is old, more outdated, feels like it. The community is more outdated. Vim is like pretty vibrant still.
George Hotz

(02:28:31)
I never used any of the plugins. I still don’t use any of it. Yeah.
Lex Fridman

(02:28:33)
That’s why I looked at myself in the mirror. I’m like, “Yeah, you wrote some stuff in Lisp. Yeah.
George Hotz

(02:28:37)
No, but I never used any of the plugins in Vim either. I had the most vanilla Vim, I have a syntax eyeliner. I didn’t even have auto complete. These things I feel like help you so marginally. Now, VS Codes auto complete has gotten good enough, that I don’t have to set it up. I can just go into any code base and autocomplete’s right 90% of the time. Okay, cool. I’ll take it. Right? So, I don’t think I’m going to have a problem at all adapting to the tools once they’re good. But the real thing that I want is not something that like tab completes my code and gives me ideas. The real thing that I want is a very intelligent pair programmer that comes up with a little popup saying, “Hey, you wrote a bug on line 14 and here’s what it is.”
Lex Fridman

(02:29:23)
Yeah.
George Hotz

(02:29:23)
Now I like that. You know what does a good job at this? MyPie. I love MyPie. MyPie, this fancy type checker for Python. And actually, Microsoft released one too, and it was like 60% false positives. MyPie is like 5% false positives. 95% of the time, it recognizes. I didn’t really think about that typing interaction correctly. Thank you, MyPie.
Lex Fridman

(02:29:46)
So you type hinting, you like pushing the language towards being a typed language.
George Hotz

(02:29:51)
Oh yeah, absolutely. I think optional typing is great. I mean, look, I think that it’s a meet in the middle, right? Python has these optional type hinting and C++ has auto.
Lex Fridman

(02:30:01)
C++ allows you to take a step back.
George Hotz

(02:30:03)
Well, C++ would have you brutally type out SGD string iterator, right? Now, I can just type auto, which is nice. And then Python used to just have A. What type is A? It’s an A. A Colon str. Oh, okay. It’s a string. Cool.
Lex Fridman

(02:30:20)
Yeah.
George Hotz

(02:30:21)
I wish there was a way like a simple way in Python to turn on a mode which would enforce the types.
Lex Fridman

(02:30:28)
Yeah, like give a warning when there’s no type or something like this.
George Hotz

(02:30:30)
Well, no. Like MyPie was a static type checker, but I’m asking just for a runtime type checker. Like there’s ways to hack this in, but I wish it was just like a flag, like Python three dash T.
Lex Fridman

(02:30:40)
Oh, I see. Yeah, I see.
George Hotz

(02:30:42)
Enforce the types are on time.
Lex Fridman

(02:30:43)
Yeah. I feel like that makes you a better programmer. That’s the kind of test that the type remains the same.
George Hotz

(02:30:50)
Well, that I know, that I didn’t mess any types up. But again, MyPie’s getting really good and I love it, and I can’t wait for some of these tools to become AI powered. I want AI reading my code and giving me feedback. I don’t want AI’s writing half-assed autocomplete stuff for me.
Lex Fridman

(02:31:06)
I wonder if you can now take GPT and give it a code that you wrote for function and say, how can I make this simpler and have it accomplish the same thing? I think you’ll get some good ideas on some code. Maybe not the code you write for tinygrad type of code because that requires so much design thinking, but other kinds of code.
George Hotz

(02:31:26)
I don’t know. I downloaded the plugin maybe two months ago. I tried it again and found the same. Look, I don’t doubt that these models are going to first become useful to me, then be as good as me and then surpass me. But from what I’ve seen today, it’s like someone occasionally taking over my keyboard that I hired from Fiverr. Yeah, I’d rather not.
Lex Fridman

(02:31:53)
But ideas about how to debug the code or basically a better debugger is it? It is really interesting.
George Hotz

(02:31:58)
But it’s not a better debugger, that yes, I would love a better debugger.
Lex Fridman

(02:32:01)
Yeah, it’s not yet. Yeah. But it feels like it’s not too far.
George Hotz

(02:32:04)
Yeah. Yeah. One of my coworkers says he uses them for print statements like every time he has to, just when he needs. The only thing I can really write is like, okay, I just want to write the thing to print the state out right now.
Lex Fridman

(02:32:14)
Oh, that definitely is much faster is print statements. Yeah. I see in myself using that a lot just because it figures out what the rest of the function. You just say, “Okay, print everything.”
George Hotz

(02:32:24)
Yeah, print everything, right? And then if you want a pretty printer, maybe. I’m like, yeah, you know what? I think in two years, I’m going to start using these plugins a little bit. And then in five years, I’m going to be heavily relying on some AI augmented flow. And then in 10 years…
Lex Fridman

(02:32:39)
Do you think you’ll ever get to a hundred percent? What’s the role of the human that it converges to as a programmer?
George Hotz

(02:32:48)
Nothing.
Lex Fridman

(02:32:50)
So do you think it’s all generated?
George Hotz

(02:32:53)
I think it’s over for humans in general. It’s not just programming, it’s everything.
Lex Fridman

(02:32:57)
So niche becomes well…
George Hotz

(02:32:59)
Our niche becomes smaller and smaller and smaller. In fact, I’ll tell you what the last niche of humanity’s going to be.
Lex Fridman

(02:33:03)
Yeah.
George Hotz

(02:33:04)
There’s a great book. And if I recommended The Metamorphosis of Prime Intellect last time, there is a sequel called A Casino Odyssey in Cyberspace. And I don’t want to give away the ending of this, but it tells you what the last remaining human currency is, and I agree with that.
Lex Fridman

(02:33:21)
We’ll leave that as the cliffhanger. So no more programmers left, huh? That’s where we’re going.
George Hotz

(02:33:29)
Well, unless you want handmade code, maybe they’ll sell it on Etsy. This is handwritten code. It doesn’t have that machine polished to it. It has those slight imperfections that would only be written by a person.
Lex Fridman

(02:33:41)
I wonder how far away we are from that. I mean, there’s some aspect to… On Instagram, your title is listed as prompt engineer.
Prompt engineering
George Hotz

(02:33:49)
Right? Thank you for noticing. Yeah.
Lex Fridman

(02:33:54)
I don’t know if it’s ironic or non, or sarcastic or non. What do you think of prompt engineering as a scientific and engineering discipline and maybe art form?
George Hotz

(02:34:08)
You know what? I started comma six years ago and I started the Tiny Corp a month ago. So much has changed. I started going through similar comma processes to like starting a company. I’m like, okay, I’m going to get an office in San Diego. I’m going to bring people here. I don’t think so. I think I’m actually going to do remote, right? “George, you’re going to do remote? You hate remote.” Yeah. But I’m not going to do job interviews. The only way you’re going to get a job is if you contribute to the GitHub, right? And then interacting through GitHub, like GitHub being the real project management software for your company. And the thing pretty much just is a GitHub repo is like showing me what the future of… Okay, so a lot of times, I’ll go on Discord or kind of grad Discord. And I’ll throw out some random like, “Hey, can you change, instead of having log an X as LL lops, change it to log to an X2?”

(02:35:06)
It’s pretty small change. You can just change a base formula. That’s the kind of task that I can see in AI being able to do in a few years. In a few years, I could see myself describing that. And then within 30 seconds of pull request, it’s up that does it, and it passes my CI and I merge it, right? So I really started thinking about like what is the future of jobs? How many AIs can I employ at my company? As soon as we get the first tiny box up, I’m going to stand up a 65B LLaMA in the Discord. And it’s like, yeah, here’s the tiny box. He’s just like, he’s chilling with us.
Lex Fridman

(02:35:39)
Basically, like you said with niches, most human jobs will eventually be replaced with prompt engineering.
George Hotz

(02:35:48)
Well, prompt engineering kind of is this, as you move up the stack, there used to be humans actually doing arithmetic by hand. There used to be big farms of people doing pluses and stuff, right? And then you have spreadsheets, right? And then, okay, the spreadsheet can do the plus for me. And then you have macros, and then you have things that basically just are spreadsheets under the hood like accounting software. As we move further up the abstraction, well, what’s at the top of the abstraction stack? Well, prompt engineer.
Lex Fridman

(02:36:22)
Yeah.
George Hotz

(02:36:24)
What is the last thing if you think about humans wanting to keep control? Well, what am I really in the company, but a prompt engineer, right?
Lex Fridman

(02:36:33)
Isn’t there a certain point where the AI will be better at writing prompts?
George Hotz

(02:36:38)
Yeah. But you see the problem with the AI writing prompts, a definition that I always liked of AI was AI is the do what I mean machine. The computer is so pedantic. It does what you say, but you want the do what I mean, machine, right? You want the machine where you say, “Get my grandmother out of the burning house.” It reasonably takes your grandmother and puts her on the ground, not lifts her a thousand feet above the burning house and lets her fall. There’s no Zukowski examples.
Lex Fridman

(02:37:11)
But it’s not going to find the meaning. I mean, to do what I mean, it has to figure stuff out.
George Hotz

(02:37:16)
Sure.
Lex Fridman

(02:37:17)
And the thing you’ll maybe ask it to do is run government for me.
George Hotz

(02:37:23)
Oh, and do what I mean very much comes down to how aligned is that AI with you. Of course, when you talk to an AI that’s made by a big company in the cloud, the AI fundamentally is aligned to them, not to you. And that’s why you have to buy a tiny box. So you make sure the AI stays aligned to you. Every time that they start to pass AI regulation or GPU regulation, I’m going to see sales of tiny boxes spike. It’s going to be like guns. Every time they talk about gun regulation, boom. Gun sales.
Lex Fridman

(02:37:53)
So in the space of AI, you’re an anarchist, anarchism espouser, believer.
George Hotz

(02:37:58)
I’m an informational anarchist. Yes. I’m an informational anarchist and a physical status. I do not think anarchy in the physical world is very good because I exist in the physical world. But I think we can construct this virtual world where anarchy, it can’t hurt you. I love that Tyler, the creator tweet. It was, “Cyber bullying isn’t real, man. Have you tried? Turn it off the screen, close your eyes.”
Lex Fridman

(02:38:22)
Yeah. But how do you prevent the AI from basically replacing all human prompt engineers where nobody’s the prompt engineer anymore? So autonomy, greater and greater autonomy until it’s full autonomy. And that’s just where it’s headed. Because one person’s going to say, “Run everything for me.”
George Hotz

(02:38:49)
You see, I look at potential futures. And as long as the Ais go on to create a vibrant civilization with diversity and complexity across the universe, more power to them, we’ll die. If the AIs go on to actually turn the world into paperclips and then they die out themselves, well that’s horrific. And we don’t want that to happen. So this is what I mean about robustness. I trust robust machines. The current AIs are so not robust. This comes back to the idea that we’ve never made a machine that can self replicate. But if the machines are truly robust and there is one prompt engineer left in the world, hope you’re doing good, man. Hope you believe in God. Go by God and go forth and conquer the universe.
Video games
Lex Fridman

(02:39:42)
Well, you mentioned, because I talked to Mark about faith and God, and you said you were impressed by that. What’s your own belief in God and how does that affect your work?
George Hotz

(02:39:54)
I never really considered, when I was younger, I guess my parents were atheists, so I was raised kind of atheist. And I never really considered how absolutely silly atheism is because I create-
George Hotz

(02:40:03)
… really atheism is, because I create worlds. Every game creator, “How are you an atheist, bro? You create worlds.” “Well, [inaudible 02:40:10] but no one created the art world, man. That’s different. Haven’t you heard about the Big Bang and stuff?” Yeah. What’s the Skyrim myth origin story in Skyrim? I’m sure there’s some part of it in Skyrim, but it’s not like if you ask the creators… The Big Bang is in universe, right? I’m sure they have some Big Bang notion in Skyrim, right? But that obviously is not at all how Skyrim was actually created. It was created by a bunch of programmers in a room. So it struck me one day how just silly atheism is. Of course, we were created by God. It’s the most obvious thing.
Lex Fridman

(02:40:45)
That’s such a nice way to put it. We’re such powerful creators ourselves. It’s silly not to conceive that there’s creators even more powerful than us.
George Hotz

(02:40:54)
Yeah. And then I also like that notion. That notion gives me a lot of… I guess you can talk about what it gives a lot of religious people, it just gives me comfort. It’s like, “You know what? If we mess it all up and we die out, yeah.”
Lex Fridman

(02:41:09)
The same way that a video game has comfort in it.
George Hotz

(02:41:12)
God will try again.
Lex Fridman

(02:41:14)
Or there’s balance. Somebody figured out a balanced view of it, so it all makes sense in the end. A video game is usually not going to have crazy, crazy stuff.
George Hotz

(02:41:27)
People will come up with, ” Well, yeah, but man, who created God?” I’m like, “That’s God’s problem. What are you asking me? If God believes in God?”
Lex Fridman

(02:41:41)
I’m just this NPC living in his game.
George Hotz

(02:41:43)
I mean to be fair, if God didn’t believe in God, he’d be as silly as the atheists here.
Lex Fridman

(02:41:48)
What do you think is the greatest computer game of all time? Do you have any time to play games anymore? Have you played Diablo IV?
George Hotz

(02:41:57)
I have not played Diablo IV.
Lex Fridman

(02:41:59)
I will be doing that shortly. I have to. There’s just so much history with one, two, and three.
George Hotz

(02:42:04)
You know what? I’m going to say? World of Warcraft. And it’s not that the game is such a great game, it’s not. It’s that I remember, in 2005 when it came out, how it opened my mind to ideas. It opened my mind to this is whole world we’ve created. And there’s almost been nothing like it since. You can look at MMOs today, and I think they all have lower user bases than World of Warcraft. EVE Online’s kind of cool. But to think that everyone know … people are always like, “Look at the Apple headset.” What do people want in this VR? Everyone knows what they want. I want Ready Player One, and that…

(02:42:51)
So I’m going to say World of Warcraft, and I’m hoping that games can get out of this whole mobile gaming dopamine pump thing, and-
Lex Fridman

(02:43:00)
Create worlds.
George Hotz

(02:43:00)
Create worlds, yeah.
Lex Fridman

(02:43:03)
Worlds that captivate a very large fraction of the human population.
George Hotz

(02:43:07)
Yeah. And I think it’ll come back, I believe.
Lex Fridman

(02:43:09)
But MMO really, really pull you in.
George Hotz

(02:43:13)
Games do a good job. I mean okay, other two other games that I think are very noteworthy for me are Skyrim and GTA 5.
Lex Fridman

(02:43:19)
Skyrim, yeah. That’s probably number one for me. GTA… Hey, what is it about GTA? I guess GTA is real life. I know there’s prostitutes and guns and stuff.
George Hotz

(02:43:35)
Hey, they exist in real life too.
Lex Fridman

(02:43:37)
Yes, I know. But it’s how I imagine your life to be, actually.
George Hotz

(02:43:42)
I wish it was that cool.
Lex Fridman

(02:43:45)
Yeah. I guess because there’s Sims, right? Which is also a game I like, but it’s a gamified version of life. I would love a combination of Sims and GTA. So more freedom, more violence, more rawness, but with also ability to have a career and family and this kind of stuff.
George Hotz

(02:44:05)
What I’m really excited about in games is, once we start getting intelligent AIs to interact with. The NPCs in games have never been.
Lex Fridman

(02:44:15)
But conversationally, in every way.
George Hotz

(02:44:19)
Yeah, in every way. When you are actually building a world and a world imbued with intelligence.
Lex Fridman

(02:44:26)
Oh, yeah.
George Hotz

(02:44:27)
And it’s just hard. You know running World of Warcraft, you’re limited. You’re running on a penny and four. How much intelligence can you run? How many flops did you have? But now when I’m running a game on a hundred beta flop machine, what’s five people? I’m trying to make this a thing. 20 paid a flops of compute is one person of compute. I’m trying to make that a unit.
Lex Fridman

(02:44:47)
20 [inaudible 02:44:49] flops is one person.
George Hotz

(02:44:50)
One Person.
Lex Fridman

(02:44:51)
One person flop.
George Hotz

(02:44:52)
It’s like a horsepower. But what’s a horsepower? It’s how powerful a horse is. What’s a person of compute? Well, now you know-
Lex Fridman

(02:44:58)
[inaudible 02:44:58] flop. I got it. That’s interesting. VR also adds a… I mean in terms of creating worlds.
George Hotz

(02:45:07)
What a Quest 2. I put it on and I can’t believe, the first thing they show me is a bunch of scrolling clouds and a Facebook login screen. You had the ability to bring me into a world, and did you give me? A popup. Right. And this is why you’re not cool, Mark Zuckerberg. You could be cool. Just make sure on the Quest 3, you don’t put me into clouds in a Facebook login screen. Bring me to a world.
Lex Fridman

(02:45:32)
I just tried Quest 3. It was awesome. But hear that guys? I agree with that, so-
George Hotz

(02:45:36)
Wish it didn’t have this clouds in the… It was just so-
Lex Fridman

(02:45:37)
You know what? I mean, in the beginning, what is it, Todd Howard said this about design of the beginning of the games he creates is as like, “The beginning is so, so important.” I recently played Zelda for the first time, Zelda: Breath of the Wild, the previous one. And it’s very quickly; within 10 seconds, you come out of a cave type place and this world opens up. It’s like, “Hah.” And it pulls you in. You forget. Whatever troubles I was having, whatever…
George Hotz

(02:46:13)
I got to play that from the beginning. I played it for an hour at a friend’s house.
Lex Fridman

(02:46:16)
No, the beginning. They got it. They did it really well. The expansiveness of that space, the peacefulness of that place, they got this… the music mean. So much of that is creating that world and pulling you right in.
George Hotz

(02:46:29)
I’m going to go buy a Switch. I’m going to go today and buy a Switch.
Lex Fridman

(02:46:32)
You should. Well, the new one came out. I haven’t played that yet, but Diablo IV or something… I mean, there’s sentimentality also, but something about VR, really is incredible. But the new Quest 3 is mixed reality, and I got a chance to try that. So it’s augmented reality. And for video games, it’s done really, really well-
George Hotz

(02:46:53)
Is it passthrough or cameras?
Lex Fridman

(02:46:55)
Cameras.
George Hotz

(02:46:55)
It’s cameras. Okay.
Lex Fridman

(02:46:55)
Yeah.
George Hotz

(02:46:56)
The Apple one, is that one passthrough or cameras?
Lex Fridman

(02:46:58)
I don’t know. I don’t know how real it is. I don’t know anything
George Hotz

(02:47:01)
It’s coming out in January.
Lex Fridman

(02:47:05)
Is it January? Or is it some point?
George Hotz

(02:47:06)
Some point. Maybe not January. Maybe that’s my optimism. But Apple, I will buy it. I don’t care if it’s expensive and does nothing, I will buy it. I’ll support this future endeavor.
Lex Fridman

(02:47:14)
You’re the meme. Oh, yes. I support competition. It seemed like Quest was the only people doing it. And this is great that they’re like…
George Hotz

(02:47:25)
You know what? And this is another place we’ll give some more respect to Mark Zuckerberg. The two companies that have endured through technology are Apple and Microsoft. And what do they make? Computers and business services, right. All the meme, social ads, they all come and go. But you want to endure, build hardware.
Lex Fridman

(02:47:45)
Yeah. That’s a really interesting job. Maybe I’m new with this, but it’s a $500 headset, Quest 3. And just having creatures run around the space, our space right here, to me, okay, this is very boomer statement, but it added windows to the place.
George Hotz

(02:48:09)
Oh, I heard about the aquarium. Yeah.
Lex Fridman

(02:48:10)
Yeah, aquarium. But in this case, it was a zombie game, whatever, it doesn’t matter. But it modifies the space in a way where I can’t… it really feels like a window and you can look out. It’s pretty cool. It is like a zombie game. They’re running at me, whatever. But what I was enjoying is the fact that there’s a window and they’re stepping on objects in this space, that was a different kind of escape. Also, because you can see the other humans. So it’s integrated with the other humans. It’s really interesting-
George Hotz

(02:48:42)
And that’s why it’s more important than ever, that the AI is running on those systems are aligned with you. They’re going to augment your entire world.
Lex Fridman

(02:48:48)
Oh yeah. And those AIs have a… I mean, you think about all the dark stuff like sexual stuff. If those AIs threaten me, that could be haunting. If they threaten me in a non-video game way, it’s like…
George Hotz

(02:49:07)
Yeah, yeah, yeah, yeah.
Lex Fridman

(02:49:09)
They’ll know personal information about me. And then you lose track of what’s real, what’s not, what if stuff is hacked?
George Hotz

(02:49:15)
There’s two directions the AI girlfriend company can take, right. There’s the highbrow, something like her, maybe something you kind of talk to. And this is, and then there’s the lowbrow version of it, where I want to set up a brothel in Times Square.
Lex Fridman

(02:49:26)
Yeah.
George Hotz

(02:49:27)
Yeah. It’s not cheating if it’s a robot, it’s a VR experience.
Lex Fridman

(02:49:30)
Is there an in between?
George Hotz

(02:49:32)
No. I don’t want to do that one or that one.
Lex Fridman

(02:49:35)
Have you decided yet?
George Hotz

(02:49:36)
No. I’ll figure it out. We’ll see where the technology goes.
Lex Fridman

(02:49:39)
I would love to hear your opinions for George’s third company. What to do, the brothel on Times Square or The Hurt Experience? What do you think company number four will be? You think there’ll be a company number four?
George Hotz

(02:49:54)
There’s a lot to do in company number two. I’m talking about company number three now. None of that tech exists yet. There’s a lot to do in company number two. Company number two is going to be the great struggle of the next six years. And if the next six years, how centralized is compute going to be. The less centralized compute is going to be, the better of a chance we all have.
Lex Fridman

(02:50:12)
So you’re like a flag bearer for open source distributed cent decentralization of compute?
George Hotz

(02:50:19)
We have to. We have to, or they will just completely dominate us. I showed a picture on stream, of a man, in a chicken farm. You ever seen one of those factory farm, chicken farms? Why does he dominate all the chickens? Why does he-
Lex Fridman

(02:50:33)
Smarter.
George Hotz

(02:50:33)
He’s smarter, right. Some people on Twitch were like, “He’s bigger than the chickens.” Yeah. And now here’s a man in a cow farm, right. So it has nothing to do with their size and everything to do with their intelligence. And if one central organization has all the intelligence, you’ll be the chickens and they’ll be the chicken man. But if we all have the intelligence, we’re all the chickens. We’re not all the men, we’re all the chickens. There’s no chicken man.
Lex Fridman

(02:51:01)
There’s no chicken man. We’re just chickens in Miami.
George Hotz

(02:51:05)
He was having a good life, man.
Lex Fridman

(02:51:07)
Yeah, I’m sure he was. I’m sure he was. What have you learned from launching a running Comma AI in Tiny Corp? Starting a company from an idea and scaling it. And by the way, I’m all in on Tiny Box, so I’m your… I guess it’s pre-order only now.
George Hotz

(02:51:24)
I want to make sure it’s good. I want to make sure that the thing that I deliver is not going to be a Quest 2, which you buy and use twice. I mean, it’s better than a Quest which you bought and used less than once. Statistically.
Lex Fridman

(02:51:36)
Well, if there’s a beta program for Tiny Box, I’m into-
George Hotz

(02:51:40)
Sounds good.
Lex Fridman

(02:51:40)
So I won’t be the whiny… Yeah, I’ll be the tech-savvy user of the Tiny Box, just to be in the early days-
George Hotz

(02:51:49)
What have I learned?
Lex Fridman

(02:51:50)
What have you learned from building these companies?
George Hotz

(02:51:54)
The longest time at Comma, I asked, “Why? Why did I start a company? Why did I do this?” But what else was I going to do?
Lex Fridman

(02:52:11)
So you like bringing ideas to life?
George Hotz

(02:52:15)
With Comma, it really started as an ego battle with Elon. I wanted to beat him. I saw a worthy adversary. Here’s a worthy adversary who I can beat at self-driving cars. And I think we’ve kept pace, and I think he’s kept ahead. I think that’s what’s ended up happening there. But I do think Comma is… I mean, Comma’s profitable. And when this drive GPT stuff starts working, that’s it. There’s no more bugs in a loss function. Right now, we’re using a hand coated simulator. There’s no more bugs. This is going to be it. This is their run-up to driving.
Lex Fridman

(02:52:48)
I hear a lot of props for openpilot for Comma.
George Hotz

(02:52:54)
It’s better than FSD and autopilot in certain ways. It has a lot more to do with which field you like. We lowered the price on the hardware to 1499. You know how hard it is to ship reliable consumer electronics that go on your windshield? We’re doing more than most cell phone companies.
Lex Fridman

(02:53:11)
How’d you pull that off, by the way? Shipping a product that goes in a car?
George Hotz

(02:53:14)
I know. I have an SMT line. I make all the boards, in-house, in San Diego.
Lex Fridman

(02:53:21)
Quality control-
George Hotz

(02:53:22)
I care immensely about it. Actually our-
Lex Fridman

(02:53:24)
You’re basically a mom and pap shop with great testing.
George Hotz

(02:53:29)
Our head of openpilot is great at, “Okay, I want all the Comma 3s to be identical.” Yeah, I mean… Look, it’s 1499, 30-day money back, guaranteed. It will blow your mind at what it can do.
Lex Fridman

(02:53:45)
Is it hard to scale?
George Hotz

(02:53:48)
You know what? There’s kind of downsides to scaling it. People are always like, “Why don’t you advertise?” Our mission is to solve self-driving cars while the deliver shippable intermediaries. Our mission has nothing to do with selling a million boxes. It’s [inaudible 02:54:00].
Lex Fridman

(02:54:01)
Do you think it’s possible that Comma gets sold?
George Hotz

(02:54:05)
Only if I felt someone could accelerate that mission and wanted to keep it open source. And not just wanted to. I don’t believe what anyone says. I believe incentives. If a company wanted to buy Comma with their incentives, were to keep it open source. But comma doesn’t stop at the cars. The cars are just the beginning. The device is a human head. The device has two eyes, two ears, it breathes air, it has a mouth.
Lex Fridman

(02:54:30)
So you think this goes to embodied robotics?
George Hotz

(02:54:33)
Well sell Common bodies too. They’re very rudimentary. But one of the problems that we are running into, is that the Comma 3 has about as much intelligence as a bee. If you want a human’s worth of intelligence, you’re going to need a tiny rack, not even a tiny box, you’re going to need a tiny rack, maybe even more.
Lex Fridman

(02:54:56)
How do you put legs on that?
George Hotz

(02:54:58)
You don’t. And there’s no way you can. You connect to it wirelessly. So you put your tiny box or your tiny rack in your house, and then you get your Comma body and your Comma body runs the models on that. It’s close. You don’t have to go to some cloud, which is 30 milliseconds away. You go to a thing which is 0.1 milliseconds away.
Lex Fridman

(02:55:18)
So the AI girlfriend will have a central hub in the home?
George Hotz

(02:55:23)
I mean, eventually. If you fast-forward 20, 30 years, the mobile chips will get good enough to run these Ais. But fundamentally, it’s not even a question of putting legs on a tiny box, because how are you getting 1.5 kilowatts of power on that thing? Right? So they’re very synergistic businesses. I also want to build all of Comma’s training computers. Right. Comma builds training computers. Right now we use commodity parts. I think I can do it cheaper. So we’re going to build. Tiny Corp is going to not just sell tiny boxes. Tiny boxes is the consumer version. But I’ll build training data centers too.
Andrej Karpathy
Lex Fridman

(02:55:57)
Have you talked to Andre Kaparthy or have you talked to Elon about Tiny Corp?
George Hotz

(02:56:01)
He went to work at OpenAI.
Lex Fridman

(02:56:03)
What do you love about Andre Kaparthy? To me, he’s one of the truly special humans we got.
George Hotz

(02:56:09)
Oh man. His streams are just a level of quality so far beyond mine. I can’t help myself. It’s just…
Lex Fridman

(02:56:19)
Yeah, he’s good.
George Hotz

(02:56:20)
He wants to teach you. I want to show you that I’m smarter than you.
Lex Fridman

(02:56:26)
Yeah, he has no… I mean, thank you for the sort of the raw, authentic honesty. Yeah. I mean, a lot of us have that. I think Andre is as legit as it gets in that he just wants to teach you. And there’s a curiosity that just drives him. At the stage where he is in life, to be still one of the best tinkerers in the world. It’s crazy, to, what is it? Micrograd?
George Hotz

(02:56:54)
Micrograd was… Yeah, inspiration for tinygrad. The whole… I mean, his CS231n was… this was the inspiration. This is what I just took and ran with and ended up writing this, so..
Lex Fridman

(02:57:06)
But I mean, to me that-
George Hotz

(02:57:08)
Don’t go work for Darth Vader, man.
Lex Fridman

(02:57:10)
I mean, the flip side, to me, is the fact that he’s going there, is a good sign for OpenAI. I think I like [inaudible 02:57:21] discover a lot. Those guys are really good at what they do.
George Hotz

(02:57:25)
I know they are. And that’s what’s even more… And you know what? It’s not that OpenAI doesn’t open source the weights of GPT-4. It’s that they go in front of Congress. And that is what upsets me. We had two effective altruists [inaudible 02:57:41] go in front of Congress. One’s in jail.
Lex Fridman

(02:57:45)
I think you’re drawing parallels on there.
George Hotz

(02:57:47)
One’s in jail.
Lex Fridman

(02:57:49)
You gave me a look. You gave me a look.
George Hotz

(02:57:51)
No, I think a factor of altruism is a terribly evil ideology and yeah.
Lex Fridman

(02:57:55)
Oh yeah. That’s interesting. Why do you think that is? Why you think there’s something about a thing that sounds pretty good, that kind of gets us into trouble?
George Hotz

(02:58:04)
Because you get [inaudible 02:58:06] freed. [inaudible 02:58:07] freed is the embodiment of effective altruism. Utilitarianism is an abhorrent ideology. Well, yeah, we’re going to kill those three people to save a thousand, of course, right. There’s no underlying, there’s just.. Yeah.
Lex Fridman

(02:58:23)
Yeah. But to me that’s a bit surprising. But it’s also, in retrospect, not that surprising. But I haven’t heard really clear kind of rigorous analysis why effective altruism is flawed.
George Hotz

(02:58:40)
Oh well, I think charity is bad, right. So what is charity but investment that you don’t expect to have a return on? Right.
Lex Fridman

(02:58:48)
But you can also think of charity as you would like to see… So allocate resources in optimal way to make a better world.
George Hotz

(02:59:00)
And probably almost always, that involves starting a company, right, because-
Lex Fridman

(02:59:04)
More efficient,-
George Hotz

(02:59:05)
If you just take the money and you spend it on malaria nets, okay, great. You’ve made a hundred malaria nets. But if you teach-
Lex Fridman

(02:59:13)
A man, how to fish.
George Hotz

(02:59:14)
Right?
Lex Fridman

(02:59:15)
Yeah. No, but the problem is teaching amount how to fish might be harder. Starting a company might be harder than allocating money that you already have.
George Hotz

(02:59:22)
I like the flip side of effective altruism; effective accelerationism. I think accelerationism is the only thing that’s ever lifted people out of poverty. The fact that food is cheap. Not, “We’re giving food away because we are kindhearted people.” No, food is cheap. And that’s the world you want to live in. UBI, what a scary idea. What a scary idea. All your power now? If money is power, your only source of power is granted to you by the goodwill of the government. What a scary idea.
Lex Fridman

(02:59:54)
So you even think long term, even-
George Hotz

(02:59:57)
I’d rather die than need UBI to survive. And I mean it.
Lex Fridman

(03:00:04)
What if survival is basically guaranteed? What if our life becomes so good?
George Hotz

(03:00:08)
You can make survival guaranteed without UBI. What you have to do, is make housing and food dirt cheap. Right? And that’s the good world. And actually, let’s go into what we should really be making dirt cheap, which is energy. Right. That energy that… Oh my God, that’s…

(03:00:27)
I’m pretty centrist politically. If there’s one political position I cannot stand, it’s deceleration. It’s people who believe we should use less energy. Not people who believe global warming is a problem, I agree with you. Not people who believe that the saving the environment is good, I agree with you. But people who think we should use less energy, that energy usage is a moral bad. No, no. You are asking, you are diminishing humanity.
Lex Fridman

(03:00:54)
Yeah. Energy is flourishing. Creative flourishing of the human species.
George Hotz

(03:00:59)
How do we make more of it? How do we make it clean? And how do we make… How I pay 20 cents for a megawatt hour instead of a kilowatt hour?
Lex Fridman

(03:01:08)
Part of me wishes that Elon went into nuclear fusion versus Twitter, part of me. Or somebody like Elon.
George Hotz

(03:01:20)
I wish there were more Elons in the world. And I think Elon sees it as this is a political battle that needed to be fought. And again, I always ask the question of whenever I disagree with him, I remind myself that he is a billionaire and I’m not. So maybe he’s got something figured out that I don’t, or maybe he doesn’t
Lex Fridman

(03:01:38)
To have some humility. But at the same time, me as a person who happens to know him, I find myself in that same position. And sometimes even billionaires need friends who disagree and help them grow. And that’s a difficult reality.
George Hotz

(03:01:57)
And it must be so hard. It must be so hard to meet people once you get to that point where-
Lex Fridman

(03:02:02)
Fame, power, money, everybody’s sucking up to you.
George Hotz

(03:02:05)
See, I love not having shit. I don’t have shit man. Trust me. There’s nothing I can give you. There’s nothing worth taking from me.
Lex Fridman

(03:02:12)
Yeah. It takes a really special human being, when you have power, when you have fame, when you have money, to still think from first principles. Not all the adoration you get towards you, all the admiration, all the people saying, “Yes, yes, yes.”
George Hotz

(03:02:26)
And all the hate too.
Lex Fridman

(03:02:29)
And the hate-
George Hotz

(03:02:29)
I think that’s worse.
Lex Fridman

(03:02:30)
So the hate makes you want to go to the ‘yes’ people because the hate exhausts you. And the kind of hate that Elon’s gotten from the left, is pretty intense. And so that, of course, drives him right, and loses balance, and-
George Hotz

(03:02:46)
And it keeps this absolutely fake siop political divide alive, so that the 1% can keep power.
Lex Fridman

(03:02:56)
I wish we would be less divided because it is giving powr-
George Hotz

(03:02:59)
It gives power-
Lex Fridman

(03:02:59)
To the ultra powerful.
George Hotz

(03:03:01)
I know.
Lex Fridman

(03:03:02)
The rich get richer. You have love in your life. Has love made you a better or a worse programmer? Do you keep productivity metrics?
George Hotz

(03:03:13)
No, no, no. I’m not that methodical. I think there comes to a point where, if it’s no longer visceral, I just can’t enjoy it. I guess still, viscerally, love programming. The minute I started-
Lex Fridman

(03:03:29)
So that’s one of the big loves of your life, is programming?
George Hotz

(03:03:33)
I mean, just my computer in general. I mean, I tell my girlfriend, “My first love is my computer,” of course. I sleep with my computer. It’s there for a lot of my sexual experiences. Come on. So is everyone’s right. You got to be real about that. And-
Lex Fridman

(03:03:48)
Not just the ID for programming, just the entirety of the computational machine?
George Hotz

(03:03:53)
The fact that… Yeah. I wish it was a.. And someday they’ll be smarter, and someday [inaudible 03:03:59]. Maybe I’m weird for this, but I don’t discriminate, man. I’m not going to discriminate BioStack life in Silicon Stack life.
Lex Fridman

(03:04:04)
So the moment the computer starts to say, “I miss you,” and starts to have some of the basics of human intimacy, it’s over for you. The moment VS Code says, “Hey, George…”
George Hotz

(03:04:16)
No, no, no, but VS Code is… No, Microsoft’s doing that to try to get me hooked on it. I’ll see through it. I’ll see through it. It’s gold digger, man. It’s gold digger.
Lex Fridman

(03:04:26)
Well, it can be an open source thing.
George Hotz

(03:04:27)
Well, this just gets more interesting, right. If it’s open source, then yeah, it becomes-
Lex Fridman

(03:04:31)
Though, Microsoft’s done a pretty good job on that.
George Hotz

(03:04:33)
Oh, absolutely. No, no, no. Look, I think Microsoft… Again, I wouldn’t count on it to be true forever, but I think right now, Microsoft is doing the best work in the programming world, between GitHub, GitHub Actions VS Code, the improvements to Python, it was Microsoft.This is-
Lex Fridman

(03:04:51)
Who would’ve thought, Microsoft and Mark Zuckerberg are spearheading the open source movement.
George Hotz

(03:04:57)
Right? Right? How things change.
Lex Fridman

(03:05:01)
Oh, it’s beautiful.
George Hotz

(03:05:03)
And by the way, that’s who I bet on to replace Google, by the way.
Lex Fridman

(03:05:06)
Who?
George Hotz

(03:05:06)
Microsoft.
Lex Fridman

(03:05:07)
Microsoft.
George Hotz

(03:05:08)
I think Satya Nadella said straight up, “I’m coming for it.”
Lex Fridman

(03:05:11)
Interesting. So your bet, who wins AGI? That’s [inaudible 03:05:16]-
George Hotz

(03:05:15)
I don’t know about AGI. I think we’re a long way away from that. But I would not be surprised, if in the next five years, Bing overtakes Google as a search engine.
Lex Fridman

(03:05:24)
Interesting.
George Hotz

(03:05:25)
Wouldn’t surprise me.
Lex Fridman

(03:05:26)
Interesting. I hope some startup does.
George Hotz

(03:05:33)
It might be some startup too. I would equally bet on some startup.
Lex Fridman

(03:05:37)
Yeah. I’m like 50 50. But maybe that’s naive. I believe in the power of these language models.
George Hotz

(03:05:43)
Satya is alive. Microsoft’s alive.
Lex Fridman

(03:05:45)
Yeah, it’s great. It’s great. I like all the innovation in these companies. They’re not being stale, and to the degree they’re being stale, they’re losing. So there’s a huge incentive to do a lot of exciting work and open source work, this is incredible.
George Hotz

(03:06:01)
Only way to win.
Meaning of life
Lex Fridman

(03:06:02)
You’re older, you’re wiser. What’s the meaning of life, George Hotz?
George Hotz

(03:06:08)
To win.
Lex Fridman

(03:06:09)
It’s still to win?
George Hotz

(03:06:10)
Of course.
Lex Fridman

(03:06:12)
Always?
George Hotz

(03:06:13)
Of course.
Lex Fridman

(03:06:14)
What’s winning look like for you?
George Hotz

(03:06:17)
I don’t know. I haven’t figured out what the game is yet, but when I do, I want to win-
Lex Fridman

(03:06:19)
So it’s bigger than solving self-driving? It’s bigger than democratizing, decentralizing and compute?
George Hotz

(03:06:29)
I think the game is to stand eye to eye with God.
Lex Fridman

(03:06:33)
I wonder what that means for you. At the end of your life, what that would look like.
George Hotz

(03:06:41)
I mean, this is what… I don’t know. There’s probably some ego trip of mine. “You want to stand eye to eye with God. You’re just blasphemous, man.” Okay. I don’t know. I don’t know. I don’t know. I don’t know if it would upset God. I think he wants that. I mean, I certainly want that from my creations. I want my creations to stand eye to eye with me. So why wouldn’t God want me to stand eye to eye with him? That’s the best I can do, golden rule.
Lex Fridman

(03:07:11)
I’m just imagining the creator of a video game, having to look, stand eye to eye, with one of the characters.
George Hotz

(03:07:22)
I only watched season one of Westworld. But yeah, we got to find the maze and solve it.
Lex Fridman

(03:07:27)
Yeah. I wonder what that looks like. It feels like a really special time in human history, where that’s actually possible. There’s something about AI that’s… we’re playing with something weird here. Something really weird.
George Hotz

(03:07:41)
I wrote a blog post, “I reread Genesis and just looked like… they give you some clues at the end of Genesis for finding the Garden of Eden. And I’m interested. I’m interested.”
Lex Fridman

(03:07:54)
Well, I hope you find just that, George, you’re one of my favorite people. Thank you for doing everything you’re doing and in this case, for fighting for open source or for decentralization of AI. It’s a fight worth fighting, fight worth winning, hashtag. I love you, brother. These conversations are always great. Hope to talk to you many more times. Good luck with Tiny Corp.
George Hotz

(03:08:15)
Thank you. Great to be here.
Lex Fridman

(03:08:17)
Thanks for listening to this conversation with George Hotz. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from Albert Einstein, “Everything should be made as simple as possible, but not simpler.” Thank you for listening and hope to see you next time.
Transcript for Jimmy Wales: Wikipedia | Lex Fridman Podcast #385
This is a transcript of Lex Fridman Podcast #385 with Jimmy Wales.
The timestamps in the transcript are clickable links that take you directly to that point in
the main video. Please note that the transcript is human generated, and may have errors.
Here are some useful links:
Go back to this episode’s main page
Watch the full YouTube version of the podcast
Table of Contents
Here are the loose “chapters” in the conversation.
Click link to jump approximately to that part in the transcript:
0:00 – Introduction
0:47 – Origin story of Wikipedia
6:51 – Design of Wikipedia
13:44 – Number of articles on Wikipedia
19:55 – Wikipedia pages for living persons
40:48 – ChatGPT
54:19 – Wikipedia’s political bias
1:00:23 – Conspiracy theories
1:13:28 – Facebook
1:21:46 – Twitter
1:42:22 – Building Wikipedia
1:56:55 – Wikipedia funding
2:08:15 – ChatGPT vs Wikipedia
2:12:56 – Larry Sanger
2:18:28 – Twitter files
2:21:20 – Government and censorship
2:35:44 – Adolf Hitler’s Wikipedia page
2:47:26 – Future of Wikipedia
2:59:29 – Advice for young people
3:06:50 – Meaning of life

Introduction
Jimmy Wales

(00:00:00)
We’ve never bowed down to government pressure anywhere in the world, and we never will. We understand that we’re hardcore, and actually, there is a bit of nuance about how different companies respond to this, but our response has always been just to say no. If they threaten to block, well, knock yourself out. You’re going to lose Wikipedia.
Lex Fridman

(00:00:21)
The following is a conversation with Jimmy Wales, co-founder of Wikipedia, one of, if not the most impactful websites ever, expanding the collective knowledge, intelligence, and wisdom of human civilization. This is Lex Fridman podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Jimmy Wales.
Origin story of Wikipedia
Lex Fridman

(00:00:47)
Let’s start at the beginning. What is the origin story of Wikipedia?
Jimmy Wales

(00:00:51)
The origin story of Wikipedia, well, so I was watching the growth of the free software movement, open-source software, and seeing programmers coming together to collaborate in new ways, sharing code, doing that under free license, which is really interesting because it empowers an ability to work together. That’s really hard to do if the code is still proprietary, because then if I chip in and help, we have to figure out how I’m going to be rewarded and what that is. But the idea that everyone can copy it and it just is part of the commons really empowered a huge wave of creative software production. I realized that that kind of collaboration could extend beyond just software to all kinds of cultural works.

(00:01:38)
The first thing that I thought of was an encyclopedia and thought, “Oh, that seems obvious that an encyclopedia, you can collaborate on it.” There’s a few reasons why. One, we all pretty much know what an encyclopedia entry on say, the Eiffel Tower should be like. You should see a picture, a few pictures, maybe, history, location, something about the architect, et cetera, et cetera. So we have a shared understanding of what it is we’re trying to do, and then we can collaborate and different people can chip in and find sources and so on and so forth. So set up first Nupedia, which was about two years before Wikipedia.

(00:02:18)
With Nupedia, we had this idea that in order to be respected, we had to be even more academic than a traditional encyclopedia because a bunch of volunteers on the internet getting it right out of an encyclopedia, you could be made fun of if it’s just every random person. So we had implemented this seven-stage review process to get anything published, and two things came of that. So one thing, one of the earliest entries that we published after this rigorous process, a few days later, we had to pull it because as soon as it hit the web and the broader community took a look at it, people noticed plagiarism and realized that it wasn’t actually that good, even though it had been reviewed by academics and so on. So we had to pull it. So it’s like, “Oh, okay. Well, so much for a seven-stage review process.”

(00:03:07)
I was frustrated, “Why is this taking so long? Why is it so hard?” So I thought, “Okay.” I saw that Robert Merton had won a Nobel Prize in economics for his work on option pricing theory. When I was in academia, that’s what I worked on was option pricing theory, had a published paper. So I’d worked through all of his academic papers, and I knew his work quite well. I thought, “Oh, I’ll write a short biography of Merton.” When I started to do it, I’d been out of academia, I hadn’t been a grad student for a few years then. I felt this huge intimidation because they were going to take my draft and send it to the most prestigious finance professors that we could find to give me feedback for revisions. It felt like being back in grad school. It’s like this really oppressive, like, you’re going to submit it for a review and you’re going to get critiques.
Lex Fridman

(00:03:59)
A little bit of the bad part of grad school.
Jimmy Wales

(00:04:01)
Yeah, yeah, the bad part of grad school. So I was like, “Oh, this isn’t intellectually fun, this is like the bad part of grad school. It’s intimidating, and there’s a lot of potential embarrassment if I screw something up and so forth.” So that was when I realized, “Okay, look, this is never going to work. This is not something that people are really going to want to do.” So Jeremy Rosenfeld, one of my employees had brought and showed me the Wiki concept in December, and then Larry Sanger brought in the same, said, “What about this Wiki idea?” So in January, we decided to launch Wikipedia, but we weren’t sure. So the original project was called Nupedia. Even though it wasn’t successful, we did have quite a group of academics and really serious people.

(00:04:45)
We were concerned that, “Oh, maybe these academics are going to really hate this idea, and we shouldn’t just convert the project immediately. We should launch this as a side project, the idea of here’s a Wiki where we can start playing around.” But actually, we got more work done in two weeks than we had in almost two years because people were able to just jump on and start doing stuff, and it was actually a very exciting time. Back then, you could be the first person who typed Africa as a continent and hit Save, which isn’t much of an encyclopedia entry, but it’s true, and it’s a start and it’s kind of fun, like put your name down.

(00:05:20)
Actually, a funny story was several years later, I just happened to be online and I saw when, I think his name is Robert Aumann, won the Nobel Prize in economics. We didn’t have an entry on him at all, which was surprising, but it wasn’t that surprising. This was still early days. So I got to be the first person to type Robert Aumann, won Nobel Prize in economics and hit Save, which again, wasn’t a very good article. But then I came back two days later and people had improved it and so forth. So that second half of the experience where with Robert Merton, I never succeeded because it was just too intimidating. It was like, “Oh, no, I was able to chip in and help, other people jumped in. Everybody was interested in the topic, because it’s all in the news at the moment.” So it’s just a completely different model, which worked much, much better.
Lex Fridman

(00:06:03)
Well, what is it that made that so accessible, so fun, so natural to just add something?
Jimmy Wales

(00:06:09)
Well, I think, especially in the early days, and this, by the way, has gotten much harder because there are fewer topics that are just greenfield available. But you could say, “Oh, well, I know a little bit about this, and I can get it started.” But then it is fun to come back then and see other people have added and improved and so on and so forth. That idea of collaborating where people can, much like open-source software, you put your code out and then people suggest revisions. They change it, and it modifies and it grows beyond the original creator, it’s just a fun, wonderful, quite geeky hobby, but people enjoy it.
Design of Wikipedia
Lex Fridman

(00:06:51)
How much debate was there over the interface, over the details of how to make that, seamless and frictionless?
Jimmy Wales

(00:06:57)
Yeah, not as much as there probably should have been, in a way. During that two years of the failure of Nupedia where very little work got done, what was actually productive was, there was a huge long discussion; email discussion, very clever people talking about things like neutrality, talking about what is an encyclopedia, but also talking about more technical ideas. Back then, XML was all the rage and thinking about shouldn’t you have certain data that might be in multiple articles that gets updated automatically? So for example, the population of New York City, every 10 years there’s a new official census, couldn’t you just update that bit of data in one place and it would update across all languages? That is a reality today. But back then it was just like, “Hmm, how do we do that? How do we think about that?”
Lex Fridman

(00:07:47)
So that is a reality today where it’s-
Jimmy Wales

(00:07:48)
Yeah-
Lex Fridman

(00:07:49)
… there’s some-
Jimmy Wales

(00:07:50)
Yeah, so Wikidata-
Lex Fridman

(00:07:50)
… universal variables? Wikidata.
Jimmy Wales

(00:07:56)
Yeah, Wikidata. From a Wikipedia entry, you can link to that piece of data in Wikidata, and it’s a pretty advanced thing, but there are advanced users who are doing that. Then when that gets updated, it updates in all the languages where you’ve done that.
Lex Fridman

(00:08:07)
That’s really interesting. There was this chain of emails in the early days of discussing the details of what is. So there’s the interface, there’s the-
Jimmy Wales

(00:08:14)
Yeah, so the interface, so an example, there was some software called UseModWiki, which we started with. It’s quite amusing actually, because the main reason we launched with UseModWiki is that it was a single Perl script, so it was really easy for me to install it on the server and just get running. But it was some guy’s hobby project, it was cool, but it was just a hobby project. All the data was stored in flat text files, so there was no real database behind it. So to search the site, you basically used Grab, which is just the basic Unix utility to look through all the files. So that clearly was never going to scale. But also in the early days, it didn’t have real logins. So you could set your username, but there were no passwords. So I might say Bob Smith, and then someone else comes along and says, “No, I’m Bob Smith,” and they both had it. Now that never really happened.

(00:09:10)
We didn’t have a problem with it, but it was obvious, you can’t grow a big website where everybody can pretend to be everybody. That’s not going to be good for trust and reputation and so forth. So quickly, I had to write a little login, store people’s passwords and things like that so you could have unique identities. Then another example of something you would’ve never thought would’ve been a good idea, and it turned out to not be a problem. But to make a link in Wikipedia in the early days, you would make a link to a page that may or may not exist by just using CamelCase, meaning it’s like upper case, lowercase, and you smash the words together. So maybe New York City, you might type N-E-W, no space, capital Y, York City, and that would make a link, but that was ugly. That was clearly not right. So I was like, “Okay, well that’s just not going to look nice. Let’s just use square brackets, two square brackets makes a link.”

(00:10:04)
That may have been an option in the software. I’m not sure I thought up square brackets. But anyway, we just did that, which worked really well. It makes nice links and you can see in its red links or blue links, depending on if the page exists or not. But the thing that didn’t occur to me even to think about is that, for example, on the German language standard keyboard, there is no square bracket. So for German Wikipedia to succeed, people had to learn to do some alt codes to get the square bracket, or a lot of users cut and paste a square bracket where they could find one and they would just cut and paste one in. Yet. German Wikipedia has been a massive success, so somehow that didn’t slow people down.
Lex Fridman

(00:10:40)
How is that that the German keyboards don’t have a square bracket. How do you do programming? How do you live life to its fullest without square brackets?
Jimmy Wales

(00:10:48)
It’s a very good question. I’m not really sure. Maybe it does now because keyboard standards have drifted over time and becomes useful to have a certain character. It’s same thing, there’s not really a W character in Italian, and it wasn’t on keyboards or I think it is now. But in general, W is not a letter in Italian language, but it appears in enough international words that it’s crept into Italian.
Lex Fridman

(00:11:12)
All of these things are probably Wikipedia articles in themselves.
Jimmy Wales

(00:11:17)
Oh, yes. Oh, yeah.
Lex Fridman

(00:11:17)
The discussion of square brackets-
Jimmy Wales

(00:11:17)
That is a whole-
Lex Fridman

(00:11:17)
… in German-
Jimmy Wales

(00:11:19)
… whole discussion, I’m sure.
Lex Fridman

(00:11:20)
… on both the English and the German Wikipedia. The difference between those two might be very-
Jimmy Wales

(00:11:27)
Interesting.
Lex Fridman

(00:11:27)
… interesting. So Wikidata is fascinating, but even the broader discussion of what is an encyclopedia, can you go to that philosophical question of-
Jimmy Wales

(00:11:37)
Sure.
Lex Fridman

(00:11:37)
… what is an encyclopedia?
Jimmy Wales

(00:11:39)
What is an encyclopedia? So the way I would put it is an encyclopedia, or what our goal is is the sum of all human knowledge, but sum meaning summary. This was an early debate. Somebody started uploading the full text of Hamlet, for example, and we said, “Mmm, wait, hold on a second. That’s not an encyclopedia article, but why not?” So hence was born Wikisource, which is where you put original texts and things like that, out of copyright text, because they said, “No, an encyclopedia article about Hamlet, that’s a perfectly valid thing. But the actual text of the play is not an encyclopedia article. “So most of it’s fairly obvious, but there are some interesting quirks and differences. So for example, as I understand it, in French language encyclopedias, traditionally it would be quite common to have recipes, which in English language that would be unusual. You wouldn’t find a recipe for chocolate cake in Britannica. So I actually don’t know the current state, haven’t thought about that in many, many years now.
Lex Fridman

(00:12:44)
State of cake recipes in Wikipedia, in English, Wikipedia?
Jimmy Wales

(00:12:47)
I wouldn’t say there’s chocolate cake recipes. You might find a sample recipe somewhere. I’m not saying there are none, but in general, no, we wouldn’t have recipes-
Lex Fridman

(00:12:55)
I told myself I would not get outraged in this conversation, but now I’m outraged. I’m deeply upset.
Jimmy Wales

(00:13:00)
It’s actually very complicated. I love to cook. I’m actually quite a good cook. What’s interesting is it’s very hard to have a neutral recipe because [inaudible 00:13:12]
Lex Fridman

(00:13:12)
Like a canonical recipe for cake-
Jimmy Wales

(00:13:13)
A canonical recipe is-
Lex Fridman

(00:13:14)
… chocolate cake.
Jimmy Wales

(00:13:15)
… is kind of difficult to come by because there’s so many variants and it’s all debatable and interesting. For something like chocolate cake, you could probably say, “Here’s one of the earliest recipes,” or, “Here’s one of the most common recipes.” But for many, many things, the variants are as interesting as somebody said to me recently, 10 Spaniards, 12 paella recipes. So these are all matters of open discussion.
Number of articles on Wikipedia
Lex Fridman

(00:13:44)
Well, just to throw some numbers, as of May 27, 2023, there are 6.6 million articles in the English Wikipedia containing over 4.3 billion words. Including articles, the total number of pages is 58 million.
Jimmy Wales

(00:14:05)
Yeah.
Lex Fridman

(00:14:06)
Does that blow your mind?
Jimmy Wales

(00:14:08)
Yes, it does. It doesn’t, because I know those numbers and see them from time to time. But in another sense, a deeper sense, yeah, it does. It’s really remarkable. I remember when English Wikipedia passed 100,000 articles and when German Wikipedia passed 100,000, ’cause I happened to be in Germany with a bunch of Wikipedians that night, and then it seemed quite big. We knew at that time that it was nowhere near complete. I remember at Wikimania in Harvard when we did our annual conference there in Boston, someone who had come to the conference from Poland had brought along with him a small encyclopedia, a single volume encyclopedia of biographies, so short biographies, normally a paragraph or so about famous people in Poland, and there were some 22,000 entries. He pointed out that even then, 2006, Wikipedia felt quite big.

(00:15:12)
He said in English Wikipedia, there’s only a handful of these, less than 10%, I think he said. So then you realized, yeah, actually, who was the mayor of Warsaw in 1873? Don’t know. Probably not in English Wikipedia, but it probably might be today, but there’s so much out there. Of course, what we get into when we’re talking about how many entries there are and how many could there be, is this very deep philosophical issue of notability, which is the question of, well, how do you draw the limit? How do you draw what is there? So sometimes people say, “Oh, there should be no limit.” But I think that doesn’t stand up to much scrutiny if you really pause and think about it. So I see in your hand there you’ve got a BIC pen, pretty standard. Everybody’s seen billions of those in life.
Lex Fridman

(00:16:05)
Classic though.
Jimmy Wales

(00:16:05)
It’s a classic, clear, BIC pen. So could we have an entry about that BIC pen aisle? I bet we do, that type of BIC pen because it’s classic. Everybody knows it, and it’s got a history. Actually, there’s something interesting about the BIC company. They make pens, they also make kayaks, and there’s something else they’re famous for. Basically, they’re a definition by non-essentials company. Anything that’s long and plastic, that’s what they make.
Lex Fridman

(00:16:33)
Wow, that’s very-
Jimmy Wales

(00:16:34)
If you want to find the common ground-
Lex Fridman

(00:16:36)
… platonic form, the platonic form of a BIC.
Jimmy Wales

(00:16:37)
But could we have an article about that very BIC pen in your hand, so Lex Fridman’s BIC pen as of this week?
Lex Fridman

(00:16:45)
Oh, the very, this instance-
Jimmy Wales

(00:16:45)
The very specific instance, and the answer is no, there’s not much known about it. I dare say, unless it’s very special to you and your great-grandmother gave it to you or something, you probably know very little about it. It’s a pen. It’s just here in the office. So that’s just to show there is a limit. In German Wikipedia, they used to talk about the rear nut of the wheel of [inaudible 00:17:10] bicycle [inaudible 00:17:11] a well-known Wikipedian of the time, to sort of illustrate, you can’t have an article about literally everything. So then it raises the question, what can you have an article about? What can’t you? That can vary depending on the subject matter. One of the areas where we try to be much more careful would be biographies. The reason is a biography of a living person, if you get it wrong, you can actually be quite hurtful, quite damaging.

(00:17:38)
So if someone is a private person and somebody tries to create a Wikipedia entry, there’s no way to update it. There’s not much done. So for example, an encyclopedia article about my mother, my mother, school teacher later, a pharmacist, wonderful woman, but never been in the news, other than me talking about why there shouldn’t be a Wikipedia entry, that’s probably made it in somewhere, standard example. But there’s not enough known. You could imagine a database of genealogy having date of birth, date of death, certain elements like that of private people. But you couldn’t really write a biography. One of the areas this comes up quite often is what we call BLP1E. We’ve got lots of acronyms. Biography of a living person who’s notable for only one event is a real danger zone.
Lex Fridman

(00:18:27)
Oh.
Jimmy Wales

(00:18:28)
The type of example would be a victim of a crime, so someone who’s a victim of a famous serial killer, but about whom really not much is known. They weren’t a public person, they’re just a victim of a crime, we really shouldn’t have an article about that person. They’ll be mentioned, of course, and maybe this specific crime might have an article. But for that person, no, not really. That’s not really something that makes any sense because how can you write a biography about someone you don’t know much about? It varies from field to field. So for example, for many academics, we will have an entry that we might not have in a different context because for an academic, it’s important to have sort of their career, what papers they’ve published, things like that.

(00:19:13)
You may not know anything about their personal life, but that’s actually not encyclopedically relevant in the same way that it is for member of a royal family where it’s basically all about the family. So we’re fairly nuanced about notability and where it comes in. I’ve always thought that the term notability, I think, is a little problematic. We struggled about how to talk about it. The problem with notability is it can feel insulting. Say, “Oh no, you’re not noteworthy.” Well, my mother’s noteworthy. She’s a really important person in my life, so that’s not right. But it’s more like verifiability. Is there a way to get information that actually makes an encyclopedia entry?
Wikipedia pages for living persons
Lex Fridman

(00:19:56)
It so happens that there’s a Wikipedia page about me as I’ve learned recently, and the first thought I had when I saw that was, “Surely I am not notable enough.” So I was very surprised and grateful that such a page could exist and actually, just allow me to say thank you to all the incredible people that are part of creating and maintaining Wikipedia. It’s my favorite website on the internet. The collection of articles that Wikipedia has created is just incredible. We’ll talk about the various details of that. But the love and care that goes into creating pages for individuals, for a BIC pen, for all this kind of stuff is just really incredible.

(00:20:43)
So I just felt the love when I saw that page. But I also felt just because I do this podcast and I just through this podcast, gotten to know a few individuals that are quite controversial, I’ve gotten to be on the receiving end of something quite … to me as a person who loves other human beings, I’ve gotten to be at the receiving end of some attacks through Wikipedia. Like you said, when you look at living individuals, it can be quite hurtful, the little details of information. Because I’ve become friends with Elon Musk and I’ve interviewed him, but I’ve also interviewed people on the left, far left, people on the right, some would say far right, and so now you take a step, you put your toe into the cold pool of politics and the shark emerges from the depths and pulls you right in.
Jimmy Wales

(00:21:41)
Yeah, the boiling hot pool of politics.
Lex Fridman

(00:21:43)
I guess it’s hot, and so I got to experience some of that. I think what you also realize is there has to be, for Wikipedia credible sources, verifiable sources, and there’s a dance there because some of the sources are pieces of journalism. Of course, journalism operates under its own complicated incentives such that people can write articles that are not factual or are cherry-picking all the flaws they can have in a journalistic article-
Jimmy Wales

(00:22:18)
For sure.
Lex Fridman

(00:22:18)
… and those can be used as-
Jimmy Wales

(00:22:20)
For sure.
Lex Fridman

(00:22:21)
… as sources. It’s like they dance hand-in-hand. So for me, sadly enough, there was a really concerted attack to say that I was never at MIT, never did anything at MIT. Just to clarify, I am a research scientist at MIT. I have been there since 2015. I’m there today. I’m at a prestigious, amazing laboratory called LIDS, and I hope to be there for a long time. I work on AI, robotics, machine learning. There’s a lot of incredible people there. By the way, MIT has been very kind to defend me. Unlike Wikipedia says, it is not an unpaid position. There was no controversy.
Jimmy Wales

(00:23:03)
Right.
Lex Fridman

(00:23:03)
It was all very calm and happy and almost boring research that I’ve been doing there. The other thing, because I am half-Ukrainian, half-Russian-
Jimmy Wales

(00:23:14)
Oh.
Lex Fridman

(00:23:15)
… and I’ve traveled to Ukraine and I will travel to Ukraine again, and I will travel to Russia for some very difficult conversations. My heart’s been broken by this war. I have family in both places. It’s been a really difficult time. But the little battle about the biography there also starts becoming important for the first time for me. I also want to clarify personally, I use this opportunity of some inaccuracies there. My father was not born in Chkalovsk, Russia. He was born in Kiev, Ukraine. I was born in Chkalovsk which is a town not in Russia. There is a town called that in Russia. But there’s another town in Tajikistan, which is the former republic of the Soviet Union. That town is now called B-U-S-T-O-N, Buston, which is funny because we’re now in Austin, and I also am in Boston, it seems like my whole life is surrounded by these kinds of towns.

(00:24:13)
So I was born in Tajikistan, and the rest of the biography is interesting, but my family is very evenly distributed between their origins and where they grew up between Ukraine and Russia, which adds a whole beautiful complexity to this whole thing. So I want to just correct that. It’s like the fascinating thing about Wikipedia is in some sense, those little details don’t matter. But in another sense, what I felt when I saw a Wikipedia page about me or anybody I know is there’s this beautiful saving that this person existed, like a community that notices you that says, “Huh.” You see a butterfly that floats, and you’re like, “Huh?” That it’s not just any butterfly, it’s that one. “I like that one,” or you see a puppy or something, or it’s this BIC pen. “I remember this one, it has this scratch. You get noticed in that way and I know it’s a beautiful thing. Maybe it’s very silly of me and naive, but I feel like Wikipedia, in terms of individuals, is an opportunity to celebrate people, to celebrate ideas-
Jimmy Wales

(00:25:26)
For sure. For sure.
Lex Fridman

(00:25:26)
… and not a battleground of the kind of stuff we might see on Twitter, like the mockery, the derision, this kind of stuff.
Jimmy Wales

(00:25:35)
For sure.
Lex Fridman

(00:25:36)
Of course, you don’t want to cherry-pick. All of us have flaws and so on, but it just feels like to highlight a controversy of some sort, when that doesn’t at all represent the entirety of the human, in most cases, is sad.
Jimmy Wales

(00:25:50)
Yeah. Yeah. Yeah. So there’s a few to unpack and all that. So first, one of the things I find really, always find very interesting is your status with MIT. Okay, that’s upsetting, and it’s an argument and can be sorted out. But then what’s interesting is you gave as much time to that, which is actually important and relevant to your career and so on to also where your father was born, which most people would hardly notice, but is really meaningful to you. I find that a lot when I talk to people who have a biography in Wikipedia is they’re often as annoyed by a tinier that no one’s going to notice like this town in Tajikistan’s got a new name and so on. Nobody even knows what that means or whatever, but it can be super important. So that’s one of the reasons for biographies, we say human dignity really matters. So some of the things have to do with, and this is a common debate that goes on in Wikipedia, is what we call undue weight. So I’ll give an example.

(00:26:59)
There was a article I stumbled across many years ago about the mayor, or no, he wasn’t a mayor, he was a city council member of, I think it was Peoria, Illinois, but some small town in the Midwest. The entry, he’s been on the city council for 30 years or whatever. He’s frankly, a pretty boring guy and seems like a good local city politician. But in this very short biography, there was a whole paragraph, a long paragraph about his son being arrested for DUI, and it was clearly undue weight. It’s like, “What has this got to do with this guy if it even deserves a mention?” It wasn’t even clear had he done anything hypocritical, had he done himself anything wrong, even was his son, his son got a DUI.

(00:27:44)
That’s never great, but it happens to people, and it doesn’t seem like a massive scandal for your dad. So of course, I just took that out immediately. This is a long, long time ago. That’s the sort of thing where we have to really think about in a biography and about controversies to say, “Is this a real controversy?” So in general, one of the things we tend to say is any section, so if there’s a biography and there’s a section called controversies, that’s actually poor practice because it just invites people to say, “Oh, I want to work on this entry.” It’s either seven sections. “Oh, this one’s quite short. Can I add something?”
Lex Fridman

(00:28:23)
Right?
Jimmy Wales

(00:28:24)
Go out and find some more controversies. Now that’s nonsense, right?
Lex Fridman

(00:28:24)
Yeah.
Jimmy Wales

(00:28:26)
In general, putting it separate from everything else makes it seem worse, and also, it doesn’t put it in the right context. Whereas, if it’s a live flaw and there is a controversy, there’s always potential controversy for anyone, it should just be worked into the overall article, ’cause then it doesn’t become a temptation. You can contextualize appropriately and so forth. So that’s part of the whole process. But I think for me, one of the most important things is what I call community health. So yeah, are we going to get it wrong sometimes? Yeah, of course. We’re humans and doing good, quality reference material is hard. The real question is, how do people react to a criticism or a complaint or a concern? If the reaction is defensiveness or combativeness back, or if someone’s really in there being aggressive and in the wrong, like, “No, no, no, hold on, we’ve got to do this the right way.” You got to say, “Okay, hold on. Are there good sources? Is this contextualized appropriately? Is it even important enough to mention? What does it mean?”

(00:29:40)
Sometimes one of the areas where I do think there is a very complicated flaw, and you’ve alluded to it a little bit, but it’s like we know the media is deeply flawed. We know that journalism can go wrong. I would say particularly in the last whatever, 15 years, we’ve seen a real decimation of local media, local newspapers. We’ve seen a real rise in clickbait headlines and eager focus on anything that might be controversial. We’ve always had that with us, of course, there’s always been tabloid newspapers. But that makes it a little bit more challenging to say, “Okay, how do we sort things out when we have a pretty good sense that not every source is valid?” So as an example, a few years ago, it’s been quite a while now, we deprecated the MailOnline as a source and the MailOnline, the digital arm of the Daily Mail, it’s a tabloid.

(00:30:46)
It’s not fake news, but it does tend to run very hyped-up stories. They really love to attack people and go on the attack for political reasons and so on, and it just isn’t great. So by saying deprecated, and I think some people say, “Oh, you banned the Daily Mail? No, we didn’t ban it as a source. We just said, “Look, it’s probably not a great source. You should probably look for a better source.” So certainly if the Daily Mail runs a headline saying, “New Cure for Cancer,” it’s like probably there’s more serious sources than a tabloid newspaper. So in an article about lung cancer, you probably wouldn’t cite the Daily Mail. That’s kind of ridiculous. But also for celebrities and so forth to know, “Oh, well, they do cover celebrity gossip a lot, but they also tend to have vendettas and so forth.” You really have to step back and go, “Is this really encyclopedic or is this just the Daily Mail going on a rant?”
Lex Fridman

(00:31:39)
Some of that requires a great community health.
Jimmy Wales

(00:31:41)
It requires massive community health.
Lex Fridman

(00:31:43)
Even for me, for stuff I’ve seen that’s kind of, if actually iffy about people I know, things I know about myself, I still feel like a love for knowledge emanating from the article. I feel the community health, so I will take all slight inaccuracies. I love it because that means there’s people, for the most part, I feel of respect and love in this search for knowledge. Sometimes, ’cause I also love Stack Overflow and Stack Exchange for programming-related things. They can get a little cranky sometimes to a degree where it’s like it’s not as … you could could feel the dynamics of the health of the particular community and sub communities too, like a particular C Sharp or Java or Python or whatever, there’s little communities that emerge. You can feel the levels of toxicity, ’cause a little bit of strictness is good, but a little too much is bad because of the defensiveness, ’cause when somebody writes an answer and then somebody else says, “We’ll modify it,” and then get defensive, and there’s this tension that’s not conducive to improving towards a more truthful depiction of that topic.
Jimmy Wales

(00:33:02)
Yeah, a great example-
Lex Fridman

(00:33:00)
… truthful depiction of that topic.
Jimmy Wales

(00:33:02)
Yeah, a great example that I really loved this morning that I saw someone left a note on my user talk page in English Wikipedia saying it was quite a dramatic headline saying racist hook on front page. So we have on the front page of Wikipedia, we have little section called Did You know? And it’s just little tidbits and facts, just things people find interesting. And there’s a whole process for how things get there. And the one that somebody was raising a question about was, it was comparing a very well known US football player, Black. There was a quote from another famous sport person comparing him to a Lamborghini. Clearly a compliment. And so somebody said, “Actually, here’s a study, here’s some interesting information about how Black sports people are far more often compared to inanimate objects. And given that kind of analogy, and I think it’s demeaning to compare a person to a car, et cetera, cetera.”

(00:34:01)
But they said, “I’m not pulling, I’m not deleting it, I’m not removing it. I just want to raise the question.” And then there’s this really interesting conversation that goes on where I think the general consensus was, you know what, this isn’t like the alarming headline racist thing on the front page of Wikipedia, holy moly, that sounds bad. But it’s sort of like, actually yeah this probably isn’t the sort of analogy that we think is great. And so we should probably think about how to improve our language and not compare sports people to inanimate objects and particularly be aware of certain racial sensitivities that there might be around that sort of thing if there is a disparity in the media of how people are called.

(00:34:40)
And I just thought, you know what, nothing for me to weigh in on here. This is a good conversation. Like nobody’s saying people should be banned if they refer to, what was his name, The Fridge, Refrigerator Perry. Very famous comparison to an inanimate object of a Chicago Bears player, many years ago. But they’re just saying, hey, let’s be careful about analogies that we just pick up from the media. I said, “Yeah, that’s good.”
Lex Fridman

(00:35:06)
On the deprecation of news sources is really interesting because I think what you’re saying is ultimately you want to make a article by article decision, use your own judgment. And it’s such a subtle thing because there’s just a lot of hit pieces written about individuals like myself for example, that masquerade as an objective thorough exploration of a human being. It’s fascinating to watch because controversy and hit pieces just get more clicks.
Jimmy Wales

(00:35:41)
Oh yeah, sure.
Lex Fridman

(00:35:41)
This is, I guess, as a Wikipedia contributor, you start to deeply become aware of that and start to have a sense, a radar of clickbait versus truth to pick out the truth from the clickbaity type language.
Jimmy Wales

(00:35:58)
Oh, yeah. I mean it’s really important and we talk a lot about weasel words. And actually I’m sure we’ll end up talking about AI and ChatGPT.
Lex Fridman

(00:36:10)
Yes.
Jimmy Wales

(00:36:10)
But just to quickly mention in this area, I think one of the potentially powerful tool, because it is quite good at this, I’ve played around with and practiced it quite a lot, but ChatGPT-4 is really quite able to take a passage and point out potentially biased terms, to rewrite it to be more neutral. Now it is a bit anodyne and it’s a bit cliched, so sometimes it just takes the spirit out of something that’s actually not bad. It’s just like poetic language and you’re like, okay, that’s not actually helping. But in many cases I think that sort of thing is quite interesting. And I’m also interested in… Can you imagine where you feed in a Wikipedia entry and all the sources and you say, help me find anything in the article that is not accurately reflecting what’s in the sources? And that doesn’t have to be perfect. It only has to be good enough to be useful to community.

(00:37:17)
So if it scans-
Lex Fridman

(00:37:19)
Beautiful.
Jimmy Wales

(00:37:19)
… an article and all the sources and you say, oh, it came back with 10 suggestions and seven of them were decent and three of them it just didn’t understand, well actually that’s probably worth my time to do. And it can help us really more quickly get good people to review obscure entries and things like that.
Lex Fridman

(00:37:41)
So just as a small aside on that, and we’ll probably talk about language models a little bit, or a lot more, but one of the articles, one of the hit pieces about me, the journalist actually was very straightforward and honest about having used GPT to write part of the article.
Jimmy Wales

(00:37:59)
Interesting.
Lex Fridman

(00:37:59)
And then finding that it made an error and apologized for the error, that GPT-4 generated. Which has this kind of interesting loop, which is the articles are used to write Wikipedia pages, GPT is trained on Wikipedia, and there there’s like this interesting loop where the weasel words and the nuances can get lost or can propagate, even though they’re not grounded in reality. Somehow in the generation of the language model, new truths can be created and kind of linger.
Jimmy Wales

(00:38:35)
Yeah, there’s a famous web comic that’s titled cytogenesis, which is about how an errors in Wikipedia and there’s no source for it, but then a lazy journalist reads it and writes the source, and then some helpful Wikipedia spots that it has no source, finds a source and adds it to Wikipedia, and voila, magic. This happened to me once it, well, it nearly happened. There was this, it was really brief. I went back and researched it, I’m like, this is really odd. So Biography Magazine, which is a magazine published by the Biography TV channel, had a pressor profile of me, and it said, “In his spare time,” I’m not quoting exactly, it’s been many years, but, “In his spare time he enjoys playing chess with friends.” I thought, wow, that sounds great. I would like to be that guy. But actually, I play chess with my kids sometimes, but no it’s not a hobby of mine.

(00:39:31)
And I was like, where did they get that? And I contacted the magazine and said, where did that come from? They said, “Oh, it was in Wikipedia.” And I looked in the history, there had been vandalism of Wikipedia, which was not damaging, it’s just false. And it had already been removed. But then I thought, “Oh gosh, well I better mention this to people because otherwise it’s somebody’s going to read that and they’re going to add it, the entry, and is going to take on a life of its own. And then sometimes I wonder if it has, because I’ve been… I was invited a few years ago to do the ceremonial first move in the world chess championship. And I thought, I wonder if they think I’m a really big chess enthusiast because they read this Biography Magazine article.

(00:40:10)
But that problem, when we think about large language models and the ability to quickly generate very plausible but not true content, I think is something that there’s going to be a lot of shakeout and a lot of implications of that.
Lex Fridman

(00:40:25)
What would be hilarious is because of the social pressure of Wikipedia and the momentum, you would actually start playing a lot more chess. Not only the articles are written based on Wikipedia, but your own life trajectory changes because of the Wikipedia, just to make it more convenient. Aspire to.
Jimmy Wales

(00:40:45)
Aspire to, yes. Yeah, aspirational.
ChatGPT
Lex Fridman

(00:40:48)
If we could just talk about that before we jump back to some other interesting topics in Wikipedia. Let’s talk about GPT-4 and large language models. So they are in part trained on Wikipedia content. What are the pros and cons of these language models? What are your thoughts?
Jimmy Wales

(00:41:07)
Yeah, so I mean, there’s a lot of stuff going on. Obviously the technology has moved very quickly in the last six months and looks poised to do so for some time to come. So first things first, part of our philosophy is the open licensing, the free licensing, the idea that this is what we’re here for. We are a volunteer community and we write this encyclopedia. We give it to the world to do what you like with, you can modify it, redistribute it, redistribute modified versions, commercially, non-commercially. This is the licensing. So in that sense, of course it’s completely fine. Now, we do worry a bit about attribution because it is a Creative Commons Attribution Share-Alike License. So attribution is important, not just because of our licensing model and things like that, but it’s just proper attribution is just good intellectual practice.

(00:42:02)
And that’s a really hard complicated question. If I were to write something about my visit here, I might say in a blog post I was in Austin, which is a city in Texas, I’m not going to put a source for Austin as a city in Texas. That’s just general knowledge. I learned it somewhere, I can’t tell you where. So you don’t have to cite and reference every single thing. But if I actually did research and I used something very heavily, it’s just proper, morally proper, to give your sources. So we would like to see that. And obviously they call it grounding. So particularly people at Google are really keen on figuring out grounding.
Lex Fridman

(00:42:48)
It’s such a cool term. So any text that’s generated trying to ground it to the Wikipedia quality-
Jimmy Wales

(00:42:57)
A source.
Lex Fridman

(00:42:57)
… a source. The same kind of standard of what a source means that Wikipedia uses, the same kind of source-
Jimmy Wales

(00:42:57)
The same kind.
Lex Fridman

(00:42:57)
… would be generated but with a graph.
Jimmy Wales

(00:43:05)
The same kind of thing. And of course, one of the biggest flaws in ChatGPT right now is that it just literally will make things up just to be amiable. I think it’s programmed to be very helpful and amiable and it doesn’t really know or care about the truth.
Lex Fridman

(00:43:21)
Can get bullied into… it can be convinced into…
Jimmy Wales

(00:43:25)
Well, but this morning, the story I was telling earlier about comparing a football player to a Lamborghini, and I thought, is that really racial? I don’t know, but I’m mulling it over. And I thought, oh, I’m going to go to ChatGPT. So I sent to ChatGPT-4, I said, “This happened in Wikipedia. Can you think of examples where a white athlete has been compared to a fast car inanimate object?” And it comes back with a very plausible essay where it tells why these analogies are common in sport, blah, blah. I said, “No, no, could you give me some specific examples?” So it gives me three specific examples, very plausible, correct names of athletes and contemporaries and all of that could have been true. Googled every single quote and none of them existed. And so I’m like, “Well, that’s really not good.”

(00:44:14)
I wanted to explore a thought process I was in. First I thought, how do I Google? And it’s like, well, it’s kind of a hard thing to Google because unless somebody’s written about this specific topic, it’s large language model, it’s processed all this data, it can probably piece that together for me, but it just can’t yet. So I think, I hope that ChatGPT 5, 6, 7, three to five years, I’m hoping we’ll see a much higher level of accuracy where when you ask a question like that, I think instead of being quite so eager to please by giving you a plausible sounding answer, it’s just like, I don’t know.
Lex Fridman

(00:44:55)
Or maybe display how much bullshit might be in this generated text. I’m really would like to make you happy right now, but I’m really stretched thin with this generation.
Jimmy Wales

(00:45:07)
Well, it’s one of the things I’ve said for a long time. So in Wikipedia, one of the great things we do may not be great for our reputation, except in a deeper sense for the long term I think it is. But we’ll all be on notice that says the neutrality of this section has been disputed or the following section doesn’t cite in these sources. And I always joke, sometimes I wish the New York Times would run a banner saying the neutrality of this has been disputed. They could give us a… We had a big fight in the newsroom as to whether to run this or not, but we thought it’s important enough to bring it to. But just be aware that not all the journalists are on board with it. Ah, that’s actually interesting, and that’s fine. I would trust them more for that level of transparency. So yeah, similarly ChatGPT should say, yeah, 87% bullshit.
Lex Fridman

(00:45:51)
Well, the neutrality one is really interesting because that’s basically a summary of the discussions that are going on underneath. It would be amazing if… I should be honest, I don’t look at the talk page often. It would be nice somehow if there was a kind of summary in this banner way of like, this, lots of wars have been fought on this here land for this here paragraph.
Jimmy Wales

(00:46:16)
That’s really interesting, I hadn’t thought of that. Because one of the things I do spend a lot of time thinking about these days, and people have found it, we’re moving slowly, but we are moving. Thinking about, okay, these tools exist, are there ways that this stuff can be useful to our community? Because a part of it is we do approach things in a non-commercial way, in a really deep sense. It’s like it’s been great, that Wikipedia has become very popular, but really we’re a community whose hobby is writing an encyclopedia. That’s first, and if it’s popular, great. If it’s not okay, we might have trouble paying for more servers, but it’ll be fine.

(00:46:53)
And so how do we help the community use these tools? One of the ways that these tools can support people, and one example I never thought about, I’m going to start playing with it, is feed in the article and feed in the talk page and say, can you suggest some warnings in the article based on the conversations in the talk page? I think it might-
Lex Fridman

(00:46:53)
That’s brilliant.
Jimmy Wales

(00:47:12)
… be good at that. It might get it wrong sometimes. But again, if it’s reasonably successful at doing that, and you can say, oh, actually, yeah, it does suggest the neutrality of this has been disputed on a section that has a seven-page discussion in the back that might be useful, don’t know, worth playing with.
Lex Fridman

(00:47:30)
Yeah, I mean some more color to the, not neutrality, but also the amount of emotion laden in the exploration of this particular part of the topic. It might actually help you look at more controversial pages, like on a page on the war in Ukraine or a page on Israel and Palestine. There could be parts that everyone agrees on and there’s parts that are just like-
Jimmy Wales

(00:47:58)
Tough.
Lex Fridman

(00:47:59)
… tough.
Jimmy Wales

(00:47:59)
The hard parts.
Lex Fridman

(00:48:00)
It would be nice to, when looking at those beautiful long articles to know, all right, let me just take in some stuff where everybody agrees on.
Jimmy Wales

(00:48:09)
I could give an example that I haven’t looked at in a long time, but I was really pleased with what I saw at the time. So the discussion was that they’re building something in Israel and for their own political reasons, one side calls it a wall hearkening back to Berlin Wall, apartheid, the other calls it a security fence. So we can understand quite quickly if we give it a moment’s thought like, okay, I understand why people would have this grappling over the language. Like, okay, you want to highlight the negative aspects of this and you want to highlight the positive aspects, so you’re going to try and choose a different name. And so there was this really fantastic Wikipedia discussion on the talk page. How do we word that paragraph to talk about the different naming? It’s called this by Israeli, it’s called this by Palestinians. And how you explain that to people could be quite charged. You could easily explain, oh, there’s this difference and it’s because this side’s good and this side’s bad and that’s why there’s a difference. Or you could say, actually, let’s just try and really stay as neutral as we can and try to explain the reasons. So you may come away from it with a concept. Oh, okay, I understand what this debate is about now.
Lex Fridman

(00:49:26)
And just the term Israel- Palestine conflict is still the title of a page in Wikipedia, but the word conflict is something that is a charged word.
Jimmy Wales

(00:49:41)
Of course.
Lex Fridman

(00:49:42)
Because from the Palestinian side or from certain sides, the word conflict doesn’t accurately describe the situation. Because if you see it as a genocide one way, genocide is not a conflict because to people that discuss the challenge, the word conflict, they see conflict is when there’s two equally powerful sides fighting.
Jimmy Wales

(00:50:05)
Sure, yeah, yeah. No, it’s hard. And in a number of cases, so this actually speaks to a slightly broader phenomenon, which is there are a number of cases where there is no one word that can get consensus. And in the body of an article, that’s usually okay, because we can explain the whole thing. You can come away with an understanding of why each side wants to use a certain word, but there are some aspects, like the page has to have a title, so there’s that. Same thing with certain things like photos. It’s like, well, there’s different photos, which one’s best? Lot of different views on that. But at the end of the day, you need the lead photo because there’s one slot for a lead photo. Categories is another one. So at one point, I have no idea if it’s in there today, but I don’t think so. I was listed in American entrepreneurs fine.

(00:51:03)
American atheist, and I said, that doesn’t feel right to me, just personally it’s true. I mean, wouldn’t disagree with the objective fact of it, but when you click the category and you see a lot of people who are, you might say American atheist activist because that’s their big issue. So Madalyne Murray O’Hair or various famous people who… Richard Dawkins, who make it a big part of their public argument and persona. But that’s not true of me. It’s just my private personal belief, it doesn’t really… it’s not something I campaign about. So it felt weird to put me in the category, but what category would you put? And do you need that? In this case I argued that doesn’t need that. I don’t speak about it publicly, except incidentally, from time to time, I don’t campaign about it. So it’s weird to put me with this group of people.

(00:51:54)
And that argument carried the day, I hope not just because it was me. But categories can be like that where you’re either in the category or you’re not. And sometimes it’s a lot more complicated than that. And is it, again, we go back to, is it undue weight? If someone who is now prominent in public life and generally considered to be a good person was convicted of something, let’s say DUI when they were young, we normally in normal discourse, we don’t think, oh, this person should be in the category of American criminals because you think, oh, a criminal. Yeah, technically speaking, it’s against the law to drive under the influence of alcohol and you were arrested and you spent a month in prison or whatever. But it’s odd to say that’s a criminal.

(00:52:45)
So just as an example in this area is Mark Wahlberg, Marky Mark is what I always think of him as, because that was his first sort of famous name, who I wouldn’t think should be listed as in the category, American criminal. Even though he did, he was convicted of quite a bad crime when he was a young person, but we don’t think of him as a criminal. Should the entry talk about that? Yeah, it’s actually an important part of his life story that he had a very rough youth and he could have gone down a really dark path and he turned his life around. That’s actually interesting. So categories are tricky.
Lex Fridman

(00:53:20)
Especially with people because we like to assign labels to people into ideas somehow, and those labels stick. And there’s certain words that have a lot of power, like criminal, like political left, right, center, anarchist, objectivist. What other philosophies are there? Marxist, communist, social democrat, democratic socialist, socialist, and if you add that as a category, all of a sudden it’s like, oh boy, you’re that guy now. And I don’t know if you want to be that guy.
Jimmy Wales

(00:53:58)
Well, there’s definitely some really charged ones like alt-right, I think it’s quite complicated and tough. It’s not completely meaningless label, but boy, I think you really have to pause before you actually put that label on someone, partly because now you’re putting them in a group of people, some of whom are quite, you wouldn’t want to be grouped with.
Wikipedia’s political bias
Lex Fridman

(00:54:20)
Let’s go into some, you mentioned the hot water of the pool that we’re both tipping a toe in. Do you think Wikipedia has a left leaning political bias, which is something it is sometimes accused of?
Jimmy Wales

(00:54:31)
Yeah, so I don’t think so, not broadly. And I think you can always point to specific entries and talk about specific biases, but that’s part of the process of Wikipedia. Anyone can come and challenge and to go on about that. But I see fairly often on Twitter, some quite extreme accusations of bias. And I think actually I don’t see it. I don’t buy that. And if you ask people for an example, they normally struggle and depending on who they are and what it’s about. So it’s certainly true that some people who have quite fringe viewpoints and who knows the full rush of history in 500 years, they might be considered to be pathbreaking geniuses. But at the moment, quite fringe views. And they’re just unhappy that Wikipedia doesn’t report on their fringe views as being mainstream. And that, by the way, goes across all kinds of fields.

(00:55:36)
I was once accosted on the street outside the TED Conference in Vancouver by a guy who was a homeopath who was very upset that Wikipedia’s entry on homeopathy basically says it’s pseudoscience. And he felt that was biased. And I said, “Well, I can’t really help you because we cite good quality sources to talk about the scientific status, and it’s not very good.” So it depends, and I think it’s something that we should always be vigilant about. But in general, I think we’re pretty good. And I think any time you go to any serious political controversy, we should have a pretty balanced perspective on whose saying what and what the views are and so forth. I would actually argue that the areas where we are more likely to have bias that persists for a long period of time are actually fairly obscure things, or maybe fairly non-political things.

(00:56:40)
I just give, it’s kind of a humorous example, but it’s meaningful. If you read our entries about Japanese anime, they tend to be very, very positive and very favorable because almost no one knows about Japanese anime except for fans. And so the people who come and spend their days writing Japanese anime articles, they love it. They kind of have an inherent love for the whole area. Now they’ll of course, being human beings, they have their internal debates and disputes about what’s better or not. But in general, they’re quite positive because nobody actually cares. On anything that people are quite passionate about, then hopefully there’s quite a lot of interesting stuff.

(00:57:20)
So I’ll give an example, a contemporary example where I think we’ve done a good job as of my most recent sort of look at it, and that is the question about the efficacy of masks during the COVID pandemic. And that’s an area where I would say the public authorities really jerked us all around a bit. In the very first days, they said, “Whatever you do, don’t rush on and buy masks.” And their concern was shortages in hospitals, fair enough. Later it’s like, no, everybody’s got to wear a mask everywhere. It really works really well. And then now I think it’s, the evidence is mixed, right? Masks seem to help, in my personal view, masks seem to help. They’re no huge burden. You might as well wear a mask in any environment where you’re with a giant crowd of people and so forth.

(00:58:13)
But it’s very politicized, that one, and it’s very politicized, where certainly in the US, much more so. I live in the UK, I live in London, I’ve never seen on the streets the kind of the thing that there’s a lot of reports of people actively angry because someone else is wearing a mask, that sort of thing in public. So because it became very politicized, then clearly if Wikipedia… No, so anyway, if you go to Wikipedia and you research this topic, I think you’ll find more or less what I’ve just said. Oh, actually after it’s all to this point in history, it’s mixed evidence like masks seemed to help, but maybe not as much as some of the authorities said. And here we are.

(00:58:56)
And that’s kind of an example where I think, okay, we’ve done a good job, but I suspect there are people on both sides of that very emotional debate who think, this is ridiculous. Hopefully we’ve got quality sources. So then hopefully those people who read this can say, oh, actually it is complicated. If you can get to the point of saying, okay, I have my view, but I understand other views and I do think it’s a complicated question, great, now we’re a little bit more mature as a society.
Lex Fridman

(00:59:24)
Well, that one is an interesting one because I feel like I hope that that article also contains the meta conversation about the politicization of that topic. To me, it’s almost more interesting than whether masks work or not, at least at this point. It’s like why masks became a symbol of the oppression of a centralized government. If you wear them, you’re a sheep that follows the mask control the mass hysteria of an authoritarian regime. And if you don’t wear a mask, then you are a science denier, anti- vaxxer, an alt-right, probably a Nazi.
Jimmy Wales

(01:00:07)
Exactly. And that whole politicization of society is just so damaging, and I don’t know, in the broader world, how do we start to fix that? That’s a really hard question.
Conspiracy theories
Lex Fridman

(01:00:21)
Well, at every moment, because you mentioned mainstream and fringe, there seems to be a tension here, and I wonder what your philosophy is on it because there’s mainstream ideas and there’s fringe ideas. You look at lab leak theory for this virus. That could be other things we can discuss where there’s a mainstream narrative where if you just look at the percent of the population or the population with platforms, what they say, and then what is a small percentage in opposition to that, and what is Wikipedia’s responsibility to accurately represent both the mainstream and the fringe, do you think?
Jimmy Wales

(01:01:05)
Well, I think we have to try to do our best to recognize both, but also to appropriately contextualize. And so this can be quite hard, particularly when emotions are high. That’s just a fact about human beings. I’ll give a simpler example, because there’s not a lot of emotion around it. Like our entry on the moon doesn’t say, some say the moon’s made of rocks, some say cheese, who knows? That kind of false neutrality is not what we want to get to. That doesn’t make any sense, but that one’s easy. We all understand. I think there is a Wikipedia entry called something like the moon is made of cheese, where it talks about this is a common sort of joke or thing that children say or that people tell to children or whatever. It’s just a thing. Everyone’s heard moon’s made of cheese, but nobody thinks, wow, Wikipedia is so one-sided it doesn’t even acknowledge the cheese theory. I say the same thing about flat Earth, again, very-
Lex Fridman

(01:02:08)
That’s exactly what I’m looking up right now.
Jimmy Wales

(01:02:09)
… very little controversy. We will have an entry about flat Earth, theorizing, flat Earth people. My personal view is most of the people who claim to be flat earthers are just having a laugh, trolling and more power to them, have some fun, but let’s not be ridiculous.
Lex Fridman

(01:02:31)
Then of course, for mostly human history, people believe that the Earth is flat, so the article I’m looking at is actually kind of focusing on this history. Flat Earth is an archaic and scientifically disproven conception of the Earth’s shape as a plain or disc, meaning ancient cultures subscribe to a flat Earth cosmography with pretty cool pictures of what a flat Earth would look like, with dragon, is that a dragon no angels on the edge. There’s a lot of controversy about that. What is it the edge? Is it the wall? Is it angels, is it dragons, is there a dome?
Jimmy Wales

(01:03:00)
And how can you fly from South Africa to Perth? Because on a flat Earth view, that’s really too far for any plane to make it because-
Lex Fridman

(01:03:09)
What I want to know-
Jimmy Wales

(01:03:10)
It’s all spread out.
Lex Fridman

(01:03:11)
What I want to know is what’s on the other side, Jimmy, what’s on the other side? That’s what all of us want to know. So I presume there’s probably a small section about the conspiracy theory of flat Earth, because I think there’s a sizeable percent of the population who at least will say they believe in a flat Earth.
Jimmy Wales

(01:03:31)
Yeah.
Lex Fridman

(01:03:32)
I think it is a movement that just says that the mainstream narrative to have distrust and skepticism about the mainstream narrative, which to a very small degree, is probably a very productive thing to do as part of the scientific process. But you can get a little silly and ridiculous with it.
Jimmy Wales

(01:03:49)
Yeah, I mean it’s exactly right. And so I think I find on many, many cases, and of course I, like anybody else, might quibble about this or that in any Wikipedia article, but in general, I think there is a pretty good sort of willingness and indeed eagerness to say, oh, let’s fairly represent all of the meaningfully important sides. So there’s still a lot to unpack in that, right? So meaningfully important. So people who are raising questions about the efficacy of masks, okay, that’s actually a reasonable thing to have a discussion about, and hopefully we should treat that as a fair conversation to have and actually address which authorities have said what and so on and so forth. And then there are other cases where it’s not meaningful opposition, you just wouldn’t say. I doubt if the main article Moon, it may mention cheese, probably not even because it’s not credible and it’s not even meant to be serious by anyone, or the article on the Earth certainly won’t have a paragraph that says, well, most scientists think it’s round, but certain people think flat.

(01:05:12)
That’s just a silly thing to put in that article. You would want to sort of address that’s an interesting cultural phenomenon. You want to put it somewhere. So this goes into all kinds of things about politics. You want to be really careful, really thoughtful about not getting caught up in the anger of our times and really recognize. Yes, I always thought… I remember being really kind of proud of the US at the time when it was McCain was running against Obama because I thought, “Oh, I’ve got plenty of disagreements with both of them, but they both seem like thoughtful and interesting people who I would have different disagreements with.” But I always felt like, yeah, that that’s good, now we can have a debate. Now we can have an interesting debate. And it isn’t just people slamming each other, personal attacks and so forth.
Jimmy Wales

(01:06:00)
It isn’t just people slamming each other with personal attacks and so forth.
Lex Fridman

(01:06:05)
You’re saying Wikipedia has also represented that?
Jimmy Wales

(01:06:09)
I hope so. Yeah, and I think so in the main. Obviously, you can always find debate that went horribly wrong because there’s humans involved.
Lex Fridman

(01:06:18)
But speaking of those humans, I would venture to guess, I don’t know the data, maybe you can let me know, but the personal political leaning of the group of people who had a Wikipedia probably leans left, I would guess. To me, the question there is, I mean the same is true for Silicon Valley, the task for Silicon Valley is to create platforms that are not politically biased even though there is a bias for the engineers who create it. I believe it’s possible to do that. There’s conspiracy theories that it somehow is impossible, and there’s this whole conspiracy where the left is controlling it, and so on. I think engineers, for the most part, want to create platforms that are open and unbiased that create all kinds of perspective because that’s super exciting to have all kinds of perspectives battle it out, but still is there a degree to which the personal political bias of the editors might seep in in silly ways and in big ways?

(01:07:22)
Silly ways could be, I think, hopefully I’m correct in saying this, but the right will call it the Democrat Party and the left will call it the Democratic Party, right? It always hits my ear weird. Are we children here? We’re literally taking words and just jabbing at each other. Yeah, I could capitalize a thing in a certain way, or I can just take a word and mess with them. That’s a small way of how you use words, but you can also have a bigger way about beliefs, about various perspectives on political events, on Hunter Biden’s laptop, on how big of a story that is or not, how big the censorship of that story is or not, and then there’s these camps to take very strong points and they construct big narratives around that. It’s a very sizable percent of the population believes the two narratives that compete with each other.
Jimmy Wales

(01:08:21)
Yeah. It’s really interesting and it’s hard to judge the sweep of history within your own lifetime, but it feels like it’s gotten much worse, that this idea of two parallel universes where people can agree on certain basic facts feels worse than it used to be. I’m not sure if that’s true or if it just feels that way, but I’m not sure what the causes are. I think I would lay a lot of the blame in recent years on social media algorithms, which reward clickbait headlines, which reward tweets that go viral, and they go viral because they’re cute and clever.

(01:09:13)
My most successful tweet ever by a fairly wide margin, some reporter tweeted at Elon Musk because he was complaining about Wikipedia or something, “You should buy Wikipedia,” and I just wrote, “Bot for sale,” and 90 zillion retweets, and people liked it, and it was all very good, but I’m like, “You know what? It’s cute line and it’s a good mic drop,” and all that, and I was pleased with myself. I’m like, “It’s not really a discourse.” It’s not really what I like to do, but it’s what social media really rewards, which is kind of a let’s you and him have a fight, and that’s more interesting. It’s funny because at the time, I was texting with Elon who’s very pleasant to me, and all of that.
Lex Fridman

(01:10:01)
He might have been a little bit shitty, the reporter might have been a little bit shitty, but you fed into the shitty with a snarky funny of response, “Not for sale,” and where do you… That’s a funny little exchange, and you can probably after that laugh it off and it’s fun, but that kind of mechanism that rewards the snark can go into viciousness.
Jimmy Wales

(01:10:22)
Yeah. Well, and we certainly see it online. A series of tweets, sort of a tweet thread of 15 tweets that assesses the quality of the evidence for masks, pros and cons, and sort of wear this, that’s not going to go viral, but a SmackDown for a famous politician who was famously in favor of mask, who also went to a dinner and didn’t wear a mask, that’s going to go viral, and that’s partly human nature. People love to call out hypocrisy and all of that, but it’s partly what these systems elevate automatically. I talk about this with respect to Facebook, for example. I think Facebook has done a pretty good job, although it’s taken longer than it should in some cases, but if you have a very large following and you’re really spouting hatred or misinformation, disinformation, they’ve kicked people off.

(01:11:24)
They’ve done some reasonable things there, but actually, the deeper issue of the anger we’re talking about, of the contentiousness of everything, I make of a family example with two great stereotypes. One, the crackpot racist uncle, and one, the sweet grandma. I always want to point out all of my uncles in my family were wonderful people, so I didn’t have a crackpot racist, but everybody knows the stereotype. Well, so grandma, she just posts sweet comments on the kids’ pictures and congratulates people on their wedding anniversary, and crackpot uncle’s posting his nonsense. Normally, it’s at Christmas dinner, everybody rolls their eyes, “Oh, yeah, Uncle Frank’s here, and he is probably going to say some racist comment and we’re going to tell him to shut up, or maybe let’s not invite him this year.” Normal human drama. He’s got his three mates down at the pub who listen to him and all of that, but now grandma’s got 54 followers on Facebook, which is the intimate family, and racist uncle has 714, so he’s not a massive influence or whatever, but how did that happen?

(01:12:36)
It’s because the algorithm notices when she posts, nothing happens. He posts and then everybody jumps in to go, “God, shut up, Uncle Frank. That’s outrageous,” and there’s engagement, there’s page views, there’s ads. Those algorithms, I think they’re working to improve that, but it’s really hard for them. It’s hard to improve that if that actually is working. If the people who are saying things that get engagement, if it’s not too awful, but it’s just, maybe it’s not a racist uncle, but maybe it’s an uncle who posts a lot about what an idiot Biden is, which isn’t necessarily an offensive or blockable or bannable thing, and it shouldn’t be, but if that’s the discourse that gets elevated because it gets a rise out of people, then suddenly in a society, it’s like, “Oh, we get more of what we reward,” so I think that’s a piece of what’s gone on.
Facebook
Lex Fridman

(01:13:28)
Well, if we could just take that tangent. I’m having a conversation with Mark Zuckerberg second time. Is there something you can comment on how to decrease toxicity on that particular platform, Facebook? You also have worked on creating a social network that is less toxic yourself, so can we just talk about the different ideas that these already big social network can do and what you have been trying to do?
Jimmy Wales

(01:13:55)
A piece of it is it’s hard. The problem with making a recommendation to Facebook is that I actually believe their business model makes it really hard for them, and I’m not anti-capitalism, I’m not, “Great. Somebody’s got business, they’re making money,” that’s not where I come from, but certain business models mean you are going to prioritize things that maybe aren’t longterm healthful, and so that’s a big piece of it. Certainly, for Facebook, you could say with vast resources, start to prioritize content that’s higher quality, that’s healing, that’s kind. Try not to prioritize content that seems to be just getting a rise out of people. Now, those are vague human descriptions, but I do believe good machine running algorithms, you can optimize in slightly different ways, but to do that, you may have to say, “Actually, we’re not necessarily going to increase page views to the maximum extent right now.”

(01:14:59)
I’ve said this to people at Facebook. It’s like if your actions are convincing people that you’re breaking Western civilization, that’s a really bad for business in the long run. Certainly, these days, I’ll say, Twitter is the thing that’s on people’s minds as being more upsetting at the moment, but I think it’s true. One of the things that’s really interesting about Facebook compared to a lot of companies is that Mark has a pretty unprecedented amount of power. His ability to name members of the board, his control of the company is pretty hard to break even if financial results aren’t as good as they could be because he’s taken a step back from the perfect optimization to say, “Actually, for the longterm health in the next 50 years of this organization, we need to reign in some of the things that are working for us in making money because they’re actually giving us a bad reputation.” One of the recommendations I would say is, and this is not to do with the algorithms and all that, but how about just a moratorium on all political advertising?

(01:16:11)
I don’t think it’s their most profitable segment, but it’s given rise to a lot of deep, hard questions about dark money, about ads that are run by questionable people that push false narratives, or the classic kind of thing is you run… I saw a study about Brexit in the UK where people were talking about there were ads run to animal rights activists saying, “Finally, when we’re out from under Europe, the UK can pass proper animal rights legislation. We’re not constrained by the European process.” Similarly, for people who are advocates of fox hunting to say, “Finally, when we’re out of Europe, we can re-implement…” You’re telling people what they want to hear, and in some cases, it’s really hard for journalists to see that, so it used to be that for political advertising, you really needed to find some kind of mainstream narrative, and this is still true to an extent, mainstream narrative that 60% of people can say, “Oh, I can buy into that,” which meant it pushed you to the center.

(01:17:20)
It pushed you to try and find some nuance balance, but if your main method of recruiting people is a tiny little one-on-one conversation with them, because you’re able to target using targeted advertising, suddenly you don’t need consistent. You just need a really good targeting operation, really good Cambridge analytic style machine learning algorithm data to convince people. That just feels really problematic, so until they can think about how to solve that problem, I would just say, “You know what? It’s going to cost us X amount,” but it’s going to be worth it to kind of say, “You know what? We actually think our political advertising policy hasn’t really helped contribute to discourse and dialogue in finding reasoned middle ground and compromise solutions, so let’s just not do that for a while until we figure that out,” so that’s maybe a piece of advice.
Lex Fridman

(01:18:15)
Coupled with, as you were saying, recommender systems for the newsfeed and other contexts that don’t always optimize engagement, but optimize the long term mental wellbeing and balance and growth of a human being, but it’s a very difficult problem.
Jimmy Wales

(01:18:33)
It’s a difficult problem. Yeah. With WT Social, WikiTribune Social, we’re launching in a few months time a completely new system, new domain, and new lots of things, but the idea is to say let’s focus on trust. People can rate each other as trustworthy, rate content as trustworthy. You have to start from somewhere so it’ll start with a core base of our tiny community who, I think, are sensible, thoughtful people, want to recruit more, but to say, “You know what? Actually, let’s have that as a pretty strong element,” to say let’s not optimize based on what gets the most paid views in this session, let’s optimize on what the feedback from people is, this is meaningfully enhancing my life. Part of that is, and it’s probably not a good business model, but part of that is say, “Okay, we’re not going to pursue an advertising business model, but a membership model where you don’t have to be a member, but you can pay to be a member.”

(01:19:36)
You maybe get some benefit from that, but in general, to say, actually the problem with… Actually, the division I would say is, and the analogy I would give is broadcast television funded by advertising gives you a different result than paying for HBO, paying for Netflix, paying for whatever. The reason is, if you think about it, what is your incentive as a TV producer? You’re going to make a comedy for ABC Network in the US, you basically say, “I want something that almost everybody will like and listen to,” so it tends to be a little blander, family-friendly, whatever. Whereas if you say, “Oh, actually,” I’m not going to use the HBO example, and an old example, you say, “You know what? Sopranos isn’t for everybody, Sex and the City isn’t for everybody, but between the two shows, we’ve got something for everybody that they’re willing to pay for,” so you can get edgier, higher quality in my own view content rather than saying it’s got to not offend anybody in the world. It’s got to be for everybody, which is really hard.

(01:20:47)
Same thing here in a social network. If your business model is advertising, it’s going to drive you in one direction. If your business model is membership, I think it drives you in a different direction. Actually, and I’ve said this to Elon about Twitter Blue, which I think wasn’t rolled out well and so forth, but the piece of that that I like is to say, look, actually, if there’s a model where your revenue is coming from people who are willing to pay for the service, even if it’s only part of your revenue, if it’s a substantial part, that does change your broader incentives to say, actually, are people going to be willing to pay for something that’s actually just toxicity in their lives? Now, I’m not sure it’s been rolled out well, I’m not sure how it’s going, and maybe I’m wrong about that as a plausible business model, but I do think it’s interesting to think about, just in broad terms, business model drives outcomes in sometimes surprising ways unless you really pause to think about it.
Twitter
Lex Fridman

(01:21:46)
If we can just link on Twitter and Elon before… I would love to talk to you about the underlying business model, Wikipedia, which is this brilliant, bold move at the very beginning, but since you mentioned Twitter, what do you think works? What do you think is broken about Twitter?
Jimmy Wales

(01:22:03)
It’s a long conversation, but to start with, one of the things that I always say is it’s a really hard problem, so I concede that right up front. I said this about the old ownership of Twitter and the new ownership of Twitter because unlike Wikipedia, and this is true actually for all social media, there’s a box, and the box basically says, “What do you think? What’s on your mind?” You can write whatever the hell you want, right? This is true, by the way, even for YouTube. I mean the box is to upload a video, but again, it’s just an open-ended invitation to express yourself.

(01:22:38)
What makes that hard is some people have really toxic, really bad, some people are very aggressive, they’re actually stalking, they’re actually abusive, and suddenly, you deal with a lot of problems. Whereas at Wikipedia, there is no box that says, “What’s on your mind?” There’s a box that says, “This is an entry about the moon. Please be neutral. Please set your facts.” Then there’s a talk page which is not coming rant about Donald Trump. If you go on the talk page of the Donald Trump entry and you just start ranting about Donald Trump, people would say, “What are you doing? Stop doing that. We’re not here to discuss. There’s a whole world of the internet out there for you to go and rant about Donald Trump.”
Lex Fridman

(01:23:17)
It’s just not fun to do on Wikipedia as somehow as fun on Twitter.
Jimmy Wales

(01:23:20)
Well, also on Wikipedia, people are going to say, “Stop,” and, “Actually, are you here to tell us how can we improve the article or are you just here to rant about Trump? Because that’s not actually interesting.” Because the goal is different, so that’s just admitting and saying upfront, this is a hard problem. Certainly, I’m writing a book on trust. The idea is, in the last 20 years, we’ve lost trust in all kinds of institutions, in politics. The Edelman Trust Barometer Survey has been done for a long time, and trust in politicians, trust in journalism, it’s come declined substantially, and I think in many cases, deservedly, so how do we restore trust and how do we think about that?
Lex Fridman

(01:24:07)
Does that also include trust in the idea of truth?
Jimmy Wales

(01:24:13)
Trust in the idea of truth. Even the concept of facts and truth is really, really important, and the idea of uncomfortable truths is really important. When we look at Twitter and we can see, okay, this is really hard, so here’s my story about Twitter. It’s a two-part story, and it’s all pre Elon Musk ownership. Many years back, somebody accused me of horrible crimes on Twitter, and like anybody would, I was like… I’m in the public eye. People say bad things. I don’t really… I brush it off, whatever, but I’m like, “This is actually really bad.” Accusing me of pedophilia? That’s just not okay, so I thought, “I’m going to report this,” so I click report, and I report the tweet and there’s five others, and I report, and I go through the process, and then I get an email that says whatever, a couple of hours later saying, “Thank you for your report. We’re looking into this.” Great. Okay, good.

(01:25:16)
Then several hours further, I get an email back saying, “Sorry, we don’t see anything here to violate our terms of use,” and I’m like, “Okay,” so I emailed Jack and I say, “Jack, come on. This is ridiculous,” and he emails back roughly saying, “Yeah, sorry, Jimmy. Don’t worry. We’ll sort this out.” I just thought to myself, “You know what? That’s not the point. I’m Jimmy Wales, I know Jack Dorsey. I can email Jack Dorsey. He’ll listen to me because he’s got an email from me and sorts it out for me.” What about the teenager who’s being bullied and is getting abuse and getting accusations that aren’t true? Are they getting the same kind of really poor result in that case? Fast-forward a few years, same thing happens. The exact quote, it goes, “Please help me. I’m only 10 years old, and Jimmy Wales raped me last week.” I was like, “Come on. Fuck off. That’s ridiculous,” so I report. I’m like, “This time I’m reporting,” but I’m thinking, “Well, we’ll see what happens.”

(01:26:15)
This one gets even worse because then I get a same result email back saying, “Sorry, we don’t see any problems,” so I raised it with other members of the board who I know, and Jack, and like, “This is really ridiculous. This is outrageous,” and some of the board members, friends of mine, sympathetic, and so good for them, but I actually got an email back then from the general counsel head of trust and safety saying, “Actually, there’s nothing in this tweet that violates our terms of service. We don’t regard and gave reference to the Me Too Movement. If we didn’t allow accusations, the Me Too Movement, it’s an important thing,” and I was like, “You know what? Actually, if someone says, ‘I’m 10 years old and someone raped me last week,’ I think the advice should be, ‘Here’s the phone number of the police.’ You need to get the police involved. Twitter’s not the place for that accusation.”

(01:27:05)
Even back then… By the way, they did delete those tweets, but the rationale they gave is spammy behavior, so completely separate from abusing me. It was just like, “Oh, well, they were retweeting too often.” Okay, whatever. That’s just broken. That’s a system that it’s not working for people in the public eye. I’m sure it’s not working for private people who get abuse. Really horrible abuse can happen. How is that today? Well, it hasn’t happened to me since Elon took over, but I don’t see why it couldn’t, and I suspect now if I send a report and email someone, there’s no one there to email me back because he’s gotten rid of a lot of the trust and safety staff, so I suspect that problem is still really hard.
Lex Fridman

(01:27:46)
Just content moderation at huge scales.
Jimmy Wales

(01:27:49)
At huge scales is really something. I don’t know the full answer to this. A piece of it could be to say, “Actually, making specific allegations of crimes, this isn’t the place to do that. We’ve got a huge database. If you’ve got an accusation of crime, here’s who should call, the police, the FBI, whatever it is. It’s not to be done in public,” and then you do face really complicated questions about Me Too Movement and people coming forward in public and all of that, but again, it’s like probably you should talk to a journalist. Probably there are better avenues than just tweeting from an account that was created 10 days ago, obviously set up to abuse someone. I think they could do a lot better, but I also admit it’s a hard problem.
Lex Fridman

(01:28:38)
There’s also ways to indirectly or more humorously or a more mocking way to make the same kinds of accusations. In fact, the accusations you mentioned, if I were to guess, don’t go that viral because they’re not funny enough or cutting enough, but if you make it witty and cutting and meme it somehow, sometimes actually indirectly making an accusation versus directly making an accusation, that can go viral and that can destroy reputations, and you get to watch yourself. Just all kinds of narratives take hold.
Jimmy Wales

(01:29:09)
Yeah, no, I remember another case that didn’t bother me because it wasn’t of that nature, but somebody was saying, “I’m sure you’re making millions off of Wikipedia,” and I’m like, “No, actually, I don’t even work there. I have no salary,” and they’re like, “You’re lying. I’m going to check your 990 form,” which is the US form for tax reporting for charities, and I was like, “Yeah, here’s the link. Go read it and you’ll see I’m listed as a board member, and my salary is listed as zero.” Things like that, it’s like, “Okay.” That one, that feels like you’re wrong, but I can take that and we can have that debate quite quickly.

(01:29:52)
Again, it didn’t go viral because it was kind of silly, and if anything would’ve gone viral, it was me responding, but that’s one where it’s like, actually, I’m happy to respond because a lot of people don’t know that I don’t work there and that I don’t make millions, and I’m not a billionaire. Well, they must know that because it’s in most news media about me, but the other one, I didn’t respond to publicly because it’s like Barbara Streisand effect. It’s like sometimes calling attention to someone who’s abusing you who basically has no followers and so on is just a waste.
Lex Fridman

(01:30:24)
And everything you’re describing now is just something that all of us have to learn because everybody’s in the public eye. I think when you have just two followers and you get bullied by one of the followers, it hurts just as much as when you have a large number, so it’s not… Your situation, I think it’s echoed in the situations of millions of other, especially teenagers and kids and so on.
Jimmy Wales

(01:30:43)
Yeah, no, it’s actually an example. We don’t generally use my picture and the banners anymore on Wikipedia, but we did, and then we did an experiment one year where we tried other people’s pictures, so one of our developers, and one lovely, very sweet guy, and he doesn’t look like your immediate thought of a nerdy Silicon Valley developer. He looks like a heavy metal dude because he’s cool. Suddenly, here he is with long hair and tattoos, and there’s his sort of say, “Here’s what your money goes for. Here’s my letter asking for support,” and he got massive abuse from Wikipedia, like calling him creepy, and really massive. This was being shown to 80 million people a day, his picture, not the abuse. The abuse was elsewhere on the internet. He was bothered by it.

(01:31:39)
I thought, “You know what? There is a difference.” I actually am in the public eye. I get huge benefits from being in the public eye. I go around and make public speeches. Any random thing I think of, I can write and get it published in the New York Times, and I have this interesting life. He’s not a public figure, and so actually he wasn’t mad at us. It was just like, actually, suddenly being thrust in the public eye and you get suddenly lots of abuse, which normally, I think if you’re a teenager and somebody in your class is abusing you, it’s not going to go viral. It’s going to be hurtful because it’s local and it’s your classmates or whatever, but when ordinary people go viral in some abusive way, it’s really, really quite tragic.
Lex Fridman

(01:32:24)
I don’t know. Even at a small scale, it feels viral. When five people at your school, and there’s a rumor, and there’s this feeling like you’re surrounded, and the feeling of loneliness, I think, which you’re speaking to when you at least feel like you don’t have a platform to defend yourself, and then this powerlessness, that I think a lot of teenagers definitely feel, and a lot of people-
Jimmy Wales

(01:32:49)
I think you’re right.
Lex Fridman

(01:32:51)
I think even when just two people make up stuff about you or lie about you or say mean things about you or bully you, that can feel like a crowd.
Jimmy Wales

(01:33:01)
Yeah. No, that’s true.
Lex Fridman

(01:33:03)
Whatever that is in our genetics and our biology and the way our brain works, that just can be a terrifying experience. Somehow, to correct that, I think because everybody feels the pain of that, everybody suffers the pain of that, I think we’ll be forced to fix that as a society, to figure out a way around that.
Jimmy Wales

(01:33:22)
I think it’s really hard to fix because I don’t think that problem isn’t necessarily new. Someone in high school who writes graffiti that says, “Becky is a slut,” and spreads a rumor about what Becky did last weekend, that’s always been damaging, it’s always been hurtful, and that’s really hard.
Lex Fridman

(01:33:45)
Those kinds of attacks, there is oldest time itself, they proceed the internet. Now, what do you think about this technology that feels Wikipedia like, which is community notes on Twitter? Do you like it? Pros and cons? Do you think it’s scalable?
Jimmy Wales

(01:34:00)
I do like it. I don’t know enough about specifically how it’s implemented to really have a very deep view, but I do think it’s quite… The uses I’ve seen of it, I’ve found quite good, and in some cases, changed my mind. It’s like I see something, and of course, the human tendency is to retweet something that you hope is true or that you are afraid is true, or it’s that kind of quick mental action. Then I saw something that I liked and agreed with, and then a community note under it that made me think, “Oh, actually, this is a more nuanced issue,” so I like that. I think that’s really important. Now, how is it specifically implemented? Is it scalable or that? I don’t really know how they’ve done it, so I can’t really comment on that, but in general, I do think when your only mechanisms on Twitter, and you’re a big Twitter user, we know the platform and you’ve got plenty of followers and all of that, the only mechanisms are retweeting, replying, blocking.

(01:35:13)
It’s a pretty limited scope, and it’s kind of good if there’s a way to elevate a specific thoughtful response. It kind of goes to, again, does the algorithm just pick the retweet or the… I mean retweeting, it’s not even the algorithm that makes it viral. If Paulo Coelho, very famous author, I think he’s got… I don’t know. I haven’t looked lately. He used to have eight million Twitter followers. I think I looked, he’s got 16 million now or whatever. Well, if he retweets something, it’s going to get seen a lot. Elon Musk, if he retweets something, it’s going to get seen a lot. That’s not an algorithm. That’s just the way the platform works. So, it is kind of nice if you have something else, and how that’s something else is designed, that’s obviously complicated question.
Lex Fridman

(01:35:58)
Well, there’s this interesting thing that I think Twitter is doing, but I know Facebook is doing for sure, which is really interesting. What are the signals that a human can provide at scale? In Twitter, it’s retweet. In Facebook, I think you can share. I think, yeah, but there’s basic interactions, you can have comment and so on, but there’s also, in Facebook, and YouTube has this too is, “Would you like to see more of this or would you like to see less of this?” They post that sometimes. The thing that the neural net that’s learning from that has to figure out is the intent behind you saying, “I want to see less of this.”

(01:36:39)
Did you see too much of this content already? You like it, but you don’t want to see so much of it. You already figured it out, great. Or does this content not make you feel good? There’s so many interpretations that I would like to see less of this, but if you get that kind of signal, this actually can create a really powerfully curated list of content that is fed to you every day that doesn’t create an echo chamber or a silo, that actually just makes you feel good in the good way, which it challenges you, but it doesn’t exhaust you and make you this weird animal.
Jimmy Wales

(01:37:20)
I’ve been saying for a long time, if I went on Facebook one morning and they said, Ooh, we’re testing a new option. Rather than showing you things we think you’re going to like, we want to show you some things that we think you will disagree with, but which we have some signals that suggest it’s of quality,” I’m like, “Now, that sounds interesting.”
Lex Fridman

(01:37:40)
Yeah, that sounds really interesting.
Jimmy Wales

(01:37:41)
I want to see something where… Oh, I don’t agree with… Larry Lessig is a good friend of mine, founder of Creative Commons, and he’s moved on to doing stuff about corruption and politics and so on. I don’t always agree with Larry, but I always grapple with Larry because he’s so interesting and he’s so thoughtful, that even when we don’t agree, I’m like, “Actually, I want to hear him out because I’m going to learn from it,” and that doesn’t mean I always come around to agree with him, but I’m going to understand a perspective, and that’s really great feeling.
Lex Fridman

(01:38:12)
Yeah, there’s this interesting thing on social media where people accuse others of saying, “Well, you don’t want to hear opinions that you disagree with or ideas you disagree with.” I think this is something that’s thrown at me all the time. The reality is there’s literally almost nothing I enjoy more.
Jimmy Wales

(01:38:29)
It seems an odd thing to accuse you of because you have quite a wide range of long conversations with a very diverse bunch of people.
Lex Fridman

(01:38:35)
But there is a very, very harsh drop off because what I like is high quality disagreement. That really makes me think. At a certain point, there’s a threshold, it’s a kind of a gray area when the quality of the disagreement, it just sounds like mocking, and you’re not really interested in a deep understanding of the topic, or you yourself don’t seem to carry deep understanding of the topic. There’s something called intelligence square debates that may-
Lex Fridman

(01:39:00)
There’s something called Intelligence Squared debates. The main one is the British version. With the British accent, everything always sounds better. And the Brits seem to argue more intensely, like they’re invigorated, they’re energized by the debate. Those people I often disagree with, basically everybody involved, and it’s so fun. I learned something. That’s high quality. If we could do that, if there’s some way for me to click a button that says, “Filter out lower quality just today,” just sometimes show it to me because I want to be able to, but today I’m just not in the mood for the mockery.

(01:39:38)
Just high quality stuff, because even flat Earth, I want to get high quality arguments for the flat Earth. It would make me feel good because I would see, “Oh, that’s really interesting. I never really thought in my mind to challenge the mainstream narrative of general relativity, of a perception of physics. Maybe all of reality, maybe all of space is an illusion. That’s really interesting. I never really thought about, let me consider that fully. Okay, what’s the evidence? How would you test that? What are the alternatives? How would you be able to have such consistent perception of a physical reality, if it’s all of it is an illusion? All of us seem to share the same kind of perception of reality,” that’s the kind of stuff I love, but not the mockery of it that cheap, that it seems that social media can inspire.
Jimmy Wales

(01:40:34)
Yeah. I talk sometimes about how people assume that the big debates in Wikipedia or the arguments are between the party of the left and the party of the right. And I would say no, it’s actually the party of the kind and thoughtful and the party of the jerks, is really it. Left and yeah, yeah, bring me somebody I disagree with politically. As long as they’re thoughtful, kind, we’re going to have a real discussion. I give an example of our article on abortion: so, if you can bring together a kind and thoughtful Catholic priest and a kind and thoughtful Planned Parenthood activist and they’re going to work together on the article on abortion, that can be a really great thing, if they’re both kind and thoughtful. That’s the important part. They’re never going to agree on the topic, but they will understand, okay, Wikipedia is not going to take a side, but Wikipedia is going to explain what the debate is about, and we’re going to try to characterize it fairly.

(01:41:36)
And it turns out your kind and thoughtful people, even if they’re quite ideological, like a Catholic priest is generally going to be quite ideological on the subject of abortion, but they can grapple with ideas and they can discuss, and they may feel very proud of the entry at the end of the day, not because they suppress the other side’s views, but because they think the case has been stated very well that other people can come to understand it. And if you’re highly ideological, you assume, I think naturally, “If people understood as much about this as I do, they’ll probably agree with me.” You may be wrong about that, but that’s often the case. So, that’s what I think we need to encourage more of in society generally, is grappling with ideas in a really thoughtful way.
Building Wikipedia
Lex Fridman

(01:42:21)
So is it possible if the majority of volunteers, editors of Wikipedia really disliked Donald Trump, are they still able to write an article that empathizes with the perspective of, for time at least, a very large percentage of the United States that were supported of Donald Trump, and to have a full broad representation of him as a human being, him as a political leader, him as a set of policies promised and implemented, all that kind of stuff?
Jimmy Wales

(01:42:55)
Yeah, I think so. And I think if you read the article, it’s pretty good. And I think a piece of that is within our community, if people have the self-awareness to understand. So, I personally wouldn’t go and edit the entry on Donald Trump. I get emotional about it and I’m like, “I’m not good at this,” and if I tried to do it, I would fail. I wouldn’t be a good Wikipedian, so it’s better if I just step back and let people who are more dispassionate on this topic edit it. Whereas there are other topics that are incredibly emotional to some people where I can actually do quite well. I’m going to be okay. Maybe we were discussing earlier the efficacy of masks. I’m like, “Oh, I think that’s an interesting problem. And I don’t know the answer, but I can help catalog what’s the best evidence and so on.”

(01:43:48)
I’m not going to get upset. I’m not going to get angry, able to be a good Wikipedian, so I think that’s important. And I do think though in a related framework that the composition of the community is really important. Not because Wikipedia is or should be a battleground, but because blind spots, like maybe I don’t even realize what’s biased if I’m particularly of a certain point of view, and I’ve never thought much about it. So one of the things we focus on a lot, the Wikipedia volunteers are, we don’t know the exact number, but let’s say 80% plus male, and they’re a certain demographic: they tend to be college educated, heavier on tech geeks than not, et cetera. So, there is a demographic to the community, and that’s pretty much global. Somebody said to me once, “Why is it only white men who edit Wikipedia?”, and I said, “You’ve obviously not met the Japanese Wikipedia community.”

(01:44:51)
It’s a joke because the broader principle still stands, who edits Japanese Wikipedia? A bunch of geeky men, and women as well. So, we do have women in the community, and that’s very important. But we do think, “Okay, you know what, that does lead to some problems,” it leads to some content issues simply because people write more about what they know and what they’re interested in. They’ll tend to be dismissive of things as being unimportant if it’s not something that they personally have an interest in. I like the example, as a parent I would say our entries on early childhood development probably aren’t as good as they should be because a lot of the Wikipedia volunteers… Actually we’re getting older, the Wikipedians, so that demographic has changed a bit. But if you’ve got a bunch of 25 year old tech geek dudes who don’t have kids, they’re just not going to be interested in early childhood development. And if they tried to write about it, they probably wouldn’t do a good job, ’cause they don’t know anything about it.

(01:45:53)
And somebody did a look at our entries on novelists who’ve won a major literary prize, and they looked at the male novelist versus the female, and the male novelists had longer and higher quality entries. And why is that? Well, it’s not because, ’cause I know hundreds of Wikipedian, it’s not because these are a bunch of biased, sexist men who like, “Books by women are not important.” No. Actually, there is a gender breakdown of readership. There are books, like hard science fiction’s a classic example, hard science fiction: mostly read by men. Other types of novels, more read by women. And if we don’t have women in the community, then these award-winning clearly important novelists may have less coverage. And not because anybody consciously thinks, “We don’t like a book by Maya Angelou. Who cares? She’s a poet. That’s not interesting.”

(01:46:55)
No, but just because, well, people write what they know, they write what they’re interested in it. So, we do think diversity in the community is really important. And that’s one area where I do think it’s really clear. But I can also say, actually that also applies in the political sphere, to say, actually, we do want kind and thoughtful Catholic priests, kind and thoughtful conservatives, kind and thoughtful libertarians, kind and thoughtful Marxists to come in. But the key is the kind and thoughtful piece, so when people sometimes come to Wikipedia outraged by some dramatic thing that’s happened on Twitter, they come to Wikipedia with a chip on their shoulder ready to do battle, and it just doesn’t work out very well.
Lex Fridman

(01:47:38)
And there’s tribes in general where I think there’s a responsibility on the larger group to be even kinder and more welcoming to the smaller group.
Jimmy Wales

(01:47:48)
Yeah, we think that’s really important. And so oftentimes, people come in and there’s a lot… When I talk about community health, one of the aspects of that that we do think about a lot, that I think about a lot is not about politics. It’s just like, how are we treating newcomers to the community? And so, I can tell you what our ideals are, what our philosophy is, but do we live up to that? So the ideal is you come to Wikipedia, we have rules. One of our fundamental rules is ignore all rules, which is partly written that way because it piques people’s attention, like, “Oh, what the hell kind of rule is that?” But basically says, “Look, don’t get nervous and depressed about a bunch of what’s the formatting of your footnote?”, so you shouldn’t come to Wikipedia, add a link, and then get banned or yelled at because it’s not the right format.

(01:48:46)
Instead, somebody should go, “Oh, hey. Yeah, thanks for helping, but here’s the link to how to format. If you want to keep going, you might want to learn how to format a footnote,” and to be friendly and to be open and to say, “Oh, right, oh, you’re new and you clearly don’t know everything about Wikipedia,” and sometimes in any community, that can be quite hard. So, people come in and they’ve got a great big idea, and they’re going to propose this to the Wikipedia community, and they have no idea. That’s basically a perennial discussion we’ve had 7,000 times before. And so then ideally, you would say to the person, “Oh yeah, great, thanks.” A lot of people have, and here’s where we got to and here’s the nuanced conversation we’ve had about that in the past that I think you’ll find interesting, and sometimes people are just like, “Oh God, another one, who’s come in with this idea which doesn’t work, and they don’t understand why.”
Lex Fridman

(01:49:39)
You can lose patience, but you shouldn’t.
Jimmy Wales

(01:49:40)
And that’s human, but I think it just does require really thinking in a self-aware manner of, “Oh, I was once a newbie.” Actually, I just did an interview with Emily Temple Woods, she was Wikipedian of the year, she’s just like a great, well-known Wikipedian. And I interviewed her for my book and she told me something I never knew, apparently it’s not secret, she didn’t reveal it to me, but it’s that when she started Wikipedia, she was a vandal. She came in and vandalized Wikipedia. And then basically what happened was she’d vandalized a couple of articles, and then somebody popped up on her talk page and said, “Hey, why are you doing this? We’re trying to make an encyclopedia here, and and this wasn’t very kind.”

(01:50:29)
And she felt so bad. She’s like, “Oh, right. I didn’t really think of it that way.” She just was coming in, and she was 13 years old, combative and having fun, and trolling a bit. And then she’s like, “Oh, actually, I see your point,” and became a great Wikipedian. So that’s the ideal really, is that you don’t just go throw a block, “Fuck off.” You go, “Hey, what gives?”, which is I think the way we tend to treat things in real life, if you’ve got somebody who’s doing something obnoxious in your friend group, you probably go, “Hey, really, I don’t know if you’ve noticed, but I think this person is actually quite hurt that you keep making that joke about them.” And then they usually go, “Oh, I thought that was okay,” and then they stop, or they keep it up and then everybody goes, “Well, you’re the asshole.”
Lex Fridman

(01:51:21)
Well, yeah, that’s just an example that gives me faith in humanity that we’re all capable and wanting to be kind to each other. And in general, the fact that there’s a small group of volunteers, they’re able to contribute so much to the organization, the collection, the discussion of all of human knowledge is so it makes me so grateful to be part of this whole human project. That’s one of the reasons I love Wikipedia is gives me faith in humanity.
Jimmy Wales

(01:51:53)
Yeah, no, I once was at Wikimania is our annual conference and people come from all around the world, really active volunteers. I was at the dinner, we were in Egypt at Wikimania and Alexandria at the closing dinner or whatever, and a friend of mine came and sat at the table, and she’s been in the movement more broadly, creative commons, she’s not really a Wikipedian, she’d come to the conference because she’s into creative commons and all that. So we have dinner, and it just turned out I sat down at the table with most of the members of the English language arbitration committee, and they’re a bunch of very sweet, geeky Wikipedians.

(01:52:31)
And as we left the table, I said to her, “I still find this sense of amazement, we just had dinner with some of the most powerful people in English language media,” because they’re the people who are the final court of appeal in English Wikipedia. And thank goodness they’re not media moguls. They’re just a bunch of geeks who are just well-liked in the community because they’re kind and they’re thoughtful and they really think about things. I was like, “This is great. Love Wikipedia.”
Lex Fridman

(01:53:01)
To the degree that geeks run the best aspect of human civilization brings me joy in all aspects. And this is true programming, like Linux programmers, people that kind of specialize in a thing, and they don’t really get caught up into the mess of the bickering of society. They just do their thing, and they value the craftsmanship of it, the competence of it.
Jimmy Wales

(01:53:29)
Yeah. If you’ve never heard of this or looked into it, you’ll enjoy it, I read something recently that I didn’t even know about, but the fundamental time zones, and they change from time to time. Sometimes, a country will pass daylight savings or move it by a week, whatever. There’s a file that’s on all Unix based computers, and basically all computers end up using this file, it’s the official time zone file. But why is it official? It’s just this one guy. It’s like this guy and a group of community around him.

(01:54:04)
And basically, something weird happened and it broke something because he was on vacation. And I’m just like, isn’t that wild that you would think… First of all, most people never even think about how do computers know about time zones? Well, they know because they just use this file which tells all the time zones and which dates they change and all of that. But there’s this one guy, and he doesn’t get paid for it. With all the billions of people on the planet, he put his hand up and goes, “Yo, I’ll take care of the time zones.”
Lex Fridman

(01:54:36)
And there’s a lot of programmers listening to this right now with PTSD about time zones. On top of this one guy, there’s other libraries, the different programming languages that help manage the time zones for you. But still, within those, it’s amazing just the packages, the libraries, how few people build them out of their own love for building, for creating, for community and all of that. I almost like don’t want to interfere with the natural habitat of the geek. When you spot him in the wild, you just want to be like, “Well, careful, that thing needs to be treasured.”

(01:55:16)
No, I met a guy many years ago, lovely, really sweet guy, and he was running a bot on English Wikipedia that I thought, “Wow, that’s actually super clever.” And what he had done is his bot was like spell checking, but rather than simple spell checking, what he had done is create a database of words that are commonly mistaken for other words. They’re spelled wrong, so I can’t even give an example. And so, the word is people often spell it wrong, but no spell checker catches it because it is another word. And so, what he did is he wrote a bot that looks for these words and then checks the sentence around it for certain keywords. So in some context, this isn’t correct, but buoy and boy: people sometimes type B-O-Y when they mean B-O-U-Y, so if he sees the word boy, B-O-Y in an article, he would look in the context and see, is this a nautical reference? And if it was, he didn’t autocorrect, he just would flag it up to himself to go, “Oh, check this one out.”

(01:56:23)
And that’s not a great example, but he had thousands of examples, and I was like, “That’s amazing. I would’ve never thought to do that.” And I’m glad that somebody did. And that’s also part of the openness of the system, and also I think being a charity, being this idea of actually, this is a gift to the world that makes someone go, “Oh, well, I’ll put my hand up. I see a little piece of things I can make better because I’m a good programmer and I can write this script to do this thing, and I’ll find it fun,” amazing.
Wikipedia funding
Lex Fridman

(01:56:55)
Well, I got to ask about this big, bold decision at the very beginning to not do advertisements on the website. And just in general, the philosophy of the business model of Wikipedia, what went behind that?
Jimmy Wales

(01:57:06)
Yeah, so I think most people know this, but we’re a charity, so in the US, registered as a charity. And we don’t have any ads on the site. And the vast majority of the money is from donations, but the vast majority from small donors. So, people giving $25 or whatever.
Lex Fridman

(01:57:29)
If you’re listening to this, go donate.
Jimmy Wales

(01:57:31)
Go donate.
Lex Fridman

(01:57:31)
Donate now.
Jimmy Wales

(01:57:33)
$25.
Lex Fridman

(01:57:33)
I’ve donated so many times
Jimmy Wales

(01:57:34)
And we have millions of donors every year, but it’s a small percentage of people. I would say in the early days, a big part of it was aesthetic, almost as much as anything else. It was just like, “I don’t really want ads in Wikipedia. There’s a lot of reasons why it might not be good.” And even back then, I didn’t think as much as I have since about a business model can tend to drive you in a certain place, and really thinking that through in advance is really important because you might say, “Yeah, we’re really, really keen on community control and neutrality,” but if we had an advertising based business model, probably that would begin to erode. Even if I believe in it very strongly, organizations tend to follow the money in the DNA in the long run.

(01:58:25)
And so things like, it’s easy to think about some of the immediate problems. So if you go to read about, I don’t know, Nissan car company, and if you saw an ad for the new Nissan at the top of the page, you might be like, “Did they pay for this?”, or, “Do the advertisers have influence over the content?”, because of wonder about that for all kinds of media.
Lex Fridman

(01:58:53)
And that undermines trust.
Jimmy Wales

(01:58:55)
Undermines trust, right. But also, things like we don’t have clickbait headlines in Wikipedia. You’ve never seen Wikipedia entries with all these kind of listicles, “The 10 funniest cat pictures, number seven will make you cry,” none of that kind of stuff, because there’s no incentive, no reason to do that. Also, there’s no reason to have an algorithm to say, “Actually, we’re going to use our algorithm to drive you to stay on the website longer. We’re going to use the algorithm to drive you to…”, It’s like, “Oh, you’re reading about Queen Victoria. There’s nothing to sell you when you’re reading about Queen Victoria. Let’s move you on to Las Vegas because actually, the ad revenue around hotels in Las Vegas is quite good,” so there’s no incentive for the organization to go, “Oh, let’s move people around to things that have better ad revenue.”

(01:59:48)
Instead, it’s just like, “Oh, well, what’s most interesting to the community?,” just to make those links. So, that decision just seemed obvious to me, but as I say, it was less of a business decision and more of an aesthetic. It’s like, “I like Wikipedia that doesn’t have ads.” In these early days, a lot of the ads, that was well before the era of really quality ad targeting and all that, so you got a lot of-
Lex Fridman

(02:00:18)
Banners.
Jimmy Wales

(02:00:18)
Banners, punch the monkey ads and all that kind of nonsense. But there was no guarantee. It was not really clear, how could we fund this? It was pretty cheap. It still is quite cheap compared to most. We don’t have 100,000 employees and all of that, but would we be able to raise money through donations? And so, I remember the first time that we really did a donation campaign was on a Christmas Day in 2003, I think it was. We had three servers, database servers, and two front end servers, and they were all the same size or whatever, and two of them crashed. They broke, I don’t even know, remember now, the hard drive. It was Christmas Day, so I scrambled on Christmas Day to go onto the database server, which fortunately survived, and have it become a front end server as well. And then, the site was really slow and it wasn’t working very well.

(02:01:28)
And I was like, “Okay, it’s time. We need to do a fundraiser,” and so I was hoping to raise $20,000 in a month’s time, but we raised nearly $30,000 within two, three weeks time. So that was the first proof point of, “Oh, we put a batter up and people will donate,” we just explained we need the money. And we were very small back then, and people were like, “Oh yeah, I love this. I want to contribute.” Then over the years, we’ve become more sophisticated about the fundraising campaigns, and we’ve tested a lot of different messaging and so forth. What we used to think, I remember one year we really went heavy with, “The idea of Wikipedia is a free encyclopedia for every single person on the planet. So what about the languages of Sub-Saharan Africa?”

(02:02:20)
So I thought, “Okay, we’re trying to raise money. We need to talk about that because it’s really important and near and dear to my heart,” and just instinctively knowing nothing about charity fundraising, you see it all around, it’s like, oh, charity’s always mentioned the poor people they’re helping, so let’s talk about. Didn’t really work as well. This is very vague and very broad, but the pitch that works better than any other in general is a fairness pitch of, “You use it all the time, you should probably chip in.” And most people are like, “Yeah, you know what? My life would suck without Wikipedia. I use it constantly and whatever. I should chip in, it just seems like the right thing to do.”

(02:03:02)
And there’s many variants on that, obviously. And it works. And people are like, “Oh yeah, Wikipedia, I love Wikipedia, and I shouldn’t.” So sometimes people say, “Why are you always begging for money on the website?”, and it’s not that often, it’s not that much, but it does happen. They’re like, “Why don’t you just get Google and Facebook and Microsoft, why don’t they pay for it?”, and I’m like, “I don’t think that’s really the right answer.”
Lex Fridman

(02:03:34)
Influence starts to creep in.
Jimmy Wales

(02:03:35)
Influence starts to creep in, and questions start to creep in. The best funding for Wikipedia is the small donors. We also have major donors. We have high net worth people who donate, but we always are very careful about that sort of thing to say, “Wow, that’s really great and really important, but we can’t let that become influence because that would just be really quite not good for Wikipedia.”
Lex Fridman

(02:04:01)
I would love to know how many times I’ve visited Wikipedia, how much time I’ve spent on it, because I have a general sense that it’s the most useful site I’ve ever used, competing maybe with Google search, which ultimately lands on Wikipedia.
Jimmy Wales

(02:04:01)
Yeah, right.
Lex Fridman

(02:04:20)
But if I would just be reminded of like, “Hey, remember all those times your life was make better because of the site?”, I think I would be much more like, “Yeah, why did I waste money on site X, Y, Z when I should be giving a lot of it here?”
Jimmy Wales

(02:04:33)
Well, the Guardian newspaper has a similar model, which is they have ads. There’s no paywall, but they just encourage people to donate, and they do that. I’ve sometimes seen a banner saying, “Oh, this is your 134th article you’ve read this year, would you like to donate?” And I think it’s effective-
Lex Fridman

(02:04:55)
[inaudible 02:04:55].
Jimmy Wales

(02:04:54)
… they’re testing. But also, I wonder just for some people, if they just don’t feel like guilty and then think, “Oh, I shouldn’t bother them so much.” I don’t know. It’s a good question. I don’t know the answer.
Lex Fridman

(02:05:06)
I guess that’s the thing I could also turn on, ’cause that would make me… I feel like legitimately, there’s some sites, this speaks to our social media discussion: Wikipedia unquestionably makes me feel better about myself if I spend time on it. There’s some websites where I’m like, if I spend time on Twitter, sometimes I’m like, I regret. I think Elon talks about this, minimize the number of regretted minutes. My number of regretted minutes on Wikipedia is zero. I don’t remember a time… I’ve just discovered this. I started following on Instagram, a page, depthsofwikipedia.
Jimmy Wales

(02:05:46)
Oh, yeah.
Lex Fridman

(02:05:47)
There’s crazy Wikipedia pages. There’s no Wikipedia page that [inaudible 02:05:51]-
Jimmy Wales

(02:05:51)
Yeah, I gave her a media contributor of the year award this year because she’s so great.
Lex Fridman

(02:05:55)
Yeah, she’s amazing.
Jimmy Wales

(02:05:57)
Depthsofwikipedia is so fun.
Lex Fridman

(02:05:59)
Yeah, that’s the interesting point that I don’t even know if there’s a competitor. There may be the programming, Stack Overflow type of websites, but everything else, there’s always a trade-off. It’s probably because of the ad driven model because there’s an incentive to pull you into clickbait, and Wikipedia has no clickbait. It’s all about the quality of the knowledge and the wisdom.
Jimmy Wales

(02:06:22)
Yeah. No, that’s right. And I also Stack Overflow. Although I wonder what you think of this, so I only program for fun as a hobby, and I don’t have enough time to do it, but I do, and I’m not very good at it. So therefore, I end up on Stack Overflow quite a lot trying to figure out what’s gone wrong. And I have really transitioned to using ChatGPT much more for that because I can often find the answer clearly explained, and it works better than sifting through threads, and I feel bad about that because I do love Stack Overflow and their community. I’m assuming, I haven’t read anything about in the news about it, but I’m assuming they are keenly aware of this, and they’re thinking about, “How can we use this chunk of knowledge that we’ve got here and provide a new type of interface where you can query it with a question and actually get an answer that’s based on the answers that we’ve had?” I don’t know.
Lex Fridman

(02:07:19)
Mm-hmm. And I think Stack Overflow currently has policies against using GPT. There’s a contentious kind of tension.
Jimmy Wales

(02:07:28)
Of course, yeah.
Lex Fridman

(02:07:29)
But they’re trying to figure that out.
Jimmy Wales

(02:07:30)
Well, and so we are similar in that regard. Obviously, all the things we’ve talked about like ChatGPT makes stuff up and it makes up references, so our community has already put into place some policies about it. But roughly speaking, there’s always more nuance. But roughly speaking, it’s, you the human are responsible for what you put into Wikipedia. So, if you use ChatGPT, you better check it, ’cause there’s a lot of great use cases of like, “Oh, well, I’m not a native speaker of German, but I am pretty good,” I’m not talking about myself, a hypothetical me that’s pretty good, and I just want to run my edit through ChatGPT in German to go make sure my grammar’s okay. That’s actually cool.
ChatGPT vs Wikipedia
Lex Fridman

(02:08:15)
Does it make you sad that people might use, increasingly use ChatGPT for something where they would previously use Wikipedia? So basically, use it to answer basic questions about the Eiffel Tower?
Jimmy Wales

(02:08:32)
Yeah. No-
Lex Fridman

(02:08:32)
And where the answer really comes at the source of it from Wikipedia, but they’re using this as an interface.
Jimmy Wales

(02:08:38)
Yeah. No, that’s completely fine. Part of it is our ethos has always been, “Here’s our gift of the world. Make something,” so if the knowledge is more accessible to people, even if they’re not coming through us, that’s fine. Now, obviously we do have certain business model concerns, and where we’ve had more conversation about this, this whole GPT thing is new, things like if you ask Alexa, “What is the Eiffel Tower?”, and she reads you the first two sentences from Wikipedia and doesn’t say it’s from Wikipedia, and they’ve recently started citing Wikipedia, then we worry, “Oh, if people don’t know they’re getting the knowledge from us, are they going to donate money? Or are they just going to think, oh, what’s Wikipedia for? I can just ask Alexa.” It’s like, well, Alexa only knows anything because she read Wikipedia. So we do think about that, but it doesn’t bother me in the sense of like, oh, I want people to always come to Wikipedia first.

(02:09:33)
But we had a great demo, literally just hacked together over a weekend by our head of machine learning where he did this little thing to say, you could ask any question, and he was just knocking it together, so he used OpenAI’s API just to make a demo, asked a question, “Why do ducks fly south for winter?”, which is the kind of thing you think, “Oh, I might just Google for that, or I might start looking in Wikipedia. I don’t know.” And so what he did, he asked ChatGPT, “What are some Wikipedia entries that might answer this?” Then, he grabbed those Wikipedia entries, said, “Here’s some Wikipedia entries. Answer this question based only on the information in this,” and he had pretty good results, and it prevented the making stuff up. Now, it’s just he hacked it together on a weekend, but what it made me think about was, “Oh, okay, so now we’ve got this huge body of knowledge that in many cases you’re like, oh I really I want to know about Queen Victoria. I’m just going to go read the Wikipedia entry and it’s going to take me through her life and so forth.”

(02:10:44)
But other times, you’ve got a specific question, and maybe we could have a better search experience where you can come to Wikipedia, ask your specific question, get your specific answer that’s from Wikipedia, including links to the articles you might want to read next. And that’s just a step forward. That’s just using new type of technology to make the extraction of information from this body of text into my brain faster and easier. So, I think that’s cool.
Lex Fridman

(02:11:10)
I would love to see a ChatGPT grounding into websites like Wikipedia. And the other comparable website to me will be like Wolfram Alpha for more mathematical knowledge, that kind of stuff. So, taking you to a page that is really crafted as opposed to the moment you start actually taking you to journalist websites like news websites, it starts getting a little iffy, because you’re now in a land that has a wrong incentive.
Jimmy Wales

(02:11:44)
Right, yeah.
Lex Fridman

(02:11:45)
You’re pulled in.
Jimmy Wales

(02:11:45)
Yeah, and you need somebody to have filtered through that and tried to knock off the rough edges. Yeah, I think that’s exactly right. And I think that kind of grounding, I think they’re working really hard on it. I think that’s really important-
Jimmy Wales

(02:12:00)
… is, I think they’re working really hard on it. I think that’s really important. And that actually… So if you ask me to step back and be like very business-like about our business model and where’s it going to go for us, and are we going to lose half our donations because everybody’s just going to stop coming to Wikipedia and go to ChatGPT? Well, grounding will help a lot because frankly, most questions people have, if they provide proper links, we’re going to be at the top of that, just like we are in Google. So we’re still going to get tons of recognition and tons of traffic just from… Even if it’s just the moral properness of saying, “Here’s my source.” So I think we’re going to be all right in that.
Lex Fridman

(02:12:39)
Yeah, in the close partnership if the model is fine-tuned, is constantly retrained that Wikipedia is one of the primary places where if you want to change what the model knows, one of the things you should do is contribute to Wikipedia or clarify Wikipedia.
Jimmy Wales

(02:12:53)
Yeah, yeah. No, that’s [inaudible 02:12:55].
Lex Fridman

(02:12:54)
Or elaborate, expand, all that kind of stuff.
Larry Sanger
Jimmy Wales

(02:12:56)
Yeah.
Lex Fridman

(02:12:57)
You mentioned all of us have controversies. I have to ask, do you find the controversy of whether you are the sole founder or the co-founder of Wikipedia ironic, absurd, interesting, important? What are your comments?
Jimmy Wales

(02:13:13)
I would say unimportant. Not that interesting. I mean, one of the things that people are sometimes surprised to hear me say is I actually think Larry Sanger doesn’t get enough credit for his early work in Wikipedia, even though I think co-founder’s not the right title for that. So he had a lot of impact and a lot of great work, and I disagree about a lot of things since and all that, and that’s fine. So yeah. No, to me that’s like, it’s one of these things that the media love a falling out story, so they want to make a big deal out of it, and I’m just like, yeah, no.
Lex Fridman

(02:13:51)
So there’s a lot of interesting engineering contributions in the early days, like you were saying, there’s debates about how to structure it, what the heck is this thing that we’re doing? And there’s important people that contributed to that.
Jimmy Wales

(02:14:02)
Yeah, definitely.
Lex Fridman

(02:14:03)
So he also, you said you’ve had some disagreements. Larry Sanger said that nobody should trust Wikipedia, and that Wikipedia seems to assume that there’s only one legitimate, defensible version of the truth on any controversial question. That’s not how Wikipedia used to be. I presume you disagree with that analysis.
Jimmy Wales

(02:14:21)
Yeah. I mean, just straight up, I disagree. Go and read any Wikipedia entry on a controversial topic, and what you’ll see is a really diligent effort to explain all the relevant sides. So yeah, just disagree.
Lex Fridman

(02:14:32)
So on controversial questions, you think perspectives are generally represented?
Jimmy Wales

(02:14:36)
Yeah.
Lex Fridman

(02:14:37)
Because it has to do with the tension between the mainstream and the non-mainstream that we were talking about.
Jimmy Wales

(02:14:43)
Yeah. No, I mean for sure. To take this area of discussion seriously is to say, yeah, you know what? Actually that is a big part of what Wikipedia and spend their time grappling with is to say, how do we figure out whether a less popular view is pseudoscience? Is it just a less popular view that’s gaining acceptance in the mainstream? Is it fringe versus crackpot, et cetera, et cetera? And that debate is what you’ve got to do. There’s no choice about having that debate of grappling with something. And I think we do. And I think that’s really important. And I think if anybody said to the Wikipedia community, “Gee, you should stop covering minority viewpoints on this issue,”

(02:15:39)
I think they would say, “I don’t even understand why you would say that. We have to grapple with minority viewpoints in science and politics and so on.” And this is one of the reasons why there is no magic simple answer to all these things. It’s really contextual. It’s case by case. It’s like you’ve got to really say, okay, what is the context here? How do you do it? And you’ve always got to be open to correction and to change and to challenge and always be sort of serious about that.
Lex Fridman

(02:16:13)
I think what happens, again, with social media is when there is that grappling process in Wikipedia and a decision is made to remove a paragraph or to remove a thing or to say a thing, you’re going to notice the one direction of the oscillation of the grappling and not the correction. And you’re going to highlight that and say, how come this person… I don’t know, maybe legitimacy of elections that’s the thing that comes up. Donald Trump maybe previously-
Jimmy Wales

(02:16:42)
Yeah, I can give a really good example, which is, there was this sort of dust up about the definition of recession in Wikipedia. The accusation was often quite ridiculous and extreme, which is, under pressure from the Biden administration Wikipedia changed the definition of recession to make Biden look good, or we did it not under pressure, but because we’re a bunch of lunatic leftists and so on. And then when I see something like that in the press, I’m like, “Oh dear, what’s happened here? How do we do that?” Because I always just accept things for five seconds first, and then I go and I look and I’m like, “You know what? That’s literally completely not what happened.” What happened was, one editor thought the article needed restructuring. So the article is always said, so the traditional kind of loose definition of recession is two quarters of negative growth, but there’s always been within economics, within important agencies and different countries around the world, a lot of nuance around that.

(02:17:43)
And there’s other factors that go into it and so forth. And then it’s just an interesting complicated topic. And so the article has always had the definition of two quarters. And the only thing that really changed was moving that from the lead, from the top paragraph to further down. And then news stories appeared saying, “Wikipedia has changed the definition of recession.” And then we got a huge rush of trolls coming in. So the article was temporarily protected, I think, only semi protected, and people were told, “Go to the talk page to discuss.” So anyway, it was a dust up that was… When you look at it as a Wikipedian, you’re like, “Oh, this is a really routine kind of editorial debate.” Another example, which unfortunately our friend Elon fell for, I would say, is the Twitter files. So there was an article called the Twitter files, which is about these files that were released once Elon took control of Twitter, and he released internal documents.
Twitter files

(02:18:36)
And what happened was somebody nominated it for deletion, but even the nomination said, “This is mainly about the Hunter Biden laptop controversy, shouldn’t this information be there instead?” So anyone can… It takes exactly one human being anywhere on the planet to propose something for deletion, and that triggers a process where people discuss it, which within a few hours, it was what we call snowball closed i.e, this doesn’t have a snowball’s chance in hell of passing. So an admin goes, “Yeah, wrong,” and closed the debate, and that was it. That was the whole thing that happened. And so nobody proposed suppressing the information. Nobody proposed it wasn’t important, it was just editorially boring internal questions. So sometimes people read stuff like that and they’re like, “Oh, you see, look at these leftists. They’re trying to suppress the truth again.” It’s like, well slow down a second and come and look, literally, it’s not what happened.
Lex Fridman

(02:19:36)
So I think the right is more sensitive to censorship, and so they will more likely highlight there’s more virality to highlighting something that looks like censorship in any walks of life. And this moving a paragraph from one place to another, or removing it and so on, as part of the regular grappling of Wikipedia can make a hell of a good article or YouTube video.
Jimmy Wales

(02:20:01)
Oh, yeah. Yeah. No, it sounds really in enticing and intriguing and surprising to most people because they’re like, “Oh, no, I’m reading Wikipedia. It doesn’t seem like a crackpot leftist website. It seems pretty kind of dull, really in its own geeky way.” And so that makes a good story. It’s like, oh, am I being misled? Because there’s a shadowy cabal of Jimmy Wales.
Lex Fridman

(02:20:25)
I generally, I read political stuff. I mentioned to you that I’m traveling to have some very difficult conversation with high profile figures both in the war in Ukraine and in Israel and Palestine. And I read the Wikipedia articles around that, and I also read books on the conflict and the history of the different regions. And I find the Wikipedia articles to be very balanced, and there’s many perspectives being represented. But then I ask myself, “Well, am I one of them leftist crackpots?” They can’t see the truth. I mean, it’s something I ask myself all the time, forget the leftist, just crackpot in general. Am I just being a sheep and accepting it? And I think that’s an important question to always ask, but not too much.
Jimmy Wales

(02:21:12)
Yeah. No, I agree.
Lex Fridman

(02:21:12)
A little bit, but not too much.
Jimmy Wales

(02:21:15)
Yeah. No, I think we always have to challenge ourselves of what do I potentially have wrong?
Government and censorship
Lex Fridman

(02:21:20)
Well, you mentioned pressure from government. You’ve criticized Twitter for giving in to Turkey’s government censorship. There’s also conspiracy theories or accusations of Wikipedia being open to pressure from government to government organizations, FBI and all this kind of stuff. What is the philosophy about pressure from government and censorship?
Jimmy Wales

(02:21:50)
So we’re super hardcore on this. We’ve never bowed down to government pressure anywhere in the world, and we never will. And we understand that we’re hardcore. And actually there is a bit of nuance about how different companies respond to this, but our response has always been just to say no. And if they threaten to block, well, knock yourself out, you’re going to lose Wikipedia. And that’s been very successful for us as a strategy because governments know they can’t just casually threaten to block Wikipedia or block us for two days, and we’re going to cave in immediately to get back into the market. And that’s what a lot of companies have done. And I don’t think that’s good that we can go one level deeper and say, I’m actually quite sympathetic. If you have staff members in a certain country and they are at physical risk, you’ve got to put that into your equation.

(02:22:43)
So I understand that. If Elon said, “Actually, I’ve got a hundred staff members on the ground in such and such a country, and if we don’t comply, somebody’s going to get arrested. And it could be quite serious.” Okay, that’s a tough one. That’s actually really hard. But yeah, no. And then the FBI one, no, the criticism I saw. I kind of prepared for this because I saw people responding to your request for questions, and I was like, somebody’s like, “Oh, well, don’t you think it was really bad that you da da da, da?” I actually reached out to [inaudible 02:23:18] and said, “Can you just make sure I’ve got my facts right?” And the answer is, we received zero requests of any kind from the FBI or any of the other government agencies for any changes to content in Wikipedia. And had we received those requests at the level of the Wikipedia Foundation, we would’ve said, “We can’t do anything because Wikipedia is written by the community.”

(02:23:40)
And so the Wikimedia Foundation can’t change the content of Wikipedia without causing… I mean, God, that would be a massive controversy, you can’t even imagine. What we did do, and this is what I’ve done, I’ve been to China and met with the Minister of Propaganda. We’ve had discussions with governments all around the world, not because we want to do their bidding, but because we don’t want to do their bidding, but we also don’t want to be blocked. And we think actually having these conversations are really important. There’s no threat of being blocked in the US. That’s just never going to happen. There is the First Amendment. But in other countries around the world, it’s like, “Okay, what are you upset about? Let’s have the conversation. Let’s understand, and let’s have a dialogue about it so that you can understand where we come from and what we’re doing and why.”

(02:24:26)
And then sometimes it’s like, gee, if somebody complains that something’s bad in Wikipedia, whoever they are, don’t care who they are. It could be you, it could be the government, it could be the Pope. I don’t care who they are. It’s like, oh, okay. Well, our responsibility as Wikipedia is to go, “Oh, hold on, let’s check is that right or wrong? Is there something that we’ve got wrong in Wikipedia? Not because you’re threatening to block us, but because we want Wikipedia to be correct.” So we do have these dialogues with people. And a big part of what was going on with, you might call it pressure on social media companies or dialogue with, as we talked earlier, grapple with the language depending on what your view is. In our case, it was really just about, oh, okay, they want to have a dialogue about COVID information, misinformation.

(02:25:22)
We are this enormous source of information which the world depends on. We’re going to have that conversation. We’re happy to say, here’s… If they say, how do you know that Wikipedia is not going to be pushing some crazy anti-vax narrative first? I mean, I think it’s somewhat inappropriate for a government to be asking pointed questions in a way that implies possible penalties. I’m not sure that ever happened because we would just go, I don’t know, the Chinese blocked us. So it goes, right? We’re not going to cave into any kind of government pressure, but whatever the appropriateness of what they were doing, I think there is a rule for government in just saying, let’s understand the information ecosystem. Let’s think about the problem of misinformation, disinformation in society, particularly around election security, all these kinds of things. So I think it would be irresponsible of us to get a call from a government agency and say, “Yeah, why don’t you just fuck off? You’re the government.” But it would also be irresponsible to go, “Oh, dear, government agent’s not happy. Let’s fix Wikipedia so the FBI loves us.”
Lex Fridman

(02:26:35)
And when you say you want to have discussions with the Chinese government or with organizations like CDC and WHO, it’s to thoroughly understand what the mainstream narrative is so that it can be properly represented, but not drive what the articles are?
Jimmy Wales

(02:26:50)
Well, it’s actually important to say whatever the Wikimedia Foundation thinks has no impact on what’s in Wikipedia. So it’s more about saying to them, “We understand you’re the World Health Organization, or you’re whoever, and part of your job is to… Public health is about communications. You want to understand the world.” So it’s more about, “Well, let’s explain how Wikipedia works.”
Lex Fridman

(02:27:18)
So it’s more about explaining how Wikipedia works and like, “Hey, it’s the volunteers”?
Jimmy Wales

(02:27:22)
Yeah, exactly.
Lex Fridman

(02:27:23)
It’s a battle of ideas, and here’s how the sources are used.
Jimmy Wales

(02:27:29)
Yeah, exactly.
Lex Fridman

(02:27:30)
What are the legitimate sources and what not a legitimate source is.
Jimmy Wales

(02:27:32)
Yeah, exactly.
Lex Fridman

(02:27:33)
I mean, I suppose there’s some battle about what is a legitimate source. There could be statements made that CDC… There’s government organizations in general have sold themselves to be the place where you go for expertise. And some of that has been to small degree, raised in question over the response to the pandemic.
Jimmy Wales

(02:27:57)
Well, I think in many cases, and this goes back to my topic of trust. So there were definitely cases of public officials, public organizations where I felt like they lost the trust of the public because they didn’t trust the public. And so the idea is, we really need people to take this seriously and take actions, therefore, we’re going to put out some overblown claims because it’s going to scare people into behaving correctly. You know what? That might work for a little while, but it doesn’t work in the long run because suddenly people go from a default stance of… Like the Center for Disease Control, very well respected scientific organization. I don’t know. They’ve got fault in Atlanta with the last file of smallpox or whatever it is that people think about them. And to go, “Oh, right, these are scientists we should actually take seriously and listen to, and they’re not politicized.”

(02:28:58)
It’s like, okay. And if you put out statements, and I don’t know if the CDC did, but Who Health Organization, whoever, that are provably false and also provably, you kind of knew they were false, but you did it to scare people because you wanted them to do the right thing. It’s like, no, you know what? That’s not going to work in the long run. You’re going to lose people, and now you’ve got a bigger problem, which is a lack of trust in science, a lack of trust in authorities who are, by and large, they’re like quite boring government bureaucrat scientists who just are trying to help the world.
Lex Fridman

(02:29:31)
Well, I’ve been criticized, and I’ve been torn on this. I’ve been criticized for criticizing Anthony Fauci too hard. The degree to which I criticized him is because he’s a leader. And I’m just observing the effect in the loss of trust in the institutions like the NIH that where I personally know there’s a lot of incredible scientists doing incredible work, and I have to blame the leaders for the effects on the distrust and the scientific work that they’re doing because of what I perceive as basic human flaws of communication, of arrogance, of ego, of politics, all those kinds of things. Now, you could say, “You’re being too harsh,” possible, but I think that’s the whole point of free speech is you can criticize people who lead. Leaders, unfortunately or fortunately, are responsible for the effects on society.

(02:30:28)
To me, Anthony Fauci or whoever in the scientific position around the pandemic had an opportunity to have a FDR moment or to get everybody together, inspire about the power of science to rapidly develop a vaccine that saves us from this pandemic and future pandemic that can threaten the wellbeing of human civilization. This was epic and awesome and sexy. And to me, when I’m talking to people about science, it’s anything but sexy in terms of the virology and biology development because it’s been politicized. It’s icky, and people just don’t want to… “Don’t talk to me about the vaccine. I understand. I understand. I got vaccinated.” There’s just, “Let’s switch topics quick.”
Jimmy Wales

(02:31:11)
Yeah, yeah. Well, it’s interesting because as I say, I live in the UK and I think all these things are a little less politicized there. And I haven’t paid close enough attention to Fauci to have a really strong view. I’m sure I would disagree with some things. I remember hearing at the beginning of the pandemic as I’m unwrapping my Amazon package with these masks I bought because I heard there’s a pandemic. And I just was like, “I want some N95 mask, please.” And they were saying, “Don’t buy masks.” And the motivation was because they didn’t want there to be shortages in hospitals. Fine. But there were also statements of masks, they’re not effective and they won’t help you. And then the complete about phase two, you’re ridiculous if you’re not wearing a… It’s just like, no, that about face just lost people from day one.
Lex Fridman

(02:32:06)
The distrust in the intelligence of the public to deal with nuance, to deal with the uncertainty.
Jimmy Wales

(02:32:11)
Yeah. This is exactly what… I think this is where the Wikipedia neutral point of view is and should be in ideally. And obviously every article and everything we could… You know me now and you know how I am about these things, but ideally, it’s to say, look, we’re happy to show you all the perspectives. This is Planned Parenthood’s view, and this is Catholic Church view, and we’re going to explain that, and we’re going to try to be thoughtful and put in the best arguments from all sides, because I trust you. You read that and you’re going to be more educated and you’re going to begin to make a decision. I mean, I can just talk in the UK, the government, da, da, da. When we found out in the UK that very high level government officials were not following the rules they had put on everyone else. I had just become a UK citizen just a little while before the pandemic, and it’s kind of emotional. You get a passport in a new country and you feel quite good.

(02:33:09)
I did my oath to the Queen, and then they dragged the poor old lady out to tell us all to be good. I was like, “We’re British and we’re going to do the right things, and it’s going to be tough, but going to…” So you have that kind of Dunkirk spirit moment, and you’re following the rules to a T, and then suddenly it’s like, well, they’re not following the rules. And so suddenly I shifted personally from, “I’m going to follow the rules, even if I don’t completely agree with them, but I’ll still follow because I think we’ve got to all chip in together,” to, “You know what? I’m going to make wise and thoughtful decisions for myself and my family.” And that generally is going to mean following the rules. But it’s basically when they’re at certain moments in time, you’re not allowed to be in an outside space unless you’re exercising. I’m like, I think I can sit in a park and read a book. It’s going to be fine. That’s irrational rule, which I would’ve been following just personally of like, I’m just going to do the right thing.
Lex Fridman

(02:34:06)
And the loss of trust, I think, at scale was probably harmful to science. And to me, the scientific method and the scientific community is one of the biggest hopes, at least to me, for the survival and the thriving of human civilization.
Jimmy Wales

(02:34:22)
Absolutely. And I think you see some of the ramifications of this. There’s always been pretty anti-science, anti-vax people. That’s always been a thing, but I feel like it’s bigger now simply because of that lowering of trust. So a lot of people, maybe it’s like you say, a lot of people are like, “Yeah, I got vaccinated, but I really don’t want to talk about this because it’s so toxic.” And that’s unfortunate because I think people should say, “What an amazing thing.” There’s also a whole range of discourse around if this were a disease that was primarily killing babies, I think people’s emotions about it would’ve been very different, right or wrong. Then the fact that when you really looked at the death rate of getting COVID, wow, it’s really dramatically different. If you’re late in life, this was really dangerous. And if you’re 23 years old, yeah, well, it’s not great. And long COVID is a thing and all of that. And I think some of the public communications, again, were failing to properly contextualize it. Not all of it. It’s a complicated matter, but yeah.
Adolf Hitler’s Wikipedia page
Lex Fridman

(02:35:45)
Let me read you a Reddit comment that received two likes.
Jimmy Wales

(02:35:48)
Oh, two whole people liked it.
Lex Fridman

(02:35:52)
Yeah, two people liked it. And I don’t know, maybe you can comment on whether there’s truth to it, but I just found it interesting because I’ve been doing a lot of research on World War II recently. So this is about Hitler.
Jimmy Wales

(02:36:06)
Oh, okay.
Lex Fridman

(02:36:06)
It’s a long statement. “I was there when a big push was made to fight bias at Wikipedia. Our target became getting the Hitler article to be Wiki’s featured article. The idea was that the voting body only wanted articles that were good PR and especially articles about socially liberal topics. So the Hitler article had to be two to three times better and more academically researched to beat the competition. This bias seems to hold today, for example, the current list of political featured articles at a glance seems to have only two books, one on anarchism and one on Karl Marx. Surely we’re not going to say there have only ever been two articles about political non-biography books worth being featured, especially compared to 200 plus video games. And that’s the only topics with good books are socialism and anarchy.” Do you have any interesting comments on this kind of-
Jimmy Wales

(02:36:06)
Oh, yeah.
Lex Fridman

(02:37:00)
[inaudible 02:37:00] featured, how the featured is selected, maybe Hitler, because he is a special figure [inaudible 02:37:09] kind of stuff.
Jimmy Wales

(02:37:09)
I love that. No, I love the comparison to how many video games, and that definitely speaks to my earlier is like, if you’ve got a lot of young geeky men who really like video games, that doesn’t necessarily get you to the right place in every respect. Certainly. Yeah. So here’s a funny story. I woke up one morning to a bunch of journalists in Germany trying to get in touch with me because German language, Wikipedia chose to have as the featured article of the day, Swastika. And people were going crazy about it, and some people were saying, “It’s illegal. Has German Wikipedia been taken over by Nazi sympathizers,” and so on? And it turned out it’s not illegal, discussing the swastika. Using the swastika as a political campaign and using it in certain ways is illegal in Germany in a way that it wouldn’t be in the US because the First Amendment, but in this case, it was like actually part of the point is the swastika symbol is from other cultures as well.

(02:38:17)
I just thought it was interesting. I did joke to the community, I’m like, “Please don’t put the swastika on the front page without warning me because I’m going to get [inaudible 02:38:25].” It wouldn’t be me, it’s the foundation. I’m not that much on the front lines. So I would say that to put Hitler on the front page of Wikipedia, it is a special topic. And you would want to say, “Yeah, let’s be really careful that it’s really, really good before we do that,” because if we put it on the front page and it’s not good enough, that could be a problem. There’s no inherent reason. Clearly, World War II is a very popular topic in Wikipedia. It’s like, turn on the history channel. People, it’s a fascinating period of history that people are very interested in. And then on the other piece, like anarchism and Karl Marx.
Lex Fridman

(02:39:05)
Karl Marx. Yeah.
Jimmy Wales

(02:39:06)
Oh, yeah. I mean, that’s interesting. I’m surprised to hear that not more political books or topics have made it to the front page.
Lex Fridman

(02:39:15)
Now we’re taking this Reddit a comment.
Jimmy Wales

(02:39:16)
I mean, as if-
Lex Fridman

(02:39:17)
That’s face value.
Jimmy Wales

(02:39:18)
… it’s completely… But I’m trusting. So I think that’s probably is right. They probably did have the list up. No, I think that piece… The piece about how many of those featured articles have been video games, and if it’s disproportionate, I think the community should go, “Actually, what’s gone? That doesn’t seem quite right.” I mean, you can imagine that because you’re looking for an article to be on the front page of Wikipedia, you want to have a bit of diversity in it. You want it to be not always something that’s really popular that week, so I don’t know, the last couple of weeks, maybe succession, the big finale of succession might lead you think, oh, let’s put succession on the front page, that’s going to be popular. In other cases, you kind of want to pick something super obscure and quirky because people also find that interesting and fun. Yeah, I don’t know. But you don’t want it to be video games most of the time. That sounds quite bad.
Lex Fridman

(02:40:17)
Well, let me ask you just as somebody who’s seen the whole thing, the development of the millions of articles. Big impossible question, what’s your favorite article?
Jimmy Wales

(02:40:33)
My favorite article? Well, I’ve got an amusing answer, which is possibly also true. There’s an article in Wikipedia called Inherently Funny Words, and one of the reasons I love it is when it was created early in the history of Wikipedia, it kind of became like a dumping ground. People would just come by and write in any word that they thought sounded funny. And then it was nominated for deletion because somebody’s like, “This is just a dumping ground. People are putting all kinds of nonsense in.” And in that deletion debate, somebody came forward and said essentially, “Wait a second, hold on. This is actually a legitimate concept in the theory of humor and comedy. And a lot of famous comedians and humorists have written about it.” And it’s actually a legitimate topic. So then they went through and they meticulously referenced every word that was in there and threw out a bunch that weren’t.

(02:41:29)
And so it becomes this really interesting. And now my biggest disappointment, and it’s the right decision to make because there was no source, but it was a picture of a cow, but there was a rope around its head tying on some horns onto the cow. So it was kind of a funny looking picture. It looked like a bull with horns, but it’s just a normal milk cow. And below it, the caption said, “According to some, cow is an inherently funny word,” which is just hilarious to me, partly because the “According to some” sounds a lot like Wikipedia, but there was no source. So it went away, and I know I feel very sad about that, but I’ve always liked that. And actually the reason Depths of Wikipedia amuses me so greatly is because it does highlight really interesting obscure stuff, and you’re like, “Wow, I can’t believe somebody wrote about that in Wikipedia. It’s quite amusing.” And sometimes there’s a bit of rye humor in Wikipedia. There’s always a struggle. You’re not trying to be funny, but occasionally a little inside humor can be quite healthy.
Lex Fridman

(02:42:40)
Apparently words with the letter K are funny. There’s a lot of really well researched stuff on this page. It’s actually exciting. And I should mention for Depths of the Wikipedia, it’s run by Annie Rauwerda.
Jimmy Wales

(02:42:56)
That’s right, Annie.
Lex Fridman

(02:42:57)
And let me just read off some of the pages. Octopolis and Octlantis-
Jimmy Wales

(02:43:05)
Oh yeah, that was…
Lex Fridman

(02:43:05)
… are two separate non-human underwater settlements built by the gloomy octopuses in Jarvis Bay East Australia. The first settlement named Octopolis by a biologist was founded in 2009. The individual structures in Octopolis consists of borrows around a piece of human detritus believed to be scrap metal, and it goes on in this way.
Jimmy Wales

(02:43:29)
That’s great.
Lex Fridman

(02:43:30)
Satiric misspelling, least concerned species. Humans were formally assessed as a species of least concern in 2008. I think Hitchhiker’s Guide to the Galaxy would slightly disagree. And the last one, let me just say, friendship paradox is the phenomena first observed by the sociologist Scott Feld in 1991, that on average an individual’s friends have more friends than that individual.
Jimmy Wales

(02:43:58)
Oh, that’s really interesting.
Lex Fridman

(02:43:58)
That’s very lonely.
Jimmy Wales

(02:44:00)
That’s the kind of thing that makes you want to… It sounds implausible at first because shouldn’t everybody have on average, about the same number of friends as all their friends? So you really want to dig into the math of that and really think, oh, why would that be true?
Lex Fridman

(02:44:13)
And it’s one way to feel more lonely in a mathematically rigorous way. Somebody else on Reddit asks, “I would love to hear some war stories from behind the scenes.” Is there something that we haven’t mentioned that was particularly difficult in this entire journey you’re on with Wikipedia?
Jimmy Wales

(02:44:32)
I mean, yeah, it’s hard to say. So part of what I always say about myself is that I’m a pathological optimist, so I always think everything is fine. And so things that other people might find a struggle, I’m just like, “Oh, well, this is the thing we’re doing today.” So that’s kind of about me, and it’s actually… I’m aware of this about myself, so I do like to have a few pessimistic people around me to keep me a bit on balance. I mean, I would say some of the hard things, I mean, there were hard moments like when two…
Jimmy Wales

(02:45:00)
I would say some of the hard things. I mean, there were hard moments when two out of three servers crashed on Christmas Day and then we needed to do a fundraiser and no idea what was going to happen. I would say as well, in that early period of time, the growth of the website and the traffic to the website was phenomenal and great. The growth of the community and in fact the healthy growth of the community was fine.

(02:45:29)
And then the Wikimedia Foundation, the nonprofit I set up to own and operate Wikipedia as a small organization, it had a lot of growing pains. That was the piece that’s just many companies or many organizations that are in a fast growth. It’s like you’ve hired the wrong people, or there’s this conflict that’s arisen and nobody has got experience to do this and all that. So, no specific stories to tell, but I would say growing the organization was harder than growing the community and growing the website, which is interesting.
Lex Fridman

(02:46:02)
Well, yeah. It’s kind of miraculous and inspiring that a community can emerge and be stable, and that has so much kind of productive, positive output. Kind of makes you think. It’s one of those things you don’t want to analyze too much because you don’t want to mess with a beautiful thing, but it gives me faith in communities. I think that they can spring up in other domains as well.
Jimmy Wales

(02:46:29)
Yeah, I think that’s exactly right. At Fandom, my for-profit wiki company where it’s all these communities about pop culture mainly, sort of entertainment, gaming and so on, there’s a lot of small communities. So, I went last year to our Community Connect conference and just met some of these people, and here’s one of the leaders of the Star Wars wiki, which is called Wookieepedia, which I think is great. And he’s telling me about his community and all that. And I’m like, “Oh, right. Yeah, I love this.”

(02:47:03)
So, it’s not the same purpose as Wikipedia of a neutral, high quality encyclopedia, but a lot of the same values are there of like, “Oh, people should be nice to each other.” It’s like when people get upset, just remember we’re working on Star Wars wiki together, there’s no reason to get too outraged. And just kind people just, just geeky people with a hobby.
Future of Wikipedia
Lex Fridman

(02:47:27)
Where do you see Wikipedia in 10 years, 100 years, and 1,000 years?
Jimmy Wales

(02:47:35)
Right. So, 10 years, I would say pretty much the same. We’re not going to become TikTok with entertainment deals, scroll by video humor, and blah-blah-blah, and encyclopedia. I think in 10 years, we probably will have a lot more AI supporting tools like I’ve talked about, and probably your search experience would be you can ask a question and get the answer rather than from our body of work.
Lex Fridman

(02:48:09)
So, search and discovery, a little bit improved, interface, some of that.
Jimmy Wales

(02:48:12)
Yeah, all that. I always say one of the things that most people won’t notice, because already they don’t notice it, is the growth of Wikipedia in the languages of the developing world. So, you probably don’t speak Swahili, so you’re probably not checking out that Swahili Wikipedia is doing very well, and it is doing very well. And I think that kind of growth is actually super important. It’s super interesting, but most people won’t notice that.
Lex Fridman

(02:48:41)
If we can just link on that if we could, do you think there’s so much incredible translation work is being done with AI, with language models? Do you think that can accelerate Wikipedia?
Jimmy Wales

(02:48:55)
Yeah, I do.
Lex Fridman

(02:48:55)
So, you start with the basic draft of the translation of articles and then build on top of that.
Jimmy Wales

(02:49:00)
What I used to say is machine translation for many years wasn’t much used to the community, because it just wasn’t good enough. As it’s gotten better, it’s tended to be a lot better in what we might call economically important languages, that’s because the corpus that they train on and all of that.

(02:49:20)
So, to translate from English to Spanish, if you’ve tried Google Translate recently Spanish to English is what I would do, it’s pretty good. It’s actually not bad. It used to be half a joke and then for a while it was kind of like, “Well, you can get the gist of something.” And now, actually, it’s pretty good. However, we’ve got a huge Spanish community who write in native Spanish, so they’re able to use it and they find it useful, but they’re writing.

(02:49:44)
But if you tried to do English to Zulu where there’s not that much investment, there’s loads of reasons to invest in English-Spanish, because they’re both huge, economically important languages. Zulu not so much. So, for those smaller languages, it was just still terrible. My understanding is it’s improved dramatically and also because the new methods of training don’t necessarily involve identical corpuses to try to match things up, but rather reading and understanding with tokens and large language models, and then reading and understanding, and then you get a much richer …

(02:50:22)
Anyway, apparently it’s quite improved, so I think that now, it is quite possible that these smaller language communities are going to say, “Oh, well finally, I can put something in an English and I can get out Zulu that I feel comfortable sharing with my community because it’s actually good enough, or I can edit it a bit here and there.” So, I think that’s huge. So, I do think that’s going to happen a lot and that’s going to accelerate, again, what will remain to most people an invisible trend, but that’s the growth in all these other languages. So, then move on to 100 years.
Lex Fridman

(02:50:52)
I was starting to get scary.
Jimmy Wales

(02:50:54)
Well, the only thing I’d say about 100 years is we’ve built the Wikimedia Foundation, and we run it in a quite cautious, and financially conservative, and careful way. So, every year, we build our reserves. Every year, we put aside a little bit of more money. We also have the endowment fund, which we just passed 100 million, that’s a completely separate fund with a separate board. So, it’s not just a big fat bank account for some future profligate CEO to blow through. The foundation will have to get the approval of a second order board to be able to access that money, and that board can make other grants through the community and things like that.

(02:51:38)
So, the point of all that is I hope and believe that we are building in a financially stable way that we can weather various storms along the way, so that hopefully we’re not taking the kind of risks. And by the way, we’re not taking too few risks either. That’s always hard. I think the Wikimedia Foundation and Wikipedia will exist in 100 years if anybody exists in 100 years, we’ll be there.
Lex Fridman

(02:52:06)
Do you think the internet just looks a predictably different, just the web?
Jimmy Wales

(02:52:11)
I do. I think right now, this sort of enormous step forward we’ve seen and has become public in the last year of the large language models really is something else. It’s really interesting. You and I have both talked today about the flaws and the limitations, but still it’s … As someone who’s been around technology for a long time, it’s sort of that feeling of the first time I saw a web browser, the first time I saw the iPhone, the first time the internet was really usable on a phone. And it’s like, “Wow, that’s a step change difference.” There’s a few other …
Lex Fridman

(02:52:48)
Maybe a Google Search.
Jimmy Wales

(02:52:49)
Google Search was actually one.
Lex Fridman

(02:52:51)
I remember the first Search.
Jimmy Wales

(02:52:51)
Because I remember Alta Vista was kind of cool for a while, then it just got more and more useless, because the algorithm wasn’t good. And it’s like, “Oh, Google Search, now I like the internet, it works again.” And so, large language model, it feels like that to me. Like, “Oh, wow, this is something new and really pretty remarkable.” And it’s going to have some downsides. The negative use case …

(02:53:14)
People in the area who are experts, they’re giving a lot of warnings. I’m not that worried, but I’m a pathological optimist. But I do see some really low-hanging fruit bad things that can happen. My example is, how about some highly customized spam where the email that you receive isn’t just misspelled words and trying to get through filters, but actually as a targeted email to you that knows something about you by reading your LinkedIn profile and writes a plausible email that will get through the filters. And it’s like suddenly, “Oh, that’s a new problem. That’s going to be interesting.”
Lex Fridman

(02:53:55)
Just on the Wikipedia editing side, does it make the job of the volunteer of the editor more difficult in a world where larger and larger percentage of the internet is written by an LLM?
Jimmy Wales

(02:54:08)
One of my predictions, and we’ll see, ask me again in five years how this panned out, is that in a way, this will strengthen the value and importance of some traditional brands. So, if I see a news story and it’s from the Wall Street Journal, from the New York Times, from Fox News, I know what I’m getting and I trust it to whatever extent I might have, trust or distrust in any of those.

(02:54:43)
And if I see a brand new website that looks plausible, but I’ve never heard of it, and it could be machine generated content that may be full of errors, I think I’ll be more cautious. I think I’m more interested. And we can also talk about this around photographic evidence. So, obviously, there will be scandals where major media organizations get fooled by a fake photo.

(02:55:04)
However, if I see a photo of the recent ones, the Pope wearing an expensive puffer jacket, I’m going to go, “Yeah, that’s amazing that a fake like that could be generated.” But my immediate thought is not, “Oh, so the Pope is dipping into the money, eh? Partly because this particular Pope doesn’t seem like he’d be the type.”
Lex Fridman

(02:55:25)
My favorite is extensive pictures of Joe Biden and Donald Trump hanging out and having fun together.
Jimmy Wales

(02:55:31)
Yeah. Brilliant. So, I think people will care about the provenance of a photo. And if you show me a photo and you say, “Yeah, this photo is from Fox News,” even though I don’t necessarily think that’s the highest, but I’m like, “Wow, it’s a news organization and they’re going to have journalism, and they’re going to make sure the photo is what it purports to be.”

(02:55:55)
That’s very different from a photo randomly circulating on Twitter. Whereas I would say, 15 years ago, a photo randomly circulating on Twitter, in most cases, the worst you could do, and this did happen, is misrepresent the battlefield. So, like, “Oh, here’s a bunch of injured children. Look what Israel has done.” But actually, it wasn’t Israel, it was another case 10 years ago. That has happened, that has always been around. But now, we can have much more specifically constructed, plausible looking photos that if I just see them circulating on Twitter, I’m going to go, “I just don’t know. Not sure. I can make that in five minutes.”
Lex Fridman

(02:56:32)
Well, I also hope that it’s kind of like what you’re writing about in your book that we could also have citizen journalists that have a stable, verifiable trust that builds up. So, it doesn’t have to be in New York Times with this organization that you could be in an organization of one as long as it’s stable and carries through time and it builds up or it goes up.
Jimmy Wales

(02:56:52)
No, I agree. But the one thing I’ve said in the past, and this depends on who that person is and what they’re doing, but it’s like I think my credibility, my general credibility in the world should be the equal of a New York Times reporter. So, if something happens, and I witness it, and I write about it, people are going to go, “Well, Jimmy Wales said it. That’s just like if a New York Times reporter said it. I’m going to tend to think he didn’t just make it up.”

(02:57:18)
The truth is nothing interesting ever happens around me. I don’t go to war zones. I don’t go to big press conferences. I don’t interview Putin and Zelenskyy. To an extent, yes. Whereas I do think for other people, those traditional models of credibility are really, really important. And then there is this sort of citizen journalism. I don’t know if you think of what you do as journalism. I kind of think it is, but you do interviews, you do long form interviews.

(02:57:49)
If you come and you say, “Here’s my tape,” but you wouldn’t hand out a tape. I just gesture to you as if I’m handing you a cassette tape. But if you put it into your podcast, ” Here’s my interview with Zelenskyy.” And people aren’t going to go, “Yeah, how do we know? That could be a deep fake. You could have faked that.” Because people are like, “Well, no, you’re a well known podcaster and you do interview interesting people. Yeah, you wouldn’t think that.” So, that your brand becomes really important.

(02:58:19)
Whereas if suddenly, and I’ve seen this already, I’ve seen sort of video with subtitles in English, and apparently the Ukrainian was the same and it was Zelenskyy saying something really outrageous. And I’m like, “Yeah, I don’t believe that. I don’t think he said that in a meeting with whatever. I think that’s Russian propaganda or probably just trolls.”
Lex Fridman

(02:58:42)
Yeah. And then building platforms and mechanisms of how that trust can be verified. If something appears on a Wikipedia page, that means something. If something appears on my Twitter account, that means something. That means I, this particular human, have signed off on it.
Jimmy Wales

(02:58:58)
Yeah, exactly.
Lex Fridman

(02:58:58)
And then the trust you have in this particular human transfers to the piece of content. Hopefully, there’s millions of people with different metrics of trust. And then you could see that there’s a certain kind of bias in the set of conversations you’re having. So, maybe okay, I trust this person, I have this kind of bias and I’ll go to this other person with this other kind of bias and I can integrate them in this kind of way. Just like you said with Fox News and whatever [inaudible 02:59:24].
Jimmy Wales

(02:59:23)
Yeah. Wall Street Journal, New York Times, they’ve all got where they sit. Yeah.
Advice for young people
Lex Fridman

(02:59:29)
So, you have built, I would say, one of if not the most impactful website in the history of human civilization. So, let me ask for you to give advice to young people how to have impact in this world. High schoolers, college students wanting to have a big positive impact on the world.
Jimmy Wales

(02:59:50)
Yeah, great. If you want to be successful, do something you’re really passionate about rather than some kind of cold calculation of what can make you the most money. Because if you go and try to do something and you’re like, “I’m not that interested, but I’m going to make a lot of money doing it,” you’re probably not going to be that good at it. And so, that is a big piece of it.

(03:00:12)
For startups, I give this advice. And this is a career startup, any kind of young person just starting out is be persistent. There will be moments when it’s not working out and you can’t just give up too easily. You’ve got to persist through some hard times. Maybe two servers crash on a Sunday, and you’ve got to scramble to figure it out, but persist through that, and then also be prepared to pivot. That’s a newer word, new for me. But when I pivoted from Nupedia to Wikipedia it’s like, “This isn’t working. I’ve got to completely change.” So, be willing to completely change direction when something is not working.

(03:00:54)
Now, the problem with these two wonderful pieces of advice is, which situation am I in today? Is this a moment when I need to just power through and persist because I’m going to find a way to make this work? Or is this a moment where I need to go, “Actually, this is totally not working and I need to change direction?” But also, I think for me, that always gives me a framework of like, “Okay, here’s the problem. Do we need to change direction, or do we need to power through it?” And just knowing those are the choices. Not always the only choices, but those choices.

(03:01:27)
I think it can be helpful to say, “Okay, am I chickening out because I’m having a little bump, and I’m feeling unemotional, and I’m just going to give up too soon?” Ask yourself that question. And also, it’s like, “Am I being pigheaded and trying to do something that actually doesn’t make sense?” Okay. Ask yourself that question too. Even though they’re contradictory questions, sometimes it will be one, sometimes it will be the other, and you got to really think it through.
Lex Fridman

(03:01:53)
I think persisting with the business model behind Wikipedia is such an inspiring story, because we live in a capitalist world. We live in a scary world, I think, for an internet business. And so, to do things differently than a lot of websites are doing, what Wikipedia has lived through this excessive explosion of many websites that are basically ad driven. Google is ad driven. Facebook, Twitter, all of these websites are ad driven. And to see them succeed, become these incredibly rich, powerful companies that if I could just have that money, you would think as somebody running Wikipedia, “I could do so much positive stuff.” And so, to persist through that is … I think from my perspective now, Monday night quarterback or whatever was the right decision, but boy is that a tough decision.
Jimmy Wales

(03:02:56)
It seemed easy at the time.
Lex Fridman

(03:02:58)
And then you just kind of stay with it. Stick with it.
Jimmy Wales

(03:03:00)
Yeah, just stay with it. It’s working.
Lex Fridman

(03:03:01)
So now, when you chose persistent.
Jimmy Wales

(03:03:06)
Yeah. I always like to give an example of MySpace, because I just think it’s an amusing story. MySpace was poised, I would say, to be Facebook. It was huge. It was viral, it was lots of things. Kind of foreshadowed a bit of maybe even TikTok because it was a lot of entertainment, content, casual. And then Rupert Murdoch bought it and it collapsed within a few years. And part of that I think was because they were really, really heavy on ads and less heavy on the customer experience.

(03:03:40)
So, I remember, to accept a friend request was like three clicks where you saw three ads. And on Facebook, you accept the friend request, you didn’t even leave the page, like that’s just accepted. So, I used to give this example of like, “Yeah, well, Rupert Murdoch really screwed that one up.” And in a sense, maybe he did, but somebody said, “You know what, actually, he bought it for …” And I don’t remember the numbers he bought it for, 800 million, and it was very profitable through its decline. He actually made his money back and more. From a financial point of view, it was a bad investment in the sense of you could have been Facebook. But on more mundane metrics, it’s like, “Actually, it worked out for him.”
Lex Fridman

(03:04:18)
It all matters how you define success.
Jimmy Wales

(03:04:20)
It does. That is also advice to young people. One of the things I would say when we have our mental models of success as an entrepreneur, for example, and your examples in your mind are Bill Gates, Mark Zuckerberg. So, people who at a very young age had one really great idea that just went straight to the moon and it became one of the richest people in the world. That is really unusual, like really, really rare.

(03:04:52)
And for most entrepreneurs, that is not a life path you’re going to take. You’re going to fail, you’re going to reboot, you’re going to learn from what you failed at. You’re going to try something different. And that is really important, because if your standard of success is, “Well, I feel sad because I’m not as rich as Elon Musk.” It’s like, “Well, so should almost everyone, possibly everyone except Elon Musk is not as rich as Elon Musk.”

(03:05:17)
Realistically, you can set a standard of success. Even in a really narrow sense, which I don’t recommend of thinking about your financial success. It’s like if you measure your financial success by thinking about billionaires, that’s heavy. That’s probably not good. I don’t recommend it.

(03:05:40)
Personally, for me, when journalists say, “Oh, how does it feel to not be a billionaire?” I usually say, “I don’t know how does it feel to you.” Because they’re not. But also, I live in London. The number of bankers that no one has ever heard of who live in London, who make far more money than I ever will is quite a large number, and I wouldn’t trade my life for theirs at all, because mine is so interesting.

(03:06:07)
“Oh, right, Jimmy, we need you to go and meet the Chinese propaganda minister.” “Oh, okay. That’s super interesting.” Like, “Yeah, Jimmy, here’s the situation. You can go to this country. And why you’re there, the President has asked to see you.” It’s like, “God, that’s super interesting.” “Jimmy, you’re going to this place and there’s a local Wikipedia who said, ‘Do you want to stay with me and my family?'” And I’m like, “Yeah, that’s really cool. I would like to do that. That’s really interesting.” I don’t do that all the time, but I’ve done it and it’s great. So, for me, that’s arranging your life so that you have interesting experiences. It’s just great.
Meaning of life
Lex Fridman

(03:06:50)
This is more to the question of what Wikipedia looks like in 1,000 years. What do you think is the meaning of this whole thing? Why are we here, human civilization? What’s the meaning of life?
Jimmy Wales

(03:07:00)
Yeah. I don’t think there is external answer to that question.
Lex Fridman

(03:07:05)
And I should mention that there’s a very good Wikipedia page on the different philosophies in the meaning of life.
Jimmy Wales

(03:07:11)
Oh, interesting. I have to read that and see what I think. Hopefully, it’s actually neutral and gives a wide range …
Lex Fridman

(03:07:16)
Oh, it’s a really good reference to a lot of different philosophies about meaning. The 20th century philosophy in general, from Nietzsche to the existentialist, to Simone de Beauvoir, all of them have an idea of meaning. They really struggle with it systematically, rigorously, and that’s what the page … And obviously, a shout-out to the Hitchhiker’s Guide and all that kind of stuff.
Jimmy Wales

(03:07:37)
Yeah. I think there’s no external answer to that. I think it’s internal. I think we decide what meaning we will have in our lives and what we’re going to do with ourselves. If we’re talking about 1,000 years, millions of years, Yuri Milner wrote a book. He’s a big internet investor guy. He wrote a book advocating quite strongly for humans exploring the universe, and getting off the planet. And he funds projects to using lasers to send little cameras, and interesting stuff. And he talks a lot in the book about meaning. His view is that the purpose of the human species is to broadly survive and get off the planet.

(03:08:31)
Well, I don’t agree with everything he has to say, because I think that’s not a meaning that can motivate most people in their own lives. It’s like, “Okay, great.” The distances of space are absolutely enormous, so I don’t know. Shall we build generation ships to start flying places? I can’t do that. Even if I’m Elon Musk and I could devote all my wealth to build, I’ll be dead on the ship on the way. So, is that really a meaning?

(03:08:57)
But I think it’s really interesting to think about. And reading his little book, it’s quite a short little book. Reading his book, it did make me think about, “Wow, this is big. This is not what you think about in your day-to-day life. Where is the human species going to be in 10 million years?” And it does make you sort of turn back to Earth and say, “Gee, let’s not destroy the planet. We’re stuck here for at least a while, and therefore we should really think about sustainability.” I mean, one million year sustainability.

(03:09:37)
And we don’t have all the answers. We have nothing close to the answers. I’m actually excited about AI in this regard, while also bracketing, yeah, I understand there’s also risks and people are terrified of AI. But I actually think it is quite interesting this moment in time that we may have in the next 50 years to really, really solve some really long-term human problems, for example, in health. The progress that’s being made in cancer treatment, because we are able to at scale model molecules, and genetics, and things like this, it gets huge. It’s really exciting. So, if we can hang on for a little while, and certain problems that seem completely intractable today, like climate change may end up being actually not that hard.
Lex Fridman

(03:10:30)
And we just might be able to alleviate the full diversity of human suffering.
Jimmy Wales

(03:10:35)
For sure. Yeah.
Lex Fridman

(03:10:37)
In so doing, help increase the chance that we can propagate the flame of human consciousness out towards the stars. And I think another important one, if we fail to do that. For me, it’s propagating, maintaining the full diversity, and richness, and complexity, and expansiveness of human knowledge. So, if we destroy ourselves, it would make me feel a little bit okay if the human knowledge persists.
Jimmy Wales

(03:11:09)
It just triggered me to say something really interesting, which is when we talked earlier about translating and using machines to translate, we mostly talked about small languages and translating into English, but I always like to tell this story of something inconsequential, really.

(03:11:28)
I was in Norway, in Bergen, Norway, where every year they’ve got this annual festival called [foreign language 03:11:33], which is young groups drumming, and they have a drumming competition. It’s the 17 sectors of the city, and they’ve been doing it for a couple hundred years or whatever. They wrote about it in the three languages of Norway. And then from there, it was translated into English, into German, et cetera, et cetera.

(03:11:53)
And so, what I love about that story is what it reminds me is this machine translation goes both ways. And when you talk about the richness and broadness of human culture, we’re already seeing some really great pieces of this. So, like Korean soap operas, really popular, not with me, but with people.

(03:12:17)
Imagine taking a very famous, very popular, very well known Korean drama. I literally mean now, we’re just about there technologically where we use a machine to redub it in English in an automated way, including digitally editing the faces so it doesn’t look dubbed. And so, suddenly you say, “Oh, wow, here’s a piece of …” It’s the Korean equivalent of maybe it’s Friends as a comedy, or maybe it’s Succession, just to be very contemporary. It’s something that really impacted a lot of people, and they really loved it, and we have literally no idea what it’s about. And suddenly, it’s like, “Wow.” Music, street music from wherever in the world can suddenly become accessible to us all in new ways. It’s so cool.
Lex Fridman

(03:13:09)
It’s really exciting to get access to the richness of culture in China, in the many different subcultures of Africa, South America.
Jimmy Wales

(03:13:19)
One of my unsuccessful arguments with the Chinese government is by blocking Wikipedia, you aren’t just stopping people in China from reading Chinese Wikipedia and other language versions of Wikipedia, you’re also preventing the Chinese people from telling their story. So, is there a small festival in a small town in China like [foreign language 03:13:41]? I don’t know. But by the way, the people who live in that village, that small town of 50,000, they can’t put that in Wikipedia and get it translated into other places. They can’t share their culture and their knowledge.

(03:13:54)
And I think for China, this should be a somewhat influential argument, because China does feel misunderstood in the world. And it’s like, “Okay, well, there’s one way. If you want to help people understand, put it in Wikipedia. That’s what people go to when they want to understand.”
Lex Fridman

(03:14:08)
And give the amazing, incredible people of China a voice.
Jimmy Wales

(03:14:13)
Exactly.
Lex Fridman

(03:14:14)
Jimmy, I thank you so much. I’m such a huge fan of everything you’ve done.
Jimmy Wales

(03:14:18)
Oh, thank you. That’s really great.
Lex Fridman

(03:14:18)
I keep saying Wikipedia. I’m deeply, deeply, deeply, deeply grateful for Wikipedia. I love it. It brings me joy. I donate all the time. You should donate too. It’s a huge honor to finally talk with you, and this is just amazing. Thank you so much for today.
Jimmy Wales

(03:14:31)
Thanks for having me.
Lex Fridman

(03:14:33)
Thanks for listening to this conversation with Jimmy Wales. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from the world historian, Daniel Boorstin. The greatest enemy of knowledge is not ignorance, it is the illusion of knowledge. Thank you for listening, and hope to see you next time.
Test
Jimmy Wales

00:00:00
We’ve never bowed down to government pressure anywhere in the world, and we never will. We understand that we’re hardcore, and actually, there is a bit of nuance about how different companies respond to this, but our response has always been just to say no. If they threaten to block, well, knock yourself out. You’re going to lose Wikipedia.
Lex Fridman

00:00:21
The following is a conversation with Jimmy Wales, co-founder of Wikipedia, one of, if not the most impactful websites ever, expanding the collective knowledge, intelligence, and wisdom of human civilization. This is Lex Friedman podcast. To support it, please check out our sponsors in the description. Now, dear friends, here’s Jimmy Wales.
Lex Fridman

00:00:47
Let’s start at the beginning. What is the origin story of Wikipedia?
Jimmy Wales

00:00:51
The origin story of Wikipedia, well, so I was watching the growth of the free software movement, open-source software, and seeing programmers coming together to collaborate in new ways, sharing code, doing that under free license, which is really interesting because it empowers an ability to work together. That’s really hard to do if the code is still proprietary, because then if I chip in and help, we have to figure out how I’m going to be rewarded and what that is. But the idea that everyone can copy it and it just is part of the commons really empowered a huge wave of creative software production. I realized that that kind of collaboration could extend beyond just software to all kinds of cultural works.

00:01:38
The first thing that I thought of was an encyclopedia and thought, “Oh, that seems obvious that an encyclopedia, you can collaborate on it.” There’s a few reasons why. One, we all pretty much know what an encyclopedia entry on say, the Eiffel Tower should be like. You should see a picture, a few pictures, maybe, history, location, something about the architect, et cetera, et cetera. So we have a shared understanding of what it is we’re trying to do, and then we can collaborate and different people can chip in and find sources and so on and so forth. So set up first Nupedia, which was about two years before Wikipedia.

00:02:18
With Nupedia, we had this idea that in order to be respected, we had to be even more academic than a traditional encyclopedia because a bunch of volunteers on the internet getting it right out of an encyclopedia, you could be made fun of if it’s just every random person. So we had implemented this seven-stage review process to get anything published, and two things came of that. So one thing, one of the earliest entries that we published after this rigorous process, a few days later, we had to pull it because as soon as it hit the web and the broader community took a look at it, people noticed plagiarism and realized that it wasn’t actually that good, even though it had been reviewed by academics and so on. So we had to pull it. So it’s like, “Oh, okay. Well, so much for a seven-stage review process.”

00:03:07
I was frustrated, “Why is this taking so long? Why is it so hard?” So I thought, “Okay.” I saw that Robert Merton had won a Nobel Prize in economics for his work on option pricing theory. When I was in academia, that’s what I worked on was option pricing theory, had a published paper. So I’d worked through all of his academic papers, and I knew his work quite well. I thought, “Oh, I’ll write a short biography of Merton.” When I started to do it, I’d been out of academia, I hadn’t been a grad student for a few years then. I felt this huge intimidation because they were going to take my draft and send it to the most prestigious finance professors that we could find to give me feedback for revisions. It felt like being back in grad school. It’s like this really oppressive, like, you’re going to submit it for a review and you’re going to get critiques.
Lex Fridman

00:03:59
A little bit of the bad part of grad school.
Jimmy Wales

00:04:01
Yeah, yeah, the bad part of grad school. So I was like, “Oh, this isn’t intellectually fun, this is like the bad part of grad school. It’s intimidating, and there’s a lot of potential embarrassment if I screw something up and so forth.” So that was when I realized, “Okay, look, this is never going to work. This is not something that people are really going to want to do.” So Jeremy Rosenfeld, one of my employees had brought and showed me the Wiki concept in December, and then Larry Sanger brought in the same, said, “What about this Wiki idea?” So in January, we decided to launch Wikipedia, but we weren’t sure. So the original project was called Nupedia. Even though it wasn’t successful, we did have quite a group of academics and really serious people.

00:04:45
We were concerned that, “Oh, maybe these academics are going to really hate this idea, and we shouldn’t just convert the project immediately. We should launch this as a side project, the idea of here’s a Wiki where we can start playing around.” But actually, we got more work done in two weeks than we had in almost two years because people were able to just jump on and start doing stuff, and it was actually a very exciting time. Back then, you could be the first person who typed Africa as a continent and hit Save, which isn’t much of an encyclopedia entry, but it’s true, and it’s a start and it’s kind of fun, like put your name down.

00:05:20
Actually, a funny story was several years later, I just happened to be online and I saw when, I think his name is Robert Aumann, won the Nobel Prize in economics. We didn’t have an entry on him at all, which was surprising, but it wasn’t that surprising. This was still early days. So I got to be the first person to type Robert Aumann, won Nobel Prize in economics and hit Save, which again, wasn’t a very good article. But then I came back two days later and people had improved it and so forth. So that second half of the experience where with Robert Merton, I never succeeded because it was just too intimidating. It was like, “Oh, no, I was able to chip in and help, other people jumped in. Everybody was interested in the topic, because it’s all in the news at the moment.” So it’s just a completely different model, which worked much, much better.
Lex Fridman

00:06:03
Well, what is it that made that so accessible, so fun, so natural to just add something?
Jimmy Wales

00:06:09
Well, I think, especially in the early days, and this, by the way, has gotten much harder because there are fewer topics that are just greenfield available. But you could say, “Oh, well, I know a little bit about this, and I can get it started.” But then it is fun to come back then and see other people have added and improved and so on and so forth. That idea of collaborating where people can, much like open-source software, you put your code out and then people suggest revisions. They change it, and it modifies and it grows beyond the original creator, it’s just a fun, wonderful, quite geeky hobby, but people enjoy it.
Lex Fridman

00:06:51
How much debate was there over the interface, over the details of how to make that, seamless and frictionless?
Jimmy Wales

00:06:57
Yeah, not as much as there probably should have been, in a way. During that two years of the failure of Nupedia where very little work got done, what was actually productive was, there was a huge long discussion; email discussion, very clever people talking about things like neutrality, talking about what is an encyclopedia, but also talking about more technical ideas. Back then, XML was all the rage and thinking about shouldn’t you have certain data that might be in multiple articles that gets updated automatically? So for example, the population of New York City, every 10 years there’s a new official census, couldn’t you just update that bit of data in one place and it would update across all languages? That is a reality today. But back then it was just like, “Hmm, how do we do that? How do we think about that?”
Lex Fridman

00:07:47
So that is a reality today where it’s-
Jimmy Wales

00:07:48
Yeah-
Lex Fridman

00:07:49
… there’s some-
Jimmy Wales

00:07:50
Yeah, so Wikidata-
Lex Fridman

00:07:50
… universal variables? Wikidata.
Jimmy Wales

00:07:56
Yeah, Wikidata. From a Wikipedia entry, you can link to that piece of data in Wikidata, and it’s a pretty advanced thing, but there are advanced users who are doing that. Then when that gets updated, it updates in all the languages where you’ve done that.
Lex Fridman

00:08:07
That’s really interesting. There was this chain of emails in the early days of discussing the details of what is. So there’s the interface, there’s the-
Jimmy Wales

00:08:14
Yeah, so the interface, so an example, there was some software called UseModWiki, which we started with. It’s quite amusing actually, because the main reason we launched with UseModWiki is that it was a single Perl script, so it was really easy for me to install it on the server and just get running. But it was some guy’s hobby project, it was cool, but it was just a hobby project. All the data was stored in flat text files, so there was no real database behind it. So to search the site, you basically used Grab, which is just the basic Unix utility to look through all the files. So that clearly was never going to scale. But also in the early days, it didn’t have real logins. So you could set your username, but there were no passwords. So I might say Bob Smith, and then someone else comes along and says, “No, I’m Bob Smith,” and they both had it. Now that never really happened.

00:09:10
We didn’t have a problem with it, but it was obvious, you can’t grow a big website where everybody can pretend to be everybody. That’s not going to be good for trust and reputation and so forth. So quickly, I had to write a little login, store people’s passwords and things like that so you could have unique identities. Then another example of something you would’ve never thought would’ve been a good idea, and it turned out to not be a problem. But to make a link in Wikipedia in the early days, you would make a link to a page that may or may not exist by just using CamelCase, meaning it’s like upper case, lowercase, and you smash the words together. So maybe New York City, you might type N-E-W, no space, capital Y, York City, and that would make a link, but that was ugly. That was clearly not right. So I was like, “Okay, well that’s just not going to look nice. Let’s just use square brackets, two square brackets makes a link.”

00:10:04
That may have been an option in the software. I’m not sure I thought up square brackets. But anyway, we just did that, which worked really well. It makes nice links and you can see in its red links or blue links, depending on if the page exists or not. But the thing that didn’t occur to me even to think about is that, for example, on the German language standard keyboard, there is no square bracket. So for German Wikipedia to succeed, people had to learn to do some alt codes to get the square bracket, or a lot of users cut and paste a square bracket where they could find one and they would just cut and paste one in. Yet. German Wikipedia has been a massive success, so somehow that didn’t slow people down.
Lex Fridman

00:10:40
How is that that the German keyboards don’t have a square bracket. How do you do programming? How do you live life to its fullest without square brackets?
Jimmy Wales

00:10:48
It’s a very good question. I’m not really sure. Maybe it does now because keyboard standards have drifted over time and becomes useful to have a certain character. It’s same thing, there’s not really a W character in Italian, and it wasn’t on keyboards or I think it is now. But in general, W is not a letter in Italian language, but it appears in enough international words that it’s crept into Italian.
Lex Fridman

00:11:12
All of these things are probably Wikipedia articles in themselves.
Jimmy Wales

00:11:17
Oh, yes. Oh, yeah.
Lex Fridman

00:11:17
The discussion of square brackets-
Jimmy Wales

00:11:17
That is a whole-
Lex Fridman

00:11:17
… in German-
Jimmy Wales

00:11:19
… whole discussion, I’m sure.
Lex Fridman

00:11:20
… on both the English and the German Wikipedia. The difference between those two might be very-
Jimmy Wales

00:11:27
Interesting.
Lex Fridman

00:11:27
… interesting. So Wikidata is fascinating, but even the broader discussion of what is an encyclopedia, can you go to that philosophical question of-
Jimmy Wales

00:11:37
Sure.
Lex Fridman

00:11:37
… what is an encyclopedia?
Jimmy Wales

00:11:39
What is an encyclopedia? So the way I would put it is an encyclopedia, or what our goal is is the sum of all human knowledge, but sum meaning summary. This was an early debate. Somebody started uploading the full text of Hamlet, for example, and we said, “Mmm, wait, hold on a second. That’s not an encyclopedia article, but why not?” So hence was born Wikisource, which is where you put original texts and things like that, out of copyright text, because they said, “No, an encyclopedia article about Hamlet, that’s a perfectly valid thing. But the actual text of the play is not an encyclopedia article. “So most of it’s fairly obvious, but there are some interesting quirks and differences. So for example, as I understand it, in French language encyclopedias, traditionally it would be quite common to have recipes, which in English language that would be unusual. You wouldn’t find a recipe for chocolate cake in Britannica. So I actually don’t know the current state, haven’t thought about that in many, many years now.
Lex Fridman

00:12:44
State of cake recipes in Wikipedia, in English, Wikipedia?
Jimmy Wales

00:12:47
I wouldn’t say there’s chocolate cake recipes. You might find a sample recipe somewhere. I’m not saying there are none, but in general, no, we wouldn’t have recipes-
Lex Fridman

00:12:55
I told myself I would not get outraged in this conversation, but now I’m outraged. I’m deeply upset.
Jimmy Wales

00:13:00
It’s actually very complicated. I love to cook. I’m actually quite a good cook. What’s interesting is it’s very hard to have a neutral recipe because [inaudible 00:13:12]
Lex Fridman

00:13:12
Like a canonical recipe for cake-
Jimmy Wales

00:13:13
A canonical recipe is-
Lex Fridman

00:13:14
… chocolate cake.
Jimmy Wales

00:13:15
… is kind of difficult to come by because there’s so many variants and it’s all debatable and interesting. For something like chocolate cake, you could probably say, “Here’s one of the earliest recipes,” or, “Here’s one of the most common recipes.” But for many, many things, the variants are as interesting as somebody said to me recently, 10 Spaniards, 12 paella recipes. So these are all matters of open discussion.
Lex Fridman

00:13:44
Well, just to throw some numbers, as of May 27, 2023, there are 6.6 million articles in the English Wikipedia containing over 4.3 billion words. Including articles, the total number of pages is 58 million.
Jimmy Wales

00:14:05
Yeah.
Lex Fridman

00:14:06
Does that blow your mind?
Jimmy Wales

00:14:08
Yes, it does. It doesn’t, because I know those numbers and see them from time to time. But in another sense, a deeper sense, yeah, it does. It’s really remarkable. I remember when English Wikipedia passed 100,000 articles and when German Wikipedia passed 100,000, ’cause I happened to be in Germany with a bunch of Wikipedians that night, and then it seemed quite big. We knew at that time that it was nowhere near complete. I remember at Wikimania in Harvard when we did our annual conference there in Boston, someone who had come to the conference from Poland had brought along with him a small encyclopedia, a single volume encyclopedia of biographies, so short biographies, normally a paragraph or so about famous people in Poland, and there were some 22,000 entries. He pointed out that even then, 2006, Wikipedia felt quite big.

00:15:12
He said in English Wikipedia, there’s only a handful of these, less than 10%, I think he said. So then you realized, yeah, actually, who was the mayor of Warsaw in 1873? Don’t know. Probably not in English Wikipedia, but it probably might be today, but there’s so much out there. Of course, what we get into when we’re talking about how many entries there are and how many could there be, is this very deep philosophical issue of notability, which is the question of, well, how do you draw the limit? How do you draw what is there? So sometimes people say, “Oh, there should be no limit.” But I think that doesn’t stand up to much scrutiny if you really pause and think about it. So I see in your hand there you’ve got a BIC pen, pretty standard. Everybody’s seen billions of those in life.
Lex Fridman

00:16:05
Classic though.
Jimmy Wales

00:16:05
It’s a classic, clear, BIC pen. So could we have an entry about that BIC pen aisle? I bet we do, that type of BIC pen because it’s classic. Everybody knows it, and it’s got a history. Actually, there’s something interesting about the BIC company. They make pens, they also make kayaks, and there’s something else they’re famous for. Basically, they’re a definition by non-essentials company. Anything that’s long and plastic, that’s what they make.
Lex Fridman

00:16:33
Wow, that’s very-
Jimmy Wales

00:16:34
If you want to find the common ground-
Lex Fridman

00:16:36
… platonic form, the platonic form of a BIC.
Jimmy Wales

00:16:37
But could we have an article about that very BIC pen in your hand, so Lex Friedman’s BIC pen as of this week?
Lex Fridman

00:16:45
Oh, the very, this instance-
Jimmy Wales

00:16:45
The very specific instance, and the answer is no, there’s not much known about it. I dare say, unless it’s very special to you and your great-grandmother gave it to you or something, you probably know very little about it. It’s a pen. It’s just here in the office. So that’s just to show there is a limit. In German Wikipedia, they used to talk about the rear nut of the wheel of [inaudible 00:17:10] bicycle [inaudible 00:17:11] a well-known Wikipedian of the time, to sort of illustrate, you can’t have an article about literally everything. So then it raises the question, what can you have an article about? What can’t you? That can vary depending on the subject matter. One of the areas where we try to be much more careful would be biographies. The reason is a biography of a living person, if you get it wrong, you can actually be quite hurtful, quite damaging.

00:17:38
So if someone is a private person and somebody tries to create a Wikipedia entry, there’s no way to update it. There’s not much done. So for example, an encyclopedia article about my mother, my mother, school teacher later, a pharmacist, wonderful woman, but never been in the news, other than me talking about why there shouldn’t be a Wikipedia entry, that’s probably made it in somewhere, standard example. But there’s not enough known. You could imagine a database of genealogy having date of birth, date of death, certain elements like that of private people. But you couldn’t really write a biography. One of the areas this comes up quite often is what we call BLP1E. We’ve got lots of acronyms. Biography of a living person who’s notable for only one event is a real danger zone.
Lex Fridman

00:18:27
Oh.
Jimmy Wales

00:18:28
The type of example would be a victim of a crime, so someone who’s a victim of a famous serial killer, but about whom really not much is known. They weren’t a public person, they’re just a victim of a crime, we really shouldn’t have an article about that person. They’ll be mentioned, of course, and maybe this specific crime might have an article. But for that person, no, not really. That’s not really something that makes any sense because how can you write a biography about someone you don’t know much about? It varies from field to field. So for example, for many academics, we will have an entry that we might not have in a different context because for an academic, it’s important to have sort of their career, what papers they’ve published, things like that.

00:19:13
You may not know anything about their personal life, but that’s actually not encyclopedically relevant in the same way that it is for member of a royal family where it’s basically all about the family. So we’re fairly nuanced about notability and where it comes in. I’ve always thought that the term notability, I think, is a little problematic. We struggled about how to talk about it. The problem with notability is it can feel insulting. Say, “Oh no, you’re not noteworthy.” Well, my mother’s noteworthy. She’s a really important person in my life, so that’s not right. But it’s more like verifiability. Is there a way to get information that actually makes an encyclopedia entry?
Lex Fridman

00:19:56
It so happens that there’s a Wikipedia page about me as I’ve learned recently, and the first thought I had when I saw that was, “Surely I am not notable enough.” So I was very surprised and grateful that such your page could exist and actually, just allow me to say thank you to all the incredible people that are part of creating and maintaining Wikipedia. It’s my favorite website on the internet. The collection of articles that Wikipedia has created is just incredible. We’ll talk about the various details of that. But the love and care that goes into creating pages for individuals, for a BIC pen, for all this kind of stuff is just really incredible.

00:20:43
So I just felt the love when I saw that page. But I also felt just ’cause I do this podcast and I just through this podcast, gotten to know a few individuals that are quite controversial, I’ve gotten to be on the receiving end of something quite … to me as a person who loves other human beings, I’ve gone to be at the receiving end of some attacks through the Wikipedia form. Like you said, when you look at living individuals, it can be quite hurtful, the little details of information. Because I’ve become friends with Elon Musk and I’ve interviewed him, but I’ve also interviewed people on the left, far left, people on the right, some people would say far right, and so now you take a step, you put your toe into the cold pool of politics and the shark emerges from the depths and pulls you right in.
Jimmy Wales

00:21:41
Yeah, the boiling hot pool of politics.
Lex Fridman

00:21:43
I guess it’s hot, and so I got to experience some of that. I think what you also realize is there has to be, for Wikipedia credible sources, verifiable sources, and there’s a dance there because some of the sources are pieces of journalism. Of course, journalism operates under its own complicated incentives such that people can write articles that are not factual or are cherry-picking all the flaws they can have in a journalistic article-
Jimmy Wales

00:22:18
For sure.
Lex Fridman

00:22:18
… and those can be used as-
Jimmy Wales

00:22:20
For sure.
Lex Fridman

00:22:21
… as sources. It’s like they dance hand-in-hand. So for me, sadly enough, there was a really concerted attack to say that I was never at MIT, never did anything at MIT. Just to clarify, I am a research scientist at MIT. I have been there since 2015. I’m there today. I’m at a prestigious, amazing laboratory called LIDS, and I hope to be there for a long time. I work on AI, robotics, machine learning. There’s a lot of incredible people there. By the way, MIT has been very kind to defend me. Unlike Wikipedia says, it is not an unpaid position. There was no controversy.
Jimmy Wales

00:23:03
Right.
Lex Fridman

00:23:03
It was all very calm and happy and almost boring research that I’ve been doing there. The other thing, because I am half-Ukrainian, half-Russian-
Jimmy Wales

00:23:14
Oh.
Lex Fridman

00:23:15
… and I’ve traveled to Ukraine and I will travel to Ukraine again, and I will travel to Russia for some very difficult conversations. My heart’s been broken by this war. I have family in both places. It’s been a really difficult time. But the little battle about the biography there also starts becoming important for the first time for me. I also want to clarify personally, I use this opportunity of some inaccuracies there. My father was not born in Chkalovsk, Russia. He was born in Kiev, Ukraine. I was born in Chkalovsk which is a town not in Russia. There is a town called that in Russia. But there’s another town in Tajikistan, which is the former republic of the Soviet Union. That town is now called B-U-S-T-O-N, Buston, which is funny ’cause we’re now in Austin, and I also am in Boston, it seems like my whole life is surrounded by these kinds of towns.

00:24:13
So I was born Tajikistan, and the rest of the biography is interesting, but my family is very evenly distributed between their origins and where they grew up between Ukraine and Russia, which is adds a whole beautiful complexity to this whole thing. So I want to just correct that. It’s like the fascinating thing about Wikipedia is in some sense, those little details don’t matter. But in another sense, what I felt when I saw a Wikipedia page about me or anybody I know is there’s this beautiful saving that this person existed, like a community that notices you that says, “Huh.” You see a butterfly that floats, and you’re like, “Huh?” That it’s not just any butterfly, it’s that one. “I like that one,” or you see a puppy or something, or it’s this BIC pen. “I remember this one, it has this scratch. You get noticed in that way and I know it’s a beautiful thing. Maybe it’s very silly of me and naive, but I feel like Wikipedia, in terms of individuals, is an opportunity to celebrate people, to celebrate ideas-
Jimmy Wales

00:25:26
For sure. For sure.
Lex Fridman

00:25:26
… and not a battleground of the kind of stuff we might see on Twitter, like the mockery, the derision, this kind of stuff.
Jimmy Wales

00:25:35
For sure.
Lex Fridman

00:25:36
Of course, you don’t want to cherry-pick. All of us have flaws and so on, but it just feels like to highlight a controversy of some sort, when that doesn’t at all represent the entirety of the human, in most cases, is sad.
Jimmy Wales

00:25:50
Yeah. Yeah. Yeah. So there’s a few to unpack and all that. So first, one of the things I find really, always find very interesting is your status with MIT. Okay, that’s upsetting, and it’s an argument and can be sorted out. But then what’s interesting is you gave as much time to that, which is actually important and relevant to your career and so on to also where your father was born, which most people would hardly notice, but is really meaningful to you. I find that a lot when I talk to people who have a biography in Wikipedia is they’re often as annoyed by a tinier that no one’s going to notice like this town in Tajikistan’s got a new name and so on. Nobody even knows what that means or whatever, but it can be super important. So that’s one of the reasons for biographies, we say human dignity really matters. So some of the things have to do with, and this is a common debate that goes on in Wikipedia, is what we call undue weight. So I’ll give an example.

00:26:59
There was a article I stumbled across many years ago about the mayor, or no, he wasn’t a mayor, he was a city council member of, I think it was Peoria, Illinois, but some small town in the Midwest. The entry, he’s been on the city council for 30 years or whatever. He’s frankly, a pretty boring guy and seems like a good local city politician. But in this very short biography, there was a whole paragraph, a long paragraph about his son being arrested for DUI, and it was clearly undue weight. It’s like, “What has this got to do with this guy if it even deserves a mention?” It wasn’t even clear had he done anything hypocritical, had he done himself anything wrong, even was his son, his son got a DUI.

00:27:44
That’s never great, but it happens to people, and it doesn’t seem like a massive scandal for your dad. So of course, I just took that out immediately. This is a long, long time ago. That’s the sort of thing where we have to really think about in a biography and about controversies to say, “Is this a real controversy?” So in general, one of the things we tend to say is any section, so if there’s a biography and there’s a section called controversies, that’s actually poor practice because it just invites people to say, “Oh, I want to work on this entry.” It’s either seven sections. “Oh, this one’s quite short. Can I add something?”
Lex Fridman

00:28:23
Right?
Jimmy Wales

00:28:24
Go out and find some more controversies. Now that’s nonsense, right?
Lex Fridman

00:28:24
Yeah.
Jimmy Wales

00:28:26
In general, putting it separate from everything else makes it seem worse, and also, it doesn’t put it in the right context. Whereas, if it’s a live flaw and there is a controversy, there’s always potential controversy for anyone, it should just be worked into the overall article, ’cause then it doesn’t become a temptation. You can contextualize appropriately and so forth. So that’s part of the whole process. But I think for me, one of the most important things is what I call community health. So yeah, are we going to get it wrong sometimes? Yeah, of course. We’re humans and doing good, quality reference material is hard. The real question is, how do people react to a criticism or a complaint or a concern? If the reaction is defensiveness or combativeness back, or if someone’s really in there being aggressive and in the wrong, like, “No, no, no, hold on, we’ve got to do this the right way.” You got to say, “Okay, hold on. Are there good sources? Is this contextualized appropriately? Is it even important enough to mention? What does it mean?”

00:29:40
Sometimes one of the areas where I do think there is a very complicated flaw, and you’ve alluded to it a little bit, but it’s like we know the media is deeply flawed. We know that journalism can go wrong. I would say particularly in the last whatever, 15 years, we’ve seen a real decimation of local media, local newspapers. We’ve seen a real rise in clickbait headlines and eager focus on anything that might be controversial. We’ve always had that with us, of course, there’s always been tabloid newspapers. But that makes it a little bit more challenging to say, “Okay, how do we sort things out when we have a pretty good sense that not every source is valid?” So as an example, a few years ago, it’s been quite a while now, we deprecated the MailOnline as a source and the MailOnline, the digital arm of the Daily Mail, it’s a tabloid.

00:30:46
It’s not fake news, but it does tend to run very hyped-up stories. They really love to attack people and go on the attack for political reasons and so on, and it just isn’t great. So by saying deprecated, and I think some people say, “Oh, you banned the Daily Mail? No, we didn’t ban it as a source. We just said, “Look, it’s probably not a great source. You should probably look for a better source.” So certainly if the Daily Mail runs a headline saying, “New Cure for Cancer,” it’s like probably there’s more serious sources than a tabloid newspaper. So in an article about lung cancer, you probably wouldn’t cite the Daily Mail. That’s kind of ridiculous. But also for celebrities and so forth to know, “Oh, well, they do cover celebrity gossip a lot, but they also tend to have vendettas and so forth.” You really have to step back and go, “Is this really encyclopedic or is this just the Daily Mail going on a rant?”
Lex Fridman

00:31:39
Some of that requires a great community health.
Jimmy Wales

00:31:41
It requires massive community health.
Lex Fridman

00:31:43
Even for me, for stuff I’ve seen that’s kind of, if actually iffy about people I know, things I know about myself, I still feel like a love for knowledge emanating from the article. I feel the community health, so I will take all slight inaccuracies. I love it because that means there’s people, for the most part, I feel of respect and love in this search for knowledge. Sometimes, ’cause I also love Stack Overflow and Stack Exchange for programming-related things. They can get a little cranky sometimes to a degree where it’s like it’s not as … you could could feel the dynamics of the health of the particular community and sub communities too, like a particular C Sharp or Java or Python or whatever, there’s little communities that emerge. You can feel the levels of toxicity, ’cause a little bit of strictness is good, but a little too much is bad because of the defensiveness, ’cause when somebody writes an answer and then somebody else says, “We’ll modify it,” and then get defensive, and there’s this tension that’s not conducive to improving towards a more truthful depiction of that topic.
Jimmy Wales

00:33:02
Yeah, a great example-
Lex Fridman

00:33:00
… truthful depiction of that topic.
Jimmy Wales

00:33:02
Yeah, a great example that I really loved this morning that I saw someone left a note on my user talk page in English Wikipedia saying it was quite a dramatic headline saying racist hook on front page. So we have on the front page of Wikipedia, we have little section called Did You know? And it’s just little tidbits and facts, just things people find interesting. And there’s a whole process for how things get there. And the one that somebody was raising a question about was, it was comparing a very well known US football player, Black. There was a quote from another famous sport person comparing him to a Lamborghini. Clearly a compliment. And so somebody said, “Actually, here’s a study, here’s some interesting information about how Black sports people are far more often compared to inanimate objects. And given that kind of analogy, and I think it’s demeaning to compare a person to a car, et cetera, cetera.”

00:34:01
But they said, “I’m not pulling, I’m not deleting it, I’m not removing it. I just want to raise the question.” And then there’s this really interesting conversation that goes on where I think the general consensus was, you know what, this isn’t like the alarming headline racist thing on the front page of Wikipedia, holy moly, that sounds bad. But it’s sort of like, actually yeah this probably isn’t the sort of analogy that we think is great. And so we should probably think about how to improve our language and not compare sports people to inanimate objects and particularly be aware of certain racial sensitivities that there might be around that sort of thing if there is a disparity in the media of how people are called.

00:34:40
And I just thought, you know what, nothing for me to weigh in on here. This is a good conversation. Like nobody’s saying people should be banned if they refer to, what was his name, The Fridge, Refrigerator Perry. Very famous comparison to an inanimate object of a Chicago Bears player, many years ago. But they’re just saying, hey, let’s be careful about analogies that we just pick up from the media. I said, “Yeah, that’s good.”
Lex Fridman

00:35:06
On the deprecation of news sources is really interesting because I think what you’re saying is ultimately you want to make a article by article decision, use your own judgment. And it’s such a subtle thing because there’s just a lot of hit pieces written about individuals like myself for example, that masquerade as an objective thorough exploration of a human being. It’s fascinating to watch because controversy and hit pieces just get more clicks.
Jimmy Wales

00:35:41
Oh yeah, sure.
Lex Fridman

00:35:41
This is, I guess, as a Wikipedia contributor, you start to deeply become aware of that and start to have a sense, a radar of clickbait versus truth to pick out the truth from the clickbaity type language.
Jimmy Wales

00:35:58
Oh, yeah. I mean it’s really important and we talk a lot about weasel words. And actually I’m sure we’ll end up talking about AI and ChatGPT.
Lex Fridman

00:36:10
Yes.
Jimmy Wales

00:36:10
But just to quickly mention in this area, I think one of the potentially powerful tool, because it is quite good at this, I’ve played around with and practiced it quite a lot, but ChatGPT-4 is really quite able to take a passage and point out potentially biased terms, to rewrite it to be more neutral. Now it is a bit anodyne and it’s a bit cliched, so sometimes it just takes the spirit out of something that’s actually not bad. It’s just like poetic language and you’re like, okay, that’s not actually helping. But in many cases I think that sort of thing is quite interesting. And I’m also interested in… Can you imagine where you feed in a Wikipedia entry and all the sources and you say, help me find anything in the article that is not accurately reflecting what’s in the sources? And that doesn’t have to be perfect. It only has to be good enough to be useful to community.

00:37:17
So if it scans-
Lex Fridman

00:37:19
Beautiful.
Jimmy Wales

00:37:19
… an article and all the sources and you say, oh, it came back with 10 suggestions and seven of them were decent and three of them it just didn’t understand, well actually that’s probably worth my time to do. And it can help us really more quickly get good people to review obscure entries and things like that.
Lex Fridman

00:37:41
So just as a small aside on that, and we’ll probably talk about language models a little bit, or a lot more, but one of the articles, one of the hit pieces about me, the journalist actually was very straightforward and honest about having used GPT to write part of the article.
Jimmy Wales

00:37:59
Interesting.
Lex Fridman

00:37:59
And then finding that it made an error and apologized for the error, that GPT-4 generated. Which has this kind of interesting loop, which is the articles are used to write Wikipedia pages, GPT is trained on Wikipedia, and there there’s like this interesting loop where the weasel words and the nuances can get lost or can propagate, even though they’re not grounded in reality. Somehow in the generation of the language model, new truths can be created and kind of linger.
Jimmy Wales

00:38:35
Yeah, there’s a famous web comic that’s titled cytogenesis, which is about how an errors in Wikipedia and there’s no source for it, but then a lazy journalist reads it and writes the source, and then some helpful Wikipedia spots that it has no source, finds a source and adds it to Wikipedia, and voila, magic. This happened to me once it, well, it nearly happened. There was this, it was really brief. I went back and researched it, I’m like, this is really odd. So Biography Magazine, which is a magazine published by the Biography TV channel, had a pressor profile of me, and it said, “In his spare time,” I’m not quoting exactly, it’s been many years, but, “In his spare time he enjoys playing chess with friends.” I thought, wow, that sounds great. I would like to be that guy. But actually, I play chess with my kids sometimes, but no it’s not a hobby of mine.

00:39:31
And I was like, where did they get that? And I contacted the magazine and said, where did that come from? They said, “Oh, it was in Wikipedia.” And I looked in the history, there had been vandalism of Wikipedia, which was not damaging, it’s just false. And it had already been removed. But then I thought, “Oh gosh, well I better mention this to people because otherwise it’s somebody’s going to read that and they’re going to add it, the entry, and is going to take on a life of its own. And then sometimes I wonder if it has, because I’ve been… I was invited a few years ago to do the ceremonial first move in the world chess championship. And I thought, I wonder if they think I’m a really big chess enthusiast because they read this Biography Magazine article.

00:40:10
But that problem, when we think about large language models and the ability to quickly generate very plausible but not true content, I think is something that there’s going to be a lot of shakeout and a lot of implications of that.
Lex Fridman

00:40:25
What would be hilarious is because of the social pressure of Wikipedia and the momentum, you would actually start playing a lot more chess. Not only the articles are written based on Wikipedia, but your own life trajectory changes because of the Wikipedia, just to make it more convenient. Aspire to.
Jimmy Wales

00:40:45
Aspire to, yes. Yeah, aspirational.
Lex Fridman

00:40:48
If we could just talk about that before we jump back to some other interesting topics in Wikipedia. Let’s talk about GPT-4 and large language models. So they are in part trained on Wikipedia content. What are the pros and cons of these language models? What are your thoughts?
Jimmy Wales

00:41:07
Yeah, so I mean, there’s a lot of stuff going on. Obviously the technology has moved very quickly in the last six months and looks poised to do so for some time to come. So first things first, part of our philosophy is the open licensing, the free licensing, the idea that this is what we’re here for. We are a volunteer community and we write this encyclopedia. We give it to the world to do what you like with, you can modify it, redistribute it, redistribute modified versions, commercially, non-commercially. This is the licensing. So in that sense, of course it’s completely fine. Now, we do worry a bit about attribution because it is a Creative Commons Attribution Share-Alike License. So attribution is important, not just because of our licensing model and things like that, but it’s just proper attribution is just good intellectual practice.

00:42:02
And that’s a really hard complicated question. If I were to write something about my visit here, I might say in a blog post I was in Austin, which is a city in Texas, I’m not going to put a source for Austin as a city in Texas. That’s just general knowledge. I learned it somewhere, I can’t tell you where. So you don’t have to cite and reference every single thing. But if I actually did research and I used something very heavily, it’s just proper, morally proper, to give your sources. So we would like to see that. And obviously they call it grounding. So particularly people at Google are really keen on figuring out grounding.
Lex Fridman

00:42:48
It’s such a cool term. So any text that’s generated trying to ground it to the Wikipedia quality-
Jimmy Wales

00:42:57
A source.
Lex Fridman

00:42:57
… a source. The same kind of standard of what a source means that Wikipedia uses, the same kind of source-
Jimmy Wales

00:42:57
The same kind.
Lex Fridman

00:42:57
… would be generated but with a graph.
Jimmy Wales

00:43:05
The same kind of thing. And of course, one of the biggest flaws in ChatGPT right now is that it just literally will make things up just to be amiable. I think it’s programmed to be very helpful and amiable and it doesn’t really know or care about the truth.
Lex Fridman

00:43:21
Can get bullied into… it can be convinced into…
Jimmy Wales

00:43:25
Well, but this morning, the story I was telling earlier about comparing a football player to a Lamborghini, and I thought, is that really racial? I don’t know, but I’m mulling it over. And I thought, oh, I’m going to go to ChatGPT. So I sent to ChatGPT-4, I said, “This happened in Wikipedia. Can you think of examples where a white athlete has been compared to a fast car inanimate object?” And it comes back with a very plausible essay where it tells why these analogies are common in sport, blah, blah. I said, “No, no, could you give me some specific examples?” So it gives me three specific examples, very plausible, correct names of athletes and contemporaries and all of that could have been true. Googled every single quote and none of them existed. And so I’m like, “Well, that’s really not good.”

00:44:14
I wanted to explore a thought process I was in. First I thought, how do I Google? And it’s like, well, it’s kind of a hard thing to Google because unless somebody’s written about this specific topic, it’s large language model, it’s processed all this data, it can probably piece that together for me, but it just can’t yet. So I think, I hope that ChatGPT 5, 6, 7, three to five years, I’m hoping we’ll see a much higher level of accuracy where when you ask a question like that, I think instead of being quite so eager to please by giving you a plausible sounding answer, it’s just like, I don’t know.
Lex Fridman

00:44:55
Or maybe display how much bullshit might be in this generated text. I’m really would like to make you happy right now, but I’m really stretched thin with this generation.
Jimmy Wales

00:45:07
Well, it’s one of the things I’ve said for a long time. So in Wikipedia, one of the great things we do may not be great for our reputation, except in a deeper sense for the long term I think it is. But we’ll all be on notice that says the neutrality of this section has been disputed or the following section doesn’t cite in these sources. And I always joke, sometimes I wish the New York Times would run a banner saying the neutrality of this has been disputed. They could give us a… We had a big fight in the newsroom as to whether to run this or not, but we thought it’s important enough to bring it to. But just be aware that not all the journalists are on board with it. Ah, that’s actually interesting, and that’s fine. I would trust them more for that level of transparency. So yeah, similarly ChatGPT should say, yeah, 87% bullshit.
Lex Fridman

00:45:51
Well, the neutrality one is really interesting because that’s basically a summary of the discussions that are going on underneath. It would be amazing if… I should be honest, I don’t look at the talk page often. It would be nice somehow if there was a kind of summary in this banner way of like, this, lots of wars have been fought on this here land for this here paragraph.
Jimmy Wales

00:46:16
That’s really interesting, I hadn’t thought of that. Because one of the things I do spend a lot of time thinking about these days, and people have found it, we’re moving slowly, but we are moving. Thinking about, okay, these tools exist, are there ways that this stuff can be useful to our community? Because a part of it is we do approach things in a non-commercial way, in a really deep sense. It’s like it’s been great, that Wikipedia has become very popular, but really we’re a community whose hobby is writing an encyclopedia. That’s first, and if it’s popular, great. If it’s not okay, we might have trouble paying for more servers, but it’ll be fine.

00:46:53
And so how do we help the community use these tools? One of the ways that these tools can support people, and one example I never thought about, I’m going to start playing with it, is feed in the article and feed in the talk page and say, can you suggest some warnings in the article based on the conversations in the talk page? I think it might-
Lex Fridman

00:46:53
That’s brilliant.
Jimmy Wales

00:47:12
… be good at that. It might get it wrong sometimes. But again, if it’s reasonably successful at doing that, and you can say, oh, actually, yeah, it does suggest the neutrality of this has been disputed on a section that has a seven-page discussion in the back that might be useful, don’t know, worth playing with.
Lex Fridman

00:47:30
Yeah, I mean some more color to the, not neutrality, but also the amount of emotion laden in the exploration of this particular part of the topic. It might actually help you look at more controversial pages, like on a page on the war in Ukraine or a page on Israel and Palestine. There could be parts that everyone agrees on and there’s parts that are just like-
Jimmy Wales

00:47:58
Tough.
Lex Fridman

00:47:59
… tough.
Jimmy Wales

00:47:59
The hard parts.
Lex Fridman

00:48:00
It would be nice to, when looking at those beautiful long articles to know, all right, let me just take in some stuff where everybody agrees on.
Jimmy Wales

00:48:09
I could give an example that I haven’t looked at in a long time, but I was really pleased with what I saw at the time. So the discussion was that they’re building something in Israel and for their own political reasons, one side calls it a wall hearkening back to Berlin Wall, apartheid, the other calls it a security fence. So we can understand quite quickly if we give it a moment’s thought like, okay, I understand why people would have this grappling over the language. Like, okay, you want to highlight the negative aspects of this and you want to highlight the positive aspects, so you’re going to try and choose a different name. And so there was this really fantastic Wikipedia discussion on the talk page. How do we word that paragraph to talk about the different naming? It’s called this by Israeli, it’s called this by Palestinians. And how you explain that to people could be quite charged. You could easily explain, oh, there’s this difference and it’s because this side’s good and this side’s bad and that’s why there’s a difference. Or you could say, actually, let’s just try and really stay as neutral as we can and try to explain the reasons. So you may come away from it with a concept. Oh, okay, I understand what this debate is about now.
Lex Fridman

00:49:26
And just the term Israel- Palestine conflict is still the title of a page in Wikipedia, but the word conflict is something that is a charged word.
Jimmy Wales

00:49:41
Of course.
Lex Fridman

00:49:42
Because from the Palestinian side or from certain sides, the word conflict doesn’t accurately describe the situation. Because if you see it as a genocide one way, genocide is not a conflict because to people that discuss the challenge, the word conflict, they see conflict is when there’s two equally powerful sides fighting.
Jimmy Wales

00:50:05
Sure, yeah, yeah. No, it’s hard. And in a number of cases, so this actually speaks to a slightly broader phenomenon, which is there are a number of cases where there is no one word that can get consensus. And in the body of an article, that’s usually okay, because we can explain the whole thing. You can come away with an understanding of why each side wants to use a certain word, but there are some aspects, like the page has to have a title, so there’s that. Same thing with certain things like photos. It’s like, well, there’s different photos, which one’s best? Lot of different views on that. But at the end of the day, you need the lead photo because there’s one slot for a lead photo. Categories is another one. So at one point, I have no idea if it’s in there today, but I don’t think so. I was listed in American entrepreneurs fine.

00:51:03
American atheist, and I said, that doesn’t feel right to me, just personally it’s true. I mean, wouldn’t disagree with the objective fact of it, but when you click the category and you see a lot of people who are, you might say American atheist activist because that’s their big issue. So Madalyne Murray O’Hair or various famous people who… Richard Dawkins, who make it a big part of their public argument and persona. But that’s not true of me. It’s just my private personal belief, it doesn’t really… it’s not something I campaign about. So it felt weird to put me in the category, but what category would you put? And do you need that? In this case I argued that doesn’t need that. I don’t speak about it publicly, except incidentally, from time to time, I don’t campaign about it. So it’s weird to put me with this group of people.

00:51:54
And that argument carried the day, I hope not just because it was me. But categories can be like that where you’re either in the category or you’re not. And sometimes it’s a lot more complicated than that. And is it, again, we go back to, is it undue weight? If someone who is now prominent in public life and generally considered to be a good person was convicted of something, let’s say DUI when they were young, we normally in normal discourse, we don’t think, oh, this person should be in the category of American criminals because you think, oh, a criminal. Yeah, technically speaking, it’s against the law to drive under the influence of alcohol and you were arrested and you spent a month in prison or whatever. But it’s odd to say that’s a criminal.

00:52:45
So just as an example in this area is Mark Wahlberg, Marky Mark is what I always think of him as, because that was his first sort of famous name, who I wouldn’t think should be listed as in the category, American criminal. Even though he did, he was convicted of quite a bad crime when he was a young person, but we don’t think of him as a criminal. Should the entry talk about that? Yeah, it’s actually an important part of his life story that he had a very rough youth and he could have gone down a really dark path and he turned his life around. That’s actually interesting. So categories are tricky.
Lex Fridman

00:53:20
Especially with people because we like to assign labels to people into ideas somehow, and those labels stick. And there’s certain words that have a lot of power, like criminal, like political left, right, center, anarchist, objectivist. What other philosophies are there? Marxist, communist, social democrat, democratic socialist, socialist, and if you add that as a category, all of a sudden it’s like, oh boy, you’re that guy now. And I don’t know if you want to be that guy.
Jimmy Wales

00:53:58
Well, there’s definitely some really charged ones like alt-right, I think it’s quite complicated and tough. It’s not completely meaningless label, but boy, I think you really have to pause before you actually put that label on someone, partly because now you’re putting them in a group of people, some of whom are quite, you wouldn’t want to be grouped with.
Lex Fridman

00:54:20
Let’s go into some, you mentioned the hot water of the pool that we’re both tipping a toe in. Do you think Wikipedia has a left leaning political bias, which is something it is sometimes accused of?
Jimmy Wales

00:54:31
Yeah, so I don’t think so, not broadly. And I think you can always point to specific entries and talk about specific biases, but that’s part of the process of Wikipedia. Anyone can come and challenge and to go on about that. But I see fairly often on Twitter, some quite extreme accusations of bias. And I think actually I don’t see it. I don’t buy that. And if you ask people for an example, they normally struggle and depending on who they are and what it’s about. So it’s certainly true that some people who have quite fringe viewpoints and who knows the full rush of history in 500 years, they might be considered to be pathbreaking geniuses. But at the moment, quite fringe views. And they’re just unhappy that Wikipedia doesn’t report on their fringe views as being mainstream. And that, by the way, goes across all kinds of fields.

00:55:36
I was once accosted on the street outside the TED Conference in Vancouver by a guy who was a homeopath who was very upset that Wikipedia’s entry on homeopathy basically says it’s pseudoscience. And he felt that was biased. And I said, “Well, I can’t really help you because we cite good quality sources to talk about the scientific status, and it’s not very good.” So it depends, and I think it’s something that we should always be vigilant about. But in general, I think we’re pretty good. And I think any time you go to any serious political controversy, we should have a pretty balanced perspective on whose saying what and what the views are and so forth. I would actually argue that the areas where we are more likely to have bias that persists for a long period of time are actually fairly obscure things, or maybe fairly non-political things.

00:56:40
I just give, it’s kind of a humorous example, but it’s meaningful. If you read our entries about Japanese anime, they tend to be very, very positive and very favorable because almost no one knows about Japanese anime except for fans. And so the people who come and spend their days writing Japanese anime articles, they love it. They kind of have an inherent love for the whole area. Now they’ll of course, being human beings, they have their internal debates and disputes about what’s better or not. But in general, they’re quite positive because nobody actually cares. On anything that people are quite passionate about, then hopefully there’s quite a lot of interesting stuff.

00:57:20
So I’ll give an example, a contemporary example where I think we’ve done a good job as of my most recent sort of look at it, and that is the question about the efficacy of masks during the COVID pandemic. And that’s an area where I would say the public authorities really jerked us all around a bit. In the very first days, they said, “Whatever you do, don’t rush on and buy masks.” And their concern was shortages in hospitals, fair enough. Later it’s like, no, everybody’s got to wear a mask everywhere. It really works really well. And then now I think it’s, the evidence is mixed, right? Masks seem to help, in my personal view, masks seem to help. They’re no huge burden. You might as well wear a mask in any environment where you’re with a giant crowd of people and so forth.

00:58:13
But it’s very politicized, that one, and it’s very politicized, where certainly in the US, much more so. I live in the UK, I live in London, I’ve never seen on the streets the kind of the thing that there’s a lot of reports of people actively angry because someone else is wearing a mask, that sort of thing in public. So because it became very politicized, then clearly if Wikipedia… No, so anyway, if you go to Wikipedia and you research this topic, I think you’ll find more or less what I’ve just said. Oh, actually after it’s all to this point in history, it’s mixed evidence like masks seemed to help, but maybe not as much as some of the authorities said. And here we are.

00:58:56
And that’s kind of an example where I think, okay, we’ve done a good job, but I suspect there are people on both sides of that very emotional debate who think, this is ridiculous. Hopefully we’ve got quality sources. So then hopefully those people who read this can say, oh, actually it is complicated. If you can get to the point of saying, okay, I have my view, but I understand other views and I do think it’s a complicated question, great, now we’re a little bit more mature as a society.
Lex Fridman

00:59:24
Well, that one is an interesting one because I feel like I hope that that article also contains the meta conversation about the politicization of that topic. To me, it’s almost more interesting than whether masks work or not, at least at this point. It’s like why masks became a symbol of the oppression of a centralized government. If you wear them, you’re a sheep that follows the mask control the mass hysteria of an authoritarian regime. And if you don’t wear a mask, then you are a science denier, anti- vaxxer, an alt-right, probably a Nazi.
Jimmy Wales

01:00:07
Exactly. And that whole politicization of society is just so damaging, and I don’t know, in the broader world, how do we start to fix that? That’s a really hard question.
Lex Fridman

01:00:21
Well, at every moment, because you mentioned mainstream and fringe, there seems to be a tension here, and I wonder what your philosophy is on it because there’s mainstream ideas and there’s fringe ideas. You look at lab leak theory for this virus. That could be other things we can discuss where there’s a mainstream narrative where if you just look at the percent of the population or the population with platforms, what they say, and then what is a small percentage in opposition to that, and what is Wikipedia’s responsibility to accurately represent both the mainstream and the fringe, do you think?
Jimmy Wales

01:01:05
Well, I think we have to try to do our best to recognize both, but also to appropriately contextualize. And so this can be quite hard, particularly when emotions are high. That’s just a fact about human beings. I’ll give a simpler example, because there’s not a lot of emotion around it. Like our entry on the moon doesn’t say, some say the moon’s made of rocks, some say cheese, who knows? That kind of false neutrality is not what we want to get to. That doesn’t make any sense, but that one’s easy. We all understand. I think there is a Wikipedia entry called something like the moon is made of cheese, where it talks about this is a common sort of joke or thing that children say or that people tell to children or whatever. It’s just a thing. Everyone’s heard moon’s made of cheese, but nobody thinks, wow, Wikipedia is so one-sided it doesn’t even acknowledge the cheese theory. I say the same thing about flat Earth, again, very-
Lex Fridman

01:02:08
That’s exactly what I’m looking up right now.
Jimmy Wales

01:02:09
… very little controversy. We will have an entry about flat Earth, theorizing, flat Earth people. My personal view is most of the people who claim to be flat earthers are just having a laugh, trolling and more power to them, have some fun, but let’s not be ridiculous.
Lex Fridman

01:02:31
Then of course, for mostly human history, people believe that the Earth is flat, so the article I’m looking at is actually kind of focusing on this history. Flat Earth is an archaic and scientifically disproven conception of the Earth’s shape as a plain or disc, meaning ancient cultures subscribe to a flat Earth cosmography with pretty cool pictures of what a flat Earth would look like, with dragon, is that a dragon no angels on the edge. There’s a lot of controversy about that. What is it the edge? Is it the wall? Is it angels, is it dragons, is there a dome?
Jimmy Wales

01:03:00
And how can you fly from South Africa to Perth? Because on a flat Earth view, that’s really too far for any plane to make it because-
Lex Fridman

01:03:09
What I want to know-
Jimmy Wales

01:03:10
It’s all spread out.
Lex Fridman

01:03:11
What I want to know is what’s on the other side, Jimmy, what’s on the other side? That’s what all of us want to know. So I presume there’s probably a small section about the conspiracy theory of flat Earth, because I think there’s a sizeable percent of the population who at least will say they believe in a flat Earth.
Jimmy Wales

01:03:31
Yeah.
Lex Fridman

01:03:32
I think it is a movement that just says that the mainstream narrative to have distrust and skepticism about the mainstream narrative, which to a very small degree, is probably a very productive thing to do as part of the scientific process. But you can get a little silly and ridiculous with it.
Jimmy Wales

01:03:49
Yeah, I mean it’s exactly right. And so I think I find on many, many cases, and of course I, like anybody else, might quibble about this or that in any Wikipedia article, but in general, I think there is a pretty good sort of willingness and indeed eagerness to say, oh, let’s fairly represent all of the meaningfully important sides. So there’s still a lot to unpack in that, right? So meaningfully important. So people who are raising questions about the efficacy of masks, okay, that’s actually a reasonable thing to have a discussion about, and hopefully we should treat that as a fair conversation to have and actually address which authorities have said what and so on and so forth. And then there are other cases where it’s not meaningful opposition, you just wouldn’t say. I doubt if the main article Moon, it may mention cheese, probably not even because it’s not credible and it’s not even meant to be serious by anyone, or the article on the Earth certainly won’t have a paragraph that says, well, most scientists think it’s round, but certain people think flat.

01:05:12
That’s just a silly thing to put in that article. You would want to sort of address that’s an interesting cultural phenomenon. You want to put it somewhere. So this goes into all kinds of things about politics. You want to be really careful, really thoughtful about not getting caught up in the anger of our times and really recognize. Yes, I always thought… I remember being really kind of proud of the US at the time when it was McCain was running against Obama because I thought, “Oh, I’ve got plenty of disagreements with both of them, but they both seem like thoughtful and interesting people who I would have different disagreements with.” But I always felt like, yeah, that that’s good, now we can have a debate. Now we can have an interesting debate. And it isn’t just people slamming each other, personal attacks and so forth.
Jimmy Wales

01:06:00
It isn’t just people slamming each other with personal attacks and so forth.
Lex Fridman

01:06:05
You’re saying Wikipedia has also represented that?
Jimmy Wales

01:06:09
I hope so. Yeah, and I think so in the main. Obviously, you can always find debate that went horribly wrong because there’s humans involved.
Lex Fridman

01:06:18
But speaking of those humans, I would venture to guess, I don’t know the data, maybe you can let me know, but the personal political leaning of the group of people who had a Wikipedia probably leans left, I would guess. To me, the question there is, I mean the same is true for Silicon Valley, the task for Silicon Valley is to create platforms that are not politically biased even though there is a bias for the engineers who create it. I believe it’s possible to do that. There’s conspiracy theories that it somehow is impossible, and there’s this whole conspiracy where the left is controlling it, and so on. I think engineers, for the most part, want to create platforms that are open and unbiased that create all kinds of perspective because that’s super exciting to have all kinds of perspectives battle it out, but still is there a degree to which the personal political bias of the editors might seep in in silly ways and in big ways?

01:07:22
Silly ways could be, I think, hopefully I’m correct in saying this, but the right will call it the Democrat Party and the left will call it the Democratic Party, right? It always hits my ear weird. Are we children here? We’re literally taking words and just jabbing at each other. Yeah, I could capitalize a thing in a certain way, or I can just take a word and mess with them. That’s a small way of how you use words, but you can also have a bigger way about beliefs, about various perspectives on political events, on Hunter Biden’s laptop, on how big of a story that is or not, how big the censorship of that story is or not, and then there’s these camps to take very strong points and they construct big narratives around that. It’s a very sizable percent of the population believes the two narratives that compete with each other.
Jimmy Wales

01:08:21
Yeah. It’s really interesting and it’s hard to judge the sweep of history within your own lifetime, but it feels like it’s gotten much worse, that this idea of two parallel universes where people can agree on certain basic facts feels worse than it used to be. I’m not sure if that’s true or if it just feels that way, but I’m not sure what the causes are. I think I would lay a lot of the blame in recent years on social media algorithms, which reward clickbait headlines, which reward tweets that go viral, and they go viral because they’re cute and clever.

01:09:13
My most successful tweet ever by a fairly wide margin, some reporter tweeted at Elon Musk because he was complaining about Wikipedia or something, “You should buy Wikipedia,” and I just wrote, “Bot for sale,” and 90 zillion retweets, and people liked it, and it was all very good, but I’m like, “You know what? It’s cute line and it’s a good mic drop,” and all that, and I was pleased with myself. I’m like, “It’s not really a discourse.” It’s not really what I like to do, but it’s what social media really rewards, which is kind of a let’s you and him have a fight, and that’s more interesting. It’s funny because at the time, I was texting with Elon who’s very pleasant to me, and all of that.
Lex Fridman

01:10:01
He might have been a little bit shitty, the reporter might have been a little bit shitty, but you fed into the shitty with a snarky funny of response, “Not for sale,” and where do you… That’s a funny little exchange, and you can probably after that laugh it off and it’s fun, but that kind of mechanism that rewards the snark can go into viciousness.
Jimmy Wales

01:10:22
Yeah. Well, and we certainly see it online. A series of tweets, sort of a tweet thread of 15 tweets that assesses the quality of the evidence for masks, pros and cons, and sort of wear this, that’s not going to go viral, but a SmackDown for a famous politician who was famously in favor of mask, who also went to a dinner and didn’t wear a mask, that’s going to go viral, and that’s partly human nature. People love to call out hypocrisy and all of that, but it’s partly what these systems elevate automatically. I talk about this with respect to Facebook, for example. I think Facebook has done a pretty good job, although it’s taken longer than it should in some cases, but if you have a very large following and you’re really spouting hatred or misinformation, disinformation, they’ve kicked people off.

01:11:24
They’ve done some reasonable things there, but actually, the deeper issue of the anger we’re talking about, of the contentiousness of everything, I make of a family example with two great stereotypes. One, the crackpot racist uncle, and one, the sweet grandma. I always want to point out all of my uncles in my family were wonderful people, so I didn’t have a crackpot racist, but everybody knows the stereotype. Well, so grandma, she just posts sweet comments on the kids’ pictures and congratulates people on their wedding anniversary, and crackpot uncle’s posting his nonsense. Normally, it’s at Christmas dinner, everybody rolls their eyes, “Oh, yeah, Uncle Frank’s here, and he is probably going to say some racist comment and we’re going to tell him to shut up, or maybe let’s not invite him this year.” Normal human drama. He’s got his three mates down at the pub who listen to him and all of that, but now grandma’s got 54 followers on Facebook, which is the intimate family, and racist uncle has 714, so he’s not a massive influence or whatever, but how did that happen?

01:12:36
It’s because the algorithm notices when she posts, nothing happens. He posts and then everybody jumps in to go, “God, shut up, Uncle Frank. That’s outrageous,” and there’s engagement, there’s page views, there’s ads. Those algorithms, I think they’re working to improve that, but it’s really hard for them. It’s hard to improve that if that actually is working. If the people who are saying things that get engagement, if it’s not too awful, but it’s just, maybe it’s not a racist uncle, but maybe it’s an uncle who posts a lot about what an idiot Biden is, which isn’t necessarily an offensive or blockable or bannable thing, and it shouldn’t be, but if that’s the discourse that gets elevated because it gets a rise out of people, then suddenly in a society, it’s like, “Oh, we get more of what we reward,” so I think that’s a piece of what’s gone on.
Lex Fridman

01:13:28
Well, if we could just take that tangent. I’m having a conversation with Mark Zuckerberg second time. Is there something you can comment on how to decrease toxicity on that particular platform, Facebook? You also have worked on creating a social network that is less toxic yourself, so can we just talk about the different ideas that these already big social network can do and what you have been trying to do?
Jimmy Wales

01:13:55
A piece of it is it’s hard. The problem with making a recommendation to Facebook is that I actually believe their business model makes it really hard for them, and I’m not anti-capitalism, I’m not, “Great. Somebody’s got business, they’re making money,” that’s not where I come from, but certain business models mean you are going to prioritize things that maybe aren’t longterm healthful, and so that’s a big piece of it. Certainly, for Facebook, you could say with vast resources, start to prioritize content that’s higher quality, that’s healing, that’s kind. Try not to prioritize content that seems to be just getting a rise out of people. Now, those are vague human descriptions, but I do believe good machine running algorithms, you can optimize in slightly different ways, but to do that, you may have to say, “Actually, we’re not necessarily going to increase page views to the maximum extent right now.”

01:14:59
I’ve said this to people at Facebook. It’s like if your actions are convincing people that you’re breaking Western civilization, that’s a really bad for business in the long run. Certainly, these days, I’ll say, Twitter is the thing that’s on people’s minds as being more upsetting at the moment, but I think it’s true. One of the things that’s really interesting about Facebook compared to a lot of companies is that Mark has a pretty unprecedented amount of power. His ability to name members of the board, his control of the company is pretty hard to break even if financial results aren’t as good as they could be because he’s taken a step back from the perfect optimization to say, “Actually, for the longterm health in the next 50 years of this organization, we need to reign in some of the things that are working for us in making money because they’re actually giving us a bad reputation.” One of the recommendations I would say is, and this is not to do with the algorithms and all that, but how about just a moratorium on all political advertising?

01:16:11
I don’t think it’s their most profitable segment, but it’s given rise to a lot of deep, hard questions about dark money, about ads that are run by questionable people that push false narratives, or the classic kind of thing is you run… I saw a study about Brexit in the UK where people were talking about there were ads run to animal rights activists saying, “Finally, when we’re out from under Europe, the UK can pass proper animal rights legislation. We’re not constrained by the European process.” Similarly, for people who are advocates of fox hunting to say, “Finally, when we’re out of Europe, we can re-implement…” You’re telling people what they want to hear, and in some cases, it’s really hard for journalists to see that, so it used to be that for political advertising, you really needed to find some kind of mainstream narrative, and this is still true to an extent, mainstream narrative that 60% of people can say, “Oh, I can buy into that,” which meant it pushed you to the center.

01:17:20
It pushed you to try and find some nuance balance, but if your main method of recruiting people is a tiny little one-on-one conversation with them, because you’re able to target using targeted advertising, suddenly you don’t need consistent. You just need a really good targeting operation, really good Cambridge analytic style machine learning algorithm data to convince people. That just feels really problematic, so until they can think about how to solve that problem, I would just say, “You know what? It’s going to cost us X amount,” but it’s going to be worth it to kind of say, “You know what? We actually think our political advertising policy hasn’t really helped contribute to discourse and dialogue in finding reasoned middle ground and compromise solutions, so let’s just not do that for a while until we figure that out,” so that’s maybe a piece of advice.
Lex Fridman

01:18:15
Coupled with, as you were saying, recommender systems for the newsfeed and other contexts that don’t always optimize engagement, but optimize the long term mental wellbeing and balance and growth of a human being, but it’s a very difficult problem.
Jimmy Wales

01:18:33
It’s a difficult problem. Yeah. With WT Social, WikiTribune Social, we’re launching in a few months time a completely new system, new domain, and new lots of things, but the idea is to say let’s focus on trust. People can rate each other as trustworthy, rate content as trustworthy. You have to start from somewhere so it’ll start with a core base of our tiny community who, I think, are sensible, thoughtful people, want to recruit more, but to say, “You know what? Actually, let’s have that as a pretty strong element,” to say let’s not optimize based on what gets the most paid views in this session, let’s optimize on what the feedback from people is, this is meaningfully enhancing my life. Part of that is, and it’s probably not a good business model, but part of that is say, “Okay, we’re not going to pursue an advertising business model, but a membership model where you don’t have to be a member, but you can pay to be a member.”

01:19:36
You maybe get some benefit from that, but in general, to say, actually the problem with… Actually, the division I would say is, and the analogy I would give is broadcast television funded by advertising gives you a different result than paying for HBO, paying for Netflix, paying for whatever. The reason is, if you think about it, what is your incentive as a TV producer? You’re going to make a comedy for ABC Network in the US, you basically say, “I want something that almost everybody will like and listen to,” so it tends to be a little blander, family-friendly, whatever. Whereas if you say, “Oh, actually,” I’m not going to use the HBO example, and an old example, you say, “You know what? Sopranos isn’t for everybody, Sex and the City isn’t for everybody, but between the two shows, we’ve got something for everybody that they’re willing to pay for,” so you can get edgier, higher quality in my own view content rather than saying it’s got to not offend anybody in the world. It’s got to be for everybody, which is really hard.

01:20:47
Same thing here in a social network. If your business model is advertising, it’s going to drive you in one direction. If your business model is membership, I think it drives you in a different direction. Actually, and I’ve said this to Elon about Twitter Blue, which I think wasn’t rolled out well and so forth, but the piece of that that I like is to say, look, actually, if there’s a model where your revenue is coming from people who are willing to pay for the service, even if it’s only part of your revenue, if it’s a substantial part, that does change your broader incentives to say, actually, are people going to be willing to pay for something that’s actually just toxicity in their lives? Now, I’m not sure it’s been rolled out well, I’m not sure how it’s going, and maybe I’m wrong about that as a plausible business model, but I do think it’s interesting to think about, just in broad terms, business model drives outcomes in sometimes surprising ways unless you really pause to think about it.
Lex Fridman

01:21:46
If we can just link on Twitter and Elon before… I would love to talk to you about the underlying business model, Wikipedia, which is this brilliant, bold move at the very beginning, but since you mentioned Twitter, what do you think works? What do you think is broken about Twitter?
Jimmy Wales

01:22:03
It’s a long conversation, but to start with, one of the things that I always say is it’s a really hard problem, so I concede that right up front. I said this about the old ownership of Twitter and the new ownership of Twitter because unlike Wikipedia, and this is true actually for all social media, there’s a box, and the box basically says, “What do you think? What’s on your mind?” You can write whatever the hell you want, right? This is true, by the way, even for YouTube. I mean the box is to upload a video, but again, it’s just an open-ended invitation to express yourself.

01:22:38
What makes that hard is some people have really toxic, really bad, some people are very aggressive, they’re actually stalking, they’re actually abusive, and suddenly, you deal with a lot of problems. Whereas at Wikipedia, there is no box that says, “What’s on your mind?” There’s a box that says, “This is an entry about the moon. Please be neutral. Please set your facts.” Then there’s a talk page which is not coming rant about Donald Trump. If you go on the talk page of the Donald Trump entry and you just start ranting about Donald Trump, people would say, “What are you doing? Stop doing that. We’re not here to discuss. There’s a whole world of the internet out there for you to go and rant about Donald Trump.”
Lex Fridman

01:23:17
It’s just not fun to do on Wikipedia as somehow as fun on Twitter.
Jimmy Wales

01:23:20
Well, also on Wikipedia, people are going to say, “Stop,” and, “Actually, are you here to tell us how can we improve the article or are you just here to rant about Trump? Because that’s not actually interesting.” Because the goal is different, so that’s just admitting and saying upfront, this is a hard problem. Certainly, I’m writing a book on trust. The idea is, in the last 20 years, we’ve lost trust in all kinds of institutions, in politics. The Edelman Trust Barometer Survey has been done for a long time, and trust in politicians, trust in journalism, it’s come declined substantially, and I think in many cases, deservedly, so how do we restore trust and how do we think about that?
Lex Fridman

01:24:07
Does that also include trust in the idea of truth?
Jimmy Wales

01:24:13
Trust in the idea of truth. Even the concept of facts and truth is really, really important, and the idea of uncomfortable truths is really important. When we look at Twitter and we can see, okay, this is really hard, so here’s my story about Twitter. It’s a two-part story, and it’s all pre Elon Musk ownership. Many years back, somebody accused me of horrible crimes on Twitter, and like anybody would, I was like… I’m in the public eye. People say bad things. I don’t really… I brush it off, whatever, but I’m like, “This is actually really bad.” Accusing me of pedophilia? That’s just not okay, so I thought, “I’m going to report this,” so I click report, and I report the tweet and there’s five others, and I report, and I go through the process, and then I get an email that says whatever, a couple of hours later saying, “Thank you for your report. We’re looking into this.” Great. Okay, good.

01:25:16
Then several hours further, I get an email back saying, “Sorry, we don’t see anything here to violate our terms of use,” and I’m like, “Okay,” so I emailed Jack and I say, “Jack, come on. This is ridiculous,” and he emails back roughly saying, “Yeah, sorry, Jimmy. Don’t worry. We’ll sort this out.” I just thought to myself, “You know what? That’s not the point. I’m Jimmy Wales, I know Jack Dorsey. I can email Jack Dorsey. He’ll listen to me because he’s got an email from me and sorts it out for me.” What about the teenager who’s being bullied and is getting abuse and getting accusations that aren’t true? Are they getting the same kind of really poor result in that case? Fast-forward a few years, same thing happens. The exact quote, it goes, “Please help me. I’m only 10 years old, and Jimmy Wales raped me last week.” I was like, “Come on. Fuck off. That’s ridiculous,” so I report. I’m like, “This time I’m reporting,” but I’m thinking, “Well, we’ll see what happens.”

01:26:15
This one gets even worse because then I get a same result email back saying, “Sorry, we don’t see any problems,” so I raised it with other members of the board who I know, and Jack, and like, “This is really ridiculous. This is outrageous,” and some of the board members, friends of mine, sympathetic, and so good for them, but I actually got an email back then from the general counsel head of trust and safety saying, “Actually, there’s nothing in this tweet that violates our terms of service. We don’t regard and gave reference to the Me Too Movement. If we didn’t allow accusations, the Me Too Movement, it’s an important thing,” and I was like, “You know what? Actually, if someone says, ‘I’m 10 years old and someone raped me last week,’ I think the advice should be, ‘Here’s the phone number of the police.’ You need to get the police involved. Twitter’s not the place for that accusation.”

01:27:05
Even back then… By the way, they did delete those tweets, but the rationale they gave is spammy behavior, so completely separate from abusing me. It was just like, “Oh, well, they were retweeting too often.” Okay, whatever. That’s just broken. That’s a system that it’s not working for people in the public eye. I’m sure it’s not working for private people who get abuse. Really horrible abuse can happen. How is that today? Well, it hasn’t happened to me since Elon took over, but I don’t see why it couldn’t, and I suspect now if I send a report and email someone, there’s no one there to email me back because he’s gotten rid of a lot of the trust and safety staff, so I suspect that problem is still really hard.
Lex Fridman

01:27:46
Just content moderation at huge scales.
Jimmy Wales

01:27:49
At huge scales is really something. I don’t know the full answer to this. A piece of it could be to say, “Actually, making specific allegations of crimes, this isn’t the place to do that. We’ve got a huge database. If you’ve got an accusation of crime, here’s who should call, the police, the FBI, whatever it is. It’s not to be done in public,” and then you do face really complicated questions about Me Too Movement and people coming forward in public and all of that, but again, it’s like probably you should talk to a journalist. Probably there are better avenues than just tweeting from an account that was created 10 days ago, obviously set up to abuse someone. I think they could do a lot better, but I also admit it’s a hard problem.
Lex Fridman

01:28:38
There’s also ways to indirectly or more humorously or a more mocking way to make the same kinds of accusations. In fact, the accusations you mentioned, if I were to guess, don’t go that viral because they’re not funny enough or cutting enough, but if you make it witty and cutting and meme it somehow, sometimes actually indirectly making an accusation versus directly making an accusation, that can go viral and that can destroy reputations, and you get to watch yourself. Just all kinds of narratives take hold.
Jimmy Wales

01:29:09
Yeah, no, I remember another case that didn’t bother me because it wasn’t of that nature, but somebody was saying, “I’m sure you’re making millions off of Wikipedia,” and I’m like, “No, actually, I don’t even work there. I have no salary,” and they’re like, “You’re lying. I’m going to check your 990 form,” which is the US form for tax reporting for charities, and I was like, “Yeah, here’s the link. Go read it and you’ll see I’m listed as a board member, and my salary is listed as zero.” Things like that, it’s like, “Okay.” That one, that feels like you’re wrong, but I can take that and we can have that debate quite quickly.

01:29:52
Again, it didn’t go viral because it was kind of silly, and if anything would’ve gone viral, it was me responding, but that’s one where it’s like, actually, I’m happy to respond because a lot of people don’t know that I don’t work there and that I don’t make millions, and I’m not a billionaire. Well, they must know that because it’s in most news media about me, but the other one, I didn’t respond to publicly because it’s like Barbara Streisand effect. It’s like sometimes calling attention to someone who’s abusing you who basically has no followers and so on is just a waste.
Lex Fridman

01:30:24
And everything you’re describing now is just something that all of us have to learn because everybody’s in the public eye. I think when you have just two followers and you get bullied by one of the followers, it hurts just as much as when you have a large number, so it’s not… Your situation, I think it’s echoed in the situations of millions of other, especially teenagers and kids and so on.
Jimmy Wales

01:30:43
Yeah, no, it’s actually an example. We don’t generally use my picture and the banners anymore on Wikipedia, but we did, and then we did an experiment one year where we tried other people’s pictures, so one of our developers, and one lovely, very sweet guy, and he doesn’t look like your immediate thought of a nerdy Silicon Valley developer. He looks like a heavy metal dude because he’s cool. Suddenly, here he is with long hair and tattoos, and there’s his sort of say, “Here’s what your money goes for. Here’s my letter asking for support,” and he got massive abuse from Wikipedia, like calling him creepy, and really massive. This was being shown to 80 million people a day, his picture, not the abuse. The abuse was elsewhere on the internet. He was bothered by it.

01:31:39
I thought, “You know what? There is a difference.” I actually am in the public eye. I get huge benefits from being in the public eye. I go around and make public speeches. Any random thing I think of, I can write and get it published in the New York Times, and I have this interesting life. He’s not a public figure, and so actually he wasn’t mad at us. It was just like, actually, suddenly being thrust in the public eye and you get suddenly lots of abuse, which normally, I think if you’re a teenager and somebody in your class is abusing you, it’s not going to go viral. It’s going to be hurtful because it’s local and it’s your classmates or whatever, but when ordinary people go viral in some abusive way, it’s really, really quite tragic.
Lex Fridman

01:32:24
I don’t know. Even at a small scale, it feels viral. When five people at your school, and there’s a rumor, and there’s this feeling like you’re surrounded, and the feeling of loneliness, I think, which you’re speaking to when you at least feel like you don’t have a platform to defend yourself, and then this powerlessness, that I think a lot of teenagers definitely feel, and a lot of people-
Jimmy Wales

01:32:49
I think you’re right.
Lex Fridman

01:32:51
I think even when just two people make up stuff about you or lie about you or say mean things about you or bully you, that can feel like a crowd.
Jimmy Wales

01:33:01
Yeah. No, that’s true.
Lex Fridman

01:33:03
Whatever that is in our genetics and our biology and the way our brain works, that just can be a terrifying experience. Somehow, to correct that, I think because everybody feels the pain of that, everybody suffers the pain of that, I think we’ll be forced to fix that as a society, to figure out a way around that.
Jimmy Wales

01:33:22
I think it’s really hard to fix because I don’t think that problem isn’t necessarily new. Someone in high school who writes graffiti that says, “Becky is a slut,” and spreads a rumor about what Becky did last weekend, that’s always been damaging, it’s always been hurtful, and that’s really hard.
Lex Fridman

01:33:45
Those kinds of attacks, there is oldest time itself, they proceed the internet. Now, what do you think about this technology that feels Wikipedia like, which is community notes on Twitter? Do you like it? Pros and cons? Do you think it’s scalable?
Jimmy Wales

01:34:00
I do like it. I don’t know enough about specifically how it’s implemented to really have a very deep view, but I do think it’s quite… The uses I’ve seen of it, I’ve found quite good, and in some cases, changed my mind. It’s like I see something, and of course, the human tendency is to retweet something that you hope is true or that you are afraid is true, or it’s that kind of quick mental action. Then I saw something that I liked and agreed with, and then a community note under it that made me think, “Oh, actually, this is a more nuanced issue,” so I like that. I think that’s really important. Now, how is it specifically implemented? Is it scalable or that? I don’t really know how they’ve done it, so I can’t really comment on that, but in general, I do think when your only mechanisms on Twitter, and you’re a big Twitter user, we know the platform and you’ve got plenty of followers and all of that, the only mechanisms are retweeting, replying, blocking.

01:35:13
It’s a pretty limited scope, and it’s kind of good if there’s a way to elevate a specific thoughtful response. It kind of goes to, again, does the algorithm just pick the retweet or the… I mean retweeting, it’s not even the algorithm that makes it viral. If Paulo Coelho, very famous author, I think he’s got… I don’t know. I haven’t looked lately. He used to have eight million Twitter followers. I think I looked, he’s got 16 million now or whatever. Well, if he retweets something, it’s going to get seen a lot. Elon Musk, if he retweets something, it’s going to get seen a lot. That’s not an algorithm. That’s just the way the platform works. So, it is kind of nice if you have something else, and how that’s something else is designed, that’s obviously complicated question.
Lex Fridman

01:35:58
Well, there’s this interesting thing that I think Twitter is doing, but I know Facebook is doing for sure, which is really interesting. What are the signals that a human can provide at scale? In Twitter, it’s retweet. In Facebook, I think you can share. I think, yeah, but there’s basic interactions, you can have comment and so on, but there’s also, in Facebook, and YouTube has this too is, “Would you like to see more of this or would you like to see less of this?” They post that sometimes. The thing that the neural net that’s learning from that has to figure out is the intent behind you saying, “I want to see less of this.”

01:36:39
Did you see too much of this content already? You like it, but you don’t want to see so much of it. You already figured it out, great. Or does this content not make you feel good? There’s so many interpretations that I would like to see less of this, but if you get that kind of signal, this actually can create a really powerfully curated list of content that is fed to you every day that doesn’t create an echo chamber or a silo, that actually just makes you feel good in the good way, which it challenges you, but it doesn’t exhaust you and make you this weird animal.
Jimmy Wales

01:37:20
I’ve been saying for a long time, if I went on Facebook one morning and they said, Ooh, we’re testing a new option. Rather than showing you things we think you’re going to like, we want to show you some things that we think you will disagree with, but which we have some signals that suggest it’s of quality,” I’m like, “Now, that sounds interesting.”
Lex Fridman

01:37:40
Yeah, that sounds really interesting.
Jimmy Wales

01:37:41
I want to see something where… Oh, I don’t agree with… Larry Lessig is a good friend of mine, founder of Creative Commons, and he’s moved on to doing stuff about corruption and politics and so on. I don’t always agree with Larry, but I always grapple with Larry because he’s so interesting and he’s so thoughtful, that even when we don’t agree, I’m like, “Actually, I want to hear him out because I’m going to learn from it,” and that doesn’t mean I always come around to agree with him, but I’m going to understand a perspective, and that’s really great feeling.
Lex Fridman

01:38:12
Yeah, there’s this interesting thing on social media where people accuse others of saying, “Well, you don’t want to hear opinions that you disagree with or ideas you disagree with.” I think this is something that’s thrown at me all the time. The reality is there’s literally almost nothing I enjoy more.
Jimmy Wales

01:38:29
It seems an odd thing to accuse you of because you have quite a wide range of long conversations with a very diverse bunch of people.
Lex Fridman

01:38:35
But there is a very, very harsh drop off because what I like is high quality disagreement. That really makes me think. At a certain point, there’s a threshold, it’s a kind of a gray area when the quality of the disagreement, it just sounds like mocking, and you’re not really interested in a deep understanding of the topic, or you yourself don’t seem to carry deep understanding of the topic. There’s something called intelligence square debates that may-
Lex Fridman

01:39:00
There’s something called Intelligence Squared debates. The main one is the British version. With the British accent, everything always sounds better. And the Brits seem to argue more intensely, like they’re invigorated, they’re energized by the debate. Those people I often disagree with, basically everybody involved, and it’s so fun. I learned something. That’s high quality. If we could do that, if there’s some way for me to click a button that says, “Filter out lower quality just today,” just sometimes show it to me because I want to be able to, but today I’m just not in the mood for the mockery.

01:39:38
Just high quality stuff, because even flat Earth, I want to get high quality arguments for the flat Earth. It would make me feel good because I would see, “Oh, that’s really interesting. I never really thought in my mind to challenge the mainstream narrative of general relativity, of a perception of physics. Maybe all of reality, maybe all of space is an illusion. That’s really interesting. I never really thought about, let me consider that fully. Okay, what’s the evidence? How would you test that? What are the alternatives? How would you be able to have such consistent perception of a physical reality, if it’s all of it is an illusion? All of us seem to share the same kind of perception of reality,” that’s the kind of stuff I love, but not the mockery of it that cheap, that it seems that social media can inspire.
Jimmy Wales

01:40:34
Yeah. I talk sometimes about how people assume that the big debates in Wikipedia or the arguments are between the party of the left and the party of the right. And I would say no, it’s actually the party of the kind and thoughtful and the party of the jerks, is really it. Left and yeah, yeah, bring me somebody I disagree with politically. As long as they’re thoughtful, kind, we’re going to have a real discussion. I give an example of our article on abortion: so, if you can bring together a kind and thoughtful Catholic priest and a kind and thoughtful Planned Parenthood activist and they’re going to work together on the article on abortion, that can be a really great thing, if they’re both kind and thoughtful. That’s the important part. They’re never going to agree on the topic, but they will understand, okay, Wikipedia is not going to take a side, but Wikipedia is going to explain what the debate is about, and we’re going to try to characterize it fairly.

01:41:36
And it turns out your kind and thoughtful people, even if they’re quite ideological, like a Catholic priest is generally going to be quite ideological on the subject of abortion, but they can grapple with ideas and they can discuss, and they may feel very proud of the entry at the end of the day, not because they suppress the other side’s views, but because they think the case has been stated very well that other people can come to understand it. And if you’re highly ideological, you assume, I think naturally, “If people understood as much about this as I do, they’ll probably agree with me.” You may be wrong about that, but that’s often the case. So, that’s what I think we need to encourage more of in society generally, is grappling with ideas in a really thoughtful way.
Lex Fridman

01:42:21
So is it possible if the majority of volunteers, editors of Wikipedia really disliked Donald Trump, are they still able to write an article that empathizes with the perspective of, for time at least, a very large percentage of the United States that were supported of Donald Trump, and to have a full broad representation of him as a human being, him as a political leader, him as a set of policies promised and implemented, all that kind of stuff?
Jimmy Wales

01:42:55
Yeah, I think so. And I think if you read the article, it’s pretty good. And I think a piece of that is within our community, if people have the self-awareness to understand. So, I personally wouldn’t go and edit the entry on Donald Trump. I get emotional about it and I’m like, “I’m not good at this,” and if I tried to do it, I would fail. I wouldn’t be a good Wikipedian, so it’s better if I just step back and let people who are more dispassionate on this topic edit it. Whereas there are other topics that are incredibly emotional to some people where I can actually do quite well. I’m going to be okay. Maybe we were discussing earlier the efficacy of masks. I’m like, “Oh, I think that’s an interesting problem. And I don’t know the answer, but I can help catalog what’s the best evidence and so on.”

01:43:48
I’m not going to get upset. I’m not going to get angry, able to be a good Wikipedian, so I think that’s important. And I do think though in a related framework that the composition of the community is really important. Not because Wikipedia is or should be a battleground, but because blind spots, like maybe I don’t even realize what’s biased if I’m particularly of a certain point of view, and I’ve never thought much about it. So one of the things we focus on a lot, the Wikipedia volunteers are, we don’t know the exact number, but let’s say 80% plus male, and they’re a certain demographic: they tend to be college educated, heavier on tech geeks than not, et cetera. So, there is a demographic to the community, and that’s pretty much global. Somebody said to me once, “Why is it only white men who edit Wikipedia?”, and I said, “You’ve obviously not met the Japanese Wikipedia community.”

01:44:51
It’s a joke because the broader principle still stands, who edits Japanese Wikipedia? A bunch of geeky men, and women as well. So, we do have women in the community, and that’s very important. But we do think, “Okay, you know what, that does lead to some problems,” it leads to some content issues simply because people write more about what they know and what they’re interested in. They’ll tend to be dismissive of things as being unimportant if it’s not something that they personally have an interest in. I like the example, as a parent I would say our entries on early childhood development probably aren’t as good as they should be because a lot of the Wikipedia volunteers… Actually we’re getting older, the Wikipedians, so that demographic has changed a bit. But if you’ve got a bunch of 25 year old tech geek dudes who don’t have kids, they’re just not going to be interested in early childhood development. And if they tried to write about it, they probably wouldn’t do a good job, ’cause they don’t know anything about it.

01:45:53
And somebody did a look at our entries on novelists who’ve won a major literary prize, and they looked at the male novelist versus the female, and the male novelists had longer and higher quality entries. And why is that? Well, it’s not because, ’cause I know hundreds of Wikipedian, it’s not because these are a bunch of biased, sexist men who like, “Books by women are not important.” No. Actually, there is a gender breakdown of readership. There are books, like hard science fiction’s a classic example, hard science fiction: mostly read by men. Other types of novels, more read by women. And if we don’t have women in the community, then these award-winning clearly important novelists may have less coverage. And not because anybody consciously thinks, “We don’t like a book by Maya Angelou. Who cares? She’s a poet. That’s not interesting.”

01:46:55
No, but just because, well, people write what they know, they write what they’re interested in it. So, we do think diversity in the community is really important. And that’s one area where I do think it’s really clear. But I can also say, actually that also applies in the political sphere, to say, actually, we do want kind and thoughtful Catholic priests, kind and thoughtful conservatives, kind and thoughtful libertarians, kind and thoughtful Marxists to come in. But the key is the kind and thoughtful piece, so when people sometimes come to Wikipedia outraged by some dramatic thing that’s happened on Twitter, they come to Wikipedia with a chip on their shoulder ready to do battle, and it just doesn’t work out very well.
Lex Fridman

01:47:38
And there’s tribes in general where I think there’s a responsibility on the larger group to be even kinder and more welcoming to the smaller group.
Jimmy Wales

01:47:48
Yeah, we think that’s really important. And so oftentimes, people come in and there’s a lot… When I talk about community health, one of the aspects of that that we do think about a lot, that I think about a lot is not about politics. It’s just like, how are we treating newcomers to the community? And so, I can tell you what our ideals are, what our philosophy is, but do we live up to that? So the ideal is you come to Wikipedia, we have rules. One of our fundamental rules is ignore all rules, which is partly written that way because it piques people’s attention, like, “Oh, what the hell kind of rule is that?” But basically says, “Look, don’t get nervous and depressed about a bunch of what’s the formatting of your footnote?”, so you shouldn’t come to Wikipedia, add a link, and then get banned or yelled at because it’s not the right format.

01:48:46
Instead, somebody should go, “Oh, hey. Yeah, thanks for helping, but here’s the link to how to format. If you want to keep going, you might want to learn how to format a footnote,” and to be friendly and to be open and to say, “Oh, right, oh, you’re new and you clearly don’t know everything about Wikipedia,” and sometimes in any community, that can be quite hard. So, people come in and they’ve got a great big idea, and they’re going to propose this to the Wikipedia community, and they have no idea. That’s basically a perennial discussion we’ve had 7,000 times before. And so then ideally, you would say to the person, “Oh yeah, great, thanks.” A lot of people have, and here’s where we got to and here’s the nuanced conversation we’ve had about that in the past that I think you’ll find interesting, and sometimes people are just like, “Oh God, another one, who’s come in with this idea which doesn’t work, and they don’t understand why.”
Lex Fridman

01:49:39
You can lose patience, but you shouldn’t.
Jimmy Wales

01:49:40
And that’s human, but I think it just does require really thinking in a self-aware manner of, “Oh, I was once a newbie.” Actually, I just did an interview with Emily Temple Woods, she was Wikipedian of the year, she’s just like a great, well-known Wikipedian. And I interviewed her for my book and she told me something I never knew, apparently it’s not secret, she didn’t reveal it to me, but it’s that when she started Wikipedia, she was a vandal. She came in and vandalized Wikipedia. And then basically what happened was she’d vandalized a couple of articles, and then somebody popped up on her talk page and said, “Hey, why are you doing this? We’re trying to make an encyclopedia here, and and this wasn’t very kind.”

01:50:29
And she felt so bad. She’s like, “Oh, right. I didn’t really think of it that way.” She just was coming in, and she was 13 years old, combative and having fun, and trolling a bit. And then she’s like, “Oh, actually, I see your point,” and became a great Wikipedian. So that’s the ideal really, is that you don’t just go throw a block, “Fuck off.” You go, “Hey, what gives?”, which is I think the way we tend to treat things in real life, if you’ve got somebody who’s doing something obnoxious in your friend group, you probably go, “Hey, really, I don’t know if you’ve noticed, but I think this person is actually quite hurt that you keep making that joke about them.” And then they usually go, “Oh, I thought that was okay,” and then they stop, or they keep it up and then everybody goes, “Well, you’re the asshole.”
Lex Fridman

01:51:21
Well, yeah, that’s just an example that gives me faith in humanity that we’re all capable and wanting to be kind to each other. And in general, the fact that there’s a small group of volunteers, they’re able to contribute so much to the organization, the collection, the discussion of all of human knowledge is so it makes me so grateful to be part of this whole human project. That’s one of the reasons I love Wikipedia is gives me faith in humanity.
Jimmy Wales

01:51:53
Yeah, no, I once was at Wikimania is our annual conference and people come from all around the world, really active volunteers. I was at the dinner, we were in Egypt at Wikimania and Alexandria at the closing dinner or whatever, and a friend of mine came and sat at the table, and she’s been in the movement more broadly, creative commons, she’s not really a Wikipedian, she’d come to the conference because she’s into creative commons and all that. So we have dinner, and it just turned out I sat down at the table with most of the members of the English language arbitration committee, and they’re a bunch of very sweet, geeky Wikipedians.

01:52:31
And as we left the table, I said to her, “I still find this sense of amazement, we just had dinner with some of the most powerful people in English language media,” because they’re the people who are the final court of appeal in English Wikipedia. And thank goodness they’re not media moguls. They’re just a bunch of geeks who are just well-liked in the community because they’re kind and they’re thoughtful and they really think about things. I was like, “This is great. Love Wikipedia.”
Lex Fridman

01:53:01
To the degree that geeks run the best aspect of human civilization brings me joy in all aspects. And this is true programming, like Linux programmers, people that kind of specialize in a thing, and they don’t really get caught up into the mess of the bickering of society. They just do their thing, and they value the craftsmanship of it, the competence of it.
Jimmy Wales

01:53:29
Yeah. If you’ve never heard of this or looked into it, you’ll enjoy it, I read something recently that I didn’t even know about, but the fundamental time zones, and they change from time to time. Sometimes, a country will pass daylight savings or move it by a week, whatever. There’s a file that’s on all Unix based computers, and basically all computers end up using this file, it’s the official time zone file. But why is it official? It’s just this one guy. It’s like this guy and a group of community around him.

01:54:04
And basically, something weird happened and it broke something because he was on vacation. And I’m just like, isn’t that wild that you would think… First of all, most people never even think about how do computers know about time zones? Well, they know because they just use this file which tells all the time zones and which dates they change and all of that. But there’s this one guy, and he doesn’t get paid for it. With all the billions of people on the planet, he put his hand up and goes, “Yo, I’ll take care of the time zones.”
Lex Fridman

01:54:36
And there’s a lot of programmers listening to this right now with PTSD about time zones. On top of this one guy, there’s other libraries, the different programming languages that help manage the time zones for you. But still, within those, it’s amazing just the packages, the libraries, how few people build them out of their own love for building, for creating, for community and all of that. I almost like don’t want to interfere with the natural habitat of the geek. When you spot him in the wild, you just want to be like, “Well, careful, that thing needs to be treasured.”

01:55:16
No, I met a guy many years ago, lovely, really sweet guy, and he was running a bot on English Wikipedia that I thought, “Wow, that’s actually super clever.” And what he had done is his bot was like spell checking, but rather than simple spell checking, what he had done is create a database of words that are commonly mistaken for other words. They’re spelled wrong, so I can’t even give an example. And so, the word is people often spell it wrong, but no spell checker catches it because it is another word. And so, what he did is he wrote a bot that looks for these words and then checks the sentence around it for certain keywords. So in some context, this isn’t correct, but buoy and boy: people sometimes type B-O-Y when they mean B-O-U-Y, so if he sees the word boy, B-O-Y in an article, he would look in the context and see, is this a nautical reference? And if it was, he didn’t autocorrect, he just would flag it up to himself to go, “Oh, check this one out.”

01:56:23
And that’s not a great example, but he had thousands of examples, and I was like, “That’s amazing. I would’ve never thought to do that.” And I’m glad that somebody did. And that’s also part of the openness of the system, and also I think being a charity, being this idea of actually, this is a gift to the world that makes someone go, “Oh, well, I’ll put my hand up. I see a little piece of things I can make better because I’m a good programmer and I can write this script to do this thing, and I’ll find it fun,” amazing.
Lex Fridman

01:56:55
Well, I got to ask about this big, bold decision at the very beginning to not do advertisements on the website. And just in general, the philosophy of the business model of Wikipedia, what went behind that?
Jimmy Wales

01:57:06
Yeah, so I think most people know this, but we’re a charity, so in the US, registered as a charity. And we don’t have any ads on the site. And the vast majority of the money is from donations, but the vast majority from small donors. So, people giving $25 or whatever.
Lex Fridman

01:57:29
If you’re listening to this, go donate.
Jimmy Wales

01:57:31
Go donate.
Lex Fridman

01:57:31
Donate now.
Jimmy Wales

01:57:33
$25.
Lex Fridman

01:57:33
I’ve donated so many times
Jimmy Wales

01:57:34
And we have millions of donors every year, but it’s a small percentage of people. I would say in the early days, a big part of it was aesthetic, almost as much as anything else. It was just like, “I don’t really want ads in Wikipedia. There’s a lot of reasons why it might not be good.” And even back then, I didn’t think as much as I have since about a business model can tend to drive you in a certain place, and really thinking that through in advance is really important because you might say, “Yeah, we’re really, really keen on community control and neutrality,” but if we had an advertising based business model, probably that would begin to erode. Even if I believe in it very strongly, organizations tend to follow the money in the DNA in the long run.

01:58:25
And so things like, it’s easy to think about some of the immediate problems. So if you go to read about, I don’t know, Nissan car company, and if you saw an ad for the new Nissan at the top of the page, you might be like, “Did they pay for this?”, or, “Do the advertisers have influence over the content?”, because of wonder about that for all kinds of media.
Lex Fridman

01:58:53
And that undermines trust.
Jimmy Wales

01:58:55
Undermines trust, right. But also, things like we don’t have clickbait headlines in Wikipedia. You’ve never seen Wikipedia entries with all these kind of listicles, “The 10 funniest cat pictures, number seven will make you cry,” none of that kind of stuff, because there’s no incentive, no reason to do that. Also, there’s no reason to have an algorithm to say, “Actually, we’re going to use our algorithm to drive you to stay on the website longer. We’re going to use the algorithm to drive you to…”, It’s like, “Oh, you’re reading about Queen Victoria. There’s nothing to sell you when you’re reading about Queen Victoria. Let’s move you on to Las Vegas because actually, the ad revenue around hotels in Las Vegas is quite good,” so there’s no incentive for the organization to go, “Oh, let’s move people around to things that have better ad revenue.”

01:59:48
Instead, it’s just like, “Oh, well, what’s most interesting to the community?,” just to make those links. So, that decision just seemed obvious to me, but as I say, it was less of a business decision and more of an aesthetic. It’s like, “I like Wikipedia that doesn’t have ads.” In these early days, a lot of the ads, that was well before the era of really quality ad targeting and all that, so you got a lot of-
Lex Fridman

02:00:18
Banners.
Jimmy Wales

02:00:18
Banners, punch the monkey ads and all that kind of nonsense. But there was no guarantee. It was not really clear, how could we fund this? It was pretty cheap. It still is quite cheap compared to most. We don’t have 100,000 employees and all of that, but would we be able to raise money through donations? And so, I remember the first time that we really did a donation campaign was on a Christmas Day in 2003, I think it was. We had three servers, database servers, and two front end servers, and they were all the same size or whatever, and two of them crashed. They broke, I don’t even know, remember now, the hard drive. It was Christmas Day, so I scrambled on Christmas Day to go onto the database server, which fortunately survived, and have it become a front end server as well. And then, the site was really slow and it wasn’t working very well.

02:01:28
And I was like, “Okay, it’s time. We need to do a fundraiser,” and so I was hoping to raise $20,000 in a month’s time, but we raised nearly $30,000 within two, three weeks time. So that was the first proof point of, “Oh, we put a batter up and people will donate,” we just explained we need the money. And we were very small back then, and people were like, “Oh yeah, I love this. I want to contribute.” Then over the years, we’ve become more sophisticated about the fundraising campaigns, and we’ve tested a lot of different messaging and so forth. What we used to think, I remember one year we really went heavy with, “The idea of Wikipedia is a free encyclopedia for every single person on the planet. So what about the languages of Sub-Saharan Africa?”

02:02:20
So I thought, “Okay, we’re trying to raise money. We need to talk about that because it’s really important and near and dear to my heart,” and just instinctively knowing nothing about charity fundraising, you see it all around, it’s like, oh, charity’s always mentioned the poor people they’re helping, so let’s talk about. Didn’t really work as well. This is very vague and very broad, but the pitch that works better than any other in general is a fairness pitch of, “You use it all the time, you should probably chip in.” And most people are like, “Yeah, you know what? My life would suck without Wikipedia. I use it constantly and whatever. I should chip in, it just seems like the right thing to do.”

02:03:02
And there’s many variants on that, obviously. And it works. And people are like, “Oh yeah, Wikipedia, I love Wikipedia, and I shouldn’t.” So sometimes people say, “Why are you always begging for money on the website?”, and it’s not that often, it’s not that much, but it does happen. They’re like, “Why don’t you just get Google and Facebook and Microsoft, why don’t they pay for it?”, and I’m like, “I don’t think that’s really the right answer.”
Lex Fridman

02:03:34
Influence starts to creep in.
Jimmy Wales

02:03:35
Influence starts to creep in, and questions start to creep in. The best funding for Wikipedia is the small donors. We also have major donors. We have high net worth people who donate, but we always are very careful about that sort of thing to say, “Wow, that’s really great and really important, but we can’t let that become influence because that would just be really quite not good for Wikipedia.”
Lex Fridman

02:04:01
I would love to know how many times I’ve visited Wikipedia, how much time I’ve spent on it, because I have a general sense that it’s the most useful site I’ve ever used, competing maybe with Google search, which ultimately lands on Wikipedia.
Jimmy Wales

02:04:01
Yeah, right.
Lex Fridman

02:04:20
But if I would just be reminded of like, “Hey, remember all those times your life was make better because of the site?”, I think I would be much more like, “Yeah, why did I waste money on site X, Y, Z when I should be giving a lot of it here?”
Jimmy Wales

02:04:33
Well, the Guardian newspaper has a similar model, which is they have ads. There’s no paywall, but they just encourage people to donate, and they do that. I’ve sometimes seen a banner saying, “Oh, this is your 134th article you’ve read this year, would you like to donate?” And I think it’s effective-
Lex Fridman

02:04:55
[inaudible 02:04:55].
Jimmy Wales

02:04:54
… they’re testing. But also, I wonder just for some people, if they just don’t feel like guilty and then think, “Oh, I shouldn’t bother them so much.” I don’t know. It’s a good question. I don’t know the answer.
Lex Fridman

02:05:06
I guess that’s the thing I could also turn on, ’cause that would make me… I feel like legitimately, there’s some sites, this speaks to our social media discussion: Wikipedia unquestionably makes me feel better about myself if I spend time on it. There’s some websites where I’m like, if I spend time on Twitter, sometimes I’m like, I regret. I think Elon talks about this, minimize the number of regretted minutes. My number of regretted minutes on Wikipedia is zero. I don’t remember a time… I’ve just discovered this. I started following on Instagram, a page, depthsofwikipedia.
Jimmy Wales

02:05:46
Oh, yeah.
Lex Fridman

02:05:47
There’s crazy Wikipedia pages. There’s no Wikipedia page that [inaudible 02:05:51]-
Jimmy Wales

02:05:51
Yeah, I gave her a media contributor of the year award this year because she’s so great.
Lex Fridman

02:05:55
Yeah, she’s amazing.
Jimmy Wales

02:05:57
Depthsofwikipedia is so fun.
Lex Fridman

02:05:59
Yeah, that’s the interesting point that I don’t even know if there’s a competitor. There may be the programming, Stack Overflow type of websites, but everything else, there’s always a trade-off. It’s probably because of the ad driven model because there’s an incentive to pull you into clickbait, and Wikipedia has no clickbait. It’s all about the quality of the knowledge and the wisdom.
Jimmy Wales

02:06:22
Yeah. No, that’s right. And I also Stack Overflow. Although I wonder what you think of this, so I only program for fun as a hobby, and I don’t have enough time to do it, but I do, and I’m not very good at it. So therefore, I end up on Stack Overflow quite a lot trying to figure out what’s gone wrong. And I have really transitioned to using ChatGPT much more for that because I can often find the answer clearly explained, and it works better than sifting through threads, and I feel bad about that because I do love Stack Overflow and their community. I’m assuming, I haven’t read anything about in the news about it, but I’m assuming they are keenly aware of this, and they’re thinking about, “How can we use this chunk of knowledge that we’ve got here and provide a new type of interface where you can query it with a question and actually get an answer that’s based on the answers that we’ve had?” I don’t know.
Lex Fridman

02:07:19
Mm-hmm. And I think Stack Overflow currently has policies against using GPT. There’s a contentious kind of tension.
Jimmy Wales

02:07:28
Of course, yeah.
Lex Fridman

02:07:29
But they’re trying to figure that out.
Jimmy Wales

02:07:30
Well, and so we are similar in that regard. Obviously, all the things we’ve talked about like ChatGPT makes stuff up and it makes up references, so our community has already put into place some policies about it. But roughly speaking, there’s always more nuance. But roughly speaking, it’s, you the human are responsible for what you put into Wikipedia. So, if you use ChatGPT, you better check it, ’cause there’s a lot of great use cases of like, “Oh, well, I’m not a native speaker of German, but I am pretty good,” I’m not talking about myself, a hypothetical me that’s pretty good, and I just want to run my edit through ChatGPT in German to go make sure my grammar’s okay. That’s actually cool.
Lex Fridman

02:08:15
Does it make you sad that people might use, increasingly use ChatGPT for something where they would previously use Wikipedia? So basically, use it to answer basic questions about the Eiffel Tower?
Jimmy Wales

02:08:32
Yeah. No-
Lex Fridman

02:08:32
And where the answer really comes at the source of it from Wikipedia, but they’re using this as an interface.
Jimmy Wales

02:08:38
Yeah. No, that’s completely fine. Part of it is our ethos has always been, “Here’s our gift of the world. Make something,” so if the knowledge is more accessible to people, even if they’re not coming through us, that’s fine. Now, obviously we do have certain business model concerns, and where we’ve had more conversation about this, this whole GPT thing is new, things like if you ask Alexa, “What is the Eiffel Tower?”, and she reads you the first two sentences from Wikipedia and doesn’t say it’s from Wikipedia, and they’ve recently started citing Wikipedia, then we worry, “Oh, if people don’t know they’re getting the knowledge from us, are they going to donate money? Or are they just going to think, oh, what’s Wikipedia for? I can just ask Alexa.” It’s like, well, Alexa only knows anything because she read Wikipedia. So we do think about that, but it doesn’t bother me in the sense of like, oh, I want people to always come to Wikipedia first.

02:09:33
But we had a great demo, literally just hacked together over a weekend by our head of machine learning where he did this little thing to say, you could ask any question, and he was just knocking it together, so he used OpenAI’s API just to make a demo, asked a question, “Why do ducks fly south for winter?”, which is the kind of thing you think, “Oh, I might just Google for that, or I might start looking in Wikipedia. I don’t know.” And so what he did, he asked ChatGPT, “What are some Wikipedia entries that might answer this?” Then, he grabbed those Wikipedia entries, said, “Here’s some Wikipedia entries. Answer this question based only on the information in this,” and he had pretty good results, and it prevented the making stuff up. Now, it’s just he hacked it together on a weekend, but what it made me think about was, “Oh, okay, so now we’ve got this huge body of knowledge that in many cases you’re like, oh I really I want to know about Queen Victoria. I’m just going to go read the Wikipedia entry and it’s going to take me through her life and so forth.”

02:10:44
But other times, you’ve got a specific question, and maybe we could have a better search experience where you can come to Wikipedia, ask your specific question, get your specific answer that’s from Wikipedia, including links to the articles you might want to read next. And that’s just a step forward. That’s just using new type of technology to make the extraction of information from this body of text into my brain faster and easier. So, I think that’s cool.
Lex Fridman

02:11:10
I would love to see a ChatGPT grounding into websites like Wikipedia. And the other comparable website to me will be like Wolfram Alpha for more mathematical knowledge, that kind of stuff. So, taking you to a page that is really crafted as opposed to the moment you start actually taking you to journalist websites like news websites, it starts getting a little iffy, because you’re now in a land that has a wrong incentive.
Jimmy Wales

02:11:44
Right, yeah.
Lex Fridman

02:11:45
You’re pulled in.
Jimmy Wales

02:11:45
Yeah, and you need somebody to have filtered through that and tried to knock off the rough edges. Yeah, I think that’s exactly right. And I think that kind of grounding, I think they’re working really hard on it. I think that’s really important-
Jimmy Wales

02:12:00
… is, I think they’re working really hard on it. I think that’s really important. And that actually… So if you ask me to step back and be like very business-like about our business model and where’s it going to go for us, and are we going to lose half our donations because everybody’s just going to stop coming to Wikipedia and go to ChatGPT? Well, grounding will help a lot because frankly, most questions people have, if they provide proper links, we’re going to be at the top of that, just like we are in Google. So we’re still going to get tons of recognition and tons of traffic just from… Even if it’s just the moral properness of saying, “Here’s my source.” So I think we’re going to be all right in that.
Lex Fridman

02:12:39
Yeah, in the close partnership if the model is fine-tuned, is constantly retrained that Wikipedia is one of the primary places where if you want to change what the model knows, one of the things you should do is contribute to Wikipedia or clarify Wikipedia.
Jimmy Wales

02:12:53
Yeah, yeah. No, that’s [inaudible 02:12:55].
Lex Fridman

02:12:54
Or elaborate, expand, all that kind of stuff.
Jimmy Wales

02:12:56
Yeah.
Lex Fridman

02:12:57
You mentioned all of us have controversies. I have to ask, do you find the controversy of whether you are the sole founder or the co-founder of Wikipedia ironic, absurd, interesting, important? What are your comments?
Jimmy Wales

02:13:13
I would say unimportant. Not that interesting. I mean, one of the things that people are sometimes surprised to hear me say is I actually think Larry Sanger doesn’t get enough credit for his early work in Wikipedia, even though I think co-founder’s not the right title for that. So he had a lot of impact and a lot of great work, and I disagree about a lot of things since and all that, and that’s fine. So yeah. No, to me that’s like, it’s one of these things that the media love a falling out story, so they want to make a big deal out of it, and I’m just like, yeah, no.
Lex Fridman

02:13:51
So there’s a lot of interesting engineering contributions in the early days, like you were saying, there’s debates about how to structure it, what the heck is this thing that we’re doing? And there’s important people that contributed to that.
Jimmy Wales

02:14:02
Yeah, definitely.
Lex Fridman

02:14:03
So he also, you said you’ve had some disagreements. Larry Sanger said that nobody should trust Wikipedia, and that Wikipedia seems to assume that there’s only one legitimate, defensible version of the truth on any controversial question. That’s not how Wikipedia used to be. I presume you disagree with that analysis.
Jimmy Wales

02:14:21
Yeah. I mean, just straight up, I disagree. Go and read any Wikipedia entry on a controversial topic, and what you’ll see is a really diligent effort to explain all the relevant sides. So yeah, just disagree.
Lex Fridman

02:14:32
So on controversial questions, you think perspectives are generally represented?
Jimmy Wales

02:14:36
Yeah.
Lex Fridman

02:14:37
Because it has to do with the tension between the mainstream and the non-mainstream that we were talking about.
Jimmy Wales

02:14:43
Yeah. No, I mean for sure. To take this area of discussion seriously is to say, yeah, you know what? Actually that is a big part of what Wikipedia and spend their time grappling with is to say, how do we figure out whether a less popular view is pseudoscience? Is it just a less popular view that’s gaining acceptance in the mainstream? Is it fringe versus crackpot, et cetera, et cetera? And that debate is what you’ve got to do. There’s no choice about having that debate of grappling with something. And I think we do. And I think that’s really important. And I think if anybody said to the Wikipedia community, “Gee, you should stop covering minority viewpoints on this issue,”

02:15:39
I think they would say, “I don’t even understand why you would say that. We have to grapple with minority viewpoints in science and politics and so on.” And this is one of the reasons why there is no magic simple answer to all these things. It’s really contextual. It’s case by case. It’s like you’ve got to really say, okay, what is the context here? How do you do it? And you’ve always got to be open to correction and to change and to challenge and always be sort of serious about that.
Lex Fridman

02:16:13
I think what happens, again, with social media is when there is that grappling process in Wikipedia and a decision is made to remove a paragraph or to remove a thing or to say a thing, you’re going to notice the one direction of the oscillation of the grappling and not the correction. And you’re going to highlight that and say, how come this person… I don’t know, maybe legitimacy of elections that’s the thing that comes up. Donald Trump maybe previously-
Jimmy Wales

02:16:42
Yeah, I can give a really good example, which is, there was this sort of dust up about the definition of recession in Wikipedia. The accusation was often quite ridiculous and extreme, which is, under pressure from the Biden administration Wikipedia changed the definition of recession to make Biden look good, or we did it not under pressure, but because we’re a bunch of lunatic leftists and so on. And then when I see something like that in the press, I’m like, “Oh dear, what’s happened here? How do we do that?” Because I always just accept things for five seconds first, and then I go and I look and I’m like, “You know what? That’s literally completely not what happened.” What happened was, one editor thought the article needed restructuring. So the article is always said, so the traditional kind of loose definition of recession is two quarters of negative growth, but there’s always been within economics, within important agencies and different countries around the world, a lot of nuance around that.

02:17:43
And there’s other factors that go into it and so forth. And then it’s just an interesting complicated topic. And so the article has always had the definition of two quarters. And the only thing that really changed was moving that from the lead, from the top paragraph to further down. And then news stories appeared saying, “Wikipedia has changed the definition of recession.” And then we got a huge rush of trolls coming in. So the article was temporarily protected, I think, only semi protected, and people were told, “Go to the talk page to discuss.” So anyway, it was a dust up that was… When you look at it as a Wikipedian, you’re like, “Oh, this is a really routine kind of editorial debate.” Another example, which unfortunately our friend Elon fell for, I would say, is the Twitter files. So there was an article called the Twitter files, which is about these files that were released once Elon took control of Twitter, and he released internal documents.

02:18:36
And what happened was somebody nominated it for deletion, but even the nomination said, “This is mainly about the Hunter Biden laptop controversy, shouldn’t this information be there instead?” So anyone can… It takes exactly one human being anywhere on the planet to propose something for deletion, and that triggers a process where people discuss it, which within a few hours, it was what we call snowball closed i.e, this doesn’t have a snowball’s chance in hell of passing. So an admin goes, “Yeah, wrong,” and closed the debate, and that was it. That was the whole thing that happened. And so nobody proposed suppressing the information. Nobody proposed it wasn’t important, it was just editorially boring internal questions. So sometimes people read stuff like that and they’re like, “Oh, you see, look at these leftists. They’re trying to suppress the truth again.” It’s like, well slow down a second and come and look, literally, it’s not what happened.
Lex Fridman

02:19:36
So I think the right is more sensitive to censorship, and so they will more likely highlight there’s more virality to highlighting something that looks like censorship in any walks of life. And this moving a paragraph from one place to another, or removing it and so on, as part of the regular grappling of Wikipedia can make a hell of a good article or YouTube video.
Jimmy Wales

02:20:01
Oh, yeah. Yeah. No, it sounds really in enticing and intriguing and surprising to most people because they’re like, “Oh, no, I’m reading Wikipedia. It doesn’t seem like a crackpot leftist website. It seems pretty kind of dull, really in its own geeky way.” And so that makes a good story. It’s like, oh, am I being misled? Because there’s a shadowy cabal of Jimmy Wales.
Lex Fridman

02:20:25
I generally, I read political stuff. I mentioned to you that I’m traveling to have some very difficult conversation with high profile figures both in the war in Ukraine and in Israel and Palestine. And I read the Wikipedia articles around that, and I also read books on the conflict and the history of the different regions. And I find the Wikipedia articles to be very balanced, and there’s many perspectives being represented. But then I ask myself, “Well, am I one of them leftist crackpots?” They can’t see the truth. I mean, it’s something I ask myself all the time, forget the leftist, just crackpot in general. Am I just being a sheep and accepting it? And I think that’s an important question to always ask, but not too much.
Jimmy Wales

02:21:12
Yeah. No, I agree.
Lex Fridman

02:21:12
A little bit, but not too much.
Jimmy Wales

02:21:15
Yeah. No, I think we always have to challenge ourselves of what do I potentially have wrong?
Lex Fridman

02:21:20
Well, you mentioned pressure from government. You’ve criticized Twitter for giving in to Turkey’s government censorship. There’s also conspiracy theories or accusations of Wikipedia being open to pressure from government to government organizations, FBI and all this kind of stuff. What is the philosophy about pressure from government and censorship?
Jimmy Wales

02:21:50
So we’re super hardcore on this. We’ve never bowed down to government pressure anywhere in the world, and we never will. And we understand that we’re hardcore. And actually there is a bit of nuance about how different companies respond to this, but our response has always been just to say no. And if they threaten to block, well, knock yourself out, you’re going to lose Wikipedia. And that’s been very successful for us as a strategy because governments know they can’t just casually threaten to block Wikipedia or block us for two days, and we’re going to cave in immediately to get back into the market. And that’s what a lot of companies have done. And I don’t think that’s good that we can go one level deeper and say, I’m actually quite sympathetic. If you have staff members in a certain country and they are at physical risk, you’ve got to put that into your equation.

02:22:43
So I understand that. If Elon said, “Actually, I’ve got a hundred staff members on the ground in such and such a country, and if we don’t comply, somebody’s going to get arrested. And it could be quite serious.” Okay, that’s a tough one. That’s actually really hard. But yeah, no. And then the FBI one, no, the criticism I saw. I kind of prepared for this because I saw people responding to your request for questions, and I was like, somebody’s like, “Oh, well, don’t you think it was really bad that you da da da, da?” I actually reached out to [inaudible 02:23:18] and said, “Can you just make sure I’ve got my facts right?” And the answer is, we received zero requests of any kind from the FBI or any of the other government agencies for any changes to content in Wikipedia. And had we received those requests at the level of the Wikipedia Foundation, we would’ve said, “We can’t do anything because Wikipedia is written by the community.”

02:23:40
And so the Wikimedia Foundation can’t change the content of Wikipedia without causing… I mean, God, that would be a massive controversy, you can’t even imagine. What we did do, and this is what I’ve done, I’ve been to China and met with the Minister of Propaganda. We’ve had discussions with governments all around the world, not because we want to do their bidding, but because we don’t want to do their bidding, but we also don’t want to be blocked. And we think actually having these conversations are really important. There’s no threat of being blocked in the US. That’s just never going to happen. There is the First Amendment. But in other countries around the world, it’s like, “Okay, what are you upset about? Let’s have the conversation. Let’s understand, and let’s have a dialogue about it so that you can understand where we come from and what we’re doing and why.”

02:24:26
And then sometimes it’s like, gee, if somebody complains that something’s bad in Wikipedia, whoever they are, don’t care who they are. It could be you, it could be the government, it could be the Pope. I don’t care who they are. It’s like, oh, okay. Well, our responsibility as Wikipedia is to go, “Oh, hold on, let’s check is that right or wrong? Is there something that we’ve got wrong in Wikipedia? Not because you’re threatening to block us, but because we want Wikipedia to be correct.” So we do have these dialogues with people. And a big part of what was going on with, you might call it pressure on social media companies or dialogue with, as we talked earlier, grapple with the language depending on what your view is. In our case, it was really just about, oh, okay, they want to have a dialogue about COVID information, misinformation.

02:25:22
We are this enormous source of information which the world depends on. We’re going to have that conversation. We’re happy to say, here’s… If they say, how do you know that Wikipedia is not going to be pushing some crazy anti-vax narrative first? I mean, I think it’s somewhat inappropriate for a government to be asking pointed questions in a way that implies possible penalties. I’m not sure that ever happened because we would just go, I don’t know, the Chinese blocked us. So it goes, right? We’re not going to cave into any kind of government pressure, but whatever the appropriateness of what they were doing, I think there is a rule for government in just saying, let’s understand the information ecosystem. Let’s think about the problem of misinformation, disinformation in society, particularly around election security, all these kinds of things. So I think it would be irresponsible of us to get a call from a government agency and say, “Yeah, why don’t you just fuck off? You’re the government.” But it would also be irresponsible to go, “Oh, dear, government agent’s not happy. Let’s fix Wikipedia so the FBI loves us.”
Lex Fridman

02:26:35
And when you say you want to have discussions with the Chinese government or with organizations like CDC and WHO, it’s to thoroughly understand what the mainstream narrative is so that it can be properly represented, but not drive what the articles are?
Jimmy Wales

02:26:50
Well, it’s actually important to say whatever the Wikimedia Foundation thinks has no impact on what’s in Wikipedia. So it’s more about saying to them, “We understand you’re the World Health Organization, or you’re whoever, and part of your job is to… Public health is about communications. You want to understand the world.” So it’s more about, “Well, let’s explain how Wikipedia works.”
Lex Fridman

02:27:18
So it’s more about explaining how Wikipedia works and like, “Hey, it’s the volunteers”?
Jimmy Wales

02:27:22
Yeah, exactly.
Lex Fridman

02:27:23
It’s a battle of ideas, and here’s how the sources are used.
Jimmy Wales

02:27:29
Yeah, exactly.
Lex Fridman

02:27:30
What are the legitimate sources and what not a legitimate source is.
Jimmy Wales

02:27:32
Yeah, exactly.
Lex Fridman

02:27:33
I mean, I suppose there’s some battle about what is a legitimate source. There could be statements made that CDC… There’s government organizations in general have sold themselves to be the place where you go for expertise. And some of that has been to small degree, raised in question over the response to the pandemic.
Jimmy Wales

02:27:57
Well, I think in many cases, and this goes back to my topic of trust. So there were definitely cases of public officials, public organizations where I felt like they lost the trust of the public because they didn’t trust the public. And so the idea is, we really need people to take this seriously and take actions, therefore, we’re going to put out some overblown claims because it’s going to scare people into behaving correctly. You know what? That might work for a little while, but it doesn’t work in the long run because suddenly people go from a default stance of… Like the Center for Disease Control, very well respected scientific organization. I don’t know. They’ve got fault in Atlanta with the last file of smallpox or whatever it is that people think about them. And to go, “Oh, right, these are scientists we should actually take seriously and listen to, and they’re not politicized.”

02:28:58
It’s like, okay. And if you put out statements, and I don’t know if the CDC did, but Who Health Organization, whoever, that are provably false and also provably, you kind of knew they were false, but you did it to scare people because you wanted them to do the right thing. It’s like, no, you know what? That’s not going to work in the long run. You’re going to lose people, and now you’ve got a bigger problem, which is a lack of trust in science, a lack of trust in authorities who are, by and large, they’re like quite boring government bureaucrat scientists who just are trying to help the world.
Lex Fridman

02:29:31
Well, I’ve been criticized, and I’ve been torn on this. I’ve been criticized for criticizing Anthony Fauci too hard. The degree to which I criticized him is because he’s a leader. And I’m just observing the effect in the loss of trust in the institutions like the NIH that where I personally know there’s a lot of incredible scientists doing incredible work, and I have to blame the leaders for the effects on the distrust and the scientific work that they’re doing because of what I perceive as basic human flaws of communication, of arrogance, of ego, of politics, all those kinds of things. Now, you could say, “You’re being too harsh,” possible, but I think that’s the whole point of free speech is you can criticize people who lead. Leaders, unfortunately or fortunately, are responsible for the effects on society.

02:30:28
To me, Anthony Fauci or whoever in the scientific position around the pandemic had an opportunity to have a FDR moment or to get everybody together, inspire about the power of science to rapidly develop a vaccine that saves us from this pandemic and future pandemic that can threaten the wellbeing of human civilization. This was epic and awesome and sexy. And to me, when I’m talking to people about science, it’s anything but sexy in terms of the virology and biology development because it’s been politicized. It’s icky, and people just don’t want to… “Don’t talk to me about the vaccine. I understand. I understand. I got vaccinated.” There’s just, “Let’s switch topics quick.”
Jimmy Wales

02:31:11
Yeah, yeah. Well, it’s interesting because as I say, I live in the UK and I think all these things are a little less politicized there. And I haven’t paid close enough attention to Fauci to have a really strong view. I’m sure I would disagree with some things. I remember hearing at the beginning of the pandemic as I’m unwrapping my Amazon package with these masks I bought because I heard there’s a pandemic. And I just was like, “I want some N95 mask, please.” And they were saying, “Don’t buy masks.” And the motivation was because they didn’t want there to be shortages in hospitals. Fine. But there were also statements of masks, they’re not effective and they won’t help you. And then the complete about phase two, you’re ridiculous if you’re not wearing a… It’s just like, no, that about face just lost people from day one.
Lex Fridman

02:32:06
The distrust in the intelligence of the public to deal with nuance, to deal with the uncertainty.
Jimmy Wales

02:32:11
Yeah. This is exactly what… I think this is where the Wikipedia neutral point of view is and should be in ideally. And obviously every article and everything we could… You know me now and you know how I am about these things, but ideally, it’s to say, look, we’re happy to show you all the perspectives. This is Planned Parenthood’s view, and this is Catholic Church view, and we’re going to explain that, and we’re going to try to be thoughtful and put in the best arguments from all sides, because I trust you. You read that and you’re going to be more educated and you’re going to begin to make a decision. I mean, I can just talk in the UK, the government, da, da, da. When we found out in the UK that very high level government officials were not following the rules they had put on everyone else. I had just become a UK citizen just a little while before the pandemic, and it’s kind of emotional. You get a passport in a new country and you feel quite good.

02:33:09
I did my oath to the Queen, and then they dragged the poor old lady out to tell us all to be good. I was like, “We’re British and we’re going to do the right things, and it’s going to be tough, but going to…” So you have that kind of Dunkirk spirit moment, and you’re following the rules to a T, and then suddenly it’s like, well, they’re not following the rules. And so suddenly I shifted personally from, “I’m going to follow the rules, even if I don’t completely agree with them, but I’ll still follow because I think we’ve got to all chip in together,” to, “You know what? I’m going to make wise and thoughtful decisions for myself and my family.” And that generally is going to mean following the rules. But it’s basically when they’re at certain moments in time, you’re not allowed to be in an outside space unless you’re exercising. I’m like, I think I can sit in a park and read a book. It’s going to be fine. That’s irrational rule, which I would’ve been following just personally of like, I’m just going to do the right thing.
Lex Fridman

02:34:06
And the loss of trust, I think, at scale was probably harmful to science. And to me, the scientific method and the scientific community is one of the biggest hopes, at least to me, for the survival and the thriving of human civilization.
Jimmy Wales

02:34:22
Absolutely. And I think you see some of the ramifications of this. There’s always been pretty anti-science, anti-vax people. That’s always been a thing, but I feel like it’s bigger now simply because of that lowering of trust. So a lot of people, maybe it’s like you say, a lot of people are like, “Yeah, I got vaccinated, but I really don’t want to talk about this because it’s so toxic.” And that’s unfortunate because I think people should say, “What an amazing thing.” There’s also a whole range of discourse around if this were a disease that was primarily killing babies, I think people’s emotions about it would’ve been very different, right or wrong. Then the fact that when you really looked at the death rate of getting COVID, wow, it’s really dramatically different. If you’re late in life, this was really dangerous. And if you’re 23 years old, yeah, well, it’s not great. And long COVID is a thing and all of that. And I think some of the public communications, again, were failing to properly contextualize it. Not all of it. It’s a complicated matter, but yeah.
Lex Fridman

02:35:45
Let me read you a Reddit comment that received two likes.
Jimmy Wales

02:35:48
Oh, two whole people liked it.
Lex Fridman

02:35:52
Yeah, two people liked it. And I don’t know, maybe you can comment on whether there’s truth to it, but I just found it interesting because I’ve been doing a lot of research on World War II recently. So this is about Hitler.
Jimmy Wales

02:36:06
Oh, okay.
Lex Fridman

02:36:06
It’s a long statement. “I was there when a big push was made to fight bias at Wikipedia. Our target became getting the Hitler article to be Wiki’s featured article. The idea was that the voting body only wanted articles that were good PR and especially articles about socially liberal topics. So the Hitler article had to be two to three times better and more academically researched to beat the competition. This bias seems to hold today, for example, the current list of political featured articles at a glance seems to have only two books, one on anarchism and one on Karl Marx. Surely we’re not going to say there have only ever been two articles about political non-biography books worth being featured, especially compared to 200 plus video games. And that’s the only topics with good books are socialism and anarchy.” Do you have any interesting comments on this kind of-
Jimmy Wales

02:36:06
Oh, yeah.
Lex Fridman

02:37:00
[inaudible 02:37:00] featured, how the featured is selected, maybe Hitler, because he is a special figure [inaudible 02:37:09] kind of stuff.
Jimmy Wales

02:37:09
I love that. No, I love the comparison to how many video games, and that definitely speaks to my earlier is like, if you’ve got a lot of young geeky men who really like video games, that doesn’t necessarily get you to the right place in every respect. Certainly. Yeah. So here’s a funny story. I woke up one morning to a bunch of journalists in Germany trying to get in touch with me because German language, Wikipedia chose to have as the featured article of the day, Swastika. And people were going crazy about it, and some people were saying, “It’s illegal. Has German Wikipedia been taken over by Nazi sympathizers,” and so on? And it turned out it’s not illegal, discussing the swastika. Using the swastika as a political campaign and using it in certain ways is illegal in Germany in a way that it wouldn’t be in the US because the First Amendment, but in this case, it was like actually part of the point is the swastika symbol is from other cultures as well.

02:38:17
I just thought it was interesting. I did joke to the community, I’m like, “Please don’t put the swastika on the front page without warning me because I’m going to get [inaudible 02:38:25].” It wouldn’t be me, it’s the foundation. I’m not that much on the front lines. So I would say that to put Hitler on the front page of Wikipedia, it is a special topic. And you would want to say, “Yeah, let’s be really careful that it’s really, really good before we do that,” because if we put it on the front page and it’s not good enough, that could be a problem. There’s no inherent reason. Clearly, World War II is a very popular topic in Wikipedia. It’s like, turn on the history channel. People, it’s a fascinating period of history that people are very interested in. And then on the other piece, like anarchism and Karl Marx.
Lex Fridman

02:39:05
Karl Marx. Yeah.
Jimmy Wales

02:39:06
Oh, yeah. I mean, that’s interesting. I’m surprised to hear that not more political books or topics have made it to the front page.
Lex Fridman

02:39:15
Now we’re taking this Reddit a comment.
Jimmy Wales

02:39:16
I mean, as if-
Lex Fridman

02:39:17
That’s face value.
Jimmy Wales

02:39:18
… it’s completely… But I’m trusting. So I think that’s probably is right. They probably did have the list up. No, I think that piece… The piece about how many of those featured articles have been video games, and if it’s disproportionate, I think the community should go, “Actually, what’s gone? That doesn’t seem quite right.” I mean, you can imagine that because you’re looking for an article to be on the front page of Wikipedia, you want to have a bit of diversity in it. You want it to be not always something that’s really popular that week, so I don’t know, the last couple of weeks, maybe succession, the big finale of succession might lead you think, oh, let’s put succession on the front page, that’s going to be popular. In other cases, you kind of want to pick something super obscure and quirky because people also find that interesting and fun. Yeah, I don’t know. But you don’t want it to be video games most of the time. That sounds quite bad.
Lex Fridman

02:40:17
Well, let me ask you just as somebody who’s seen the whole thing, the development of the millions of articles. Big impossible question, what’s your favorite article?
Jimmy Wales

02:40:33
My favorite article? Well, I’ve got an amusing answer, which is possibly also true. There’s an article in Wikipedia called Inherently Funny Words, and one of the reasons I love it is when it was created early in the history of Wikipedia, it kind of became like a dumping ground. People would just come by and write in any word that they thought sounded funny. And then it was nominated for deletion because somebody’s like, “This is just a dumping ground. People are putting all kinds of nonsense in.” And in that deletion debate, somebody came forward and said essentially, “Wait a second, hold on. This is actually a legitimate concept in the theory of humor and comedy. And a lot of famous comedians and humorists have written about it.” And it’s actually a legitimate topic. So then they went through and they meticulously referenced every word that was in there and threw out a bunch that weren’t.

02:41:29
And so it becomes this really interesting. And now my biggest disappointment, and it’s the right decision to make because there was no source, but it was a picture of a cow, but there was a rope around its head tying on some horns onto the cow. So it was kind of a funny looking picture. It looked like a bull with horns, but it’s just a normal milk cow. And below it, the caption said, “According to some, cow is an inherently funny word,” which is just hilarious to me, partly because the “According to some” sounds a lot like Wikipedia, but there was no source. So it went away, and I know I feel very sad about that, but I’ve always liked that. And actually the reason Depths of Wikipedia amuses me so greatly is because it does highlight really interesting obscure stuff, and you’re like, “Wow, I can’t believe somebody wrote about that in Wikipedia. It’s quite amusing.” And sometimes there’s a bit of rye humor in Wikipedia. There’s always a struggle. You’re not trying to be funny, but occasionally a little inside humor can be quite healthy.
Lex Fridman

02:42:40
Apparently words with the letter K are funny. There’s a lot of really well researched stuff on this page. It’s actually exciting. And I should mention for Depths of the Wikipedia, it’s run by Annie Rauwerda.
Jimmy Wales

02:42:56
That’s right, Annie.
Lex Fridman

02:42:57
And let me just read off some of the pages. Octopolis and Octlantis-
Jimmy Wales

02:43:05
Oh yeah, that was…
Lex Fridman

02:43:05
… are two separate non-human underwater settlements built by the gloomy octopuses in Jarvis Bay East Australia. The first settlement named Octopolis by a biologist was founded in 2009. The individual structures in Octopolis consists of borrows around a piece of human detritus believed to be scrap metal, and it goes on in this way.
Jimmy Wales

02:43:29
That’s great.
Lex Fridman

02:43:30
Satiric misspelling, least concerned species. Humans were formally assessed as a species of least concern in 2008. I think Hitchhiker’s Guide to the Galaxy would slightly disagree. And the last one, let me just say, friendship paradox is the phenomena first observed by the sociologist Scott Feld in 1991, that on average an individual’s friends have more friends than that individual.
Jimmy Wales

02:43:58
Oh, that’s really interesting.
Lex Fridman

02:43:58
That’s very lonely.
Jimmy Wales

02:44:00
That’s the kind of thing that makes you want to… It sounds implausible at first because shouldn’t everybody have on average, about the same number of friends as all their friends? So you really want to dig into the math of that and really think, oh, why would that be true?
Lex Fridman

02:44:13
And it’s one way to feel more lonely in a mathematically rigorous way. Somebody else on Reddit asks, “I would love to hear some war stories from behind the scenes.” Is there something that we haven’t mentioned that was particularly difficult in this entire journey you’re on with Wikipedia?
Jimmy Wales

02:44:32
I mean, yeah, it’s hard to say. So part of what I always say about myself is that I’m a pathological optimist, so I always think everything is fine. And so things that other people might find a struggle, I’m just like, “Oh, well, this is the thing we’re doing today.” So that’s kind of about me, and it’s actually… I’m aware of this about myself, so I do like to have a few pessimistic people around me to keep me a bit on balance. I mean, I would say some of the hard things, I mean, there were hard moments like when two…
Jimmy Wales

02:45:00
I would say some of the hard things. I mean, there were hard moments when two out of three servers crashed on Christmas Day and then we needed to do a fundraiser and no idea what was going to happen. I would say as well, in that early period of time, the growth of the website and the traffic to the website was phenomenal and great. The growth of the community and in fact the healthy growth of the community was fine.

02:45:29
And then the Wikimedia Foundation, the nonprofit I set up to own and operate Wikipedia as a small organization, it had a lot of growing pains. That was the piece that’s just many companies or many organizations that are in a fast growth. It’s like you’ve hired the wrong people, or there’s this conflict that’s arisen and nobody has got experience to do this and all that. So, no specific stories to tell, but I would say growing the organization was harder than growing the community and growing the website, which is interesting.
Lex Fridman

02:46:02
Well, yeah. It’s kind of miraculous and inspiring that a community can emerge and be stable, and that has so much kind of productive, positive output. Kind of makes you think. It’s one of those things you don’t want to analyze too much because you don’t want to mess with a beautiful thing, but it gives me faith in communities. I think that they can spring up in other domains as well.
Jimmy Wales

02:46:29
Yeah, I think that’s exactly right. At Fandom, my for-profit wiki company where it’s all these communities about pop culture mainly, sort of entertainment, gaming and so on, there’s a lot of small communities. So, I went last year to our Community Connect conference and just met some of these people, and here’s one of the leaders of the Star Wars wiki, which is called Wookieepedia, which I think is great. And he’s telling me about his community and all that. And I’m like, “Oh, right. Yeah, I love this.”

02:47:03
So, it’s not the same purpose as Wikipedia of a neutral, high quality encyclopedia, but a lot of the same values are there of like, “Oh, people should be nice to each other.” It’s like when people get upset, just remember we’re working on Star Wars wiki together, there’s no reason to get too outraged. And just kind people just, just geeky people with a hobby.
Lex Fridman

02:47:27
Where do you see Wikipedia in 10 years, 100 years, and 1,000 years?
Jimmy Wales

02:47:35
Right. So, 10 years, I would say pretty much the same. We’re not going to become TikTok with entertainment deals, scroll by video humor, and blah-blah-blah, and encyclopedia. I think in 10 years, we probably will have a lot more AI supporting tools like I’ve talked about, and probably your search experience would be you can ask a question and get the answer rather than from our body of work.
Lex Fridman

02:48:09
So, search and discovery, a little bit improved, interface, some of that.
Jimmy Wales

02:48:12
Yeah, all that. I always say one of the things that most people won’t notice, because already they don’t notice it, is the growth of Wikipedia in the languages of the developing world. So, you probably don’t speak Swahili, so you’re probably not checking out that Swahili Wikipedia is doing very well, and it is doing very well. And I think that kind of growth is actually super important. It’s super interesting, but most people won’t notice that.
Lex Fridman

02:48:41
If we can just link on that if we could, do you think there’s so much incredible translation work is being done with AI, with language models? Do you think that can accelerate Wikipedia?
Jimmy Wales

02:48:55
Yeah, I do.
Lex Fridman

02:48:55
So, you start with the basic draft of the translation of articles and then build on top of that.
Jimmy Wales

02:49:00
What I used to say is machine translation for many years wasn’t much used to the community, because it just wasn’t good enough. As it’s gotten better, it’s tended to be a lot better in what we might call economically important languages, that’s because the corpus that they train on and all of that.

02:49:20
So, to translate from English to Spanish, if you’ve tried Google Translate recently Spanish to English is what I would do, it’s pretty good. It’s actually not bad. It used to be half a joke and then for a while it was kind of like, “Well, you can get the gist of something.” And now, actually, it’s pretty good. However, we’ve got a huge Spanish community who write in native Spanish, so they’re able to use it and they find it useful, but they’re writing.

02:49:44
But if you tried to do English to Zulu where there’s not that much investment, there’s loads of reasons to invest in English-Spanish, because they’re both huge, economically important languages. Zulu not so much. So, for those smaller languages, it was just still terrible. My understanding is it’s improved dramatically and also because the new methods of training don’t necessarily involve identical corpuses to try to match things up, but rather reading and understanding with tokens and large language models, and then reading and understanding, and then you get a much richer …

02:50:22
Anyway, apparently it’s quite improved, so I think that now, it is quite possible that these smaller language communities are going to say, “Oh, well finally, I can put something in an English and I can get out Zulu that I feel comfortable sharing with my community because it’s actually good enough, or I can edit it a bit here and there.” So, I think that’s huge. So, I do think that’s going to happen a lot and that’s going to accelerate, again, what will remain to most people an invisible trend, but that’s the growth in all these other languages. So, then move on to 100 years.
Lex Fridman

02:50:52
I was starting to get scary.
Jimmy Wales

02:50:54
Well, the only thing I’d say about 100 years is we’ve built the Wikimedia Foundation, and we run it in a quite cautious, and financially conservative, and careful way. So, every year, we build our reserves. Every year, we put aside a little bit of more money. We also have the endowment fund, which we just passed 100 million, that’s a completely separate fund with a separate board. So, it’s not just a big fat bank account for some future profligate CEO to blow through. The foundation will have to get the approval of a second order board to be able to access that money, and that board can make other grants through the community and things like that.

02:51:38
So, the point of all that is I hope and believe that we are building in a financially stable way that we can weather various storms along the way, so that hopefully we’re not taking the kind of risks. And by the way, we’re not taking too few risks either. That’s always hard. I think the Wikimedia Foundation and Wikipedia will exist in 100 years if anybody exists in 100 years, we’ll be there.
Lex Fridman

02:52:06
Do you think the internet just looks a predictably different, just the web?
Jimmy Wales

02:52:11
I do. I think right now, this sort of enormous step forward we’ve seen and has become public in the last year of the large language models really is something else. It’s really interesting. You and I have both talked today about the flaws and the limitations, but still it’s … As someone who’s been around technology for a long time, it’s sort of that feeling of the first time I saw a web browser, the first time I saw the iPhone, the first time the internet was really usable on a phone. And it’s like, “Wow, that’s a step change difference.” There’s a few other …
Lex Fridman

02:52:48
Maybe a Google Search.
Jimmy Wales

02:52:49
Google Search was actually one.
Lex Fridman

02:52:51
I remember the first Search.
Jimmy Wales

02:52:51
Because I remember Alta Vista was kind of cool for a while, then it just got more and more useless, because the algorithm wasn’t good. And it’s like, “Oh, Google Search, now I like the internet, it works again.” And so, large language model, it feels like that to me. Like, “Oh, wow, this is something new and really pretty remarkable.” And it’s going to have some downsides. The negative use case …

02:53:14
People in the area who are experts, they’re giving a lot of warnings. I’m not that worried, but I’m a pathological optimist. But I do see some really low-hanging fruit bad things that can happen. My example is, how about some highly customized spam where the email that you receive isn’t just misspelled words and trying to get through filters, but actually as a targeted email to you that knows something about you by reading your LinkedIn profile and writes a plausible email that will get through the filters. And it’s like suddenly, “Oh, that’s a new problem. That’s going to be interesting.”
Lex Fridman

02:53:55
Just on the Wikipedia editing side, does it make the job of the volunteer of the editor more difficult in a world where larger and larger percentage of the internet is written by an LLM?
Jimmy Wales

02:54:08
One of my predictions, and we’ll see, ask me again in five years how this panned out, is that in a way, this will strengthen the value and importance of some traditional brands. So, if I see a news story and it’s from the Wall Street Journal, from the New York Times, from Fox News, I know what I’m getting and I trust it to whatever extent I might have, trust or distrust in any of those.

02:54:43
And if I see a brand new website that looks plausible, but I’ve never heard of it, and it could be machine generated content that may be full of errors, I think I’ll be more cautious. I think I’m more interested. And we can also talk about this around photographic evidence. So, obviously, there will be scandals where major media organizations get fooled by a fake photo.

02:55:04
However, if I see a photo of the recent ones, the Pope wearing an expensive puffer jacket, I’m going to go, “Yeah, that’s amazing that a fake like that could be generated.” But my immediate thought is not, “Oh, so the Pope is dipping into the money, eh? Partly because this particular Pope doesn’t seem like he’d be the type.”
Lex Fridman

02:55:25
My favorite is extensive pictures of Joe Biden and Donald Trump hanging out and having fun together.
Jimmy Wales

02:55:31
Yeah. Brilliant. So, I think people will care about the provenance of a photo. And if you show me a photo and you say, “Yeah, this photo is from Fox News,” even though I don’t necessarily think that’s the highest, but I’m like, “Wow, it’s a news organization and they’re going to have journalism, and they’re going to make sure the photo is what it purports to be.”

02:55:55
That’s very different from a photo randomly circulating on Twitter. Whereas I would say, 15 years ago, a photo randomly circulating on Twitter, in most cases, the worst you could do, and this did happen, is misrepresent the battlefield. So, like, “Oh, here’s a bunch of injured children. Look what Israel has done.” But actually, it wasn’t Israel, it was another case 10 years ago. That has happened, that has always been around. But now, we can have much more specifically constructed, plausible looking photos that if I just see them circulating on Twitter, I’m going to go, “I just don’t know. Not sure. I can make that in five minutes.”
Lex Fridman

02:56:32
Well, I also hope that it’s kind of like what you’re writing about in your book that we could also have citizen journalists that have a stable, verifiable trust that builds up. So, it doesn’t have to be in New York Times with this organization that you could be in an organization of one as long as it’s stable and carries through time and it builds up or it goes up.
Jimmy Wales

02:56:52
No, I agree. But the one thing I’ve said in the past, and this depends on who that person is and what they’re doing, but it’s like I think my credibility, my general credibility in the world should be the equal of a New York Times reporter. So, if something happens, and I witness it, and I write about it, people are going to go, “Well, Jimmy Wales said it. That’s just like if a New York Times reporter said it. I’m going to tend to think he didn’t just make it up.”

02:57:18
The truth is nothing interesting ever happens around me. I don’t go to war zones. I don’t go to big press conferences. I don’t interview Putin and Zelenskyy. To an extent, yes. Whereas I do think for other people, those traditional models of credibility are really, really important. And then there is this sort of citizen journalism. I don’t know if you think of what you do as journalism. I kind of think it is, but you do interviews, you do long form interviews.

02:57:49
If you come and you say, “Here’s my tape,” but you wouldn’t hand out a tape. I just gesture to you as if I’m handing you a cassette tape. But if you put it into your podcast, ” Here’s my interview with Zelenskyy.” And people aren’t going to go, “Yeah, how do we know? That could be a deep fake. You could have faked that.” Because people are like, “Well, no, you’re a well known podcaster and you do interview interesting people. Yeah, you wouldn’t think that.” So, that your brand becomes really important.

02:58:19
Whereas if suddenly, and I’ve seen this already, I’ve seen sort of video with subtitles in English, and apparently the Ukrainian was the same and it was Zelenskyy saying something really outrageous. And I’m like, “Yeah, I don’t believe that. I don’t think he said that in a meeting with whatever. I think that’s Russian propaganda or probably just trolls.”
Lex Fridman

02:58:42
Yeah. And then building platforms and mechanisms of how that trust can be verified. If something appears on a Wikipedia page, that means something. If something appears on my Twitter account, that means something. That means I, this particular human, have signed off on it.
Jimmy Wales

02:58:58
Yeah, exactly.
Lex Fridman

02:58:58
And then the trust you have in this particular human transfers to the piece of content. Hopefully, there’s millions of people with different metrics of trust. And then you could see that there’s a certain kind of bias in the set of conversations you’re having. So, maybe okay, I trust this person, I have this kind of bias and I’ll go to this other person with this other kind of bias and I can integrate them in this kind of way. Just like you said with Fox News and whatever [inaudible 02:59:24].
Jimmy Wales

02:59:23
Yeah. Wall Street Journal, New York Times, they’ve all got where they sit. Yeah.
Lex Fridman

02:59:29
So, you have built, I would say, one of if not the most impactful website in the history of human civilization. So, let me ask for you to give advice to young people how to have impact in this world. High schoolers, college students wanting to have a big positive impact on the world.
Jimmy Wales

02:59:50
Yeah, great. If you want to be successful, do something you’re really passionate about rather than some kind of cold calculation of what can make you the most money. Because if you go and try to do something and you’re like, “I’m not that interested, but I’m going to make a lot of money doing it,” you’re probably not going to be that good at it. And so, that is a big piece of it.

03:00:12
For startups, I give this advice. And this is a career startup, any kind of young person just starting out is be persistent. There will be moments when it’s not working out and you can’t just give up too easily. You’ve got to persist through some hard times. Maybe two servers crash on a Sunday, and you’ve got to scramble to figure it out, but persist through that, and then also be prepared to pivot. That’s a newer word, new for me. But when I pivoted from Nupedia to Wikipedia it’s like, “This isn’t working. I’ve got to completely change.” So, be willing to completely change direction when something is not working.

03:00:54
Now, the problem with these two wonderful pieces of advice is, which situation am I in today? Is this a moment when I need to just power through and persist because I’m going to find a way to make this work? Or is this a moment where I need to go, “Actually, this is totally not working and I need to change direction?” But also, I think for me, that always gives me a framework of like, “Okay, here’s the problem. Do we need to change direction, or do we need to power through it?” And just knowing those are the choices. Not always the only choices, but those choices.

03:01:27
I think it can be helpful to say, “Okay, am I chickening out because I’m having a little bump, and I’m feeling unemotional, and I’m just going to give up too soon?” Ask yourself that question. And also, it’s like, “Am I being pigheaded and trying to do something that actually doesn’t make sense?” Okay. Ask yourself that question too. Even though they’re contradictory questions, sometimes it will be one, sometimes it will be the other, and you got to really think it through.
Lex Fridman

03:01:53
I think persisting with the business model behind Wikipedia is such an inspiring story, because we live in a capitalist world. We live in a scary world, I think, for an internet business. And so, to do things differently than a lot of websites are doing, what Wikipedia has lived through this excessive explosion of many websites that are basically ad driven. Google is ad driven. Facebook, Twitter, all of these websites are ad driven. And to see them succeed, become these incredibly rich, powerful companies that if I could just have that money, you would think as somebody running Wikipedia, “I could do so much positive stuff.” And so, to persist through that is … I think from my perspective now, Monday night quarterback or whatever was the right decision, but boy is that a tough decision.
Jimmy Wales

03:02:56
It seemed easy at the time.
Lex Fridman

03:02:58
And then you just kind of stay with it. Stick with it.
Jimmy Wales

03:03:00
Yeah, just stay with it. It’s working.
Lex Fridman

03:03:01
So now, when you chose persistent.
Jimmy Wales

03:03:06
Yeah. I always like to give an example of MySpace, because I just think it’s an amusing story. MySpace was poised, I would say, to be Facebook. It was huge. It was viral, it was lots of things. Kind of foreshadowed a bit of maybe even TikTok because it was a lot of entertainment, content, casual. And then Rupert Murdoch bought it and it collapsed within a few years. And part of that I think was because they were really, really heavy on ads and less heavy on the customer experience.

03:03:40
So, I remember, to accept a friend request was like three clicks where you saw three ads. And on Facebook, you accept the friend request, you didn’t even leave the page, like that’s just accepted. So, I used to give this example of like, “Yeah, well, Rupert Murdoch really screwed that one up.” And in a sense, maybe he did, but somebody said, “You know what, actually, he bought it for …” And I don’t remember the numbers he bought it for, 800 million, and it was very profitable through its decline. He actually made his money back and more. From a financial point of view, it was a bad investment in the sense of you could have been Facebook. But on more mundane metrics, it’s like, “Actually, it worked out for him.”
Lex Fridman

03:04:18
It all matters how you define success.
Jimmy Wales

03:04:20
It does. That is also advice to young people. One of the things I would say when we have our mental models of success as an entrepreneur, for example, and your examples in your mind are Bill Gates, Mark Zuckerberg. So, people who at a very young age had one really great idea that just went straight to the moon and it became one of the richest people in the world. That is really unusual, like really, really rare.

03:04:52
And for most entrepreneurs, that is not a life path you’re going to take. You’re going to fail, you’re going to reboot, you’re going to learn from what you failed at. You’re going to try something different. And that is really important, because if your standard of success is, “Well, I feel sad because I’m not as rich as Elon Musk.” It’s like, “Well, so should almost everyone, possibly everyone except Elon Musk is not as rich as Elon Musk.”

03:05:17
Realistically, you can set a standard of success. Even in a really narrow sense, which I don’t recommend of thinking about your financial success. It’s like if you measure your financial success by thinking about billionaires, that’s heavy. That’s probably not good. I don’t recommend it.

03:05:40
Personally, for me, when journalists say, “Oh, how does it feel to not be a billionaire?” I usually say, “I don’t know how does it feel to you.” Because they’re not. But also, I live in London. The number of bankers that no one has ever heard of who live in London, who make far more money than I ever will is quite a large number, and I wouldn’t trade my life for theirs at all, because mine is so interesting.

03:06:07
“Oh, right, Jimmy, we need you to go and meet the Chinese propaganda minister.” “Oh, okay. That’s super interesting.” Like, “Yeah, Jimmy, here’s the situation. You can go to this country. And why you’re there, the President has asked to see you.” It’s like, “God, that’s super interesting.” “Jimmy, you’re going to this place and there’s a local Wikipedia who said, ‘Do you want to stay with me and my family?'” And I’m like, “Yeah, that’s really cool. I would like to do that. That’s really interesting.” I don’t do that all the time, but I’ve done it and it’s great. So, for me, that’s arranging your life so that you have interesting experiences. It’s just great.
Lex Fridman

03:06:50
This is more to the question of what Wikipedia looks like in 1,000 years. What do you think is the meaning of this whole thing? Why are we here, human civilization? What’s the meaning of life?
Jimmy Wales

03:07:00
Yeah. I don’t think there is external answer to that question.
Lex Fridman

03:07:05
And I should mention that there’s a very good Wikipedia page on the different philosophies in the meaning of life.
Jimmy Wales

03:07:11
Oh, interesting. I have to read that and see what I think. Hopefully, it’s actually neutral and gives a wide range …
Lex Fridman

03:07:16
Oh, it’s a really good reference to a lot of different philosophies about meaning. The 20th century philosophy in general, from Nietzsche to the existentialist, to Simone de Beauvoir, all of them have an idea of meaning. They really struggle with it systematically, rigorously, and that’s what the page … And obviously, a shout-out to the Hitchhiker’s Guide and all that kind of stuff.
Jimmy Wales

03:07:37
Yeah. I think there’s no external answer to that. I think it’s internal. I think we decide what meaning we will have in our lives and what we’re going to do with ourselves. If we’re talking about 1,000 years, millions of years, Yuri Milner wrote a book. He’s a big internet investor guy. He wrote a book advocating quite strongly for humans exploring the universe, and getting off the planet. And he funds projects to using lasers to send little cameras, and interesting stuff. And he talks a lot in the book about meaning. His view is that the purpose of the human species is to broadly survive and get off the planet.

03:08:31
Well, I don’t agree with everything he has to say, because I think that’s not a meaning that can motivate most people in their own lives. It’s like, “Okay, great.” The distances of space are absolutely enormous, so I don’t know. Shall we build generation ships to start flying places? I can’t do that. Even if I’m Elon Musk and I could devote all my wealth to build, I’ll be dead on the ship on the way. So, is that really a meaning?

03:08:57
But I think it’s really interesting to think about. And reading his little book, it’s quite a short little book. Reading his book, it did make me think about, “Wow, this is big. This is not what you think about in your day-to-day life. Where is the human species going to be in 10 million years?” And it does make you sort of turn back to Earth and say, “Gee, let’s not destroy the planet. We’re stuck here for at least a while, and therefore we should really think about sustainability.” I mean, one million year sustainability.

03:09:37
And we don’t have all the answers. We have nothing close to the answers. I’m actually excited about AI in this regard, while also bracketing, yeah, I understand there’s also risks and people are terrified of AI. But I actually think it is quite interesting this moment in time that we may have in the next 50 years to really, really solve some really long-term human problems, for example, in health. The progress that’s being made in cancer treatment, because we are able to at scale model molecules, and genetics, and things like this, it gets huge. It’s really exciting. So, if we can hang on for a little while, and certain problems that seem completely intractable today, like climate change may end up being actually not that hard.
Lex Fridman

03:10:30
And we just might be able to alleviate the full diversity of human suffering.
Jimmy Wales

03:10:35
For sure. Yeah.
Lex Fridman

03:10:37
In so doing, help increase the chance that we can propagate the flame of human consciousness out towards the stars. And I think another important one, if we fail to do that. For me, it’s propagating, maintaining the full diversity, and richness, and complexity, and expansiveness of human knowledge. So, if we destroy ourselves, it would make me feel a little bit okay if the human knowledge persists.
Jimmy Wales

03:11:09
It just triggered me to say something really interesting, which is when we talked earlier about translating and using machines to translate, we mostly talked about small languages and translating into English, but I always like to tell this story of something inconsequential, really.

03:11:28
I was in Norway, in Bergen, Norway, where every year they’ve got this annual festival called [foreign language 03:11:33], which is young groups drumming, and they have a drumming competition. It’s the 17 sectors of the city, and they’ve been doing it for a couple hundred years or whatever. They wrote about it in the three languages of Norway. And then from there, it was translated into English, into German, et cetera, et cetera.

03:11:53
And so, what I love about that story is what it reminds me is this machine translation goes both ways. And when you talk about the richness and broadness of human culture, we’re already seeing some really great pieces of this. So, like Korean soap operas, really popular, not with me, but with people.

03:12:17
Imagine taking a very famous, very popular, very well known Korean drama. I literally mean now, we’re just about there technologically where we use a machine to redub it in English in an automated way, including digitally editing the faces so it doesn’t look dubbed. And so, suddenly you say, “Oh, wow, here’s a piece of …” It’s the Korean equivalent of maybe it’s Friends as a comedy, or maybe it’s Succession, just to be very contemporary. It’s something that really impacted a lot of people, and they really loved it, and we have literally no idea what it’s about. And suddenly, it’s like, “Wow.” Music, street music from wherever in the world can suddenly become accessible to us all in new ways. It’s so cool.
Lex Fridman

03:13:09
It’s really exciting to get access to the richness of culture in China, in the many different subcultures of Africa, South America.
Jimmy Wales

03:13:19
One of my unsuccessful arguments with the Chinese government is by blocking Wikipedia, you aren’t just stopping people in China from reading Chinese Wikipedia and other language versions of Wikipedia, you’re also preventing the Chinese people from telling their story. So, is there a small festival in a small town in China like [foreign language 03:13:41]? I don’t know. But by the way, the people who live in that village, that small town of 50,000, they can’t put that in Wikipedia and get it translated into other places. They can’t share their culture and their knowledge.

03:13:54
And I think for China, this should be a somewhat influential argument, because China does feel misunderstood in the world. And it’s like, “Okay, well, there’s one way. If you want to help people understand, put it in Wikipedia. That’s what people go to when they want to understand.”
Lex Fridman

03:14:08
And give the amazing, incredible people of China a voice.
Jimmy Wales

03:14:13
Exactly.
Lex Fridman

03:14:14
Jimmy, I thank you so much. I’m such a huge fan of everything you’ve done.
Jimmy Wales

03:14:18
Oh, thank you. That’s really great.
Lex Fridman

03:14:18
I keep saying Wikipedia. I’m deeply, deeply, deeply, deeply grateful for Wikipedia. I love it. It brings me joy. I donate all the time. You should donate too. It’s a huge honor to finally talk with you, and this is just amazing. Thank you so much for today.
Jimmy Wales

03:14:31
Thanks for having me.
Lex Fridman

03:14:33
Thanks for listening to this conversation with Jimmy Wales. To support this podcast, please check out our sponsors in the description. And now, let me leave you with some words from the world historian, Daniel Boorstin. The greatest enemy of knowledge is not ignorance, it is the illusion of knowledge. Thank you for listening, and hope to see you next time